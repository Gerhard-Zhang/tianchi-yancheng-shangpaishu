{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    3    1   68]\n",
      " [   2    4    1   36]\n",
      " [   3    5    1 5565]\n",
      " ..., \n",
      " [1030    2    1 4003]\n",
      " [1031    3    1 2513]\n",
      " [1032    4    1 1306]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   1,    3,   68],\n",
       "       [   2,    4,   36],\n",
       "       [   3,    5, 5565],\n",
       "       ..., \n",
       "       [1030,    2, 4003],\n",
       "       [1031,    3, 2513],\n",
       "       [1032,    4, 1306]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#简单处理数据-1   算总量\n",
    "\n",
    "train = np.loadtxt('train_20171215.txt',dtype='int')\n",
    "\n",
    "pro_train = []\n",
    "i_pro_train = 0\n",
    "pro_train.append(train[0])\n",
    "\n",
    "for i in range(1,train.shape[0]):\n",
    "    if train[i][0] == pro_train[i_pro_train][0]:\n",
    "        pro_train[i_pro_train][3] += train[i][3]\n",
    "    else:\n",
    "        i_pro_train += 1\n",
    "        pro_train.append(train[i])\n",
    "\n",
    "pro_train = np.array(pro_train)\n",
    "\n",
    "print(pro_train)\n",
    "\n",
    "# 去掉类别那一行\n",
    "pro_train = np.delete(pro_train,2,axis=1)\n",
    "\n",
    "pro_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载测试数据\n",
    "test = np.loadtxt('test_A_20171225.txt',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 写文件\n",
    "np.savetxt('data_date-weekday-sum.txt', pro_train, fmt='%d', delimiter = '\\t')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c868f58240>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFdCAYAAAC0B5/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKjw8PDw8PDycwBsVHh4eHh4eHk7w/wG3VLIIiuyifQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c86b3844a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图看看数据变动\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = pro_train[:,0]\n",
    "y = pro_train[:,2]\n",
    "\n",
    "x = x[0:150]\n",
    "y = y[0:150]\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_week_train:  170\n"
     ]
    }
   ],
   "source": [
    "# 我先看看有多少个星期\n",
    "num_week_train = 1\n",
    "for i in range( 0,pro_train.shape[0]-1 ):\n",
    "    if pro_train[i+1][1] < pro_train[i][1]:\n",
    "        num_week_train += 1\n",
    "print('num_week_train: ',num_week_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_week_train:  45\n"
     ]
    }
   ],
   "source": [
    "# 看看test数据中包含多少个星期\n",
    "num_week_test = 1\n",
    "for i in range( 0,test.shape[0]-1 ):\n",
    "    if test[i+1][1] < test[i][1]:\n",
    "        num_week_test += 1\n",
    "print('num_week_train: ',num_week_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''2018/01/09'''\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import  stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 68\n",
      "2 4 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1032, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#处理数据-2   分星期算总量 并存好文件'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = np.loadtxt('data_date-weekday-sum.txt',dtype='int')\n",
    "\n",
    "print(train[0][0],train[0][1],train[0][2])   # 1 3 68\n",
    "print(train[1][0],train[1][1],train[1][2])   # 2 4 36\n",
    "\n",
    "train.shape  # (1032, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_week(train)\n",
    "    Mon = Tues = Wed = Thur = Fri = Sat = Sun = 0\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        if train[i][1] == 1:\n",
    "            Mon = Mon + 1\n",
    "        if train[i][1] == 2:\n",
    "            Tues = Tues + 1\n",
    "        if train[i][1] == 3:\n",
    "            Wed = Wed + 1\n",
    "        if train[i][1] == 4:\n",
    "            Thur = Thur + 1\n",
    "        if train[i][1] == 5:\n",
    "            Fri = Fri + 1\n",
    "        if train[i][1] == 6:\n",
    "            Sat = Sat + 1\n",
    "        if train[i][1] == 7:\n",
    "            Sun = Sun + 1\n",
    "    print(Mon,Tues,Wed,Thur,Fri,Sat,Sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 163 165 166 164 160 54\n",
      "train:  None\n",
      "42 43 44 46 42 43 16\n",
      "test:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \",data_week(train))\n",
    "print(\"test: \",data_week(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_week_save(folder,train):\n",
    "    Mon = []\n",
    "    Tues = []\n",
    "    Wed = []\n",
    "    Thur = []\n",
    "    Fri = []\n",
    "    Sat = []\n",
    "    Sun = []\n",
    "    for i in range(train.shape[0]):\n",
    "        if train[i][1] == 1:\n",
    "            Mon.append(train[i][2])\n",
    "        if train[i][1] == 2:\n",
    "            Tues.append(train[i][2])\n",
    "        if train[i][1] == 3:\n",
    "            Wed.append(train[i][2])\n",
    "        if train[i][1] == 4:\n",
    "            Thur.append(train[i][2])\n",
    "        if train[i][1] == 5:\n",
    "            Fri.append(train[i][2])\n",
    "        if train[i][1] == 6:\n",
    "            Sat.append(train[i][2])\n",
    "        if train[i][1] == 7:\n",
    "            Sun.append(train[i][2])\n",
    "    # 写文件\n",
    "    np.savetxt(folder+'Sum-Mon.txt', Mon, fmt='%d', delimiter = '\\t')\n",
    "    np.savetxt(folder+'Sum-Tues.txt', Tues, fmt='%d', delimiter = '\\t')\n",
    "    np.savetxt(folder+'Sum-Wed.txt', Wed, fmt='%d', delimiter = '\\t')\n",
    "    np.savetxt(folder+'Sum-Thur.txt', Thur, fmt='%d', delimiter = '\\t')\n",
    "    np.savetxt(folder+'Sum-Fri.txt', Fri, fmt='%d', delimiter = '\\t')\n",
    "    np.savetxt(folder+'Sum-Sat.txt', Sat, fmt='%d', delimiter = '\\t')\n",
    "    np.savetxt(folder+'Sum-Sun.txt', Sun, fmt='%d', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_week_save('sum-week/train/',train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''#处理数据-3   根据星期算总量之后，先搞个平均数提交一下试试'''\n",
    "\n",
    "data = np.loadtxt('test_A_20171225.txt',dtype='int')\n",
    "test = data[:,1]\n",
    "ID = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mon = np.loadtxt('sum-week/train/Sum-Mon.txt',dtype='int')\n",
    "Tues = np.loadtxt('sum-week/train/Sum-Tues.txt',dtype='int')\n",
    "Wed = np.loadtxt('sum-week/train/Sum-Wed.txt',dtype='int')\n",
    "Thur = np.loadtxt('sum-week/train/Sum-Thur.txt',dtype='int')\n",
    "Fri = np.loadtxt('sum-week/train/Sum-Fri.txt',dtype='int')\n",
    "Sat = np.loadtxt('sum-week/train/Sum-Sat.txt',dtype='int')\n",
    "Sun = np.loadtxt('sum-week/train/Sum-Sun.txt',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(test.shape[0]):\n",
    "    if(test[i] == 1):\n",
    "        test[i] = round(np.average(Mon))\n",
    "    if(test[i] == 2):\n",
    "        test[i] = round(np.average(Tues))\n",
    "    if(test[i] == 3):\n",
    "        test[i] = round(np.average(Wed))\n",
    "    if(test[i] == 4):\n",
    "        test[i] = round(np.average(Thur))\n",
    "    if(test[i] == 5):\n",
    "        test[i] = round(np.average(Fri))\n",
    "    if(test[i] == 6):\n",
    "        test[i] = round(np.average(Sat))\n",
    "    if(test[i] == 7):\n",
    "        test[i] = round(np.average(Sun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412, 2364, 2496,\n",
       "       2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412, 2496,\n",
       "       2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412, 2364,\n",
       "       2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412,\n",
       "       2364, 2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626,  412,\n",
       "        743, 2364, 2496, 2095, 1626, 1889,  412,  743, 2364, 2496, 2095,\n",
       "       1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412, 2364, 2496,\n",
       "       2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412, 2364,\n",
       "       2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412,\n",
       "       2364, 2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,\n",
       "        412, 2364, 2496, 2095, 1626, 1889,  412,  743, 2364, 2496, 2095,\n",
       "       1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412,  743, 2364,\n",
       "       2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626,  412,  743,\n",
       "       2364, 2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,\n",
       "       2095, 1626, 1889,  412,  743, 2364, 2496, 2095, 1626, 1889,  412,\n",
       "        743, 2364, 2496, 2095, 1626, 1889,  412,  743, 2364, 2496, 2095,\n",
       "       1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412,  743, 2364,\n",
       "       2496, 2095, 1626, 1889,  412,  743, 2364, 2496, 2095, 1626, 1889,\n",
       "        412, 2364, 2496, 2095, 1626, 1889,  412,  743, 2364, 2496, 2095,\n",
       "       1626, 1889,  412,  743, 2364, 2496, 2095, 1626, 1889,  412, 2364,\n",
       "       2496, 2095, 1626, 1889,  412, 2364, 2496, 2095, 1626, 1889,  412,\n",
       "       2364, 2496, 2095, 1626, 1889,  412,  743, 2364, 2496, 2095, 1626,\n",
       "       1889,  412,  743, 2364, 2496, 2095, 1626, 1889,  412, 2364, 2496,\n",
       "       2095, 1626, 1889,  412,  743, 2364, 2496, 2095, 1626, 1626, 1889,\n",
       "        412,  743, 2364, 2496, 2095, 1626, 1889,  412, 2364, 2496, 2095,\n",
       "       1626])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = np.vstack( (ID,test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1032, 1626],\n",
       "       [1033, 1889],\n",
       "       [1034,  412],\n",
       "       [1035, 2364],\n",
       "       [1036, 2496],\n",
       "       [1037, 2095],\n",
       "       [1038, 1626],\n",
       "       [1039, 1889],\n",
       "       [1040,  412],\n",
       "       [1041, 2364],\n",
       "       [1042, 2496],\n",
       "       [1043, 2095],\n",
       "       [1044, 1626],\n",
       "       [1045, 1889],\n",
       "       [1046,  412],\n",
       "       [1047, 2364],\n",
       "       [1048, 2496],\n",
       "       [1049, 2095],\n",
       "       [1050, 1626],\n",
       "       [1051, 1889],\n",
       "       [1052,  412],\n",
       "       [1053, 2496],\n",
       "       [1054, 2095],\n",
       "       [1055, 1626],\n",
       "       [1056, 1889],\n",
       "       [1057,  412],\n",
       "       [1058, 2364],\n",
       "       [1059, 2496],\n",
       "       [1060, 2095],\n",
       "       [1061, 1626],\n",
       "       [1062, 1889],\n",
       "       [1063,  412],\n",
       "       [1064, 2364],\n",
       "       [1065, 2496],\n",
       "       [1066, 2095],\n",
       "       [1067, 1626],\n",
       "       [1068, 1889],\n",
       "       [1069,  412],\n",
       "       [1070, 2364],\n",
       "       [1071, 2496],\n",
       "       [1072, 2095],\n",
       "       [1073, 1626],\n",
       "       [1074, 1889],\n",
       "       [1075,  412],\n",
       "       [1076, 2364],\n",
       "       [1077, 2496],\n",
       "       [1078, 2095],\n",
       "       [1079, 1626],\n",
       "       [1080, 1889],\n",
       "       [1081,  412],\n",
       "       [1082, 2364],\n",
       "       [1083, 2496],\n",
       "       [1084, 2095],\n",
       "       [1085, 1626],\n",
       "       [1086,  412],\n",
       "       [1087,  743],\n",
       "       [1088, 2364],\n",
       "       [1089, 2496],\n",
       "       [1090, 2095],\n",
       "       [1091, 1626],\n",
       "       [1092, 1889],\n",
       "       [1093,  412],\n",
       "       [1094,  743],\n",
       "       [1095, 2364],\n",
       "       [1096, 2496],\n",
       "       [1097, 2095],\n",
       "       [1098, 1626],\n",
       "       [1099, 1889],\n",
       "       [1100,  412],\n",
       "       [1101, 2364],\n",
       "       [1102, 2496],\n",
       "       [1103, 2095],\n",
       "       [1104, 1626],\n",
       "       [1105, 1889],\n",
       "       [1106,  412],\n",
       "       [1107, 2364],\n",
       "       [1108, 2496],\n",
       "       [1109, 2095],\n",
       "       [1110, 1626],\n",
       "       [1111, 1889],\n",
       "       [1112,  412],\n",
       "       [1113, 2364],\n",
       "       [1114, 2496],\n",
       "       [1115, 2095],\n",
       "       [1116, 1626],\n",
       "       [1117, 1889],\n",
       "       [1118,  412],\n",
       "       [1119, 2364],\n",
       "       [1120, 2496],\n",
       "       [1121, 2095],\n",
       "       [1122, 1626],\n",
       "       [1123, 1889],\n",
       "       [1124,  412],\n",
       "       [1125, 2364],\n",
       "       [1126, 2496],\n",
       "       [1127, 2095],\n",
       "       [1128, 1626],\n",
       "       [1129, 1889],\n",
       "       [1130,  412],\n",
       "       [1131, 2364],\n",
       "       [1132, 2496],\n",
       "       [1133, 2095],\n",
       "       [1134, 1626],\n",
       "       [1135, 1889],\n",
       "       [1136,  412],\n",
       "       [1137, 2364],\n",
       "       [1138, 2496],\n",
       "       [1139, 2095],\n",
       "       [1140, 1626],\n",
       "       [1141, 1889],\n",
       "       [1142,  412],\n",
       "       [1143, 2364],\n",
       "       [1144, 2496],\n",
       "       [1145, 2095],\n",
       "       [1146, 1626],\n",
       "       [1147, 1889],\n",
       "       [1148,  412],\n",
       "       [1149,  743],\n",
       "       [1150, 2364],\n",
       "       [1151, 2496],\n",
       "       [1152, 2095],\n",
       "       [1153, 1626],\n",
       "       [1154, 1889],\n",
       "       [1155,  412],\n",
       "       [1156, 2364],\n",
       "       [1157, 2496],\n",
       "       [1158, 2095],\n",
       "       [1159, 1626],\n",
       "       [1160, 1889],\n",
       "       [1161,  412],\n",
       "       [1162,  743],\n",
       "       [1163, 2364],\n",
       "       [1164, 2496],\n",
       "       [1165, 2095],\n",
       "       [1166, 1626],\n",
       "       [1167, 1889],\n",
       "       [1168,  412],\n",
       "       [1169, 2364],\n",
       "       [1170, 2496],\n",
       "       [1171, 2095],\n",
       "       [1172, 1626],\n",
       "       [1173,  412],\n",
       "       [1174,  743],\n",
       "       [1175, 2364],\n",
       "       [1176, 2496],\n",
       "       [1177, 2095],\n",
       "       [1178, 1626],\n",
       "       [1179, 1889],\n",
       "       [1180,  412],\n",
       "       [1181, 2364],\n",
       "       [1182, 2496],\n",
       "       [1183, 2095],\n",
       "       [1184, 1626],\n",
       "       [1185, 1889],\n",
       "       [1186, 2095],\n",
       "       [1187, 1626],\n",
       "       [1188, 1889],\n",
       "       [1189,  412],\n",
       "       [1190,  743],\n",
       "       [1191, 2364],\n",
       "       [1192, 2496],\n",
       "       [1193, 2095],\n",
       "       [1194, 1626],\n",
       "       [1195, 1889],\n",
       "       [1196,  412],\n",
       "       [1197,  743],\n",
       "       [1198, 2364],\n",
       "       [1199, 2496],\n",
       "       [1200, 2095],\n",
       "       [1201, 1626],\n",
       "       [1202, 1889],\n",
       "       [1203,  412],\n",
       "       [1204,  743],\n",
       "       [1205, 2364],\n",
       "       [1206, 2496],\n",
       "       [1207, 2095],\n",
       "       [1208, 1626],\n",
       "       [1209, 1889],\n",
       "       [1210,  412],\n",
       "       [1211, 2364],\n",
       "       [1212, 2496],\n",
       "       [1213, 2095],\n",
       "       [1214, 1626],\n",
       "       [1215, 1889],\n",
       "       [1216,  412],\n",
       "       [1217,  743],\n",
       "       [1218, 2364],\n",
       "       [1219, 2496],\n",
       "       [1220, 2095],\n",
       "       [1221, 1626],\n",
       "       [1222, 1889],\n",
       "       [1223,  412],\n",
       "       [1224,  743],\n",
       "       [1225, 2364],\n",
       "       [1226, 2496],\n",
       "       [1227, 2095],\n",
       "       [1228, 1626],\n",
       "       [1229, 1889],\n",
       "       [1230,  412],\n",
       "       [1231, 2364],\n",
       "       [1232, 2496],\n",
       "       [1233, 2095],\n",
       "       [1234, 1626],\n",
       "       [1235, 1889],\n",
       "       [1236,  412],\n",
       "       [1237,  743],\n",
       "       [1238, 2364],\n",
       "       [1239, 2496],\n",
       "       [1240, 2095],\n",
       "       [1241, 1626],\n",
       "       [1242, 1889],\n",
       "       [1243,  412],\n",
       "       [1244,  743],\n",
       "       [1245, 2364],\n",
       "       [1246, 2496],\n",
       "       [1247, 2095],\n",
       "       [1248, 1626],\n",
       "       [1249, 1889],\n",
       "       [1250,  412],\n",
       "       [1251, 2364],\n",
       "       [1252, 2496],\n",
       "       [1253, 2095],\n",
       "       [1254, 1626],\n",
       "       [1255, 1889],\n",
       "       [1256,  412],\n",
       "       [1257, 2364],\n",
       "       [1258, 2496],\n",
       "       [1259, 2095],\n",
       "       [1260, 1626],\n",
       "       [1261, 1889],\n",
       "       [1262,  412],\n",
       "       [1263, 2364],\n",
       "       [1264, 2496],\n",
       "       [1265, 2095],\n",
       "       [1266, 1626],\n",
       "       [1267, 1889],\n",
       "       [1268,  412],\n",
       "       [1269,  743],\n",
       "       [1270, 2364],\n",
       "       [1271, 2496],\n",
       "       [1272, 2095],\n",
       "       [1273, 1626],\n",
       "       [1274, 1889],\n",
       "       [1275,  412],\n",
       "       [1276,  743],\n",
       "       [1277, 2364],\n",
       "       [1278, 2496],\n",
       "       [1279, 2095],\n",
       "       [1280, 1626],\n",
       "       [1281, 1889],\n",
       "       [1282,  412],\n",
       "       [1283, 2364],\n",
       "       [1284, 2496],\n",
       "       [1285, 2095],\n",
       "       [1286, 1626],\n",
       "       [1287, 1889],\n",
       "       [1288,  412],\n",
       "       [1289,  743],\n",
       "       [1290, 2364],\n",
       "       [1291, 2496],\n",
       "       [1292, 2095],\n",
       "       [1293, 1626],\n",
       "       [1294, 1626],\n",
       "       [1295, 1889],\n",
       "       [1296,  412],\n",
       "       [1297,  743],\n",
       "       [1298, 2364],\n",
       "       [1299, 2496],\n",
       "       [1300, 2095],\n",
       "       [1301, 1626],\n",
       "       [1302, 1889],\n",
       "       [1303,  412],\n",
       "       [1304, 2364],\n",
       "       [1305, 2496],\n",
       "       [1306, 2095],\n",
       "       [1307, 1626]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = ans.T\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 写入文件\n",
    "np.savetxt('submit/'+'week-average.txt',ans, fmt='%d', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''#处理数据-4   根据星期算总量之后，画图看看效果'''\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_results(data):\n",
    "    plt.plot(data)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBbLyaafrQ1RDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d57f2bcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx3FqlL8B0as6PrPH+ssAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d57f2beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d57ea9470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2KDrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d57ee1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d580782e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d580af518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20d58116470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(Mon)\n",
    "plot_results(Tues)\n",
    "plot_results(Wed)\n",
    "plot_results(Thur)\n",
    "plot_results(Fri)\n",
    "plot_results(Sat)\n",
    "plot_results(Sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''#处理数据-5   七个周天，七种预测值'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Mon = np.loadtxt('sum-week/train/Sum-Mon.txt',dtype='int')\n",
    "Tues = np.loadtxt('sum-week/train/Sum-Tues.txt',dtype='int')\n",
    "Wed = np.loadtxt('sum-week/train/Sum-Wed.txt',dtype='int')\n",
    "Thur = np.loadtxt('sum-week/train/Sum-Thur.txt',dtype='int')\n",
    "Fri = np.loadtxt('sum-week/train/Sum-Fri.txt',dtype='int')\n",
    "Sat = np.loadtxt('sum-week/train/Sum-Sat.txt',dtype='int')\n",
    "Sun = np.loadtxt('sum-week/train/Sum-Sun.txt',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''切数据'''\n",
    "def slicing_data(data,seq_len):    \n",
    "    \n",
    "    print('result len(data):',len(data))\n",
    "    print('result data.shape:',np.array(data).shape)\n",
    "    \n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])  #得到长度为seq_len+1的向量，最后一个作为label\n",
    "    \n",
    "    print('result len(slicing):',len(result))\n",
    "    print('result slicing_shape:',np.array(result).shape)\n",
    "    print(result[:1])\n",
    "    \n",
    "    result = np.array(result)\n",
    "    \n",
    "    #划分train、test\n",
    "    row = len(result)-1  #四舍五入\n",
    "    train = result[:row, :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[row:, :-1]\n",
    "    y_test = result[row:, -1]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "#    print('result x_train.shape',x_train.shape)\n",
    "#    print('result y_train.shape',y_train.shape)\n",
    "#    print('result x_test.shape',x_test.shape)\n",
    "#    print('result y_test.shape',y_test.shape)\n",
    " \n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''跑模型 LSTM'''\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers): #layers ： [1,50,100,1]\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(input_dim=layers[0],output_dim=layers[1],return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(layers[2],return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    return model\n",
    "\n",
    "#直接全部预测\n",
    "def predict_point_by_point(model, data):\n",
    "    predicted = model.predict(data)\n",
    "    print('predicted shape:',np.array(predicted).shape)  #(412L,1L)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "'''训练模型'''\n",
    "model = build_model([1, 50, 100, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('result len(data):', 163)\n",
      "('result data.shape:', (163,))\n",
      "('result len(slicing):', 138)\n",
      "('result slicing_shape:', (138, 25))\n",
      "[array([4146, 2386, 2700, 3016, 4059, 1740, 1844, 1900, 1812, 1889, 1794,\n",
      "       2424, 2143, 1631, 1584, 2587, 2284, 2342, 2055, 1885, 2178, 2336,\n",
      "       1781, 1615, 1759])]\n",
      "X_train shape: (137, 24, 1)\n",
      "y_train shape: (137,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 130 samples, validate on 7 samples\n",
      "Epoch 1/500\n",
      "130/130 [==============================] - 0s - loss: 6215301.7308 - val_loss: 13235573.7857\n",
      "Epoch 2/500\n",
      "130/130 [==============================] - 0s - loss: 6194921.4846 - val_loss: 13214567.7143\n",
      "Epoch 3/500\n",
      "130/130 [==============================] - 0s - loss: 6175216.8731 - val_loss: 13194650.8571\n",
      "Epoch 4/500\n",
      "130/130 [==============================] - 0s - loss: 6166863.6308 - val_loss: 13174093.9286\n",
      "Epoch 5/500\n",
      "130/130 [==============================] - 0s - loss: 6154323.7923 - val_loss: 13154057.1429\n",
      "Epoch 6/500\n",
      "130/130 [==============================] - 0s - loss: 6135911.6538 - val_loss: 13133851.1429\n",
      "Epoch 7/500\n",
      "130/130 [==============================] - 0s - loss: 6129459.2615 - val_loss: 13113348.6429\n",
      "Epoch 8/500\n",
      "130/130 [==============================] - 0s - loss: 6112090.1769 - val_loss: 13093414.8571\n",
      "Epoch 9/500\n",
      "130/130 [==============================] - 0s - loss: 6105271.0692 - val_loss: 13073042.0714\n",
      "Epoch 10/500\n",
      "130/130 [==============================] - 0s - loss: 6078803.3077 - val_loss: 13052713.6429\n",
      "Epoch 11/500\n",
      "130/130 [==============================] - 0s - loss: 6070108.5615 - val_loss: 13032824.6429\n",
      "Epoch 12/500\n",
      "130/130 [==============================] - 0s - loss: 6053133.3000 - val_loss: 13012562.8571\n",
      "Epoch 13/500\n",
      "130/130 [==============================] - 0s - loss: 6038373.7846 - val_loss: 12991941.9286\n",
      "Epoch 14/500\n",
      "130/130 [==============================] - 0s - loss: 6035413.9538 - val_loss: 12972210.5000\n",
      "Epoch 15/500\n",
      "130/130 [==============================] - 0s - loss: 6016268.1692 - val_loss: 12952303.7857\n",
      "Epoch 16/500\n",
      "130/130 [==============================] - 0s - loss: 5998866.0923 - val_loss: 12931646.0000\n",
      "Epoch 17/500\n",
      "130/130 [==============================] - 0s - loss: 5979171.4365 - val_loss: 12912148.8571\n",
      "Epoch 18/500\n",
      "130/130 [==============================] - 0s - loss: 5979728.3308 - val_loss: 12892242.9286\n",
      "Epoch 19/500\n",
      "130/130 [==============================] - 0s - loss: 5955438.8077 - val_loss: 12872573.0714\n",
      "Epoch 20/500\n",
      "130/130 [==============================] - 0s - loss: 5954657.8231 - val_loss: 12852555.2143\n",
      "Epoch 21/500\n",
      "130/130 [==============================] - 0s - loss: 5935172.8231 - val_loss: 12832487.1429\n",
      "Epoch 22/500\n",
      "130/130 [==============================] - 0s - loss: 5912866.9538 - val_loss: 12812388.0714\n",
      "Epoch 23/500\n",
      "130/130 [==============================] - 0s - loss: 5899416.6346 - val_loss: 12792504.2857\n",
      "Epoch 24/500\n",
      "130/130 [==============================] - 0s - loss: 5893898.4346 - val_loss: 12772885.7143\n",
      "Epoch 25/500\n",
      "130/130 [==============================] - 0s - loss: 5885112.7615 - val_loss: 12753096.7857\n",
      "Epoch 26/500\n",
      "130/130 [==============================] - 0s - loss: 5869110.0615 - val_loss: 12733006.5714\n",
      "Epoch 27/500\n",
      "130/130 [==============================] - 0s - loss: 5851511.3462 - val_loss: 12713220.2857\n",
      "Epoch 28/500\n",
      "130/130 [==============================] - 0s - loss: 5838010.0923 - val_loss: 12692943.5000\n",
      "Epoch 29/500\n",
      "130/130 [==============================] - 0s - loss: 5829144.8385 - val_loss: 12673966.3571\n",
      "Epoch 30/500\n",
      "130/130 [==============================] - 0s - loss: 5801592.2769 - val_loss: 12653610.7857\n",
      "Epoch 31/500\n",
      "130/130 [==============================] - 0s - loss: 5812856.4308 - val_loss: 12633978.7857\n",
      "Epoch 32/500\n",
      "130/130 [==============================] - 0s - loss: 5780012.9038 - val_loss: 12614228.5714\n",
      "Epoch 33/500\n",
      "130/130 [==============================] - 0s - loss: 5772970.8808 - val_loss: 12594503.9286\n",
      "Epoch 34/500\n",
      "130/130 [==============================] - 0s - loss: 5756835.4000 - val_loss: 12574969.7857\n",
      "Epoch 35/500\n",
      "130/130 [==============================] - 0s - loss: 5746678.4308 - val_loss: 12555384.5000\n",
      "Epoch 36/500\n",
      "130/130 [==============================] - 0s - loss: 5729647.5000 - val_loss: 12535620.5714\n",
      "Epoch 37/500\n",
      "130/130 [==============================] - 0s - loss: 5711658.8923 - val_loss: 12515763.6429\n",
      "Epoch 38/500\n",
      "130/130 [==============================] - 0s - loss: 5706300.3769 - val_loss: 12496075.5000\n",
      "Epoch 39/500\n",
      "130/130 [==============================] - 0s - loss: 5683021.7942 - val_loss: 12477006.0714\n",
      "Epoch 40/500\n",
      "130/130 [==============================] - 0s - loss: 5684472.4769 - val_loss: 12456822.3571\n",
      "Epoch 41/500\n",
      "130/130 [==============================] - 0s - loss: 5660725.6000 - val_loss: 12438002.3571\n",
      "Epoch 42/500\n",
      "130/130 [==============================] - 0s - loss: 5660257.6308 - val_loss: 12418445.5000\n",
      "Epoch 43/500\n",
      "130/130 [==============================] - 0s - loss: 5631394.0769 - val_loss: 12399057.6429\n",
      "Epoch 44/500\n",
      "130/130 [==============================] - 0s - loss: 5614472.6385 - val_loss: 12379574.3571\n",
      "Epoch 45/500\n",
      "130/130 [==============================] - 0s - loss: 5617461.9000 - val_loss: 12360155.3571\n",
      "Epoch 46/500\n",
      "130/130 [==============================] - 0s - loss: 5601945.0462 - val_loss: 12340190.7857\n",
      "Epoch 47/500\n",
      "130/130 [==============================] - 0s - loss: 5575226.1846 - val_loss: 12321084.5714\n",
      "Epoch 48/500\n",
      "130/130 [==============================] - 0s - loss: 5582424.9885 - val_loss: 12301637.2143\n",
      "Epoch 49/500\n",
      "130/130 [==============================] - 0s - loss: 5546743.5577 - val_loss: 12282332.2857\n",
      "Epoch 50/500\n",
      "130/130 [==============================] - 0s - loss: 5553395.3846 - val_loss: 12263044.2143\n",
      "Epoch 51/500\n",
      "130/130 [==============================] - 0s - loss: 5530750.0308 - val_loss: 12243794.0714\n",
      "Epoch 52/500\n",
      "130/130 [==============================] - 0s - loss: 5515027.0385 - val_loss: 12224561.2143\n",
      "Epoch 53/500\n",
      "130/130 [==============================] - 0s - loss: 5505776.6538 - val_loss: 12204799.3571\n",
      "Epoch 54/500\n",
      "130/130 [==============================] - 0s - loss: 5492955.3769 - val_loss: 12185575.42860\n",
      "Epoch 55/500\n",
      "130/130 [==============================] - 0s - loss: 5475368.1577 - val_loss: 12166358.0714\n",
      "Epoch 56/500\n",
      "130/130 [==============================] - 0s - loss: 5469896.9577 - val_loss: 12147142.8571\n",
      "Epoch 57/500\n",
      "130/130 [==============================] - 0s - loss: 5464101.7500 - val_loss: 12128582.0000\n",
      "Epoch 58/500\n",
      "130/130 [==============================] - 0s - loss: 5436340.4462 - val_loss: 12109265.6429\n",
      "Epoch 59/500\n",
      "130/130 [==============================] - 0s - loss: 5427038.0692 - val_loss: 12090315.6429\n",
      "Epoch 60/500\n",
      "130/130 [==============================] - 0s - loss: 5414794.0000 - val_loss: 12071091.1429\n",
      "Epoch 61/500\n",
      "130/130 [==============================] - 0s - loss: 5407939.3231 - val_loss: 12052443.6429\n",
      "Epoch 62/500\n",
      "130/130 [==============================] - 0s - loss: 5386690.8077 - val_loss: 12033234.5714\n",
      "Epoch 63/500\n",
      "130/130 [==============================] - 0s - loss: 5373555.8115 - val_loss: 12013901.6429\n",
      "Epoch 64/500\n",
      "130/130 [==============================] - 0s - loss: 5353623.9577 - val_loss: 11994837.2143\n",
      "Epoch 65/500\n",
      "130/130 [==============================] - 0s - loss: 5343869.1615 - val_loss: 11975934.2143\n",
      "Epoch 66/500\n",
      "130/130 [==============================] - 0s - loss: 5339237.6115 - val_loss: 11957099.4286\n",
      "Epoch 67/500\n",
      "130/130 [==============================] - 0s - loss: 5316458.9231 - val_loss: 11937824.2857\n",
      "Epoch 68/500\n",
      "130/130 [==============================] - 0s - loss: 5312374.6808 - val_loss: 11918814.3571\n",
      "Epoch 69/500\n",
      "130/130 [==============================] - 0s - loss: 5303909.5923 - val_loss: 11899442.9286\n",
      "Epoch 70/500\n",
      "130/130 [==============================] - 0s - loss: 5283868.3615 - val_loss: 11880952.3571\n",
      "Epoch 71/500\n",
      "130/130 [==============================] - 0s - loss: 5279744.2615 - val_loss: 11861819.4286\n",
      "Epoch 72/500\n",
      "130/130 [==============================] - 0s - loss: 5261670.8962 - val_loss: 11843159.4286\n",
      "Epoch 73/500\n",
      "130/130 [==============================] - 0s - loss: 5236379.4154 - val_loss: 11823992.0000\n",
      "Epoch 74/500\n",
      "130/130 [==============================] - 0s - loss: 5227578.2385 - val_loss: 11804571.3571\n",
      "Epoch 75/500\n",
      "130/130 [==============================] - 0s - loss: 5216254.2654 - val_loss: 11786372.0714\n",
      "Epoch 76/500\n",
      "130/130 [==============================] - 0s - loss: 5217545.5462 - val_loss: 11767539.2143\n",
      "Epoch 77/500\n",
      "130/130 [==============================] - 0s - loss: 5194563.9885 - val_loss: 11748811.2143\n",
      "Epoch 78/500\n",
      "130/130 [==============================] - 0s - loss: 5190434.6731 - val_loss: 11729519.1429\n",
      "Epoch 79/500\n",
      "130/130 [==============================] - 0s - loss: 5160501.0500 - val_loss: 11710494.5714\n",
      "Epoch 80/500\n",
      "130/130 [==============================] - 0s - loss: 5152767.8038 - val_loss: 11691769.6429\n",
      "Epoch 81/500\n",
      "130/130 [==============================] - 0s - loss: 5139643.6385 - val_loss: 11672967.3571\n",
      "Epoch 82/500\n",
      "130/130 [==============================] - 0s - loss: 5134946.5308 - val_loss: 11654466.0714\n",
      "Epoch 83/500\n",
      "130/130 [==============================] - 0s - loss: 5121971.2500 - val_loss: 11635075.5000\n",
      "Epoch 84/500\n",
      "130/130 [==============================] - 0s - loss: 5108538.0077 - val_loss: 11617259.2143\n",
      "Epoch 85/500\n",
      "130/130 [==============================] - 0s - loss: 5101937.8154 - val_loss: 11598441.8571\n",
      "Epoch 86/500\n",
      "130/130 [==============================] - 0s - loss: 5080476.3000 - val_loss: 11579823.0000\n",
      "Epoch 87/500\n",
      "130/130 [==============================] - 0s - loss: 5066616.6308 - val_loss: 11561080.7857\n",
      "Epoch 88/500\n",
      "130/130 [==============================] - 0s - loss: 5046255.4808 - val_loss: 11542597.7143\n",
      "Epoch 89/500\n",
      "130/130 [==============================] - 0s - loss: 5049110.3154 - val_loss: 11524119.3571\n",
      "Epoch 90/500\n",
      "130/130 [==============================] - 0s - loss: 5039565.3885 - val_loss: 11505083.2143\n",
      "Epoch 91/500\n",
      "130/130 [==============================] - 0s - loss: 5007808.7731 - val_loss: 11487146.6429\n",
      "Epoch 92/500\n",
      "130/130 [==============================] - 0s - loss: 5013998.0962 - val_loss: 11468751.7857\n",
      "Epoch 93/500\n",
      "130/130 [==============================] - 0s - loss: 5007881.9096 - val_loss: 11450778.9286\n",
      "Epoch 94/500\n",
      "130/130 [==============================] - 0s - loss: 4984424.3538 - val_loss: 11432237.2143\n",
      "Epoch 95/500\n",
      "130/130 [==============================] - 0s - loss: 4976685.0077 - val_loss: 11413936.6429\n",
      "Epoch 96/500\n",
      "130/130 [==============================] - 0s - loss: 4956363.0154 - val_loss: 11395449.0714\n",
      "Epoch 97/500\n",
      "130/130 [==============================] - 0s - loss: 4947867.5808 - val_loss: 11377046.6429\n",
      "Epoch 98/500\n",
      "130/130 [==============================] - 0s - loss: 4954124.8250 - val_loss: 11358546.5714\n",
      "Epoch 99/500\n",
      "130/130 [==============================] - 0s - loss: 4922705.1000 - val_loss: 11340017.2857\n",
      "Epoch 100/500\n",
      "130/130 [==============================] - 0s - loss: 4898243.7038 - val_loss: 11322277.0714\n",
      "Epoch 101/500\n",
      "130/130 [==============================] - 0s - loss: 4901510.9077 - val_loss: 11303637.5000\n",
      "Epoch 102/500\n",
      "130/130 [==============================] - 0s - loss: 4883521.8308 - val_loss: 11285501.5000\n",
      "Epoch 103/500\n",
      "130/130 [==============================] - 1s - loss: 4878047.3846 - val_loss: 11267283.1429\n",
      "Epoch 104/500\n",
      "130/130 [==============================] - 0s - loss: 4849888.3846 - val_loss: 11248794.9286\n",
      "Epoch 105/500\n",
      "130/130 [==============================] - 0s - loss: 4848839.5885 - val_loss: 11230815.3571\n",
      "Epoch 106/500\n",
      "130/130 [==============================] - 0s - loss: 4834727.5077 - val_loss: 11212543.5000\n",
      "Epoch 107/500\n",
      "130/130 [==============================] - 0s - loss: 4835402.8481 - val_loss: 11194584.9286\n",
      "Epoch 108/500\n",
      "130/130 [==============================] - 0s - loss: 4813272.5154 - val_loss: 11176277.9286\n",
      "Epoch 109/500\n",
      "130/130 [==============================] - 0s - loss: 4795779.1115 - val_loss: 11158102.5000\n",
      "Epoch 110/500\n",
      "130/130 [==============================] - 0s - loss: 4792661.1538 - val_loss: 11139754.3571\n",
      "Epoch 111/500\n",
      "130/130 [==============================] - 0s - loss: 4788304.6385 - val_loss: 11121459.5714\n",
      "Epoch 112/500\n",
      "130/130 [==============================] - 0s - loss: 4764315.1077 - val_loss: 11103334.3571\n",
      "Epoch 113/500\n",
      "130/130 [==============================] - 0s - loss: 4772506.7808 - val_loss: 11085597.5714\n",
      "Epoch 114/500\n",
      "130/130 [==============================] - 0s - loss: 4751825.7308 - val_loss: 11067515.9286\n",
      "Epoch 115/500\n",
      "130/130 [==============================] - 0s - loss: 4742948.8808 - val_loss: 11049106.2143\n",
      "Epoch 116/500\n",
      "130/130 [==============================] - 0s - loss: 4724345.3269 - val_loss: 11031105.7857\n",
      "Epoch 117/500\n",
      "130/130 [==============================] - 0s - loss: 4705773.0346 - val_loss: 11013416.9286\n",
      "Epoch 118/500\n",
      "130/130 [==============================] - 0s - loss: 4715251.1673 - val_loss: 10995636.2857\n",
      "Epoch 119/500\n",
      "130/130 [==============================] - 0s - loss: 4686467.3615 - val_loss: 10977440.3571\n",
      "Epoch 120/500\n",
      "130/130 [==============================] - 0s - loss: 4673249.7577 - val_loss: 10959464.7857\n",
      "Epoch 121/500\n",
      "130/130 [==============================] - 0s - loss: 4660795.9615 - val_loss: 10941402.2143\n",
      "Epoch 122/500\n",
      "130/130 [==============================] - 0s - loss: 4664275.4423 - val_loss: 10923329.7857\n",
      "Epoch 123/500\n",
      "130/130 [==============================] - 0s - loss: 4634359.8923 - val_loss: 10905739.0714\n",
      "Epoch 124/500\n",
      "130/130 [==============================] - 0s - loss: 4633853.4077 - val_loss: 10887602.7857\n",
      "Epoch 125/500\n",
      "130/130 [==============================] - 0s - loss: 4617298.6654 - val_loss: 10870039.2143\n",
      "Epoch 126/500\n",
      "130/130 [==============================] - 0s - loss: 4618180.8038 - val_loss: 10852708.5714\n",
      "Epoch 127/500\n",
      "130/130 [==============================] - 0s - loss: 4584181.8731 - val_loss: 10834521.0714\n",
      "Epoch 128/500\n",
      "130/130 [==============================] - 0s - loss: 4588938.5923 - val_loss: 10816613.7857\n",
      "Epoch 129/500\n",
      "130/130 [==============================] - 0s - loss: 4573155.6692 - val_loss: 10799031.4286\n",
      "Epoch 130/500\n",
      "130/130 [==============================] - 0s - loss: 4565563.6154 - val_loss: 10781703.7143\n",
      "Epoch 131/500\n",
      "130/130 [==============================] - 0s - loss: 4547616.2000 - val_loss: 10763816.6429\n",
      "Epoch 132/500\n",
      "130/130 [==============================] - 0s - loss: 4546074.6500 - val_loss: 10745931.6429\n",
      "Epoch 133/500\n",
      "130/130 [==============================] - 0s - loss: 4512436.3231 - val_loss: 10727998.9286\n",
      "Epoch 134/500\n",
      "130/130 [==============================] - 0s - loss: 4508769.3462 - val_loss: 10710453.6429\n",
      "Epoch 135/500\n",
      "130/130 [==============================] - 0s - loss: 4521778.1808 - val_loss: 10692769.7143\n",
      "Epoch 136/500\n",
      "130/130 [==============================] - 0s - loss: 4476508.2192 - val_loss: 10674968.7857\n",
      "Epoch 137/500\n",
      "130/130 [==============================] - 0s - loss: 4490226.8038 - val_loss: 10657432.3571\n",
      "Epoch 138/500\n",
      "130/130 [==============================] - 0s - loss: 4456216.8038 - val_loss: 10639880.5714\n",
      "Epoch 139/500\n",
      "130/130 [==============================] - 0s - loss: 4451475.9962 - val_loss: 10622585.2143\n",
      "Epoch 140/500\n",
      "130/130 [==============================] - 0s - loss: 4444217.7346 - val_loss: 10604951.4286\n",
      "Epoch 141/500\n",
      "130/130 [==============================] - 0s - loss: 4434868.4846 - val_loss: 10587654.0000\n",
      "Epoch 142/500\n",
      "130/130 [==============================] - 0s - loss: 4409928.6692 - val_loss: 10569957.9286\n",
      "Epoch 143/500\n",
      "130/130 [==============================] - 0s - loss: 4408534.8731 - val_loss: 10552514.1429\n",
      "Epoch 144/500\n",
      "130/130 [==============================] - 0s - loss: 4408523.6115 - val_loss: 10535243.0714\n",
      "Epoch 145/500\n",
      "130/130 [==============================] - 0s - loss: 4391302.3692 - val_loss: 10518135.4286\n",
      "Epoch 146/500\n",
      "130/130 [==============================] - 0s - loss: 4374922.7385 - val_loss: 10500421.6429\n",
      "Epoch 147/500\n",
      "130/130 [==============================] - 0s - loss: 4362590.6731 - val_loss: 10482411.5000\n",
      "Epoch 148/500\n",
      "130/130 [==============================] - 0s - loss: 4348460.0538 - val_loss: 10465486.9286\n",
      "Epoch 149/500\n",
      "130/130 [==============================] - 0s - loss: 4342096.2731 - val_loss: 10447878.5000\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 4322546.1615 - val_loss: 10430280.3571\n",
      "Epoch 151/500\n",
      "130/130 [==============================] - 0s - loss: 4305045.6885 - val_loss: 10413306.5714\n",
      "Epoch 152/500\n",
      "130/130 [==============================] - 0s - loss: 4303607.5000 - val_loss: 10395820.6429\n",
      "Epoch 153/500\n",
      "130/130 [==============================] - 0s - loss: 4303404.5577 - val_loss: 10378512.3571\n",
      "Epoch 154/500\n",
      "130/130 [==============================] - 0s - loss: 4281415.6769 - val_loss: 10361695.3571\n",
      "Epoch 155/500\n",
      "130/130 [==============================] - 0s - loss: 4298968.2115 - val_loss: 10344580.9286\n",
      "Epoch 156/500\n",
      "130/130 [==============================] - 0s - loss: 4276192.1962 - val_loss: 10327264.0714\n",
      "Epoch 157/500\n",
      "130/130 [==============================] - 0s - loss: 4266378.6385 - val_loss: 10309900.5000\n",
      "Epoch 158/500\n",
      "130/130 [==============================] - 0s - loss: 4228058.6500 - val_loss: 10292730.3571\n",
      "Epoch 159/500\n",
      "130/130 [==============================] - 0s - loss: 4214498.7231 - val_loss: 10276009.5000\n",
      "Epoch 160/500\n",
      "130/130 [==============================] - 0s - loss: 4227987.3115 - val_loss: 10258847.3571\n",
      "Epoch 161/500\n",
      "130/130 [==============================] - 0s - loss: 4209412.7923 - val_loss: 10241636.5000\n",
      "Epoch 162/500\n",
      "130/130 [==============================] - 1s - loss: 4190171.7385 - val_loss: 10224449.2143\n",
      "Epoch 163/500\n",
      "130/130 [==============================] - 0s - loss: 4183526.3231 - val_loss: 10207610.3571\n",
      "Epoch 164/500\n",
      "130/130 [==============================] - 0s - loss: 4173920.9423 - val_loss: 10190397.3571\n",
      "Epoch 165/500\n",
      "130/130 [==============================] - 0s - loss: 4163782.6192 - val_loss: 10173106.8571\n",
      "Epoch 166/500\n",
      "130/130 [==============================] - 0s - loss: 4147380.5731 - val_loss: 10155727.7857\n",
      "Epoch 167/500\n",
      "130/130 [==============================] - 0s - loss: 4128727.9923 - val_loss: 10138609.4286\n",
      "Epoch 168/500\n",
      "130/130 [==============================] - 0s - loss: 4129713.6500 - val_loss: 10122099.7143\n",
      "Epoch 169/500\n",
      "130/130 [==============================] - 0s - loss: 4126045.0942 - val_loss: 10105314.0714\n",
      "Epoch 170/500\n",
      "130/130 [==============================] - 0s - loss: 4127749.5077 - val_loss: 10088291.5000\n",
      "Epoch 171/500\n",
      "130/130 [==============================] - 0s - loss: 4086023.6038 - val_loss: 10071546.7857\n",
      "Epoch 172/500\n",
      "130/130 [==============================] - 0s - loss: 4117231.6962 - val_loss: 10055264.8571\n",
      "Epoch 173/500\n",
      "130/130 [==============================] - 0s - loss: 4078747.2115 - val_loss: 10038710.7857\n",
      "Epoch 174/500\n",
      "130/130 [==============================] - 0s - loss: 4077648.0000 - val_loss: 10021790.2143\n",
      "Epoch 175/500\n",
      "130/130 [==============================] - 0s - loss: 4059279.0087 - val_loss: 10004823.2143\n",
      "Epoch 176/500\n",
      "130/130 [==============================] - 0s - loss: 4041337.8077 - val_loss: 9987710.0714\n",
      "Epoch 177/500\n",
      "130/130 [==============================] - 0s - loss: 4033386.4115 - val_loss: 9971011.1071\n",
      "Epoch 178/500\n",
      "130/130 [==============================] - 0s - loss: 4000175.2846 - val_loss: 9954343.0000\n",
      "Epoch 179/500\n",
      "130/130 [==============================] - 0s - loss: 4037302.7692 - val_loss: 9938017.4286\n",
      "Epoch 180/500\n",
      "130/130 [==============================] - 0s - loss: 3983575.8096 - val_loss: 9921361.8214\n",
      "Epoch 181/500\n",
      "130/130 [==============================] - 0s - loss: 4003378.7577 - val_loss: 9904514.5714\n",
      "Epoch 182/500\n",
      "130/130 [==============================] - 0s - loss: 3979907.3308 - val_loss: 9887969.3214\n",
      "Epoch 183/500\n",
      "130/130 [==============================] - 0s - loss: 3968929.2596 - val_loss: 9871868.6071\n",
      "Epoch 184/500\n",
      "130/130 [==============================] - 0s - loss: 3955827.8538 - val_loss: 9854781.1786\n",
      "Epoch 185/500\n",
      "130/130 [==============================] - 0s - loss: 3947007.1808 - val_loss: 9838047.4643\n",
      "Epoch 186/500\n",
      "130/130 [==============================] - 0s - loss: 3971501.6731 - val_loss: 9821589.3214\n",
      "Epoch 187/500\n",
      "130/130 [==============================] - 0s - loss: 3959493.2712 - val_loss: 9805662.0000\n",
      "Epoch 188/500\n",
      "130/130 [==============================] - 0s - loss: 3913630.4077 - val_loss: 9789168.2857\n",
      "Epoch 189/500\n",
      "130/130 [==============================] - 0s - loss: 3896053.1712 - val_loss: 9772570.1786\n",
      "Epoch 190/500\n",
      "130/130 [==============================] - 0s - loss: 3884106.7731 - val_loss: 9756417.1071\n",
      "Epoch 191/500\n",
      "130/130 [==============================] - 0s - loss: 3891125.2231 - val_loss: 9739407.6786\n",
      "Epoch 192/500\n",
      "130/130 [==============================] - 0s - loss: 3877482.9135 - val_loss: 9723468.4643\n",
      "Epoch 193/500\n",
      "130/130 [==============================] - 0s - loss: 3883167.1885 - val_loss: 9706754.6071\n",
      "Epoch 194/500\n",
      "130/130 [==============================] - 0s - loss: 3873151.1808 - val_loss: 9690410.0357\n",
      "Epoch 195/500\n",
      "130/130 [==============================] - 0s - loss: 3831064.8769 - val_loss: 9673982.2857\n",
      "Epoch 196/500\n",
      "130/130 [==============================] - 0s - loss: 3845053.4692 - val_loss: 9657661.1429\n",
      "Epoch 197/500\n",
      "130/130 [==============================] - 0s - loss: 3827005.1731 - val_loss: 9641420.8214\n",
      "Epoch 198/500\n",
      "130/130 [==============================] - 0s - loss: 3787553.2519 - val_loss: 9625243.2857\n",
      "Epoch 199/500\n",
      "130/130 [==============================] - 0s - loss: 3812261.5846 - val_loss: 9608834.0000\n",
      "Epoch 200/500\n",
      "130/130 [==============================] - 0s - loss: 3793519.1712 - val_loss: 9592762.0357\n",
      "Epoch 201/500\n",
      "130/130 [==============================] - 0s - loss: 3799528.9077 - val_loss: 9576195.1071\n",
      "Epoch 202/500\n",
      "130/130 [==============================] - 0s - loss: 3787582.9404 - val_loss: 9559914.5357\n",
      "Epoch 203/500\n",
      "130/130 [==============================] - 0s - loss: 3771087.0846 - val_loss: 9544590.3214\n",
      "Epoch 204/500\n",
      "130/130 [==============================] - 0s - loss: 3743940.7288 - val_loss: 9527337.6786\n",
      "Epoch 205/500\n",
      "130/130 [==============================] - 0s - loss: 3735815.6423 - val_loss: 9511877.5714\n",
      "Epoch 206/500\n",
      "130/130 [==============================] - 0s - loss: 3741184.0779 - val_loss: 9495582.3929\n",
      "Epoch 207/500\n",
      "130/130 [==============================] - 0s - loss: 3730990.9173 - val_loss: 9479453.4286\n",
      "Epoch 208/500\n",
      "130/130 [==============================] - 0s - loss: 3700292.1673 - val_loss: 9463441.8929\n",
      "Epoch 209/500\n",
      "130/130 [==============================] - 0s - loss: 3700219.0962 - val_loss: 9446659.8214\n",
      "Epoch 210/500\n",
      "130/130 [==============================] - 0s - loss: 3711470.9654 - val_loss: 9431440.6071\n",
      "Epoch 211/500\n",
      "130/130 [==============================] - 0s - loss: 3678779.6615 - val_loss: 9415268.2500\n",
      "Epoch 212/500\n",
      "130/130 [==============================] - 0s - loss: 3687005.5885 - val_loss: 9399657.9643\n",
      "Epoch 213/500\n",
      "130/130 [==============================] - 0s - loss: 3678344.6231 - val_loss: 9383323.1071\n",
      "Epoch 214/500\n",
      "130/130 [==============================] - 0s - loss: 3655279.2769 - val_loss: 9367666.0357\n",
      "Epoch 215/500\n",
      "130/130 [==============================] - 0s - loss: 3644159.8827 - val_loss: 9352034.0000\n",
      "Epoch 216/500\n",
      "130/130 [==============================] - 0s - loss: 3647135.7673 - val_loss: 9335932.8214\n",
      "Epoch 217/500\n",
      "130/130 [==============================] - 0s - loss: 3632436.8288 - val_loss: 9320219.5357\n",
      "Epoch 218/500\n",
      "130/130 [==============================] - 0s - loss: 3616912.9096 - val_loss: 9303253.7143\n",
      "Epoch 219/500\n",
      "130/130 [==============================] - 0s - loss: 3603653.2692 - val_loss: 9288220.3214\n",
      "Epoch 220/500\n",
      "130/130 [==============================] - 0s - loss: 3593169.6058 - val_loss: 9272601.1429\n",
      "Epoch 221/500\n",
      "130/130 [==============================] - 0s - loss: 3584843.0981 - val_loss: 9256441.1786\n",
      "Epoch 222/500\n",
      "130/130 [==============================] - 0s - loss: 3597820.8712 - val_loss: 9240114.2500\n",
      "Epoch 223/500\n",
      "130/130 [==============================] - 0s - loss: 3563969.3115 - val_loss: 9224403.4286\n",
      "Epoch 224/500\n",
      "130/130 [==============================] - 0s - loss: 3566088.4500 - val_loss: 9209303.1429\n",
      "Epoch 225/500\n",
      "130/130 [==============================] - 0s - loss: 3560370.4115 - val_loss: 9193372.5714\n",
      "Epoch 226/500\n",
      "130/130 [==============================] - 0s - loss: 3530039.2269 - val_loss: 9178372.0357\n",
      "Epoch 227/500\n",
      "130/130 [==============================] - 0s - loss: 3534945.3308 - val_loss: 9162932.8929\n",
      "Epoch 228/500\n",
      "130/130 [==============================] - 0s - loss: 3539704.4846 - val_loss: 9147076.7143\n",
      "Epoch 229/500\n",
      "130/130 [==============================] - 0s - loss: 3504376.8346 - val_loss: 9131172.5357\n",
      "Epoch 230/500\n",
      "130/130 [==============================] - 0s - loss: 3513977.3692 - val_loss: 9116148.8214\n",
      "Epoch 231/500\n",
      "130/130 [==============================] - 0s - loss: 3522288.3904 - val_loss: 9100392.2500\n",
      "Epoch 232/500\n",
      "130/130 [==============================] - 0s - loss: 3481459.9154 - val_loss: 9084731.1786\n",
      "Epoch 233/500\n",
      "130/130 [==============================] - 0s - loss: 3475979.9346 - val_loss: 9068518.5357\n",
      "Epoch 234/500\n",
      "130/130 [==============================] - 0s - loss: 3460625.4962 - val_loss: 9052953.7500\n",
      "Epoch 235/500\n",
      "130/130 [==============================] - 0s - loss: 3480851.0240 - val_loss: 9037738.3929\n",
      "Epoch 236/500\n",
      "130/130 [==============================] - 0s - loss: 3432967.1856 - val_loss: 9022274.0357\n",
      "Epoch 237/500\n",
      "130/130 [==============================] - 0s - loss: 3452197.5423 - val_loss: 9007202.6786\n",
      "Epoch 238/500\n",
      "130/130 [==============================] - 0s - loss: 3446094.6269 - val_loss: 8991123.1429\n",
      "Epoch 239/500\n",
      "130/130 [==============================] - 0s - loss: 3427776.6904 - val_loss: 8975750.3214\n",
      "Epoch 240/500\n",
      "130/130 [==============================] - 0s - loss: 3413446.5423 - val_loss: 8960327.3929\n",
      "Epoch 241/500\n",
      "130/130 [==============================] - 0s - loss: 3393937.4423 - val_loss: 8944903.1786\n",
      "Epoch 242/500\n",
      "130/130 [==============================] - 0s - loss: 3416140.3981 - val_loss: 8929552.0000\n",
      "Epoch 243/500\n",
      "130/130 [==============================] - 0s - loss: 3396789.9673 - val_loss: 8914346.1071\n",
      "Epoch 244/500\n",
      "130/130 [==============================] - 0s - loss: 3367910.1885 - val_loss: 8899078.3214\n",
      "Epoch 245/500\n",
      "130/130 [==============================] - 0s - loss: 3356614.0971 - val_loss: 8883838.6071\n",
      "Epoch 246/500\n",
      "130/130 [==============================] - 0s - loss: 3368476.6173 - val_loss: 8868467.4286\n",
      "Epoch 247/500\n",
      "130/130 [==============================] - 0s - loss: 3364921.4231 - val_loss: 8852753.0000\n",
      "Epoch 248/500\n",
      "130/130 [==============================] - 0s - loss: 3330114.3231 - val_loss: 8837912.8929\n",
      "Epoch 249/500\n",
      "130/130 [==============================] - 0s - loss: 3325496.5308 - val_loss: 8822799.7500944\n",
      "Epoch 250/500\n",
      "130/130 [==============================] - 0s - loss: 3328464.0808 - val_loss: 8807263.7143\n",
      "Epoch 251/500\n",
      "130/130 [==============================] - 0s - loss: 3325252.6788 - val_loss: 8792660.8214\n",
      "Epoch 252/500\n",
      "130/130 [==============================] - 0s - loss: 3284118.0115 - val_loss: 8777586.8214\n",
      "Epoch 253/500\n",
      "130/130 [==============================] - 0s - loss: 3282519.7712 - val_loss: 8762624.2500\n",
      "Epoch 254/500\n",
      "130/130 [==============================] - 0s - loss: 3277925.7500 - val_loss: 8746791.8571\n",
      "Epoch 255/500\n",
      "130/130 [==============================] - 0s - loss: 3247643.4692 - val_loss: 8732535.1071\n",
      "Epoch 256/500\n",
      "130/130 [==============================] - 0s - loss: 3262475.9558 - val_loss: 8717023.6786\n",
      "Epoch 257/500\n",
      "130/130 [==============================] - 0s - loss: 3244608.3692 - val_loss: 8701720.8571\n",
      "Epoch 258/500\n",
      "130/130 [==============================] - 0s - loss: 3246519.1712 - val_loss: 8686834.3214\n",
      "Epoch 259/500\n",
      "130/130 [==============================] - 0s - loss: 3244882.4462 - val_loss: 8672213.3214\n",
      "Epoch 260/500\n",
      "130/130 [==============================] - 0s - loss: 3240840.0788 - val_loss: 8657140.7143\n",
      "Epoch 261/500\n",
      "130/130 [==============================] - 0s - loss: 3237597.7981 - val_loss: 8642113.1786\n",
      "Epoch 262/500\n",
      "130/130 [==============================] - 0s - loss: 3217116.9327 - val_loss: 8627514.2857\n",
      "Epoch 263/500\n",
      "130/130 [==============================] - 0s - loss: 3212587.7269 - val_loss: 8612208.8571\n",
      "Epoch 264/500\n",
      "130/130 [==============================] - 0s - loss: 3201878.0115 - val_loss: 8597364.8929\n",
      "Epoch 265/500\n",
      "130/130 [==============================] - 0s - loss: 3215059.4923 - val_loss: 8582869.0000\n",
      "Epoch 266/500\n",
      "130/130 [==============================] - 0s - loss: 3183664.1731 - val_loss: 8567827.7143\n",
      "Epoch 267/500\n",
      "130/130 [==============================] - 0s - loss: 3185834.2481 - val_loss: 8553118.5714\n",
      "Epoch 268/500\n",
      "130/130 [==============================] - 0s - loss: 3151866.1462 - val_loss: 8538114.8571\n",
      "Epoch 269/500\n",
      "130/130 [==============================] - 0s - loss: 3124499.8154 - val_loss: 8523503.7143\n",
      "Epoch 270/500\n",
      "130/130 [==============================] - 0s - loss: 3116800.8212 - val_loss: 8508973.3214\n",
      "Epoch 271/500\n",
      "130/130 [==============================] - 0s - loss: 3126480.1144 - val_loss: 8494090.7500\n",
      "Epoch 272/500\n",
      "130/130 [==============================] - 0s - loss: 3122926.4212 - val_loss: 8478546.5357\n",
      "Epoch 273/500\n",
      "130/130 [==============================] - 0s - loss: 3116463.3923 - val_loss: 8464774.6071\n",
      "Epoch 274/500\n",
      "130/130 [==============================] - 0s - loss: 3119426.0769 - val_loss: 8449704.8571\n",
      "Epoch 275/500\n",
      "130/130 [==============================] - 0s - loss: 3097186.7192 - val_loss: 8434567.8929\n",
      "Epoch 276/500\n",
      "130/130 [==============================] - 0s - loss: 3077290.7192 - val_loss: 8419917.6786\n",
      "Epoch 277/500\n",
      "130/130 [==============================] - 0s - loss: 3076761.7481 - val_loss: 8405347.6786\n",
      "Epoch 278/500\n",
      "130/130 [==============================] - 0s - loss: 3067242.2231 - val_loss: 8390443.7143\n",
      "Epoch 279/500\n",
      "130/130 [==============================] - 0s - loss: 3073239.9471 - val_loss: 8375823.4286\n",
      "Epoch 280/500\n",
      "130/130 [==============================] - 0s - loss: 3032374.3269 - val_loss: 8361764.5357\n",
      "Epoch 281/500\n",
      "130/130 [==============================] - 0s - loss: 3034941.4154 - val_loss: 8346746.3214\n",
      "Epoch 282/500\n",
      "130/130 [==============================] - 0s - loss: 3022627.1981 - val_loss: 8332289.5357\n",
      "Epoch 283/500\n",
      "130/130 [==============================] - 0s - loss: 3022102.4635 - val_loss: 8318456.8571\n",
      "Epoch 284/500\n",
      "130/130 [==============================] - 0s - loss: 3021767.9346 - val_loss: 8303632.6786\n",
      "Epoch 285/500\n",
      "130/130 [==============================] - 0s - loss: 3016604.2250 - val_loss: 8289022.3214\n",
      "Epoch 286/500\n",
      "130/130 [==============================] - 0s - loss: 3003617.7038 - val_loss: 8276454.2500\n",
      "Epoch 287/500\n",
      "130/130 [==============================] - 0s - loss: 2981316.3481 - val_loss: 8261987.7143\n",
      "Epoch 288/500\n",
      "130/130 [==============================] - 0s - loss: 2984514.2288 - val_loss: 8246882.0000\n",
      "Epoch 289/500\n",
      "130/130 [==============================] - 0s - loss: 2950457.5288 - val_loss: 8233021.8571\n",
      "Epoch 290/500\n",
      "130/130 [==============================] - 0s - loss: 2988665.7481 - val_loss: 8218113.1071\n",
      "Epoch 291/500\n",
      "130/130 [==============================] - 0s - loss: 2933198.1654 - val_loss: 8203217.8571\n",
      "Epoch 292/500\n",
      "130/130 [==============================] - 0s - loss: 2948034.1308 - val_loss: 8189492.4643\n",
      "Epoch 293/500\n",
      "130/130 [==============================] - 0s - loss: 2951953.0404 - val_loss: 8174961.4643\n",
      "Epoch 294/500\n",
      "130/130 [==============================] - 0s - loss: 2925177.7875 - val_loss: 8161007.8929\n",
      "Epoch 295/500\n",
      "130/130 [==============================] - 0s - loss: 2928495.3212 - val_loss: 8146289.6786\n",
      "Epoch 296/500\n",
      "130/130 [==============================] - 0s - loss: 2943636.3385 - val_loss: 8132526.1429\n",
      "Epoch 297/500\n",
      "130/130 [==============================] - 0s - loss: 2895682.1250 - val_loss: 8118709.5357\n",
      "Epoch 298/500\n",
      "130/130 [==============================] - 0s - loss: 2896681.6115 - val_loss: 8103853.7500\n",
      "Epoch 299/500\n",
      "130/130 [==============================] - 0s - loss: 2870339.2596 - val_loss: 8089658.0000\n",
      "Epoch 300/500\n",
      "130/130 [==============================] - 0s - loss: 2898561.1308 - val_loss: 8076099.7143\n",
      "Epoch 301/500\n",
      "130/130 [==============================] - 0s - loss: 2863332.7875 - val_loss: 8061654.1071\n",
      "Epoch 302/500\n",
      "130/130 [==============================] - 0s - loss: 2866103.0038 - val_loss: 8048054.8214\n",
      "Epoch 303/500\n",
      "130/130 [==============================] - 0s - loss: 2865701.4077 - val_loss: 8033993.1071\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 2865558.7808 - val_loss: 8020215.2500\n",
      "Epoch 305/500\n",
      "130/130 [==============================] - 0s - loss: 2848763.9279 - val_loss: 8006590.2857\n",
      "Epoch 306/500\n",
      "130/130 [==============================] - 0s - loss: 2846962.5731 - val_loss: 7991836.1071\n",
      "Epoch 307/500\n",
      "130/130 [==============================] - 0s - loss: 2821465.1462 - val_loss: 7978595.6429\n",
      "Epoch 308/500\n",
      "130/130 [==============================] - 0s - loss: 2831656.0731 - val_loss: 7964654.0357\n",
      "Epoch 309/500\n",
      "130/130 [==============================] - 0s - loss: 2814056.5500 - val_loss: 7950016.6429\n",
      "Epoch 310/500\n",
      "130/130 [==============================] - 0s - loss: 2802518.3317 - val_loss: 7937238.1429\n",
      "Epoch 311/500\n",
      "130/130 [==============================] - 0s - loss: 2809554.6250 - val_loss: 7923352.1429\n",
      "Epoch 312/500\n",
      "130/130 [==============================] - 0s - loss: 2780542.7096 - val_loss: 7909065.2143\n",
      "Epoch 313/500\n",
      "130/130 [==============================] - 0s - loss: 2809229.1269 - val_loss: 7895110.0357\n",
      "Epoch 314/500\n",
      "130/130 [==============================] - 0s - loss: 2754758.8894 - val_loss: 7881492.5357\n",
      "Epoch 315/500\n",
      "130/130 [==============================] - 0s - loss: 2776345.7538 - val_loss: 7867869.3214\n",
      "Epoch 316/500\n",
      "130/130 [==============================] - 0s - loss: 2754944.4346 - val_loss: 7854509.5357\n",
      "Epoch 317/500\n",
      "130/130 [==============================] - 0s - loss: 2718838.3827 - val_loss: 7840477.1429\n",
      "Epoch 318/500\n",
      "130/130 [==============================] - 0s - loss: 2730296.1000 - val_loss: 7826369.8929\n",
      "Epoch 319/500\n",
      "130/130 [==============================] - 0s - loss: 2707922.0173 - val_loss: 7812608.000044939\n",
      "Epoch 320/500\n",
      "130/130 [==============================] - 0s - loss: 2719117.5548 - val_loss: 7799311.3214\n",
      "Epoch 321/500\n",
      "130/130 [==============================] - 0s - loss: 2724296.8971 - val_loss: 7785905.8214\n",
      "Epoch 322/500\n",
      "130/130 [==============================] - 0s - loss: 2742176.6115 - val_loss: 7771894.2500\n",
      "Epoch 323/500\n",
      "130/130 [==============================] - 0s - loss: 2723197.6923 - val_loss: 7758936.8929\n",
      "Epoch 324/500\n",
      "130/130 [==============================] - 0s - loss: 2720264.2788 - val_loss: 7745233.8571\n",
      "Epoch 325/500\n",
      "130/130 [==============================] - 0s - loss: 2693282.7962 - val_loss: 7731759.6786\n",
      "Epoch 326/500\n",
      "130/130 [==============================] - 0s - loss: 2666639.9519 - val_loss: 7718220.6071\n",
      "Epoch 327/500\n",
      "130/130 [==============================] - 0s - loss: 2652806.8216 - val_loss: 7705076.3929\n",
      "Epoch 328/500\n",
      "130/130 [==============================] - 0s - loss: 2646075.5712 - val_loss: 7691070.0357\n",
      "Epoch 329/500\n",
      "130/130 [==============================] - 0s - loss: 2652800.9615 - val_loss: 7677337.6071\n",
      "Epoch 330/500\n",
      "130/130 [==============================] - 0s - loss: 2666544.5760 - val_loss: 7664223.7500\n",
      "Epoch 331/500\n",
      "130/130 [==============================] - 0s - loss: 2668444.2077 - val_loss: 7650724.2857\n",
      "Epoch 332/500\n",
      "130/130 [==============================] - 0s - loss: 2645791.0115 - val_loss: 7636696.9643\n",
      "Epoch 333/500\n",
      "130/130 [==============================] - 0s - loss: 2634462.3231 - val_loss: 7623635.4643\n",
      "Epoch 334/500\n",
      "130/130 [==============================] - 0s - loss: 2598588.5212 - val_loss: 7609864.4286\n",
      "Epoch 335/500\n",
      "130/130 [==============================] - 0s - loss: 2598800.1615 - val_loss: 7596415.1071\n",
      "Epoch 336/500\n",
      "130/130 [==============================] - 0s - loss: 2594179.3442 - val_loss: 7582666.1786\n",
      "Epoch 337/500\n",
      "130/130 [==============================] - 0s - loss: 2614927.4058 - val_loss: 7570127.3929\n",
      "Epoch 338/500\n",
      "130/130 [==============================] - 0s - loss: 2589629.2904 - val_loss: 7556538.7500\n",
      "Epoch 339/500\n",
      "130/130 [==============================] - 0s - loss: 2565611.9923 - val_loss: 7543926.4286\n",
      "Epoch 340/500\n",
      "130/130 [==============================] - 0s - loss: 2552682.0077 - val_loss: 7530136.0357\n",
      "Epoch 341/500\n",
      "130/130 [==============================] - 0s - loss: 2599799.2471 - val_loss: 7517198.2500\n",
      "Epoch 342/500\n",
      "130/130 [==============================] - 0s - loss: 2561461.8038 - val_loss: 7503557.6786\n",
      "Epoch 343/500\n",
      "130/130 [==============================] - 0s - loss: 2560954.2519 - val_loss: 7490489.4643\n",
      "Epoch 344/500\n",
      "130/130 [==============================] - 0s - loss: 2549155.9529 - val_loss: 7477283.5714\n",
      "Epoch 345/500\n",
      "130/130 [==============================] - 0s - loss: 2542780.4082 - val_loss: 7463405.1429\n",
      "Epoch 346/500\n",
      "130/130 [==============================] - 0s - loss: 2521847.1745 - val_loss: 7450531.1786\n",
      "Epoch 347/500\n",
      "130/130 [==============================] - 0s - loss: 2510909.7644 - val_loss: 7437132.4286\n",
      "Epoch 348/500\n",
      "130/130 [==============================] - 0s - loss: 2513844.8769 - val_loss: 7423928.4643\n",
      "Epoch 349/500\n",
      "130/130 [==============================] - 0s - loss: 2528119.4452 - val_loss: 7410781.5357\n",
      "Epoch 350/500\n",
      "130/130 [==============================] - 0s - loss: 2540381.0808 - val_loss: 7397822.4643\n",
      "Epoch 351/500\n",
      "130/130 [==============================] - 0s - loss: 2478945.4865 - val_loss: 7384337.7857\n",
      "Epoch 352/500\n",
      "130/130 [==============================] - 0s - loss: 2471874.9183 - val_loss: 7371133.7143\n",
      "Epoch 353/500\n",
      "130/130 [==============================] - 0s - loss: 2471441.6438 - val_loss: 7358301.7143\n",
      "Epoch 354/500\n",
      "130/130 [==============================] - 0s - loss: 2486838.2308 - val_loss: 7345760.8929\n",
      "Epoch 355/500\n",
      "130/130 [==============================] - 0s - loss: 2500105.9702 - val_loss: 7332061.7143\n",
      "Epoch 356/500\n",
      "130/130 [==============================] - 0s - loss: 2462379.3288 - val_loss: 7319302.3929\n",
      "Epoch 357/500\n",
      "130/130 [==============================] - 0s - loss: 2446638.7990 - val_loss: 7306524.1429\n",
      "Epoch 358/500\n",
      "130/130 [==============================] - 0s - loss: 2437352.7332 - val_loss: 7293637.1786\n",
      "Epoch 359/500\n",
      "130/130 [==============================] - 0s - loss: 2451552.5385 - val_loss: 7280163.9286\n",
      "Epoch 360/500\n",
      "130/130 [==============================] - 0s - loss: 2442907.5538 - val_loss: 7267209.178600813.57\n",
      "Epoch 361/500\n",
      "130/130 [==============================] - 0s - loss: 2431836.3490 - val_loss: 7254965.4643\n",
      "Epoch 362/500\n",
      "130/130 [==============================] - 0s - loss: 2469918.5144 - val_loss: 7242010.8571\n",
      "Epoch 363/500\n",
      "130/130 [==============================] - 0s - loss: 2398366.0250 - val_loss: 7228937.8214\n",
      "Epoch 364/500\n",
      "130/130 [==============================] - 0s - loss: 2405511.2260 - val_loss: 7216315.7500\n",
      "Epoch 365/500\n",
      "130/130 [==============================] - 0s - loss: 2380986.4875 - val_loss: 7203738.5357\n",
      "Epoch 366/500\n",
      "130/130 [==============================] - 0s - loss: 2410628.4260 - val_loss: 7190652.5357\n",
      "Epoch 367/500\n",
      "130/130 [==============================] - 0s - loss: 2397307.6740 - val_loss: 7177964.4643\n",
      "Epoch 368/500\n",
      "130/130 [==============================] - 0s - loss: 2375329.0702 - val_loss: 7165203.6429\n",
      "Epoch 369/500\n",
      "130/130 [==============================] - 0s - loss: 2350789.4135 - val_loss: 7152514.678693041\n",
      "Epoch 370/500\n",
      "130/130 [==============================] - 0s - loss: 2337634.6683 - val_loss: 7139550.5357\n",
      "Epoch 371/500\n",
      "130/130 [==============================] - 0s - loss: 2359071.5880 - val_loss: 7127440.7143\n",
      "Epoch 372/500\n",
      "130/130 [==============================] - 0s - loss: 2360413.8731 - val_loss: 7115022.2500\n",
      "Epoch 373/500\n",
      "130/130 [==============================] - 1s - loss: 2353936.1712 - val_loss: 7102382.2500\n",
      "Epoch 374/500\n",
      "130/130 [==============================] - 0s - loss: 2373816.0010 - val_loss: 7089456.6071\n",
      "Epoch 375/500\n",
      "130/130 [==============================] - 0s - loss: 2322416.2942 - val_loss: 7076684.9643\n",
      "Epoch 376/500\n",
      "130/130 [==============================] - 0s - loss: 2300452.1298 - val_loss: 7064122.2143\n",
      "Epoch 377/500\n",
      "130/130 [==============================] - 0s - loss: 2325942.9433 - val_loss: 7051823.0357\n",
      "Epoch 378/500\n",
      "130/130 [==============================] - 0s - loss: 2313443.9683 - val_loss: 7039383.6071\n",
      "Epoch 379/500\n",
      "130/130 [==============================] - 0s - loss: 2308555.9231 - val_loss: 7027713.785732464.740\n",
      "Epoch 380/500\n",
      "130/130 [==============================] - 0s - loss: 2286547.8096 - val_loss: 7015000.5714\n",
      "Epoch 381/500\n",
      "130/130 [==============================] - 0s - loss: 2285825.6279 - val_loss: 7002887.0357\n",
      "Epoch 382/500\n",
      "130/130 [==============================] - 0s - loss: 2294325.8058 - val_loss: 6990152.3929\n",
      "Epoch 383/500\n",
      "130/130 [==============================] - 0s - loss: 2269966.8971 - val_loss: 6977830.5714\n",
      "Epoch 384/500\n",
      "130/130 [==============================] - 0s - loss: 2280254.7889 - val_loss: 6965424.4286\n",
      "Epoch 385/500\n",
      "130/130 [==============================] - 0s - loss: 2252857.3702 - val_loss: 6953385.5357\n",
      "Epoch 386/500\n",
      "130/130 [==============================] - 0s - loss: 2235134.2952 - val_loss: 6940272.1071\n",
      "Epoch 387/500\n",
      "130/130 [==============================] - 0s - loss: 2251581.5702 - val_loss: 6928696.5357\n",
      "Epoch 388/500\n",
      "130/130 [==============================] - 0s - loss: 2267504.1356 - val_loss: 6915888.6607\n",
      "Epoch 389/500\n",
      "130/130 [==============================] - 0s - loss: 2230452.2740 - val_loss: 6903209.2679\n",
      "Epoch 390/500\n",
      "130/130 [==============================] - 0s - loss: 2230960.6346 - val_loss: 6891581.4286\n",
      "Epoch 391/500\n",
      "130/130 [==============================] - 0s - loss: 2222711.1337 - val_loss: 6879697.7143\n",
      "Epoch 392/500\n",
      "130/130 [==============================] - 0s - loss: 2240723.5197 - val_loss: 6867601.9286\n",
      "Epoch 393/500\n",
      "130/130 [==============================] - 0s - loss: 2215347.5183 - val_loss: 6855326.9821\n",
      "Epoch 394/500\n",
      "130/130 [==============================] - 0s - loss: 2181881.9827 - val_loss: 6843111.6607\n",
      "Epoch 395/500\n",
      "130/130 [==============================] - 0s - loss: 2196231.3779 - val_loss: 6830655.5714\n",
      "Epoch 396/500\n",
      "130/130 [==============================] - 0s - loss: 2183493.1212 - val_loss: 6819113.4464\n",
      "Epoch 397/500\n",
      "130/130 [==============================] - 0s - loss: 2197672.4990 - val_loss: 6806318.5536\n",
      "Epoch 398/500\n",
      "130/130 [==============================] - 0s - loss: 2191881.9007 - val_loss: 6794488.4464\n",
      "Epoch 399/500\n",
      "130/130 [==============================] - 0s - loss: 2181523.0385 - val_loss: 6782658.7143\n",
      "Epoch 400/500\n",
      "130/130 [==============================] - 0s - loss: 2163915.1125 - val_loss: 6770687.4286\n",
      "Epoch 401/500\n",
      "130/130 [==============================] - 0s - loss: 2160275.8464 - val_loss: 6758679.2857\n",
      "Epoch 402/500\n",
      "130/130 [==============================] - 0s - loss: 2162021.5750 - val_loss: 6746438.3036\n",
      "Epoch 403/500\n",
      "130/130 [==============================] - 0s - loss: 2157452.4750 - val_loss: 6735014.1250\n",
      "Epoch 404/500\n",
      "130/130 [==============================] - 0s - loss: 2129142.0286 - val_loss: 6722617.1607\n",
      "Epoch 405/500\n",
      "130/130 [==============================] - 0s - loss: 2134749.1692 - val_loss: 6710162.7679\n",
      "Epoch 406/500\n",
      "130/130 [==============================] - 0s - loss: 2123565.6370 - val_loss: 6698852.8393\n",
      "Epoch 407/500\n",
      "130/130 [==============================] - 0s - loss: 2101968.4519 - val_loss: 6686547.4107\n",
      "Epoch 408/500\n",
      "130/130 [==============================] - 0s - loss: 2119316.6793 - val_loss: 6674815.2679\n",
      "Epoch 409/500\n",
      "130/130 [==============================] - 0s - loss: 2133685.9279 - val_loss: 6663589.2679\n",
      "Epoch 410/500\n",
      "130/130 [==============================] - 0s - loss: 2104939.9885 - val_loss: 6651529.3036\n",
      "Epoch 411/500\n",
      "130/130 [==============================] - 0s - loss: 2064015.7120 - val_loss: 6639826.3036\n",
      "Epoch 412/500\n",
      "130/130 [==============================] - 0s - loss: 2071902.5166 - val_loss: 6628232.7321\n",
      "Epoch 413/500\n",
      "130/130 [==============================] - 0s - loss: 2059833.2038 - val_loss: 6616591.696436626.79\n",
      "Epoch 414/500\n",
      "130/130 [==============================] - 0s - loss: 2091732.1609 - val_loss: 6605468.1250\n",
      "Epoch 415/500\n",
      "130/130 [==============================] - 0s - loss: 2095470.9846 - val_loss: 6594322.5893\n",
      "Epoch 416/500\n",
      "130/130 [==============================] - 0s - loss: 2068437.2413 - val_loss: 6582100.1607\n",
      "Epoch 417/500\n",
      "130/130 [==============================] - 0s - loss: 2047075.2668 - val_loss: 6570335.9821\n",
      "Epoch 418/500\n",
      "130/130 [==============================] - 0s - loss: 2034497.8553 - val_loss: 6558192.3750\n",
      "Epoch 419/500\n",
      "130/130 [==============================] - 0s - loss: 2081857.6159 - val_loss: 6547725.0000\n",
      "Epoch 420/500\n",
      "130/130 [==============================] - 0s - loss: 2022560.8812 - val_loss: 6536286.0179\n",
      "Epoch 421/500\n",
      "130/130 [==============================] - 0s - loss: 2033727.6538 - val_loss: 6524235.5714\n",
      "Epoch 422/500\n",
      "130/130 [==============================] - 0s - loss: 2033156.8875 - val_loss: 6513014.3036\n",
      "Epoch 423/500\n",
      "130/130 [==============================] - 0s - loss: 2007448.5731 - val_loss: 6501725.1250\n",
      "Epoch 424/500\n",
      "130/130 [==============================] - 0s - loss: 2018026.2332 - val_loss: 6490345.8393\n",
      "Epoch 425/500\n",
      "130/130 [==============================] - 0s - loss: 2014558.1214 - val_loss: 6478689.8036\n",
      "Epoch 426/500\n",
      "130/130 [==============================] - 0s - loss: 1999044.2005 - val_loss: 6467139.9464\n",
      "Epoch 427/500\n",
      "130/130 [==============================] - 0s - loss: 2035037.1596 - val_loss: 6455802.4286\n",
      "Epoch 428/500\n",
      "130/130 [==============================] - 0s - loss: 1991097.5096 - val_loss: 6444651.2679\n",
      "Epoch 429/500\n",
      "130/130 [==============================] - 0s - loss: 1999017.3817 - val_loss: 6432876.9821\n",
      "Epoch 430/500\n",
      "130/130 [==============================] - 0s - loss: 1970336.0038 - val_loss: 6421715.5000\n",
      "Epoch 431/500\n",
      "130/130 [==============================] - 0s - loss: 2000582.7630 - val_loss: 6410352.5714\n",
      "Epoch 432/500\n",
      "130/130 [==============================] - 0s - loss: 1950099.9865 - val_loss: 6399597.9821\n",
      "Epoch 433/500\n",
      "130/130 [==============================] - 0s - loss: 1983614.9245 - val_loss: 6388011.5536\n",
      "Epoch 434/500\n",
      "130/130 [==============================] - 0s - loss: 1930512.1990 - val_loss: 6376559.7321\n",
      "Epoch 435/500\n",
      "130/130 [==============================] - 0s - loss: 1948236.9115 - val_loss: 6365374.9107\n",
      "Epoch 436/500\n",
      "130/130 [==============================] - 0s - loss: 1946509.2394 - val_loss: 6354087.8393\n",
      "Epoch 437/500\n",
      "130/130 [==============================] - 0s - loss: 1958629.4791 - val_loss: 6342582.6429\n",
      "Epoch 438/500\n",
      "130/130 [==============================] - 0s - loss: 1964470.4601 - val_loss: 6331256.8750\n",
      "Epoch 439/500\n",
      "130/130 [==============================] - 0s - loss: 1931187.3418 - val_loss: 6320073.7321\n",
      "Epoch 440/500\n",
      "130/130 [==============================] - 0s - loss: 1913917.5038 - val_loss: 6308677.5893\n",
      "Epoch 441/500\n",
      "130/130 [==============================] - 0s - loss: 1923791.9731 - val_loss: 6297385.2143\n",
      "Epoch 442/500\n",
      "130/130 [==============================] - 0s - loss: 1911662.9481 - val_loss: 6286351.0179\n",
      "Epoch 443/500\n",
      "130/130 [==============================] - 0s - loss: 1909148.3587 - val_loss: 6276217.4107\n",
      "Epoch 444/500\n",
      "130/130 [==============================] - 0s - loss: 1918802.9543 - val_loss: 6264989.3036\n",
      "Epoch 445/500\n",
      "130/130 [==============================] - 0s - loss: 1906312.0706 - val_loss: 6254552.2321\n",
      "Epoch 446/500\n",
      "130/130 [==============================] - 0s - loss: 1902457.4106 - val_loss: 6243082.8393\n",
      "Epoch 447/500\n",
      "130/130 [==============================] - 0s - loss: 1889468.4577 - val_loss: 6232778.0179\n",
      "Epoch 448/500\n",
      "130/130 [==============================] - 0s - loss: 1877823.6346 - val_loss: 6221520.4464\n",
      "Epoch 449/500\n",
      "130/130 [==============================] - 0s - loss: 1925458.0687 - val_loss: 6210324.7321\n",
      "Epoch 450/500\n",
      "130/130 [==============================] - 0s - loss: 1861798.2197 - val_loss: 6199093.2857\n",
      "Epoch 451/500\n",
      "130/130 [==============================] - 0s - loss: 1892408.6644 - val_loss: 6188539.9464\n",
      "Epoch 452/500\n",
      "130/130 [==============================] - 0s - loss: 1880300.5587 - val_loss: 6178454.7321\n",
      "Epoch 453/500\n",
      "130/130 [==============================] - 0s - loss: 1875873.2442 - val_loss: 6168103.8571\n",
      "Epoch 454/500\n",
      "130/130 [==============================] - 0s - loss: 1840436.8942 - val_loss: 6156790.0000\n",
      "Epoch 455/500\n",
      "130/130 [==============================] - 0s - loss: 1868636.1079 - val_loss: 6147274.9821\n",
      "Epoch 456/500\n",
      "130/130 [==============================] - 0s - loss: 1874932.7024 - val_loss: 6136001.1250\n",
      "Epoch 457/500\n",
      "130/130 [==============================] - 0s - loss: 1883343.4296 - val_loss: 6126233.1429\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1807790.4495 - val_loss: 6115354.0179\n",
      "Epoch 459/500\n",
      "130/130 [==============================] - 0s - loss: 1840437.3981 - val_loss: 6104059.5714\n",
      "Epoch 460/500\n",
      "130/130 [==============================] - 0s - loss: 1823470.7700 - val_loss: 6093833.1429\n",
      "Epoch 461/500\n",
      "130/130 [==============================] - 0s - loss: 1805946.3594 - val_loss: 6083615.428614194.007\n",
      "Epoch 462/500\n",
      "130/130 [==============================] - 0s - loss: 1826358.4510 - val_loss: 6073248.4107\n",
      "Epoch 463/500\n",
      "130/130 [==============================] - 0s - loss: 1805230.0832 - val_loss: 6062787.8571\n",
      "Epoch 464/500\n",
      "130/130 [==============================] - 0s - loss: 1817363.4639 - val_loss: 6052349.9464\n",
      "Epoch 465/500\n",
      "130/130 [==============================] - 0s - loss: 1818133.8341 - val_loss: 6042219.5893\n",
      "Epoch 466/500\n",
      "130/130 [==============================] - 0s - loss: 1814180.2990 - val_loss: 6031330.7321\n",
      "Epoch 467/500\n",
      "130/130 [==============================] - 0s - loss: 1832812.3245 - val_loss: 6021258.0179\n",
      "Epoch 468/500\n",
      "130/130 [==============================] - 0s - loss: 1788469.0817 - val_loss: 6011292.6964\n",
      "Epoch 469/500\n",
      "130/130 [==============================] - 0s - loss: 1818487.0940 - val_loss: 6000677.6250\n",
      "Epoch 470/500\n",
      "130/130 [==============================] - 0s - loss: 1777002.3502 - val_loss: 5990953.1250\n",
      "Epoch 471/500\n",
      "130/130 [==============================] - 0s - loss: 1770145.5365 - val_loss: 5980201.4107\n",
      "Epoch 472/500\n",
      "130/130 [==============================] - 0s - loss: 1744916.3719 - val_loss: 5969269.9464\n",
      "Epoch 473/500\n",
      "130/130 [==============================] - 0s - loss: 1787318.7168 - val_loss: 5959824.2857\n",
      "Epoch 474/500\n",
      "130/130 [==============================] - 0s - loss: 1753138.3839 - val_loss: 5949333.5714\n",
      "Epoch 475/500\n",
      "130/130 [==============================] - 0s - loss: 1772641.4260 - val_loss: 5939854.2321\n",
      "Epoch 476/500\n",
      "130/130 [==============================] - 0s - loss: 1754108.7755 - val_loss: 5929939.1250\n",
      "Epoch 477/500\n",
      "130/130 [==============================] - 0s - loss: 1757587.9837 - val_loss: 5919729.7679\n",
      "Epoch 478/500\n",
      "130/130 [==============================] - 0s - loss: 1755723.3986 - val_loss: 5908838.9464\n",
      "Epoch 479/500\n",
      "130/130 [==============================] - 0s - loss: 1721296.4274 - val_loss: 5899112.0000\n",
      "Epoch 480/500\n",
      "130/130 [==============================] - 0s - loss: 1735085.2038 - val_loss: 5889159.5536\n",
      "Epoch 481/500\n",
      "130/130 [==============================] - 0s - loss: 1734256.0358 - val_loss: 5879430.8750\n",
      "Epoch 482/500\n",
      "130/130 [==============================] - 0s - loss: 1679313.6654 - val_loss: 5869063.9107\n",
      "Epoch 483/500\n",
      "130/130 [==============================] - 0s - loss: 1715628.5389 - val_loss: 5858925.0179\n",
      "Epoch 484/500\n",
      "130/130 [==============================] - 0s - loss: 1698295.8428 - val_loss: 5848736.3036\n",
      "Epoch 485/500\n",
      "130/130 [==============================] - 0s - loss: 1734185.6957 - val_loss: 5838704.7143\n",
      "Epoch 486/500\n",
      "130/130 [==============================] - 0s - loss: 1697844.5029 - val_loss: 5828637.5536\n",
      "Epoch 487/500\n",
      "130/130 [==============================] - 0s - loss: 1716090.5868 - val_loss: 5818648.0000\n",
      "Epoch 488/500\n",
      "130/130 [==============================] - 0s - loss: 1708264.5493 - val_loss: 5808828.9107\n",
      "Epoch 489/500\n",
      "130/130 [==============================] - 0s - loss: 1708879.1442 - val_loss: 5798574.1607\n",
      "Epoch 490/500\n",
      "130/130 [==============================] - 0s - loss: 1732878.4887 - val_loss: 5788247.5714\n",
      "Epoch 491/500\n",
      "130/130 [==============================] - 0s - loss: 1680272.3356 - val_loss: 5779082.30361\n",
      "Epoch 492/500\n",
      "130/130 [==============================] - 0s - loss: 1676283.9885 - val_loss: 5768699.9107\n",
      "Epoch 493/500\n",
      "130/130 [==============================] - 0s - loss: 1689685.6481 - val_loss: 5758916.5893\n",
      "Epoch 494/500\n",
      "130/130 [==============================] - 0s - loss: 1671275.6415 - val_loss: 5748743.4821\n",
      "Epoch 495/500\n",
      "130/130 [==============================] - 0s - loss: 1661300.5800 - val_loss: 5739903.2857\n",
      "Epoch 496/500\n",
      "130/130 [==============================] - 0s - loss: 1680582.0577 - val_loss: 5729794.6071\n",
      "Epoch 497/500\n",
      "130/130 [==============================] - 0s - loss: 1663749.5452 - val_loss: 5720692.6250\n",
      "Epoch 498/500\n",
      "130/130 [==============================] - 0s - loss: 1642051.0094 - val_loss: 5710455.2857\n",
      "Epoch 499/500\n",
      "130/130 [==============================] - 0s - loss: 1680934.0851 - val_loss: 5700697.6429\n",
      "Epoch 500/500\n",
      "130/130 [==============================] - 0s - loss: 1647133.8749 - val_loss: 5691454.2321\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 1644.06811523]\n"
     ]
    }
   ],
   "source": [
    "'''跑数据和模型'''\n",
    "epochs  = 500\n",
    "seq_len = 24\n",
    "\n",
    "X_train, y_train, X_test, y_test = slicing_data( Tues , seq_len )\n",
    "print('X_train shape:',X_train.shape)  #(3709L, 50L, 1L)\n",
    "print('y_train shape:',y_train.shape)  #(3709L,)\n",
    "print('X_test shape:',X_test.shape)    #(412L, 50L, 1L)\n",
    "print('y_test shape:',y_test.shape)    #(412L,)\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=4,nb_epoch=epochs,validation_split=0.05)\n",
    "'''做预测'''\n",
    "point_by_point_predictions = predict_point_by_point(model, X_test)\n",
    "print('point_by_point_predictions shape:',np.array(point_by_point_predictions).shape)  #(412L)\n",
    "\n",
    "print('result: ',point_by_point_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4146 2386 2700 3016 4059 1740 1844 1900 1812 1889 1794 2424 2143 1631 1584\n",
      " 2587 2284 2342 2055 1885 2178 2336 1781 1615 1759 2033 1751 1905 1760 2281\n",
      " 1811 2032 1965 1900 2483 4723 2669 2541 2077 1849 2338 2160 2170 2126 2002\n",
      " 1680 1514  950 5090 2796 3528 3957 3525 1904 3224 2018 1802 2848 2051 1915\n",
      " 3076 1870 2607 2174 2257 1857 1841 1769 2908 1288 1713 2016 2822 2209 2072\n",
      " 1739 1749 2787 1416 1941 2049 2466 4044 2231 2219 3137   15 2441 2085 2389\n",
      " 1946 1692 2356 2242 1778 2490 2036 3091 1292 7226 3472 2794 3526 3498 4630\n",
      " 2040   23 4032 2479 2491 2325 2007 3380 2024 2985 2830 2383 2472 1948 2246\n",
      " 2114 1925 1926 3157 1465 3005 2520 2255 2076 2596 1608 1902 2200 2477 2684\n",
      " 2256 2445 3804 3546 3639 2019 2594 2538 2268 1947 2535 2098 2181 2771 1839\n",
      " 7069 3848 4572 3865 5592 5537 3315 2627 2344 2326 1934 3208 4003]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1644.06811523], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Tues)\n",
    "point_by_point_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''跑数据和模型 写成函数的形式'''\n",
    "def run_model(data):\n",
    "    epochs  = 1000\n",
    "    seq_len = 24\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = slicing_data( data , seq_len )\n",
    "    print('X_train shape:',X_train.shape)  #(3709L, 50L, 1L)\n",
    "    print('y_train shape:',y_train.shape)  #(3709L,)\n",
    "    print('X_test shape:',X_test.shape)    #(412L, 50L, 1L)\n",
    "    print('y_test shape:',y_test.shape)    #(412L,)\n",
    "    \n",
    "    model.fit( X_train,y_train, batch_size=4, nb_epoch=epochs, validation_split=0.05 )\n",
    "    '''做预测'''\n",
    "    point_by_point_predictions = predict_point_by_point(model, X_test)\n",
    "    print('point_by_point_predictions shape:',np.array(point_by_point_predictions).shape)  #(412L)\n",
    "    \n",
    "    print('result: ',point_by_point_predictions)\n",
    "    \n",
    "    return point_by_point_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result len(data): 160\n",
      "result data.shape: (160,)\n",
      "result len(slicing): 135\n",
      "result slicing_shape: (135, 25)\n",
      "[array([3396, 2735, 3903, 3377, 4094, 2377, 1874, 1843, 1933, 1797, 1739,\n",
      "        744, 1745, 2164, 2104,   73, 2427, 2509, 1940, 1794, 2374,   89,\n",
      "       1612, 1778, 1819])]\n",
      "X_train shape: (134, 24, 1)\n",
      "y_train shape: (134,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 127 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "127/127 [==============================] - 2s - loss: 6742899.3898 - val_loss: 5835897.5000\n",
      "Epoch 2/1000\n",
      "127/127 [==============================] - 0s - loss: 6712296.5118 - val_loss: 5820862.2143\n",
      "Epoch 3/1000\n",
      "127/127 [==============================] - 0s - loss: 6698608.0551 - val_loss: 5807324.2857\n",
      "Epoch 4/1000\n",
      "127/127 [==============================] - 0s - loss: 6683669.6909 - val_loss: 5793090.5714\n",
      "Epoch 5/1000\n",
      "127/127 [==============================] - 0s - loss: 6668462.5591 - val_loss: 5778743.0000\n",
      "Epoch 6/1000\n",
      "127/127 [==============================] - 0s - loss: 6655455.1890 - val_loss: 5765026.2143\n",
      "Epoch 7/1000\n",
      "127/127 [==============================] - 0s - loss: 6641558.7283 - val_loss: 5750786.6429\n",
      "Epoch 8/1000\n",
      "127/127 [==============================] - 0s - loss: 6625475.7854 - val_loss: 5737097.7857\n",
      "Epoch 9/1000\n",
      "127/127 [==============================] - 0s - loss: 6610042.5748 - val_loss: 5722681.7143\n",
      "Epoch 10/1000\n",
      "127/127 [==============================] - 0s - loss: 6597481.5335 - val_loss: 5708852.3571\n",
      "Epoch 11/1000\n",
      "127/127 [==============================] - 0s - loss: 6583172.7087 - val_loss: 5695142.7143\n",
      "Epoch 12/1000\n",
      "127/127 [==============================] - 0s - loss: 6567177.3031 - val_loss: 5681111.7857\n",
      "Epoch 13/1000\n",
      "127/127 [==============================] - 0s - loss: 6553018.2972 - val_loss: 5667209.1429\n",
      "Epoch 14/1000\n",
      "127/127 [==============================] - 0s - loss: 6540092.2402 - val_loss: 5653601.6429\n",
      "Epoch 15/1000\n",
      "127/127 [==============================] - 0s - loss: 6525440.7362 - val_loss: 5639677.7857\n",
      "Epoch 16/1000\n",
      "127/127 [==============================] - 0s - loss: 6512978.3661 - val_loss: 5625447.1429\n",
      "Epoch 17/1000\n",
      "127/127 [==============================] - 0s - loss: 6498087.6122 - val_loss: 5611557.3571\n",
      "Epoch 18/1000\n",
      "127/127 [==============================] - 0s - loss: 6485009.7913 - val_loss: 5597709.4286\n",
      "Epoch 19/1000\n",
      "127/127 [==============================] - 0s - loss: 6468034.3602 - val_loss: 5583698.4286\n",
      "Epoch 20/1000\n",
      "127/127 [==============================] - 0s - loss: 6453454.3071 - val_loss: 5569813.4286\n",
      "Epoch 21/1000\n",
      "127/127 [==============================] - 0s - loss: 6441952.2756 - val_loss: 5556176.5000\n",
      "Epoch 22/1000\n",
      "127/127 [==============================] - 0s - loss: 6425810.4055 - val_loss: 5542156.3929\n",
      "Epoch 23/1000\n",
      "127/127 [==============================] - 0s - loss: 6410541.2480 - val_loss: 5528567.2857\n",
      "Epoch 24/1000\n",
      "127/127 [==============================] - 0s - loss: 6396765.7323 - val_loss: 5514861.1786\n",
      "Epoch 25/1000\n",
      "127/127 [==============================] - 0s - loss: 6383493.1811 - val_loss: 5500802.1071\n",
      "Epoch 26/1000\n",
      "127/127 [==============================] - 0s - loss: 6372169.1476 - val_loss: 5487402.0357\n",
      "Epoch 27/1000\n",
      "127/127 [==============================] - 0s - loss: 6358849.1732 - val_loss: 5473382.2500\n",
      "Epoch 28/1000\n",
      "127/127 [==============================] - 0s - loss: 6344850.1417 - val_loss: 5459572.0000\n",
      "Epoch 29/1000\n",
      "127/127 [==============================] - 0s - loss: 6329936.8937 - val_loss: 5446256.1429\n",
      "Epoch 30/1000\n",
      "127/127 [==============================] - 0s - loss: 6311888.4331 - val_loss: 5432550.9643\n",
      "Epoch 31/1000\n",
      "127/127 [==============================] - 0s - loss: 6305057.5079 - val_loss: 5418819.1429\n",
      "Epoch 32/1000\n",
      "127/127 [==============================] - 0s - loss: 6288175.8937 - val_loss: 5405374.9643\n",
      "Epoch 33/1000\n",
      "127/127 [==============================] - 0s - loss: 6271238.6594 - val_loss: 5391570.0000\n",
      "Epoch 34/1000\n",
      "127/127 [==============================] - 0s - loss: 6258139.7795 - val_loss: 5378039.3214\n",
      "Epoch 35/1000\n",
      "127/127 [==============================] - 0s - loss: 6247024.3957 - val_loss: 5364648.5714\n",
      "Epoch 36/1000\n",
      "127/127 [==============================] - 0s - loss: 6233319.8504 - val_loss: 5350831.6071\n",
      "Epoch 37/1000\n",
      "127/127 [==============================] - 0s - loss: 6215879.9606 - val_loss: 5337286.1429\n",
      "Epoch 38/1000\n",
      "127/127 [==============================] - 0s - loss: 6204475.7323 - val_loss: 5323811.2857\n",
      "Epoch 39/1000\n",
      "127/127 [==============================] - 0s - loss: 6192146.1024 - val_loss: 5310336.8214\n",
      "Epoch 40/1000\n",
      "127/127 [==============================] - 0s - loss: 6177435.1575 - val_loss: 5297252.5714\n",
      "Epoch 41/1000\n",
      "127/127 [==============================] - 0s - loss: 6161118.8366 - val_loss: 5283864.4286\n",
      "Epoch 42/1000\n",
      "127/127 [==============================] - 0s - loss: 6146269.7185 - val_loss: 5270421.7143\n",
      "Epoch 43/1000\n",
      "127/127 [==============================] - 0s - loss: 6136274.9547 - val_loss: 5256788.5357\n",
      "Epoch 44/1000\n",
      "127/127 [==============================] - 0s - loss: 6117891.1969 - val_loss: 5243268.8929\n",
      "Epoch 45/1000\n",
      "127/127 [==============================] - 0s - loss: 6110347.8425 - val_loss: 5229989.2500\n",
      "Epoch 46/1000\n",
      "127/127 [==============================] - 0s - loss: 6095147.6614 - val_loss: 5216320.3929\n",
      "Epoch 47/1000\n",
      "127/127 [==============================] - 0s - loss: 6082163.6102 - val_loss: 5203574.0000\n",
      "Epoch 48/1000\n",
      "127/127 [==============================] - 0s - loss: 6062568.5984 - val_loss: 5189948.4286\n",
      "Epoch 49/1000\n",
      "127/127 [==============================] - 0s - loss: 6050631.2500 - val_loss: 5176703.1071\n",
      "Epoch 50/1000\n",
      "127/127 [==============================] - 0s - loss: 6031909.5000 - val_loss: 5163160.0000\n",
      "Epoch 51/1000\n",
      "127/127 [==============================] - 0s - loss: 6026736.8189 - val_loss: 5150022.7500\n",
      "Epoch 52/1000\n",
      "127/127 [==============================] - 0s - loss: 6003709.4213 - val_loss: 5136554.2857\n",
      "Epoch 53/1000\n",
      "127/127 [==============================] - 0s - loss: 5989525.6486 - val_loss: 5123335.7500\n",
      "Epoch 54/1000\n",
      "127/127 [==============================] - 0s - loss: 5983739.8346 - val_loss: 5110295.7500\n",
      "Epoch 55/1000\n",
      "127/127 [==============================] - 0s - loss: 5975018.8937 - val_loss: 5097228.6071\n",
      "Epoch 56/1000\n",
      "127/127 [==============================] - 0s - loss: 5957235.0177 - val_loss: 5083939.1429\n",
      "Epoch 57/1000\n",
      "127/127 [==============================] - 0s - loss: 5947125.1811 - val_loss: 5070600.2857\n",
      "Epoch 58/1000\n",
      "127/127 [==============================] - 0s - loss: 5932258.6555 - val_loss: 5057381.8929\n",
      "Epoch 59/1000\n",
      "127/127 [==============================] - 0s - loss: 5914531.7165 - val_loss: 5044121.1786\n",
      "Epoch 60/1000\n",
      "127/127 [==============================] - 0s - loss: 5907426.0906 - val_loss: 5030940.0000\n",
      "Epoch 61/1000\n",
      "127/127 [==============================] - 0s - loss: 5891273.2992 - val_loss: 5018039.7143\n",
      "Epoch 62/1000\n",
      "127/127 [==============================] - 0s - loss: 5873393.3386 - val_loss: 5004855.5714\n",
      "Epoch 63/1000\n",
      "127/127 [==============================] - 0s - loss: 5860258.8878 - val_loss: 4992282.0357\n",
      "Epoch 64/1000\n",
      "127/127 [==============================] - 0s - loss: 5845223.0472 - val_loss: 4978982.8214\n",
      "Epoch 65/1000\n",
      "127/127 [==============================] - 0s - loss: 5831023.9803 - val_loss: 4966156.1429\n",
      "Epoch 66/1000\n",
      "127/127 [==============================] - 0s - loss: 5815868.7480 - val_loss: 4953239.4286\n",
      "Epoch 67/1000\n",
      "127/127 [==============================] - 0s - loss: 5812495.1752 - val_loss: 4940431.5357\n",
      "Epoch 68/1000\n",
      "127/127 [==============================] - 0s - loss: 5804330.6811 - val_loss: 4927283.9643\n",
      "Epoch 69/1000\n",
      "127/127 [==============================] - 0s - loss: 5771575.1594 - val_loss: 4914155.6786\n",
      "Epoch 70/1000\n",
      "127/127 [==============================] - 0s - loss: 5767905.9055 - val_loss: 4901252.8214\n",
      "Epoch 71/1000\n",
      "127/127 [==============================] - 0s - loss: 5750201.3248 - val_loss: 4888366.8929\n",
      "Epoch 72/1000\n",
      "127/127 [==============================] - 0s - loss: 5741859.6693 - val_loss: 4875320.5357\n",
      "Epoch 73/1000\n",
      "127/127 [==============================] - 0s - loss: 5729314.3543 - val_loss: 4862722.4643\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 5704005.0945 - val_loss: 4849836.1429\n",
      "Epoch 75/1000\n",
      "127/127 [==============================] - 0s - loss: 5708282.0846 - val_loss: 4837109.5714\n",
      "Epoch 76/1000\n",
      "127/127 [==============================] - 0s - loss: 5696404.2795 - val_loss: 4824262.9643\n",
      "Epoch 77/1000\n",
      "127/127 [==============================] - 0s - loss: 5672112.0906 - val_loss: 4811805.8571\n",
      "Epoch 78/1000\n",
      "127/127 [==============================] - 0s - loss: 5666464.0748 - val_loss: 4798970.8929\n",
      "Epoch 79/1000\n",
      "127/127 [==============================] - 0s - loss: 5657150.7795 - val_loss: 4786332.6071\n",
      "Epoch 80/1000\n",
      "127/127 [==============================] - 0s - loss: 5636017.0591 - val_loss: 4773700.7143\n",
      "Epoch 81/1000\n",
      "127/127 [==============================] - 0s - loss: 5623349.7323 - val_loss: 4761362.6786\n",
      "Epoch 82/1000\n",
      "127/127 [==============================] - 0s - loss: 5613516.2520 - val_loss: 4748263.4286\n",
      "Epoch 83/1000\n",
      "127/127 [==============================] - 0s - loss: 5594746.1063 - val_loss: 4735564.0000\n",
      "Epoch 84/1000\n",
      "127/127 [==============================] - 0s - loss: 5589925.7008 - val_loss: 4722869.2500\n",
      "Epoch 85/1000\n",
      "127/127 [==============================] - 0s - loss: 5571307.5659 - val_loss: 4711062.9643\n",
      "Epoch 86/1000\n",
      "127/127 [==============================] - 0s - loss: 5560147.4803 - val_loss: 4698240.5357\n",
      "Epoch 87/1000\n",
      "127/127 [==============================] - 0s - loss: 5541577.4291 - val_loss: 4685577.0357\n",
      "Epoch 88/1000\n",
      "127/127 [==============================] - 0s - loss: 5533780.2933 - val_loss: 4673003.8929\n",
      "Epoch 89/1000\n",
      "127/127 [==============================] - 0s - loss: 5517438.2264 - val_loss: 4660411.8571\n",
      "Epoch 90/1000\n",
      "127/127 [==============================] - 0s - loss: 5498571.0236 - val_loss: 4647835.1786\n",
      "Epoch 91/1000\n",
      "127/127 [==============================] - 0s - loss: 5489999.5276 - val_loss: 4635596.8571\n",
      "Epoch 92/1000\n",
      "127/127 [==============================] - 0s - loss: 5487885.4272 - val_loss: 4622854.2500\n",
      "Epoch 93/1000\n",
      "127/127 [==============================] - 0s - loss: 5460042.8169 - val_loss: 4610349.8571\n",
      "Epoch 94/1000\n",
      "127/127 [==============================] - 0s - loss: 5462850.3307 - val_loss: 4597744.3929\n",
      "Epoch 95/1000\n",
      "127/127 [==============================] - 0s - loss: 5442397.2677 - val_loss: 4585246.1071\n",
      "Epoch 96/1000\n",
      "127/127 [==============================] - 0s - loss: 5436513.0906 - val_loss: 4572920.6071\n",
      "Epoch 97/1000\n",
      "127/127 [==============================] - 0s - loss: 5418142.8189 - val_loss: 4560653.5714\n",
      "Epoch 98/1000\n",
      "127/127 [==============================] - 0s - loss: 5413015.6083 - val_loss: 4548219.3929\n",
      "Epoch 99/1000\n",
      "127/127 [==============================] - 0s - loss: 5387235.7776 - val_loss: 4535716.6071\n",
      "Epoch 100/1000\n",
      "127/127 [==============================] - 0s - loss: 5372050.6614 - val_loss: 4523415.8214\n",
      "Epoch 101/1000\n",
      "127/127 [==============================] - 0s - loss: 5365105.1280 - val_loss: 4511239.1786\n",
      "Epoch 102/1000\n",
      "127/127 [==============================] - 0s - loss: 5354333.7992 - val_loss: 4498743.4643\n",
      "Epoch 103/1000\n",
      "127/127 [==============================] - 0s - loss: 5346006.9764 - val_loss: 4486588.3214\n",
      "Epoch 104/1000\n",
      "127/127 [==============================] - 0s - loss: 5328120.2598 - val_loss: 4474549.4286\n",
      "Epoch 105/1000\n",
      "127/127 [==============================] - 0s - loss: 5311168.4252 - val_loss: 4462017.3214\n",
      "Epoch 106/1000\n",
      "127/127 [==============================] - 0s - loss: 5311431.1929 - val_loss: 4450163.8571\n",
      "Epoch 107/1000\n",
      "127/127 [==============================] - 0s - loss: 5299878.9193 - val_loss: 4437980.4643\n",
      "Epoch 108/1000\n",
      "127/127 [==============================] - 0s - loss: 5271696.8957 - val_loss: 4426026.4643\n",
      "Epoch 109/1000\n",
      "127/127 [==============================] - 0s - loss: 5265483.6122 - val_loss: 4413487.3929\n",
      "Epoch 110/1000\n",
      "127/127 [==============================] - 0s - loss: 5247964.8386 - val_loss: 4401404.2857\n",
      "Epoch 111/1000\n",
      "127/127 [==============================] - 0s - loss: 5236391.0827 - val_loss: 4389231.0000\n",
      "Epoch 112/1000\n",
      "127/127 [==============================] - 0s - loss: 5238979.6791 - val_loss: 4377456.6071\n",
      "Epoch 113/1000\n",
      "127/127 [==============================] - 0s - loss: 5226282.2126 - val_loss: 4365292.2857\n",
      "Epoch 114/1000\n",
      "127/127 [==============================] - 0s - loss: 5209850.0453 - val_loss: 4353132.2500\n",
      "Epoch 115/1000\n",
      "127/127 [==============================] - 0s - loss: 5200855.0177 - val_loss: 4341226.2857\n",
      "Epoch 116/1000\n",
      "127/127 [==============================] - 0s - loss: 5182304.3051 - val_loss: 4329381.1429\n",
      "Epoch 117/1000\n",
      "127/127 [==============================] - 0s - loss: 5170293.3071 - val_loss: 4317269.7500\n",
      "Epoch 118/1000\n",
      "127/127 [==============================] - 0s - loss: 5148413.5669 - val_loss: 4305031.0357\n",
      "Epoch 119/1000\n",
      "127/127 [==============================] - 0s - loss: 5134006.8287 - val_loss: 4293515.2500\n",
      "Epoch 120/1000\n",
      "127/127 [==============================] - 0s - loss: 5135109.0039 - val_loss: 4281318.1071\n",
      "Epoch 121/1000\n",
      "127/127 [==============================] - 0s - loss: 5120695.6516 - val_loss: 4269303.4643\n",
      "Epoch 122/1000\n",
      "127/127 [==============================] - 0s - loss: 5088119.8425 - val_loss: 4257448.8929\n",
      "Epoch 123/1000\n",
      "127/127 [==============================] - 0s - loss: 5088653.8268 - val_loss: 4245650.9643\n",
      "Epoch 124/1000\n",
      "127/127 [==============================] - 0s - loss: 5075448.8268 - val_loss: 4233735.1429\n",
      "Epoch 125/1000\n",
      "127/127 [==============================] - 0s - loss: 5058587.8425 - val_loss: 4222048.8214\n",
      "Epoch 126/1000\n",
      "127/127 [==============================] - 0s - loss: 5065370.1142 - val_loss: 4210304.1786\n",
      "Epoch 127/1000\n",
      "127/127 [==============================] - 0s - loss: 5038135.7106 - val_loss: 4198624.1429\n",
      "Epoch 128/1000\n",
      "127/127 [==============================] - 0s - loss: 5026181.8346 - val_loss: 4186660.4286\n",
      "Epoch 129/1000\n",
      "127/127 [==============================] - 0s - loss: 5017559.9173 - val_loss: 4174901.1786\n",
      "Epoch 130/1000\n",
      "127/127 [==============================] - 0s - loss: 5010652.4075 - val_loss: 4163450.4643\n",
      "Epoch 131/1000\n",
      "127/127 [==============================] - 0s - loss: 5006023.1024 - val_loss: 4151505.8929\n",
      "Epoch 132/1000\n",
      "127/127 [==============================] - 0s - loss: 4992324.1791 - val_loss: 4140128.3214\n",
      "Epoch 133/1000\n",
      "127/127 [==============================] - 0s - loss: 4991788.5020 - val_loss: 4128174.4643\n",
      "Epoch 134/1000\n",
      "127/127 [==============================] - 0s - loss: 4950871.6929 - val_loss: 4116634.5357\n",
      "Epoch 135/1000\n",
      "127/127 [==============================] - 0s - loss: 4953510.7224 - val_loss: 4104887.0357\n",
      "Epoch 136/1000\n",
      "127/127 [==============================] - 0s - loss: 4938006.2047 - val_loss: 4093120.5714\n",
      "Epoch 137/1000\n",
      "127/127 [==============================] - 0s - loss: 4929508.1161 - val_loss: 4081587.1786\n",
      "Epoch 138/1000\n",
      "127/127 [==============================] - 0s - loss: 4920733.4744 - val_loss: 4070283.1429\n",
      "Epoch 139/1000\n",
      "127/127 [==============================] - 0s - loss: 4920046.6457 - val_loss: 4058675.4643\n",
      "Epoch 140/1000\n",
      "127/127 [==============================] - 0s - loss: 4879694.1339 - val_loss: 4047017.2857\n",
      "Epoch 141/1000\n",
      "127/127 [==============================] - 0s - loss: 4888994.2185 - val_loss: 4035432.5357\n",
      "Epoch 142/1000\n",
      "127/127 [==============================] - 0s - loss: 4863073.2421 - val_loss: 4024201.1786\n",
      "Epoch 143/1000\n",
      "127/127 [==============================] - 0s - loss: 4856775.2992 - val_loss: 4012335.8929\n",
      "Epoch 144/1000\n",
      "127/127 [==============================] - 0s - loss: 4854852.8425 - val_loss: 4000766.3929\n",
      "Epoch 145/1000\n",
      "127/127 [==============================] - 0s - loss: 4833010.1772 - val_loss: 3989077.7500\n",
      "Epoch 146/1000\n",
      "127/127 [==============================] - 0s - loss: 4846273.2618 - val_loss: 3977968.7500\n",
      "Epoch 147/1000\n",
      "127/127 [==============================] - 0s - loss: 4806724.4488 - val_loss: 3966576.3214\n",
      "Epoch 148/1000\n",
      "127/127 [==============================] - 0s - loss: 4794828.1535 - val_loss: 3955284.1071\n",
      "Epoch 149/1000\n",
      "127/127 [==============================] - 0s - loss: 4785065.6220 - val_loss: 3943857.9643\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 4770708.5886 - val_loss: 3932457.4643\n",
      "Epoch 151/1000\n",
      "127/127 [==============================] - 0s - loss: 4766570.8169 - val_loss: 3921562.6786\n",
      "Epoch 152/1000\n",
      "127/127 [==============================] - 0s - loss: 4755527.6417 - val_loss: 3910173.2500\n",
      "Epoch 153/1000\n",
      "127/127 [==============================] - 0s - loss: 4734190.1811 - val_loss: 3898857.0357\n",
      "Epoch 154/1000\n",
      "127/127 [==============================] - 0s - loss: 4727711.2146 - val_loss: 3887527.3571\n",
      "Epoch 155/1000\n",
      "127/127 [==============================] - 0s - loss: 4709293.2047 - val_loss: 3876489.8571\n",
      "Epoch 156/1000\n",
      "127/127 [==============================] - 0s - loss: 4680267.3642 - val_loss: 3865139.3571\n",
      "Epoch 157/1000\n",
      "127/127 [==============================] - 0s - loss: 4688147.6909 - val_loss: 3854051.7500\n",
      "Epoch 158/1000\n",
      "127/127 [==============================] - 0s - loss: 4672969.5512 - val_loss: 3842666.0714\n",
      "Epoch 159/1000\n",
      "127/127 [==============================] - 0s - loss: 4664795.5945 - val_loss: 3831679.1071\n",
      "Epoch 160/1000\n",
      "127/127 [==============================] - 0s - loss: 4666338.4961 - val_loss: 3820164.3929\n",
      "Epoch 161/1000\n",
      "127/127 [==============================] - 0s - loss: 4645845.0984 - val_loss: 3809086.0357\n",
      "Epoch 162/1000\n",
      "127/127 [==============================] - 0s - loss: 4634095.8238 - val_loss: 3798145.0357\n",
      "Epoch 163/1000\n",
      "127/127 [==============================] - 0s - loss: 4606074.9380 - val_loss: 3787005.7500\n",
      "Epoch 164/1000\n",
      "127/127 [==============================] - 0s - loss: 4608176.8799 - val_loss: 3776098.3571\n",
      "Epoch 165/1000\n",
      "127/127 [==============================] - 0s - loss: 4607026.3366 - val_loss: 3765067.8571\n",
      "Epoch 166/1000\n",
      "127/127 [==============================] - 0s - loss: 4578816.1004 - val_loss: 3753948.3214\n",
      "Epoch 167/1000\n",
      "127/127 [==============================] - 0s - loss: 4568146.6043 - val_loss: 3742829.0357\n",
      "Epoch 168/1000\n",
      "127/127 [==============================] - 0s - loss: 4567622.9193 - val_loss: 3731921.7500\n",
      "Epoch 169/1000\n",
      "127/127 [==============================] - 0s - loss: 4553939.5827 - val_loss: 3721011.214361723.50\n",
      "Epoch 170/1000\n",
      "127/127 [==============================] - 0s - loss: 4544348.0335 - val_loss: 3710216.9643\n",
      "Epoch 171/1000\n",
      "127/127 [==============================] - 0s - loss: 4524779.0118 - val_loss: 3699339.6429\n",
      "Epoch 172/1000\n",
      "127/127 [==============================] - 0s - loss: 4518355.2854 - val_loss: 3688464.1429\n",
      "Epoch 173/1000\n",
      "127/127 [==============================] - 0s - loss: 4512626.3031 - val_loss: 3677311.5714\n",
      "Epoch 174/1000\n",
      "127/127 [==============================] - 0s - loss: 4493578.7480 - val_loss: 3666324.7143\n",
      "Epoch 175/1000\n",
      "127/127 [==============================] - 0s - loss: 4481150.4173 - val_loss: 3655432.5357\n",
      "Epoch 176/1000\n",
      "127/127 [==============================] - 0s - loss: 4465416.1412 - val_loss: 3644772.7857\n",
      "Epoch 177/1000\n",
      "127/127 [==============================] - 0s - loss: 4461085.6417 - val_loss: 3633944.1071\n",
      "Epoch 178/1000\n",
      "127/127 [==============================] - 0s - loss: 4448734.6201 - val_loss: 3623180.1786\n",
      "Epoch 179/1000\n",
      "127/127 [==============================] - 0s - loss: 4434636.1033 - val_loss: 3612236.6786\n",
      "Epoch 180/1000\n",
      "127/127 [==============================] - 0s - loss: 4427552.1673 - val_loss: 3601603.3571\n",
      "Epoch 181/1000\n",
      "127/127 [==============================] - 0s - loss: 4407752.2638 - val_loss: 3590993.5000\n",
      "Epoch 182/1000\n",
      "127/127 [==============================] - 0s - loss: 4394519.1831 - val_loss: 3580209.750046966.\n",
      "Epoch 183/1000\n",
      "127/127 [==============================] - 0s - loss: 4417926.8238 - val_loss: 3569812.1786\n",
      "Epoch 184/1000\n",
      "127/127 [==============================] - 0s - loss: 4400272.8238 - val_loss: 3559157.4286\n",
      "Epoch 185/1000\n",
      "127/127 [==============================] - 0s - loss: 4390402.1870 - val_loss: 3548132.6429\n",
      "Epoch 186/1000\n",
      "127/127 [==============================] - 0s - loss: 4356714.6437 - val_loss: 3537562.1429\n",
      "Epoch 187/1000\n",
      "127/127 [==============================] - 0s - loss: 4351543.6398 - val_loss: 3526909.1786\n",
      "Epoch 188/1000\n",
      "127/127 [==============================] - 0s - loss: 4351990.2913 - val_loss: 3516429.8571\n",
      "Epoch 189/1000\n",
      "127/127 [==============================] - 0s - loss: 4327139.4508 - val_loss: 3505265.7500\n",
      "Epoch 190/1000\n",
      "127/127 [==============================] - 0s - loss: 4310353.2461 - val_loss: 3494999.8214\n",
      "Epoch 191/1000\n",
      "127/127 [==============================] - 0s - loss: 4319209.0925 - val_loss: 3484452.3214\n",
      "Epoch 192/1000\n",
      "127/127 [==============================] - 0s - loss: 4300030.5512 - val_loss: 3473827.4286\n",
      "Epoch 193/1000\n",
      "127/127 [==============================] - 0s - loss: 4279024.2835 - val_loss: 3463395.2143\n",
      "Epoch 194/1000\n",
      "127/127 [==============================] - 0s - loss: 4281916.0787 - val_loss: 3452837.3929\n",
      "Epoch 195/1000\n",
      "127/127 [==============================] - 0s - loss: 4255039.5236 - val_loss: 3442351.4643\n",
      "Epoch 196/1000\n",
      "127/127 [==============================] - 0s - loss: 4247130.8169 - val_loss: 3431992.2143\n",
      "Epoch 197/1000\n",
      "127/127 [==============================] - 0s - loss: 4255077.0433 - val_loss: 3421331.1786\n",
      "Epoch 198/1000\n",
      "127/127 [==============================] - 0s - loss: 4240220.8622 - val_loss: 3411088.7143\n",
      "Epoch 199/1000\n",
      "127/127 [==============================] - 0s - loss: 4224374.0984 - val_loss: 3400622.9643\n",
      "Epoch 200/1000\n",
      "127/127 [==============================] - 0s - loss: 4202570.6969 - val_loss: 3390276.0714\n",
      "Epoch 201/1000\n",
      "127/127 [==============================] - 0s - loss: 4200796.7283 - val_loss: 3379511.1071\n",
      "Epoch 202/1000\n",
      "127/127 [==============================] - 0s - loss: 4173585.5925 - val_loss: 3369559.1071\n",
      "Epoch 203/1000\n",
      "127/127 [==============================] - 0s - loss: 4191962.6575 - val_loss: 3359305.1429\n",
      "Epoch 204/1000\n",
      "127/127 [==============================] - 0s - loss: 4184484.8976 - val_loss: 3348744.6071\n",
      "Epoch 205/1000\n",
      "127/127 [==============================] - 0s - loss: 4162465.1063 - val_loss: 3338185.8929\n",
      "Epoch 206/1000\n",
      "127/127 [==============================] - 0s - loss: 4149133.0413 - val_loss: 3328198.1786\n",
      "Epoch 207/1000\n",
      "127/127 [==============================] - 0s - loss: 4132102.6142 - val_loss: 3317993.8929\n",
      "Epoch 208/1000\n",
      "127/127 [==============================] - 0s - loss: 4128039.5709 - val_loss: 3307463.5357\n",
      "Epoch 209/1000\n",
      "127/127 [==============================] - 0s - loss: 4117855.7598 - val_loss: 3297472.3929\n",
      "Epoch 210/1000\n",
      "127/127 [==============================] - 0s - loss: 4091710.6575 - val_loss: 3287752.5000\n",
      "Epoch 211/1000\n",
      "127/127 [==============================] - 0s - loss: 4089123.1919 - val_loss: 3277207.8214\n",
      "Epoch 212/1000\n",
      "127/127 [==============================] - 0s - loss: 4096203.5295 - val_loss: 3267319.0357\n",
      "Epoch 213/1000\n",
      "127/127 [==============================] - 0s - loss: 4093617.7559 - val_loss: 3257148.3214\n",
      "Epoch 214/1000\n",
      "127/127 [==============================] - 0s - loss: 4050999.1211 - val_loss: 3247180.7143\n",
      "Epoch 215/1000\n",
      "127/127 [==============================] - 0s - loss: 4051473.1870 - val_loss: 3236920.1071\n",
      "Epoch 216/1000\n",
      "127/127 [==============================] - 0s - loss: 4062242.6713 - val_loss: 3226656.4286\n",
      "Epoch 217/1000\n",
      "127/127 [==============================] - 0s - loss: 4038663.9016 - val_loss: 3216570.0000\n",
      "Epoch 218/1000\n",
      "127/127 [==============================] - 0s - loss: 4027686.5069 - val_loss: 3206507.9286\n",
      "Epoch 219/1000\n",
      "127/127 [==============================] - 0s - loss: 3998989.7126 - val_loss: 3196319.9286\n",
      "Epoch 220/1000\n",
      "127/127 [==============================] - 0s - loss: 4005255.2283 - val_loss: 3186575.8571\n",
      "Epoch 221/1000\n",
      "127/127 [==============================] - 0s - loss: 3989296.0246 - val_loss: 3176684.7857\n",
      "Epoch 222/1000\n",
      "127/127 [==============================] - 0s - loss: 3984179.0069 - val_loss: 3166821.4643\n",
      "Epoch 223/1000\n",
      "127/127 [==============================] - 0s - loss: 3972190.5551 - val_loss: 3156911.0357\n",
      "Epoch 224/1000\n",
      "127/127 [==============================] - 0s - loss: 3968356.2402 - val_loss: 3146991.6429\n",
      "Epoch 225/1000\n",
      "127/127 [==============================] - 0s - loss: 3962356.4783 - val_loss: 3136788.5714\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 3939732.1683 - val_loss: 3127011.9286\n",
      "Epoch 227/1000\n",
      "127/127 [==============================] - 0s - loss: 3926863.4843 - val_loss: 3116971.3036\n",
      "Epoch 228/1000\n",
      "127/127 [==============================] - 0s - loss: 3915475.0453 - val_loss: 3107297.3750\n",
      "Epoch 229/1000\n",
      "127/127 [==============================] - 0s - loss: 3894019.2992 - val_loss: 3097436.7679\n",
      "Epoch 230/1000\n",
      "127/127 [==============================] - 0s - loss: 3909923.2067 - val_loss: 3087779.4286\n",
      "Epoch 231/1000\n",
      "127/127 [==============================] - 0s - loss: 3891717.7657 - val_loss: 3077851.0000\n",
      "Epoch 232/1000\n",
      "127/127 [==============================] - 0s - loss: 3889787.5866 - val_loss: 3068183.5714\n",
      "Epoch 233/1000\n",
      "127/127 [==============================] - 0s - loss: 3860768.3120 - val_loss: 3058862.8750\n",
      "Epoch 234/1000\n",
      "127/127 [==============================] - 0s - loss: 3855694.1604 - val_loss: 3049013.7143\n",
      "Epoch 235/1000\n",
      "127/127 [==============================] - 0s - loss: 3865092.5886 - val_loss: 3039236.1964\n",
      "Epoch 236/1000\n",
      "127/127 [==============================] - 0s - loss: 3840249.1555 - val_loss: 3029729.1429\n",
      "Epoch 237/1000\n",
      "127/127 [==============================] - 0s - loss: 3833873.6880 - val_loss: 3019818.4286\n",
      "Epoch 238/1000\n",
      "127/127 [==============================] - 0s - loss: 3814138.7165 - val_loss: 3010007.9464\n",
      "Epoch 239/1000\n",
      "127/127 [==============================] - 0s - loss: 3794233.9813 - val_loss: 3000600.6250\n",
      "Epoch 240/1000\n",
      "127/127 [==============================] - 0s - loss: 3806393.2638 - val_loss: 2991170.8036\n",
      "Epoch 241/1000\n",
      "127/127 [==============================] - 0s - loss: 3768968.9577 - val_loss: 2981323.5536\n",
      "Epoch 242/1000\n",
      "127/127 [==============================] - 0s - loss: 3755185.3071 - val_loss: 2971960.3393\n",
      "Epoch 243/1000\n",
      "127/127 [==============================] - 0s - loss: 3761965.0364 - val_loss: 2962579.7857\n",
      "Epoch 244/1000\n",
      "127/127 [==============================] - 0s - loss: 3777470.7874 - val_loss: 2952754.7143\n",
      "Epoch 245/1000\n",
      "127/127 [==============================] - 0s - loss: 3733879.5659 - val_loss: 2943409.3750\n",
      "Epoch 246/1000\n",
      "127/127 [==============================] - 0s - loss: 3739936.3504 - val_loss: 2933990.3036\n",
      "Epoch 247/1000\n",
      "127/127 [==============================] - 0s - loss: 3725962.7461 - val_loss: 2924347.0893\n",
      "Epoch 248/1000\n",
      "127/127 [==============================] - 0s - loss: 3703663.7835 - val_loss: 2914688.4464\n",
      "Epoch 249/1000\n",
      "127/127 [==============================] - 0s - loss: 3714703.5896 - val_loss: 2905538.7143\n",
      "Epoch 250/1000\n",
      "127/127 [==============================] - 0s - loss: 3706775.6427 - val_loss: 2896151.6250\n",
      "Epoch 251/1000\n",
      "127/127 [==============================] - 0s - loss: 3696175.7057 - val_loss: 2886625.9286\n",
      "Epoch 252/1000\n",
      "127/127 [==============================] - 0s - loss: 3662638.1220 - val_loss: 2877324.2143\n",
      "Epoch 253/1000\n",
      "127/127 [==============================] - 0s - loss: 3690337.7795 - val_loss: 2868118.0179\n",
      "Epoch 254/1000\n",
      "127/127 [==============================] - 0s - loss: 3675965.3593 - val_loss: 2858749.8571\n",
      "Epoch 255/1000\n",
      "127/127 [==============================] - 0s - loss: 3646928.0468 - val_loss: 2849753.7857\n",
      "Epoch 256/1000\n",
      "127/127 [==============================] - 0s - loss: 3663989.3150 - val_loss: 2840612.3750\n",
      "Epoch 257/1000\n",
      "127/127 [==============================] - 0s - loss: 3626525.3976 - val_loss: 2831184.8393\n",
      "Epoch 258/1000\n",
      "127/127 [==============================] - 0s - loss: 3613181.8041 - val_loss: 2821878.0000\n",
      "Epoch 259/1000\n",
      "127/127 [==============================] - 0s - loss: 3631298.7746 - val_loss: 2812994.3571\n",
      "Epoch 260/1000\n",
      "127/127 [==============================] - 0s - loss: 3619051.8091 - val_loss: 2803648.4821\n",
      "Epoch 261/1000\n",
      "127/127 [==============================] - 0s - loss: 3579078.9941 - val_loss: 2794510.8571\n",
      "Epoch 262/1000\n",
      "127/127 [==============================] - 0s - loss: 3576305.6752 - val_loss: 2785606.1250\n",
      "Epoch 263/1000\n",
      "127/127 [==============================] - 0s - loss: 3586405.0512 - val_loss: 2776042.2857\n",
      "Epoch 264/1000\n",
      "127/127 [==============================] - 0s - loss: 3539133.8209 - val_loss: 2766901.3393\n",
      "Epoch 265/1000\n",
      "127/127 [==============================] - 0s - loss: 3549844.9921 - val_loss: 2757628.3036\n",
      "Epoch 266/1000\n",
      "127/127 [==============================] - 0s - loss: 3528945.9134 - val_loss: 2748719.1250\n",
      "Epoch 267/1000\n",
      "127/127 [==============================] - 0s - loss: 3519548.5394 - val_loss: 2739399.3036\n",
      "Epoch 268/1000\n",
      "127/127 [==============================] - 0s - loss: 3527006.0266 - val_loss: 2730215.9107\n",
      "Epoch 269/1000\n",
      "127/127 [==============================] - 0s - loss: 3527276.5177 - val_loss: 2721271.9821\n",
      "Epoch 270/1000\n",
      "127/127 [==============================] - 0s - loss: 3525856.4173 - val_loss: 2712616.5714\n",
      "Epoch 271/1000\n",
      "127/127 [==============================] - 0s - loss: 3519323.7500 - val_loss: 2703615.4107\n",
      "Epoch 272/1000\n",
      "127/127 [==============================] - 0s - loss: 3470562.3238 - val_loss: 2694379.7857\n",
      "Epoch 273/1000\n",
      "127/127 [==============================] - 0s - loss: 3466650.1693 - val_loss: 2685123.9821\n",
      "Epoch 274/1000\n",
      "127/127 [==============================] - 0s - loss: 3477405.6211 - val_loss: 2676377.5893\n",
      "Epoch 275/1000\n",
      "127/127 [==============================] - 0s - loss: 3469903.3819 - val_loss: 2667575.5714\n",
      "Epoch 276/1000\n",
      "127/127 [==============================] - 0s - loss: 3421295.3061 - val_loss: 2658758.5893\n",
      "Epoch 277/1000\n",
      "127/127 [==============================] - 0s - loss: 3451590.6919 - val_loss: 2649638.2321\n",
      "Epoch 278/1000\n",
      "127/127 [==============================] - 0s - loss: 3436264.5226 - val_loss: 2640839.6429\n",
      "Epoch 279/1000\n",
      "127/127 [==============================] - 0s - loss: 3428554.2096 - val_loss: 2632003.7143\n",
      "Epoch 280/1000\n",
      "127/127 [==============================] - 0s - loss: 3424864.0581 - val_loss: 2622977.8571\n",
      "Epoch 281/1000\n",
      "127/127 [==============================] - 0s - loss: 3395975.3878 - val_loss: 2614140.6964433\n",
      "Epoch 282/1000\n",
      "127/127 [==============================] - 0s - loss: 3396260.4301 - val_loss: 2605625.0893\n",
      "Epoch 283/1000\n",
      "127/127 [==============================] - 0s - loss: 3404865.2618 - val_loss: 2596587.5893\n",
      "Epoch 284/1000\n",
      "127/127 [==============================] - 0s - loss: 3376518.6673 - val_loss: 2587931.5000\n",
      "Epoch 285/1000\n",
      "127/127 [==============================] - 0s - loss: 3383450.9272 - val_loss: 2578986.7143\n",
      "Epoch 286/1000\n",
      "127/127 [==============================] - 0s - loss: 3371130.7352 - val_loss: 2570291.7679\n",
      "Epoch 287/1000\n",
      "127/127 [==============================] - 0s - loss: 3362098.2500 - val_loss: 2561647.4464\n",
      "Epoch 288/1000\n",
      "127/127 [==============================] - 0s - loss: 3333000.7106 - val_loss: 2552950.1250\n",
      "Epoch 289/1000\n",
      "127/127 [==============================] - 0s - loss: 3366301.2343 - val_loss: 2544349.2679\n",
      "Epoch 290/1000\n",
      "127/127 [==============================] - 0s - loss: 3328469.6161 - val_loss: 2535475.8393\n",
      "Epoch 291/1000\n",
      "127/127 [==============================] - 0s - loss: 3329147.1919 - val_loss: 2527136.5000\n",
      "Epoch 292/1000\n",
      "127/127 [==============================] - 0s - loss: 3305554.1949 - val_loss: 2518324.9821\n",
      "Epoch 293/1000\n",
      "127/127 [==============================] - 0s - loss: 3322597.4390 - val_loss: 2509885.4464\n",
      "Epoch 294/1000\n",
      "127/127 [==============================] - 0s - loss: 3302798.1658 - val_loss: 2501478.2143\n",
      "Epoch 295/1000\n",
      "127/127 [==============================] - 0s - loss: 3280933.9380 - val_loss: 2492491.9464\n",
      "Epoch 296/1000\n",
      "127/127 [==============================] - 0s - loss: 3286380.2854 - val_loss: 2484034.8750\n",
      "Epoch 297/1000\n",
      "127/127 [==============================] - 0s - loss: 3244420.3219 - val_loss: 2475495.2143\n",
      "Epoch 298/1000\n",
      "127/127 [==============================] - 0s - loss: 3262565.0157 - val_loss: 2467008.7143\n",
      "Epoch 299/1000\n",
      "127/127 [==============================] - 0s - loss: 3234947.1969 - val_loss: 2458476.1429\n",
      "Epoch 300/1000\n",
      "127/127 [==============================] - 0s - loss: 3244727.2343 - val_loss: 2449986.0000\n",
      "Epoch 301/1000\n",
      "127/127 [==============================] - 0s - loss: 3230140.6309 - val_loss: 2441386.0714\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 3230347.7510 - val_loss: 2433294.5536\n",
      "Epoch 303/1000\n",
      "127/127 [==============================] - 0s - loss: 3228569.6535 - val_loss: 2424755.7321\n",
      "Epoch 304/1000\n",
      "127/127 [==============================] - 0s - loss: 3185493.9587 - val_loss: 2416528.6607\n",
      "Epoch 305/1000\n",
      "127/127 [==============================] - 0s - loss: 3224984.5098 - val_loss: 2408176.1964\n",
      "Epoch 306/1000\n",
      "127/127 [==============================] - 0s - loss: 3175562.7008 - val_loss: 2400185.2143\n",
      "Epoch 307/1000\n",
      "127/127 [==============================] - 0s - loss: 3175522.3110 - val_loss: 2391588.9107\n",
      "Epoch 308/1000\n",
      "127/127 [==============================] - 0s - loss: 3158273.1634 - val_loss: 2383520.5000\n",
      "Epoch 309/1000\n",
      "127/127 [==============================] - 0s - loss: 3183336.0005 - val_loss: 2375397.2857\n",
      "Epoch 310/1000\n",
      "127/127 [==============================] - 0s - loss: 3171040.0148 - val_loss: 2367112.3393\n",
      "Epoch 311/1000\n",
      "127/127 [==============================] - 0s - loss: 3150307.4380 - val_loss: 2359014.6607\n",
      "Epoch 312/1000\n",
      "127/127 [==============================] - 0s - loss: 3096100.5217 - val_loss: 2350762.0714\n",
      "Epoch 313/1000\n",
      "127/127 [==============================] - 0s - loss: 3132306.3981 - val_loss: 2342886.4286\n",
      "Epoch 314/1000\n",
      "127/127 [==============================] - 0s - loss: 3125490.5591 - val_loss: 2334463.4107\n",
      "Epoch 315/1000\n",
      "127/127 [==============================] - 0s - loss: 3090535.7697 - val_loss: 2326328.8036\n",
      "Epoch 316/1000\n",
      "127/127 [==============================] - 0s - loss: 3131841.1781 - val_loss: 2318256.4286\n",
      "Epoch 317/1000\n",
      "127/127 [==============================] - 0s - loss: 3103943.1142 - val_loss: 2310168.0536\n",
      "Epoch 318/1000\n",
      "127/127 [==============================] - 0s - loss: 3101338.4744 - val_loss: 2302194.4107\n",
      "Epoch 319/1000\n",
      "127/127 [==============================] - 0s - loss: 3081097.5315 - val_loss: 2294228.9464\n",
      "Epoch 320/1000\n",
      "127/127 [==============================] - 0s - loss: 3063200.2190 - val_loss: 2286260.0714\n",
      "Epoch 321/1000\n",
      "127/127 [==============================] - 0s - loss: 3056816.9665 - val_loss: 2278356.7321\n",
      "Epoch 322/1000\n",
      "127/127 [==============================] - 0s - loss: 3065574.3509 - val_loss: 2270480.3929\n",
      "Epoch 323/1000\n",
      "127/127 [==============================] - 0s - loss: 3046508.4852 - val_loss: 2262290.6429\n",
      "Epoch 324/1000\n",
      "127/127 [==============================] - 0s - loss: 3034597.4154 - val_loss: 2254135.1964\n",
      "Epoch 325/1000\n",
      "127/127 [==============================] - 0s - loss: 3034704.4508 - val_loss: 2246278.0536\n",
      "Epoch 326/1000\n",
      "127/127 [==============================] - 0s - loss: 3019127.0571 - val_loss: 2238426.7679\n",
      "Epoch 327/1000\n",
      "127/127 [==============================] - 0s - loss: 3004691.4774 - val_loss: 2230595.9464\n",
      "Epoch 328/1000\n",
      "127/127 [==============================] - 0s - loss: 3024847.6417 - val_loss: 2222660.3393\n",
      "Epoch 329/1000\n",
      "127/127 [==============================] - 0s - loss: 2985997.6496 - val_loss: 2214575.0000\n",
      "Epoch 330/1000\n",
      "127/127 [==============================] - 0s - loss: 2997261.8563 - val_loss: 2206743.4821\n",
      "Epoch 331/1000\n",
      "127/127 [==============================] - 0s - loss: 2982900.1142 - val_loss: 2198583.4464\n",
      "Epoch 332/1000\n",
      "127/127 [==============================] - 0s - loss: 2986038.8784 - val_loss: 2191138.3036\n",
      "Epoch 333/1000\n",
      "127/127 [==============================] - 0s - loss: 2925197.5049 - val_loss: 2183504.3929\n",
      "Epoch 334/1000\n",
      "127/127 [==============================] - 0s - loss: 2964494.6432 - val_loss: 2175721.0000\n",
      "Epoch 335/1000\n",
      "127/127 [==============================] - 0s - loss: 2983723.9336 - val_loss: 2167703.2143\n",
      "Epoch 336/1000\n",
      "127/127 [==============================] - 0s - loss: 2939431.6752 - val_loss: 2159962.7857\n",
      "Epoch 337/1000\n",
      "127/127 [==============================] - 0s - loss: 2945821.5778 - val_loss: 2152422.5536\n",
      "Epoch 338/1000\n",
      "127/127 [==============================] - 0s - loss: 2931145.8278 - val_loss: 2144567.3393\n",
      "Epoch 339/1000\n",
      "127/127 [==============================] - 0s - loss: 2901787.9567 - val_loss: 2136419.982188631\n",
      "Epoch 340/1000\n",
      "127/127 [==============================] - 0s - loss: 2904035.0212 - val_loss: 2129229.4821\n",
      "Epoch 341/1000\n",
      "127/127 [==============================] - 0s - loss: 2886323.7392 - val_loss: 2121642.3750\n",
      "Epoch 342/1000\n",
      "127/127 [==============================] - 0s - loss: 2887586.5443 - val_loss: 2114260.4821\n",
      "Epoch 343/1000\n",
      "127/127 [==============================] - 0s - loss: 2910337.3189 - val_loss: 2106363.4821\n",
      "Epoch 344/1000\n",
      "127/127 [==============================] - 0s - loss: 2863273.7539 - val_loss: 2098669.8750\n",
      "Epoch 345/1000\n",
      "127/127 [==============================] - 0s - loss: 2842691.7835 - val_loss: 2090847.0000\n",
      "Epoch 346/1000\n",
      "127/127 [==============================] - 0s - loss: 2855383.9724 - val_loss: 2083922.3393\n",
      "Epoch 347/1000\n",
      "127/127 [==============================] - 0s - loss: 2845931.8346 - val_loss: 2076181.8214\n",
      "Epoch 348/1000\n",
      "127/127 [==============================] - 0s - loss: 2841386.9528 - val_loss: 2069170.8750\n",
      "Epoch 349/1000\n",
      "127/127 [==============================] - 0s - loss: 2805087.9916 - val_loss: 2061550.0893\n",
      "Epoch 350/1000\n",
      "127/127 [==============================] - 0s - loss: 2855574.5433 - val_loss: 2053991.7857\n",
      "Epoch 351/1000\n",
      "127/127 [==============================] - 0s - loss: 2813756.7677 - val_loss: 2046334.0179\n",
      "Epoch 352/1000\n",
      "127/127 [==============================] - 0s - loss: 2782267.4213 - val_loss: 2039086.0179\n",
      "Epoch 353/1000\n",
      "127/127 [==============================] - 0s - loss: 2821217.1230 - val_loss: 2031907.5179\n",
      "Epoch 354/1000\n",
      "127/127 [==============================] - 0s - loss: 2812240.3371 - val_loss: 2024280.4107\n",
      "Epoch 355/1000\n",
      "127/127 [==============================] - 0s - loss: 2795136.2874 - val_loss: 2016776.3750\n",
      "Epoch 356/1000\n",
      "127/127 [==============================] - 0s - loss: 2797768.9724 - val_loss: 2009374.9107\n",
      "Epoch 357/1000\n",
      "127/127 [==============================] - 0s - loss: 2794732.3268 - val_loss: 2002129.5179\n",
      "Epoch 358/1000\n",
      "127/127 [==============================] - 0s - loss: 2757267.2899 - val_loss: 1994594.8750\n",
      "Epoch 359/1000\n",
      "127/127 [==============================] - 0s - loss: 2752261.8504 - val_loss: 1987639.3750\n",
      "Epoch 360/1000\n",
      "127/127 [==============================] - 0s - loss: 2748317.3917 - val_loss: 1980190.0000\n",
      "Epoch 361/1000\n",
      "127/127 [==============================] - 0s - loss: 2742196.6093 - val_loss: 1973116.1607\n",
      "Epoch 362/1000\n",
      "127/127 [==============================] - 0s - loss: 2747946.7874 - val_loss: 1965491.1071\n",
      "Epoch 363/1000\n",
      "127/127 [==============================] - 0s - loss: 2726598.2283 - val_loss: 1958504.6964\n",
      "Epoch 364/1000\n",
      "127/127 [==============================] - 0s - loss: 2720598.5325 - val_loss: 1951051.5179\n",
      "Epoch 365/1000\n",
      "127/127 [==============================] - 0s - loss: 2714356.7589 - val_loss: 1943951.8750\n",
      "Epoch 366/1000\n",
      "127/127 [==============================] - 0s - loss: 2683421.9774 - val_loss: 1936973.2321\n",
      "Epoch 367/1000\n",
      "127/127 [==============================] - 0s - loss: 2684117.7308 - val_loss: 1929908.2679\n",
      "Epoch 368/1000\n",
      "127/127 [==============================] - 0s - loss: 2692246.8120 - val_loss: 1922717.8393\n",
      "Epoch 369/1000\n",
      "127/127 [==============================] - 0s - loss: 2700137.9744 - val_loss: 1915655.3393\n",
      "Epoch 370/1000\n",
      "127/127 [==============================] - 0s - loss: 2676370.1491 - val_loss: 1908615.3214\n",
      "Epoch 371/1000\n",
      "127/127 [==============================] - 0s - loss: 2672798.9774 - val_loss: 1901525.4107\n",
      "Epoch 372/1000\n",
      "127/127 [==============================] - 0s - loss: 2654280.6506 - val_loss: 1894386.8393\n",
      "Epoch 373/1000\n",
      "127/127 [==============================] - 0s - loss: 2621406.7249 - val_loss: 1887280.6964\n",
      "Epoch 374/1000\n",
      "127/127 [==============================] - 0s - loss: 2651957.6467 - val_loss: 1880217.8750\n",
      "Epoch 375/1000\n",
      "127/127 [==============================] - 0s - loss: 2643631.3701 - val_loss: 1873107.732106007.713\n",
      "Epoch 376/1000\n",
      "127/127 [==============================] - 0s - loss: 2611736.0089 - val_loss: 1866110.5714\n",
      "Epoch 377/1000\n",
      "127/127 [==============================] - 0s - loss: 2629937.4744 - val_loss: 1858755.2857\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 2662613.1909 - val_loss: 1851956.8393\n",
      "Epoch 379/1000\n",
      "127/127 [==============================] - 0s - loss: 2614969.7702 - val_loss: 1845153.9643\n",
      "Epoch 380/1000\n",
      "127/127 [==============================] - 0s - loss: 2602489.7515 - val_loss: 1838189.6339\n",
      "Epoch 381/1000\n",
      "127/127 [==============================] - 0s - loss: 2573702.5935 - val_loss: 1831309.3214\n",
      "Epoch 382/1000\n",
      "127/127 [==============================] - 0s - loss: 2576484.8317 - val_loss: 1824412.7857\n",
      "Epoch 383/1000\n",
      "127/127 [==============================] - 0s - loss: 2581955.5940 - val_loss: 1817703.6696\n",
      "Epoch 384/1000\n",
      "127/127 [==============================] - 0s - loss: 2573081.5458 - val_loss: 1811022.3571\n",
      "Epoch 385/1000\n",
      "127/127 [==============================] - 0s - loss: 2558946.9961 - val_loss: 1804207.0446\n",
      "Epoch 386/1000\n",
      "127/127 [==============================] - 0s - loss: 2558488.7539 - val_loss: 1797153.6786\n",
      "Epoch 387/1000\n",
      "127/127 [==============================] - 0s - loss: 2557170.1112 - val_loss: 1790676.6518\n",
      "Epoch 388/1000\n",
      "127/127 [==============================] - 0s - loss: 2557729.3268 - val_loss: 1783864.5625\n",
      "Epoch 389/1000\n",
      "127/127 [==============================] - 0s - loss: 2509029.9400 - val_loss: 1777327.5625\n",
      "Epoch 390/1000\n",
      "127/127 [==============================] - 0s - loss: 2536856.6998 - val_loss: 1770347.0625\n",
      "Epoch 391/1000\n",
      "127/127 [==============================] - 0s - loss: 2529985.9911 - val_loss: 1763729.8125\n",
      "Epoch 392/1000\n",
      "127/127 [==============================] - 0s - loss: 2542483.3750 - val_loss: 1756847.88390735\n",
      "Epoch 393/1000\n",
      "127/127 [==============================] - 0s - loss: 2503826.0512 - val_loss: 1750297.0982\n",
      "Epoch 394/1000\n",
      "127/127 [==============================] - 0s - loss: 2502991.9739 - val_loss: 1743874.0625\n",
      "Epoch 395/1000\n",
      "127/127 [==============================] - 0s - loss: 2487291.3996 - val_loss: 1737108.4911\n",
      "Epoch 396/1000\n",
      "127/127 [==============================] - 0s - loss: 2496525.7564 - val_loss: 1730478.6339\n",
      "Epoch 397/1000\n",
      "127/127 [==============================] - 0s - loss: 2483081.4774 - val_loss: 1723736.1875\n",
      "Epoch 398/1000\n",
      "127/127 [==============================] - 0s - loss: 2486277.9872 - val_loss: 1717516.9286\n",
      "Epoch 399/1000\n",
      "127/127 [==============================] - 0s - loss: 2465011.4921 - val_loss: 1710496.5268\n",
      "Epoch 400/1000\n",
      "127/127 [==============================] - 0s - loss: 2463847.1093 - val_loss: 1703941.9554\n",
      "Epoch 401/1000\n",
      "127/127 [==============================] - 0s - loss: 2441777.7357 - val_loss: 1697643.2054\n",
      "Epoch 402/1000\n",
      "127/127 [==============================] - 0s - loss: 2444696.1668 - val_loss: 1691150.348229045.\n",
      "Epoch 403/1000\n",
      "127/127 [==============================] - 0s - loss: 2432047.0221 - val_loss: 1684540.1429\n",
      "Epoch 404/1000\n",
      "127/127 [==============================] - 0s - loss: 2428769.3425 - val_loss: 1678249.1161\n",
      "Epoch 405/1000\n",
      "127/127 [==============================] - 0s - loss: 2446844.1216 - val_loss: 1671940.0714\n",
      "Epoch 406/1000\n",
      "127/127 [==============================] - 0s - loss: 2408524.1476 - val_loss: 1665094.4286\n",
      "Epoch 407/1000\n",
      "127/127 [==============================] - 0s - loss: 2432385.4498 - val_loss: 1658854.0357\n",
      "Epoch 408/1000\n",
      "127/127 [==============================] - 0s - loss: 2398897.0202 - val_loss: 1652123.9375\n",
      "Epoch 409/1000\n",
      "127/127 [==============================] - 0s - loss: 2398346.6083 - val_loss: 1645792.6696\n",
      "Epoch 410/1000\n",
      "127/127 [==============================] - 0s - loss: 2392854.8661 - val_loss: 1639151.4554276\n",
      "Epoch 411/1000\n",
      "127/127 [==============================] - 0s - loss: 2394341.7594 - val_loss: 1632911.6518\n",
      "Epoch 412/1000\n",
      "127/127 [==============================] - 0s - loss: 2368377.8730 - val_loss: 1626715.8661\n",
      "Epoch 413/1000\n",
      "127/127 [==============================] - 0s - loss: 2349155.1407 - val_loss: 1620215.5446\n",
      "Epoch 414/1000\n",
      "127/127 [==============================] - 0s - loss: 2347149.8868 - val_loss: 1613745.4196\n",
      "Epoch 415/1000\n",
      "127/127 [==============================] - 0s - loss: 2367627.3622 - val_loss: 1607523.2054\n",
      "Epoch 416/1000\n",
      "127/127 [==============================] - 0s - loss: 2353961.7293 - val_loss: 1601104.473215880.0\n",
      "Epoch 417/1000\n",
      "127/127 [==============================] - 0s - loss: 2331658.6383 - val_loss: 1595257.3839\n",
      "Epoch 418/1000\n",
      "127/127 [==============================] - 0s - loss: 2329213.7421 - val_loss: 1588974.1429\n",
      "Epoch 419/1000\n",
      "127/127 [==============================] - 0s - loss: 2340644.9478 - val_loss: 1582684.4196\n",
      "Epoch 420/1000\n",
      "127/127 [==============================] - 0s - loss: 2315553.2064 - val_loss: 1576610.2143\n",
      "Epoch 421/1000\n",
      "127/127 [==============================] - 0s - loss: 2328956.8898 - val_loss: 1570126.6786\n",
      "Epoch 422/1000\n",
      "127/127 [==============================] - 0s - loss: 2324435.6545 - val_loss: 1564216.4911621\n",
      "Epoch 423/1000\n",
      "127/127 [==============================] - 0s - loss: 2311400.3297 - val_loss: 1557827.6696\n",
      "Epoch 424/1000\n",
      "127/127 [==============================] - 0s - loss: 2298625.6673 - val_loss: 1552084.8214\n",
      "Epoch 425/1000\n",
      "127/127 [==============================] - 0s - loss: 2282358.5600 - val_loss: 1545972.2589\n",
      "Epoch 426/1000\n",
      "127/127 [==============================] - 0s - loss: 2283628.8957 - val_loss: 1539932.2054\n",
      "Epoch 427/1000\n",
      "127/127 [==============================] - 0s - loss: 2280143.1624 - val_loss: 1533913.7857\n",
      "Epoch 428/1000\n",
      "127/127 [==============================] - 0s - loss: 2291465.5955 - val_loss: 1527636.9911\n",
      "Epoch 429/1000\n",
      "127/127 [==============================] - 0s - loss: 2256054.3898 - val_loss: 1522013.9643\n",
      "Epoch 430/1000\n",
      "127/127 [==============================] - 0s - loss: 2270999.8337 - val_loss: 1516116.678697564.\n",
      "Epoch 431/1000\n",
      "127/127 [==============================] - 0s - loss: 2249917.2347 - val_loss: 1509937.312521720.\n",
      "Epoch 432/1000\n",
      "127/127 [==============================] - 0s - loss: 2258335.9498 - val_loss: 1504067.1071\n",
      "Epoch 433/1000\n",
      "127/127 [==============================] - 0s - loss: 2214526.4424 - val_loss: 1498141.3125\n",
      "Epoch 434/1000\n",
      "127/127 [==============================] - 0s - loss: 2216622.6580 - val_loss: 1492206.0982\n",
      "Epoch 435/1000\n",
      "127/127 [==============================] - 0s - loss: 2202122.2785 - val_loss: 1486159.4643\n",
      "Epoch 436/1000\n",
      "127/127 [==============================] - 0s - loss: 2240751.3834 - val_loss: 1480561.9911\n",
      "Epoch 437/1000\n",
      "127/127 [==============================] - 0s - loss: 2193409.6713 - val_loss: 1474584.2768\n",
      "Epoch 438/1000\n",
      "127/127 [==============================] - 0s - loss: 2211503.9788 - val_loss: 1468960.9375\n",
      "Epoch 439/1000\n",
      "127/127 [==============================] - 0s - loss: 2240787.0330 - val_loss: 1463020.0357\n",
      "Epoch 440/1000\n",
      "127/127 [==============================] - 0s - loss: 2207309.1865 - val_loss: 1457316.0804\n",
      "Epoch 441/1000\n",
      "127/127 [==============================] - 0s - loss: 2203144.5945 - val_loss: 1451341.9286\n",
      "Epoch 442/1000\n",
      "127/127 [==============================] - 0s - loss: 2166600.4478 - val_loss: 1445946.0982\n",
      "Epoch 443/1000\n",
      "127/127 [==============================] - 0s - loss: 2176246.5020 - val_loss: 1439994.3125\n",
      "Epoch 444/1000\n",
      "127/127 [==============================] - 0s - loss: 2180452.2382 - val_loss: 1434266.9375\n",
      "Epoch 445/1000\n",
      "127/127 [==============================] - 0s - loss: 2205795.9385 - val_loss: 1428751.7857\n",
      "Epoch 446/1000\n",
      "127/127 [==============================] - 0s - loss: 2135032.7785 - val_loss: 1423322.7768\n",
      "Epoch 447/1000\n",
      "127/127 [==============================] - 0s - loss: 2159776.4104 - val_loss: 1417434.0357\n",
      "Epoch 448/1000\n",
      "127/127 [==============================] - 0s - loss: 2149924.0492 - val_loss: 1411953.9375\n",
      "Epoch 449/1000\n",
      "127/127 [==============================] - 0s - loss: 2179325.7530 - val_loss: 1406032.3839\n",
      "Epoch 450/1000\n",
      "127/127 [==============================] - 0s - loss: 2132865.8273 - val_loss: 1400743.9196\n",
      "Epoch 451/1000\n",
      "127/127 [==============================] - 0s - loss: 2128558.8337 - val_loss: 1395114.3482\n",
      "Epoch 452/1000\n",
      "127/127 [==============================] - 0s - loss: 2121861.5025 - val_loss: 1389589.1875\n",
      "Epoch 453/1000\n",
      "127/127 [==============================] - 0s - loss: 2137969.7874 - val_loss: 1383926.3304\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 2152910.2215 - val_loss: 1378166.9286\n",
      "Epoch 455/1000\n",
      "127/127 [==============================] - 0s - loss: 2103669.0620 - val_loss: 1372448.7500\n",
      "Epoch 456/1000\n",
      "127/127 [==============================] - 0s - loss: 2090774.9493 - val_loss: 1367290.7232\n",
      "Epoch 457/1000\n",
      "127/127 [==============================] - 0s - loss: 2090168.3903 - val_loss: 1361806.7411\n",
      "Epoch 458/1000\n",
      "127/127 [==============================] - 0s - loss: 2101672.2719 - val_loss: 1356228.4554\n",
      "Epoch 459/1000\n",
      "127/127 [==============================] - 0s - loss: 2087880.0728 - val_loss: 1350749.8661\n",
      "Epoch 460/1000\n",
      "127/127 [==============================] - 0s - loss: 2062915.7357 - val_loss: 1345499.1161\n",
      "Epoch 461/1000\n",
      "127/127 [==============================] - 0s - loss: 2105323.1496 - val_loss: 1340002.7143\n",
      "Epoch 462/1000\n",
      "127/127 [==============================] - 0s - loss: 2098840.8356 - val_loss: 1334907.4732\n",
      "Epoch 463/1000\n",
      "127/127 [==============================] - 0s - loss: 2046482.4825 - val_loss: 1329766.5536\n",
      "Epoch 464/1000\n",
      "127/127 [==============================] - 0s - loss: 2025259.2128 - val_loss: 1324297.2321\n",
      "Epoch 465/1000\n",
      "127/127 [==============================] - 0s - loss: 2036024.0866 - val_loss: 1319235.7500\n",
      "Epoch 466/1000\n",
      "127/127 [==============================] - 0s - loss: 2041408.1250 - val_loss: 1313911.5714\n",
      "Epoch 467/1000\n",
      "127/127 [==============================] - 0s - loss: 2056368.0817 - val_loss: 1308336.7589\n",
      "Epoch 468/1000\n",
      "127/127 [==============================] - 0s - loss: 2038728.0901 - val_loss: 1302935.3571\n",
      "Epoch 469/1000\n",
      "127/127 [==============================] - 0s - loss: 2059522.7589 - val_loss: 1297572.2232\n",
      "Epoch 470/1000\n",
      "127/127 [==============================] - 0s - loss: 2022724.6826 - val_loss: 1292353.4018\n",
      "Epoch 471/1000\n",
      "127/127 [==============================] - 0s - loss: 2023057.0300 - val_loss: 1287531.2321\n",
      "Epoch 472/1000\n",
      "127/127 [==============================] - 0s - loss: 2030187.6471 - val_loss: 1282278.8482\n",
      "Epoch 473/1000\n",
      "127/127 [==============================] - 0s - loss: 2005202.2800 - val_loss: 1277033.7946\n",
      "Epoch 474/1000\n",
      "127/127 [==============================] - 0s - loss: 1984830.5485 - val_loss: 1272053.1696\n",
      "Epoch 475/1000\n",
      "127/127 [==============================] - 0s - loss: 1998978.1954 - val_loss: 1266802.5446\n",
      "Epoch 476/1000\n",
      "127/127 [==============================] - 0s - loss: 1989919.0271 - val_loss: 1261700.7321\n",
      "Epoch 477/1000\n",
      "127/127 [==============================] - 0s - loss: 1974213.4651 - val_loss: 1256761.5268\n",
      "Epoch 478/1000\n",
      "127/127 [==============================] - 0s - loss: 1995665.2933 - val_loss: 1251470.5536\n",
      "Epoch 479/1000\n",
      "127/127 [==============================] - 0s - loss: 1988797.5295 - val_loss: 1246615.294629507.8\n",
      "Epoch 480/1000\n",
      "127/127 [==============================] - 0s - loss: 1938075.9783 - val_loss: 1241794.2768\n",
      "Epoch 481/1000\n",
      "127/127 [==============================] - 0s - loss: 1998865.3469 - val_loss: 1236701.2321\n",
      "Epoch 482/1000\n",
      "127/127 [==============================] - 0s - loss: 1956722.4656 - val_loss: 1231591.3571\n",
      "Epoch 483/1000\n",
      "127/127 [==============================] - 0s - loss: 1966280.6491 - val_loss: 1226754.0268\n",
      "Epoch 484/1000\n",
      "127/127 [==============================] - 0s - loss: 1953943.3684 - val_loss: 1222030.4375\n",
      "Epoch 485/1000\n",
      "127/127 [==============================] - 0s - loss: 1973181.9277 - val_loss: 1217255.0089\n",
      "Epoch 486/1000\n",
      "127/127 [==============================] - 0s - loss: 1956152.9822 - val_loss: 1212466.6339\n",
      "Epoch 487/1000\n",
      "127/127 [==============================] - 0s - loss: 1940217.0290 - val_loss: 1207322.9375\n",
      "Epoch 488/1000\n",
      "127/127 [==============================] - 0s - loss: 1889678.4341 - val_loss: 1202660.0446\n",
      "Epoch 489/1000\n",
      "127/127 [==============================] - 0s - loss: 1905645.0244 - val_loss: 1197397.0982232\n",
      "Epoch 490/1000\n",
      "127/127 [==============================] - 0s - loss: 1917312.4927 - val_loss: 1192509.8304\n",
      "Epoch 491/1000\n",
      "127/127 [==============================] - 0s - loss: 1919155.0433 - val_loss: 1187674.2946\n",
      "Epoch 492/1000\n",
      "127/127 [==============================] - 0s - loss: 1924450.9178 - val_loss: 1182707.6696\n",
      "Epoch 493/1000\n",
      "127/127 [==============================] - 0s - loss: 1905797.5276 - val_loss: 1178167.6339\n",
      "Epoch 494/1000\n",
      "127/127 [==============================] - 0s - loss: 1913001.7559 - val_loss: 1173110.3750\n",
      "Epoch 495/1000\n",
      "127/127 [==============================] - 0s - loss: 1912932.0118 - val_loss: 1168188.1696\n",
      "Epoch 496/1000\n",
      "127/127 [==============================] - 0s - loss: 1872429.8880 - val_loss: 1163613.3393\n",
      "Epoch 497/1000\n",
      "127/127 [==============================] - 0s - loss: 1896573.9936 - val_loss: 1159048.7321\n",
      "Epoch 498/1000\n",
      "127/127 [==============================] - 0s - loss: 1843139.2003 - val_loss: 1154292.5804\n",
      "Epoch 499/1000\n",
      "127/127 [==============================] - 0s - loss: 1853209.1096 - val_loss: 1149694.2411\n",
      "Epoch 500/1000\n",
      "127/127 [==============================] - 0s - loss: 1871609.3848 - val_loss: 1144773.2545\n",
      "Epoch 501/1000\n",
      "127/127 [==============================] - 0s - loss: 1833480.9173 - val_loss: 1140356.8929\n",
      "Epoch 502/1000\n",
      "127/127 [==============================] - 0s - loss: 1871784.4798 - val_loss: 1135798.2277\n",
      "Epoch 503/1000\n",
      "127/127 [==============================] - 0s - loss: 1882755.1142 - val_loss: 1131279.7188\n",
      "Epoch 504/1000\n",
      "127/127 [==============================] - 0s - loss: 1851523.8287 - val_loss: 1126378.6830\n",
      "Epoch 505/1000\n",
      "127/127 [==============================] - 0s - loss: 1876543.4033 - val_loss: 1121923.0580\n",
      "Epoch 506/1000\n",
      "127/127 [==============================] - 0s - loss: 1836492.6058 - val_loss: 1117429.1920\n",
      "Epoch 507/1000\n",
      "127/127 [==============================] - 0s - loss: 1833334.8812 - val_loss: 1112839.0536\n",
      "Epoch 508/1000\n",
      "127/127 [==============================] - 0s - loss: 1809519.9203 - val_loss: 1108126.7634\n",
      "Epoch 509/1000\n",
      "127/127 [==============================] - 0s - loss: 1834406.6185 - val_loss: 1103774.0491\n",
      "Epoch 510/1000\n",
      "127/127 [==============================] - 0s - loss: 1813705.7707 - val_loss: 1099078.0045\n",
      "Epoch 511/1000\n",
      "127/127 [==============================] - 0s - loss: 1828948.4885 - val_loss: 1094407.78572935\n",
      "Epoch 512/1000\n",
      "127/127 [==============================] - 0s - loss: 1801350.4429 - val_loss: 1089982.7812\n",
      "Epoch 513/1000\n",
      "127/127 [==============================] - 0s - loss: 1816384.6713 - val_loss: 1085522.6964\n",
      "Epoch 514/1000\n",
      "127/127 [==============================] - 0s - loss: 1783752.3255 - val_loss: 1081227.3080\n",
      "Epoch 515/1000\n",
      "127/127 [==============================] - 0s - loss: 1779675.4685 - val_loss: 1076990.2188\n",
      "Epoch 516/1000\n",
      "127/127 [==============================] - 0s - loss: 1777975.3066 - val_loss: 1072396.9955\n",
      "Epoch 517/1000\n",
      "127/127 [==============================] - 0s - loss: 1818983.6871 - val_loss: 1067501.1429\n",
      "Epoch 518/1000\n",
      "127/127 [==============================] - 0s - loss: 1774475.3644 - val_loss: 1063634.0536\n",
      "Epoch 519/1000\n",
      "127/127 [==============================] - 0s - loss: 1803196.7800 - val_loss: 1059246.6562\n",
      "Epoch 520/1000\n",
      "127/127 [==============================] - 0s - loss: 1770069.2982 - val_loss: 1054960.2098\n",
      "Epoch 521/1000\n",
      "127/127 [==============================] - 0s - loss: 1751088.9097 - val_loss: 1050784.6429\n",
      "Epoch 522/1000\n",
      "127/127 [==============================] - 0s - loss: 1735911.0965 - val_loss: 1046765.0000\n",
      "Epoch 523/1000\n",
      "127/127 [==============================] - 0s - loss: 1752670.9950 - val_loss: 1042605.6830\n",
      "Epoch 524/1000\n",
      "127/127 [==============================] - 0s - loss: 1771345.3115 - val_loss: 1038210.3884\n",
      "Epoch 525/1000\n",
      "127/127 [==============================] - 0s - loss: 1777606.5064 - val_loss: 1033977.3527\n",
      "Epoch 526/1000\n",
      "127/127 [==============================] - 0s - loss: 1732885.9092 - val_loss: 1029805.6384\n",
      "Epoch 527/1000\n",
      "127/127 [==============================] - 0s - loss: 1723118.8814 - val_loss: 1025807.5848\n",
      "Epoch 528/1000\n",
      "127/127 [==============================] - 0s - loss: 1756970.5827 - val_loss: 1021228.8973\n",
      "Epoch 529/1000\n",
      "127/127 [==============================] - 0s - loss: 1743560.9144 - val_loss: 1016944.4821\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 1758591.6703 - val_loss: 1013009.0938\n",
      "Epoch 531/1000\n",
      "127/127 [==============================] - 0s - loss: 1729094.5837 - val_loss: 1008920.3616\n",
      "Epoch 532/1000\n",
      "127/127 [==============================] - 0s - loss: 1737667.3394 - val_loss: 1005072.1562\n",
      "Epoch 533/1000\n",
      "127/127 [==============================] - 0s - loss: 1693291.3848 - val_loss: 1000777.5134\n",
      "Epoch 534/1000\n",
      "127/127 [==============================] - 0s - loss: 1747029.6702 - val_loss: 997115.1295\n",
      "Epoch 535/1000\n",
      "127/127 [==============================] - 0s - loss: 1705068.0914 - val_loss: 992956.9330\n",
      "Epoch 536/1000\n",
      "127/127 [==============================] - 0s - loss: 1728883.8369 - val_loss: 988843.4866\n",
      "Epoch 537/1000\n",
      "127/127 [==============================] - 0s - loss: 1692588.2894 - val_loss: 984839.2455\n",
      "Epoch 538/1000\n",
      "127/127 [==============================] - 0s - loss: 1690705.0655 - val_loss: 980691.2455\n",
      "Epoch 539/1000\n",
      "127/127 [==============================] - 0s - loss: 1678038.1473 - val_loss: 976867.9821\n",
      "Epoch 540/1000\n",
      "127/127 [==============================] - 0s - loss: 1695196.7831 - val_loss: 972696.3438\n",
      "Epoch 541/1000\n",
      "127/127 [==============================] - 0s - loss: 1673149.8747 - val_loss: 968913.8170\n",
      "Epoch 542/1000\n",
      "127/127 [==============================] - 0s - loss: 1694373.7527 - val_loss: 965033.7188\n",
      "Epoch 543/1000\n",
      "127/127 [==============================] - 0s - loss: 1705258.3695 - val_loss: 961118.7009\n",
      "Epoch 544/1000\n",
      "127/127 [==============================] - 0s - loss: 1650542.9345 - val_loss: 957129.7366\n",
      "Epoch 545/1000\n",
      "127/127 [==============================] - 0s - loss: 1693498.3612 - val_loss: 953245.1295\n",
      "Epoch 546/1000\n",
      "127/127 [==============================] - 0s - loss: 1682749.8381 - val_loss: 949554.4777\n",
      "Epoch 547/1000\n",
      "127/127 [==============================] - 0s - loss: 1702819.1521 - val_loss: 945719.4330\n",
      "Epoch 548/1000\n",
      "127/127 [==============================] - 0s - loss: 1658686.7037 - val_loss: 942140.8795\n",
      "Epoch 549/1000\n",
      "127/127 [==============================] - 0s - loss: 1683271.4735 - val_loss: 938419.1964\n",
      "Epoch 550/1000\n",
      "127/127 [==============================] - 0s - loss: 1656501.8563 - val_loss: 934468.9821\n",
      "Epoch 551/1000\n",
      "127/127 [==============================] - 0s - loss: 1628298.6693 - val_loss: 930698.7188\n",
      "Epoch 552/1000\n",
      "127/127 [==============================] - 0s - loss: 1623529.7480 - val_loss: 926711.3616\n",
      "Epoch 553/1000\n",
      "127/127 [==============================] - 0s - loss: 1617001.1850 - val_loss: 923001.8929\n",
      "Epoch 554/1000\n",
      "127/127 [==============================] - 0s - loss: 1598357.3500 - val_loss: 919371.2455\n",
      "Epoch 555/1000\n",
      "127/127 [==============================] - 0s - loss: 1611172.1956 - val_loss: 915568.9152\n",
      "Epoch 556/1000\n",
      "127/127 [==============================] - 0s - loss: 1638818.4167 - val_loss: 911868.1071\n",
      "Epoch 557/1000\n",
      "127/127 [==============================] - 0s - loss: 1647880.0563 - val_loss: 908268.6429\n",
      "Epoch 558/1000\n",
      "127/127 [==============================] - 0s - loss: 1615277.1860 - val_loss: 904670.6250\n",
      "Epoch 559/1000\n",
      "127/127 [==============================] - 0s - loss: 1592606.5666 - val_loss: 901152.8750\n",
      "Epoch 560/1000\n",
      "127/127 [==============================] - 0s - loss: 1624429.2435 - val_loss: 897560.4241\n",
      "Epoch 561/1000\n",
      "127/127 [==============================] - 0s - loss: 1618224.8403 - val_loss: 893765.9420\n",
      "Epoch 562/1000\n",
      "127/127 [==============================] - 0s - loss: 1570918.9651 - val_loss: 889994.8348\n",
      "Epoch 563/1000\n",
      "127/127 [==============================] - 0s - loss: 1568815.1969 - val_loss: 886199.9330\n",
      "Epoch 564/1000\n",
      "127/127 [==============================] - 0s - loss: 1599836.8866 - val_loss: 882775.6741\n",
      "Epoch 565/1000\n",
      "127/127 [==============================] - 0s - loss: 1592170.9838 - val_loss: 879219.1652\n",
      "Epoch 566/1000\n",
      "127/127 [==============================] - 0s - loss: 1571915.2274 - val_loss: 875509.9911\n",
      "Epoch 567/1000\n",
      "127/127 [==============================] - 0s - loss: 1570983.3127 - val_loss: 872085.2188\n",
      "Epoch 568/1000\n",
      "127/127 [==============================] - 0s - loss: 1552569.1072 - val_loss: 868560.2455\n",
      "Epoch 569/1000\n",
      "127/127 [==============================] - 0s - loss: 1575435.6042 - val_loss: 865320.1071\n",
      "Epoch 570/1000\n",
      "127/127 [==============================] - 0s - loss: 1537589.7072 - val_loss: 861802.2455\n",
      "Epoch 571/1000\n",
      "127/127 [==============================] - 0s - loss: 1549866.1465 - val_loss: 858338.2679\n",
      "Epoch 572/1000\n",
      "127/127 [==============================] - 0s - loss: 1530999.9990 - val_loss: 854868.1875\n",
      "Epoch 573/1000\n",
      "127/127 [==============================] - 0s - loss: 1583341.8880 - val_loss: 851639.1920\n",
      "Epoch 574/1000\n",
      "127/127 [==============================] - 0s - loss: 1597720.9553 - val_loss: 848192.8527\n",
      "Epoch 575/1000\n",
      "127/127 [==============================] - 0s - loss: 1546788.3206 - val_loss: 845087.0804\n",
      "Epoch 576/1000\n",
      "127/127 [==============================] - 0s - loss: 1504007.2338 - val_loss: 841926.5804\n",
      "Epoch 577/1000\n",
      "127/127 [==============================] - 0s - loss: 1547223.3594 - val_loss: 838553.3616\n",
      "Epoch 578/1000\n",
      "127/127 [==============================] - 0s - loss: 1532617.8170 - val_loss: 835168.2946\n",
      "Epoch 579/1000\n",
      "127/127 [==============================] - 0s - loss: 1524736.8595 - val_loss: 831797.1161\n",
      "Epoch 580/1000\n",
      "127/127 [==============================] - 0s - loss: 1509541.3473 - val_loss: 828629.1562\n",
      "Epoch 581/1000\n",
      "127/127 [==============================] - 0s - loss: 1524385.3125 - val_loss: 825064.2098\n",
      "Epoch 582/1000\n",
      "127/127 [==============================] - 0s - loss: 1532849.0033 - val_loss: 821922.2143\n",
      "Epoch 583/1000\n",
      "127/127 [==============================] - 0s - loss: 1516266.5958 - val_loss: 818778.6027\n",
      "Epoch 584/1000\n",
      "127/127 [==============================] - 0s - loss: 1481459.9874 - val_loss: 815426.2902\n",
      "Epoch 585/1000\n",
      "127/127 [==============================] - 0s - loss: 1515251.3693 - val_loss: 812089.7321\n",
      "Epoch 586/1000\n",
      "127/127 [==============================] - 0s - loss: 1494114.0064 - val_loss: 808970.9866\n",
      "Epoch 587/1000\n",
      "127/127 [==============================] - 0s - loss: 1506239.8120 - val_loss: 805644.3795\n",
      "Epoch 588/1000\n",
      "127/127 [==============================] - 0s - loss: 1515678.6456 - val_loss: 802639.8884\n",
      "Epoch 589/1000\n",
      "127/127 [==============================] - 0s - loss: 1484648.5879 - val_loss: 799424.3929\n",
      "Epoch 590/1000\n",
      "127/127 [==============================] - 0s - loss: 1474319.4348 - val_loss: 796260.8438\n",
      "Epoch 591/1000\n",
      "127/127 [==============================] - 0s - loss: 1517556.6828 - val_loss: 793172.9911\n",
      "Epoch 592/1000\n",
      "127/127 [==============================] - 0s - loss: 1544564.8935 - val_loss: 790208.5536\n",
      "Epoch 593/1000\n",
      "127/127 [==============================] - 0s - loss: 1474707.7956 - val_loss: 787087.0938\n",
      "Epoch 594/1000\n",
      "127/127 [==============================] - 0s - loss: 1510390.1164 - val_loss: 783589.245543\n",
      "Epoch 595/1000\n",
      "127/127 [==============================] - 0s - loss: 1471879.3196 - val_loss: 780893.3795\n",
      "Epoch 596/1000\n",
      "127/127 [==============================] - 0s - loss: 1455889.4774 - val_loss: 777720.9777\n",
      "Epoch 597/1000\n",
      "127/127 [==============================] - 0s - loss: 1481344.4389 - val_loss: 774734.2277\n",
      "Epoch 598/1000\n",
      "127/127 [==============================] - 0s - loss: 1467000.2953 - val_loss: 771859.5000\n",
      "Epoch 599/1000\n",
      "127/127 [==============================] - 0s - loss: 1468444.5336 - val_loss: 768978.7009812519\n",
      "Epoch 600/1000\n",
      "127/127 [==============================] - 0s - loss: 1448614.6064 - val_loss: 765904.9464\n",
      "Epoch 601/1000\n",
      "127/127 [==============================] - 0s - loss: 1462259.7835 - val_loss: 763034.9688\n",
      "Epoch 602/1000\n",
      "127/127 [==============================] - 0s - loss: 1459083.1013 - val_loss: 760351.3661\n",
      "Epoch 603/1000\n",
      "127/127 [==============================] - 0s - loss: 1433183.0484 - val_loss: 757797.5134\n",
      "Epoch 604/1000\n",
      "127/127 [==============================] - 0s - loss: 1449394.6420 - val_loss: 754815.2545\n",
      "Epoch 605/1000\n",
      "127/127 [==============================] - 0s - loss: 1456195.5192 - val_loss: 752005.4911\n",
      "Epoch 606/1000\n",
      "127/127 [==============================] - 0s - loss: 1456359.6201 - val_loss: 749454.6339\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 1443136.0368 - val_loss: 746738.4777\n",
      "Epoch 608/1000\n",
      "127/127 [==============================] - 0s - loss: 1446437.3597 - val_loss: 743929.5000\n",
      "Epoch 609/1000\n",
      "127/127 [==============================] - 0s - loss: 1440634.2551 - val_loss: 741163.0045\n",
      "Epoch 610/1000\n",
      "127/127 [==============================] - 0s - loss: 1430464.8425 - val_loss: 738428.6161\n",
      "Epoch 611/1000\n",
      "127/127 [==============================] - 0s - loss: 1479241.8541 - val_loss: 735464.1071\n",
      "Epoch 612/1000\n",
      "127/127 [==============================] - 0s - loss: 1453101.7518 - val_loss: 732764.5915476102.186\n",
      "Epoch 613/1000\n",
      "127/127 [==============================] - 0s - loss: 1417394.7963 - val_loss: 730219.0826\n",
      "Epoch 614/1000\n",
      "127/127 [==============================] - 0s - loss: 1403205.5592 - val_loss: 727471.1362\n",
      "Epoch 615/1000\n",
      "127/127 [==============================] - 0s - loss: 1410405.4656 - val_loss: 724771.3125\n",
      "Epoch 616/1000\n",
      "127/127 [==============================] - 0s - loss: 1413894.7222 - val_loss: 722062.4487\n",
      "Epoch 617/1000\n",
      "127/127 [==============================] - 0s - loss: 1414767.5426 - val_loss: 719395.0469\n",
      "Epoch 618/1000\n",
      "127/127 [==============================] - 0s - loss: 1391948.0426 - val_loss: 716548.8371\n",
      "Epoch 619/1000\n",
      "127/127 [==============================] - 0s - loss: 1434507.7694 - val_loss: 713813.2344\n",
      "Epoch 620/1000\n",
      "127/127 [==============================] - 0s - loss: 1413903.3051 - val_loss: 711042.7857\n",
      "Epoch 621/1000\n",
      "127/127 [==============================] - 0s - loss: 1399600.0512 - val_loss: 708459.2165\n",
      "Epoch 622/1000\n",
      "127/127 [==============================] - 0s - loss: 1398368.3392 - val_loss: 705940.0558\n",
      "Epoch 623/1000\n",
      "127/127 [==============================] - 0s - loss: 1394848.6005 - val_loss: 703566.0625\n",
      "Epoch 624/1000\n",
      "127/127 [==============================] - 0s - loss: 1401732.2787 - val_loss: 700884.3839\n",
      "Epoch 625/1000\n",
      "127/127 [==============================] - 0s - loss: 1445656.4119 - val_loss: 698387.0357\n",
      "Epoch 626/1000\n",
      "127/127 [==============================] - 0s - loss: 1349389.7632 - val_loss: 695987.2679\n",
      "Epoch 627/1000\n",
      "127/127 [==============================] - 0s - loss: 1389015.9635 - val_loss: 693692.1451313085.\n",
      "Epoch 628/1000\n",
      "127/127 [==============================] - 0s - loss: 1385895.6618 - val_loss: 691220.3237\n",
      "Epoch 629/1000\n",
      "127/127 [==============================] - 0s - loss: 1384250.0265 - val_loss: 688713.3504\n",
      "Epoch 630/1000\n",
      "127/127 [==============================] - 0s - loss: 1372508.2618 - val_loss: 685966.3728\n",
      "Epoch 631/1000\n",
      "127/127 [==============================] - 0s - loss: 1384301.0563 - val_loss: 683646.3281\n",
      "Epoch 632/1000\n",
      "127/127 [==============================] - 0s - loss: 1394766.7958 - val_loss: 681040.9040\n",
      "Epoch 633/1000\n",
      "127/127 [==============================] - 0s - loss: 1363961.6586 - val_loss: 678505.1228\n",
      "Epoch 634/1000\n",
      "127/127 [==============================] - 0s - loss: 1330970.4441 - val_loss: 676198.7656\n",
      "Epoch 635/1000\n",
      "127/127 [==============================] - 0s - loss: 1331980.7023 - val_loss: 673645.8996\n",
      "Epoch 636/1000\n",
      "127/127 [==============================] - 0s - loss: 1351967.7116 - val_loss: 671134.9643\n",
      "Epoch 637/1000\n",
      "127/127 [==============================] - 0s - loss: 1346268.4970 - val_loss: 668762.9129\n",
      "Epoch 638/1000\n",
      "127/127 [==============================] - 0s - loss: 1382430.2537 - val_loss: 666558.2232\n",
      "Epoch 639/1000\n",
      "127/127 [==============================] - 0s - loss: 1327674.0226 - val_loss: 664165.4487\n",
      "Epoch 640/1000\n",
      "127/127 [==============================] - 0s - loss: 1325548.6529 - val_loss: 661754.7790\n",
      "Epoch 641/1000\n",
      "127/127 [==============================] - 0s - loss: 1326798.2218 - val_loss: 659465.0112\n",
      "Epoch 642/1000\n",
      "127/127 [==============================] - 0s - loss: 1328848.1771 - val_loss: 656841.1004\n",
      "Epoch 643/1000\n",
      "127/127 [==============================] - 0s - loss: 1307860.9067 - val_loss: 654296.8594\n",
      "Epoch 644/1000\n",
      "127/127 [==============================] - 0s - loss: 1353031.5519 - val_loss: 652125.7790\n",
      "Epoch 645/1000\n",
      "127/127 [==============================] - 0s - loss: 1329260.4033 - val_loss: 650077.0804\n",
      "Epoch 646/1000\n",
      "127/127 [==============================] - 0s - loss: 1355820.3437 - val_loss: 647723.4085\n",
      "Epoch 647/1000\n",
      "127/127 [==============================] - 0s - loss: 1311783.7456 - val_loss: 645327.0960\n",
      "Epoch 648/1000\n",
      "127/127 [==============================] - 0s - loss: 1330100.4310 - val_loss: 643124.1094\n",
      "Epoch 649/1000\n",
      "127/127 [==============================] - 0s - loss: 1311808.5800 - val_loss: 641170.2924\n",
      "Epoch 650/1000\n",
      "127/127 [==============================] - 0s - loss: 1306423.0984 - val_loss: 638964.2121\n",
      "Epoch 651/1000\n",
      "127/127 [==============================] - 0s - loss: 1301936.2765 - val_loss: 636759.5692\n",
      "Epoch 652/1000\n",
      "127/127 [==============================] - 0s - loss: 1315461.2389 - val_loss: 634634.6763\n",
      "Epoch 653/1000\n",
      "127/127 [==============================] - 0s - loss: 1295640.2352 - val_loss: 632281.3862\n",
      "Epoch 654/1000\n",
      "127/127 [==============================] - 0s - loss: 1349507.8537 - val_loss: 630202.5982\n",
      "Epoch 655/1000\n",
      "127/127 [==============================] - 0s - loss: 1304769.4972 - val_loss: 628125.7924\n",
      "Epoch 656/1000\n",
      "127/127 [==============================] - 0s - loss: 1296079.8716 - val_loss: 626024.3013\n",
      "Epoch 657/1000\n",
      "127/127 [==============================] - 0s - loss: 1257918.3071 - val_loss: 624060.1272\n",
      "Epoch 658/1000\n",
      "127/127 [==============================] - 0s - loss: 1331646.9037 - val_loss: 622110.5871\n",
      "Epoch 659/1000\n",
      "127/127 [==============================] - 0s - loss: 1322809.3840 - val_loss: 620269.7299\n",
      "Epoch 660/1000\n",
      "127/127 [==============================] - 0s - loss: 1289666.8537 - val_loss: 618204.8750\n",
      "Epoch 661/1000\n",
      "127/127 [==============================] - 0s - loss: 1338714.5674 - val_loss: 616124.57813383\n",
      "Epoch 662/1000\n",
      "127/127 [==============================] - 0s - loss: 1306851.3585 - val_loss: 613883.1964\n",
      "Epoch 663/1000\n",
      "127/127 [==============================] - 0s - loss: 1308193.6347 - val_loss: 611791.2567\n",
      "Epoch 664/1000\n",
      "127/127 [==============================] - 0s - loss: 1269785.3467 - val_loss: 609897.5379\n",
      "Epoch 665/1000\n",
      "127/127 [==============================] - 0s - loss: 1304241.8103 - val_loss: 607884.4888\n",
      "Epoch 666/1000\n",
      "127/127 [==============================] - 0s - loss: 1302868.9756 - val_loss: 605694.4732\n",
      "Epoch 667/1000\n",
      "127/127 [==============================] - 0s - loss: 1282812.2206 - val_loss: 603567.5982\n",
      "Epoch 668/1000\n",
      "127/127 [==============================] - 0s - loss: 1289059.2680 - val_loss: 601944.6138\n",
      "Epoch 669/1000\n",
      "127/127 [==============================] - 0s - loss: 1282958.6652 - val_loss: 600080.3951\n",
      "Epoch 670/1000\n",
      "127/127 [==============================] - 0s - loss: 1296733.1564 - val_loss: 598214.7411\n",
      "Epoch 671/1000\n",
      "127/127 [==============================] - 0s - loss: 1283125.7685 - val_loss: 596275.9308\n",
      "Epoch 672/1000\n",
      "127/127 [==============================] - 0s - loss: 1244788.3279 - val_loss: 594225.0915\n",
      "Epoch 673/1000\n",
      "127/127 [==============================] - 0s - loss: 1257827.5891 - val_loss: 592576.3460\n",
      "Epoch 674/1000\n",
      "127/127 [==============================] - 0s - loss: 1237107.5894 - val_loss: 590633.6518\n",
      "Epoch 675/1000\n",
      "127/127 [==============================] - 0s - loss: 1269177.2169 - val_loss: 588654.4442\n",
      "Epoch 676/1000\n",
      "127/127 [==============================] - 0s - loss: 1277480.0277 - val_loss: 586930.4018\n",
      "Epoch 677/1000\n",
      "127/127 [==============================] - 0s - loss: 1279793.2688 - val_loss: 585220.92868850\n",
      "Epoch 678/1000\n",
      "127/127 [==============================] - 0s - loss: 1283107.8684 - val_loss: 583394.5781\n",
      "Epoch 679/1000\n",
      "127/127 [==============================] - 0s - loss: 1258006.2780 - val_loss: 581635.4353\n",
      "Epoch 680/1000\n",
      "127/127 [==============================] - 0s - loss: 1265039.6604 - val_loss: 579867.0379\n",
      "Epoch 681/1000\n",
      "127/127 [==============================] - 0s - loss: 1286479.8187 - val_loss: 578196.1228\n",
      "Epoch 682/1000\n",
      "127/127 [==============================] - 0s - loss: 1277273.3049 - val_loss: 576557.9085\n",
      "Epoch 683/1000\n",
      "127/127 [==============================] - 0s - loss: 1247485.9920 - val_loss: 575092.0112\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 1248295.9054 - val_loss: 573331.4799\n",
      "Epoch 685/1000\n",
      "127/127 [==============================] - 0s - loss: 1246906.5922 - val_loss: 571472.2835\n",
      "Epoch 686/1000\n",
      "127/127 [==============================] - 0s - loss: 1267393.8342 - val_loss: 569895.5000\n",
      "Epoch 687/1000\n",
      "127/127 [==============================] - 0s - loss: 1243271.6359 - val_loss: 568106.4754\n",
      "Epoch 688/1000\n",
      "127/127 [==============================] - 0s - loss: 1251177.7917 - val_loss: 566446.0290\n",
      "Epoch 689/1000\n",
      "127/127 [==============================] - 0s - loss: 1233237.2506 - val_loss: 564712.8549\n",
      "Epoch 690/1000\n",
      "127/127 [==============================] - 0s - loss: 1219097.9828 - val_loss: 562920.9933\n",
      "Epoch 691/1000\n",
      "127/127 [==============================] - 0s - loss: 1248324.0513 - val_loss: 561317.1629\n",
      "Epoch 692/1000\n",
      "127/127 [==============================] - 0s - loss: 1274036.8137 - val_loss: 559452.0513\n",
      "Epoch 693/1000\n",
      "127/127 [==============================] - 0s - loss: 1212012.8161 - val_loss: 557980.0290\n",
      "Epoch 694/1000\n",
      "127/127 [==============================] - 0s - loss: 1240975.3816 - val_loss: 556479.3571\n",
      "Epoch 695/1000\n",
      "127/127 [==============================] - 0s - loss: 1228763.4331 - val_loss: 554700.3147\n",
      "Epoch 696/1000\n",
      "127/127 [==============================] - 0s - loss: 1231898.1559 - val_loss: 553158.9621\n",
      "Epoch 697/1000\n",
      "127/127 [==============================] - 0s - loss: 1257437.8318 - val_loss: 551622.4732\n",
      "Epoch 698/1000\n",
      "127/127 [==============================] - 0s - loss: 1239294.0576 - val_loss: 549952.7299\n",
      "Epoch 699/1000\n",
      "127/127 [==============================] - 0s - loss: 1192543.7544 - val_loss: 548472.8393\n",
      "Epoch 700/1000\n",
      "127/127 [==============================] - 0s - loss: 1248868.5913 - val_loss: 546804.0022\n",
      "Epoch 701/1000\n",
      "127/127 [==============================] - 0s - loss: 1212218.6097 - val_loss: 545187.5737\n",
      "Epoch 702/1000\n",
      "127/127 [==============================] - 0s - loss: 1227297.2973 - val_loss: 543647.8147\n",
      "Epoch 703/1000\n",
      "127/127 [==============================] - 0s - loss: 1211549.9519 - val_loss: 542126.2031\n",
      "Epoch 704/1000\n",
      "127/127 [==============================] - 0s - loss: 1240018.7996 - val_loss: 540584.4576\n",
      "Epoch 705/1000\n",
      "127/127 [==============================] - 0s - loss: 1185135.5389 - val_loss: 539103.8371\n",
      "Epoch 706/1000\n",
      "127/127 [==============================] - 0s - loss: 1184867.0684 - val_loss: 537374.6228\n",
      "Epoch 707/1000\n",
      "127/127 [==============================] - 0s - loss: 1214332.1234 - val_loss: 536064.1451\n",
      "Epoch 708/1000\n",
      "127/127 [==============================] - 0s - loss: 1187468.6951 - val_loss: 534556.0804\n",
      "Epoch 709/1000\n",
      "127/127 [==============================] - 0s - loss: 1211334.3739 - val_loss: 533177.8571\n",
      "Epoch 710/1000\n",
      "127/127 [==============================] - 0s - loss: 1189950.9154 - val_loss: 531570.8795\n",
      "Epoch 711/1000\n",
      "127/127 [==============================] - 0s - loss: 1187083.7713 - val_loss: 530207.4643\n",
      "Epoch 712/1000\n",
      "127/127 [==============================] - 0s - loss: 1205775.2800 - val_loss: 528778.2857\n",
      "Epoch 713/1000\n",
      "127/127 [==============================] - 0s - loss: 1218315.6540 - val_loss: 527286.9129\n",
      "Epoch 714/1000\n",
      "127/127 [==============================] - 0s - loss: 1172674.3315 - val_loss: 525835.0580\n",
      "Epoch 715/1000\n",
      "127/127 [==============================] - 0s - loss: 1207204.3821 - val_loss: 524438.2076\n",
      "Epoch 716/1000\n",
      "127/127 [==============================] - 0s - loss: 1167599.3079 - val_loss: 522955.0089\n",
      "Epoch 717/1000\n",
      "127/127 [==============================] - 0s - loss: 1190018.7815 - val_loss: 521690.4464\n",
      "Epoch 718/1000\n",
      "127/127 [==============================] - 0s - loss: 1176199.9404 - val_loss: 520366.8192\n",
      "Epoch 719/1000\n",
      "127/127 [==============================] - 0s - loss: 1183637.6838 - val_loss: 518967.4487\n",
      "Epoch 720/1000\n",
      "127/127 [==============================] - 0s - loss: 1204182.3949 - val_loss: 517602.7790\n",
      "Epoch 721/1000\n",
      "127/127 [==============================] - 0s - loss: 1209018.4553 - val_loss: 516214.9732\n",
      "Epoch 722/1000\n",
      "127/127 [==============================] - 0s - loss: 1153202.1611 - val_loss: 515111.7701\n",
      "Epoch 723/1000\n",
      "127/127 [==============================] - 0s - loss: 1181792.0879 - val_loss: 513745.7701\n",
      "Epoch 724/1000\n",
      "127/127 [==============================] - 0s - loss: 1188470.5455 - val_loss: 512486.3192\n",
      "Epoch 725/1000\n",
      "127/127 [==============================] - 0s - loss: 1177801.3729 - val_loss: 511010.0982\n",
      "Epoch 726/1000\n",
      "127/127 [==============================] - 0s - loss: 1217373.4683 - val_loss: 509680.3080\n",
      "Epoch 727/1000\n",
      "127/127 [==============================] - 0s - loss: 1176941.8565 - val_loss: 508584.0603\n",
      "Epoch 728/1000\n",
      "127/127 [==============================] - 0s - loss: 1178740.2353 - val_loss: 507384.8192\n",
      "Epoch 729/1000\n",
      "127/127 [==============================] - 0s - loss: 1165227.1279 - val_loss: 506137.6295\n",
      "Epoch 730/1000\n",
      "127/127 [==============================] - 0s - loss: 1182934.5950 - val_loss: 505064.0022\n",
      "Epoch 731/1000\n",
      "127/127 [==============================] - 0s - loss: 1199706.5982 - val_loss: 503876.5513\n",
      "Epoch 732/1000\n",
      "127/127 [==============================] - 0s - loss: 1193903.3998 - val_loss: 502769.0558\n",
      "Epoch 733/1000\n",
      "127/127 [==============================] - 0s - loss: 1148078.1238 - val_loss: 501486.1496\n",
      "Epoch 734/1000\n",
      "127/127 [==============================] - 0s - loss: 1152327.4713 - val_loss: 500318.3571\n",
      "Epoch 735/1000\n",
      "127/127 [==============================] - 0s - loss: 1175112.8198 - val_loss: 499221.6451\n",
      "Epoch 736/1000\n",
      "127/127 [==============================] - 0s - loss: 1162766.5656 - val_loss: 497992.2143\n",
      "Epoch 737/1000\n",
      "127/127 [==============================] - 0s - loss: 1143323.7885 - val_loss: 496742.8817\n",
      "Epoch 738/1000\n",
      "127/127 [==============================] - 0s - loss: 1169179.4691 - val_loss: 495526.9263\n",
      "Epoch 739/1000\n",
      "127/127 [==============================] - 0s - loss: 1109023.4047 - val_loss: 494435.5737\n",
      "Epoch 740/1000\n",
      "127/127 [==============================] - 0s - loss: 1171776.2559 - val_loss: 493351.8594\n",
      "Epoch 741/1000\n",
      "127/127 [==============================] - 0s - loss: 1164723.4963 - val_loss: 492324.8147\n",
      "Epoch 742/1000\n",
      "127/127 [==============================] - 0s - loss: 1174780.3393 - val_loss: 491388.9442\n",
      "Epoch 743/1000\n",
      "127/127 [==============================] - 0s - loss: 1155082.7768 - val_loss: 490225.5112\n",
      "Epoch 744/1000\n",
      "127/127 [==============================] - 0s - loss: 1164015.3367 - val_loss: 489090.5335\n",
      "Epoch 745/1000\n",
      "127/127 [==============================] - 0s - loss: 1128643.3805 - val_loss: 488016.7946\n",
      "Epoch 746/1000\n",
      "127/127 [==============================] - 0s - loss: 1137762.7104 - val_loss: 486961.2879\n",
      "Epoch 747/1000\n",
      "127/127 [==============================] - 0s - loss: 1154502.1689 - val_loss: 485803.0335\n",
      "Epoch 748/1000\n",
      "127/127 [==============================] - 0s - loss: 1155510.9243 - val_loss: 484647.0089\n",
      "Epoch 749/1000\n",
      "127/127 [==============================] - 0s - loss: 1161679.2970 - val_loss: 483539.4263\n",
      "Epoch 750/1000\n",
      "127/127 [==============================] - 0s - loss: 1153393.9255 - val_loss: 482452.7991\n",
      "Epoch 751/1000\n",
      "127/127 [==============================] - 0s - loss: 1174491.0038 - val_loss: 481509.0714\n",
      "Epoch 752/1000\n",
      "127/127 [==============================] - 0s - loss: 1187106.6326 - val_loss: 480456.2299\n",
      "Epoch 753/1000\n",
      "127/127 [==============================] - 0s - loss: 1133740.9129 - val_loss: 479455.2388\n",
      "Epoch 754/1000\n",
      "127/127 [==============================] - 0s - loss: 1117764.1236 - val_loss: 478399.5402\n",
      "Epoch 755/1000\n",
      "127/127 [==============================] - 0s - loss: 1123604.3622 - val_loss: 477350.1183\n",
      "Epoch 756/1000\n",
      "127/127 [==============================] - 0s - loss: 1142126.3638 - val_loss: 476394.3304\n",
      "Epoch 757/1000\n",
      "127/127 [==============================] - 0s - loss: 1134400.1357 - val_loss: 475546.7589\n",
      "Epoch 758/1000\n",
      "127/127 [==============================] - 0s - loss: 1105153.3743 - val_loss: 474525.8683\n",
      "Epoch 759/1000\n",
      "127/127 [==============================] - 0s - loss: 1123600.6553 - val_loss: 473557.0871\n",
      "Epoch 760/1000\n",
      "127/127 [==============================] - 0s - loss: 1092970.5185 - val_loss: 472516.6161\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 1127445.5368 - val_loss: 471673.1518\n",
      "Epoch 762/1000\n",
      "127/127 [==============================] - 0s - loss: 1153409.4700 - val_loss: 470690.5022\n",
      "Epoch 763/1000\n",
      "127/127 [==============================] - 0s - loss: 1121855.3516 - val_loss: 469660.7969\n",
      "Epoch 764/1000\n",
      "127/127 [==============================] - 0s - loss: 1133588.7317 - val_loss: 468796.6183\n",
      "Epoch 765/1000\n",
      "127/127 [==============================] - 0s - loss: 1140170.7468 - val_loss: 468087.3929\n",
      "Epoch 766/1000\n",
      "127/127 [==============================] - 0s - loss: 1134016.3245 - val_loss: 467150.9152\n",
      "Epoch 767/1000\n",
      "127/127 [==============================] - 0s - loss: 1093930.6220 - val_loss: 466326.3817\n",
      "Epoch 768/1000\n",
      "127/127 [==============================] - 0s - loss: 1145595.4237 - val_loss: 465548.2411\n",
      "Epoch 769/1000\n",
      "127/127 [==============================] - 0s - loss: 1151787.7680 - val_loss: 464616.5045\n",
      "Epoch 770/1000\n",
      "127/127 [==============================] - 0s - loss: 1139705.7113 - val_loss: 463832.6272\n",
      "Epoch 771/1000\n",
      "127/127 [==============================] - 0s - loss: 1126585.6182 - val_loss: 462889.3415\n",
      "Epoch 772/1000\n",
      "127/127 [==============================] - 0s - loss: 1127194.0334 - val_loss: 462018.6808\n",
      "Epoch 773/1000\n",
      "127/127 [==============================] - 0s - loss: 1150716.9197 - val_loss: 461125.1629\n",
      "Epoch 774/1000\n",
      "127/127 [==============================] - 0s - loss: 1093613.3438 - val_loss: 460253.5112\n",
      "Epoch 775/1000\n",
      "127/127 [==============================] - 0s - loss: 1110612.5073 - val_loss: 459419.6607\n",
      "Epoch 776/1000\n",
      "127/127 [==============================] - 0s - loss: 1124856.8287 - val_loss: 458650.2701\n",
      "Epoch 777/1000\n",
      "127/127 [==============================] - 0s - loss: 1111043.6958 - val_loss: 457879.8594\n",
      "Epoch 778/1000\n",
      "127/127 [==============================] - 0s - loss: 1109813.4598 - val_loss: 457023.6317\n",
      "Epoch 779/1000\n",
      "127/127 [==============================] - 0s - loss: 1123639.5411 - val_loss: 456232.7946\n",
      "Epoch 780/1000\n",
      "127/127 [==============================] - 0s - loss: 1113710.1250 - val_loss: 455428.9978\n",
      "Epoch 781/1000\n",
      "127/127 [==============================] - 0s - loss: 1145584.6214 - val_loss: 454667.5960\n",
      "Epoch 782/1000\n",
      "127/127 [==============================] - 0s - loss: 1099683.9212 - val_loss: 453758.5692\n",
      "Epoch 783/1000\n",
      "127/127 [==============================] - 0s - loss: 1131396.1701 - val_loss: 452988.2879\n",
      "Epoch 784/1000\n",
      "127/127 [==============================] - 0s - loss: 1145593.5292 - val_loss: 452096.0558\n",
      "Epoch 785/1000\n",
      "127/127 [==============================] - 0s - loss: 1114313.5772 - val_loss: 451445.5357\n",
      "Epoch 786/1000\n",
      "127/127 [==============================] - 0s - loss: 1136044.9219 - val_loss: 450784.3906\n",
      "Epoch 787/1000\n",
      "127/127 [==============================] - 0s - loss: 1111224.3610 - val_loss: 450132.6116\n",
      "Epoch 788/1000\n",
      "127/127 [==============================] - 0s - loss: 1118239.8351 - val_loss: 449343.1808\n",
      "Epoch 789/1000\n",
      "127/127 [==============================] - 0s - loss: 1103692.0582 - val_loss: 448537.4732\n",
      "Epoch 790/1000\n",
      "127/127 [==============================] - 0s - loss: 1121875.6677 - val_loss: 447816.5201\n",
      "Epoch 791/1000\n",
      "127/127 [==============================] - 0s - loss: 1105678.3215 - val_loss: 447139.4933\n",
      "Epoch 792/1000\n",
      "127/127 [==============================] - 0s - loss: 1127451.6536 - val_loss: 446516.7902\n",
      "Epoch 793/1000\n",
      "127/127 [==============================] - 0s - loss: 1105943.1773 - val_loss: 445812.3862\n",
      "Epoch 794/1000\n",
      "127/127 [==============================] - 0s - loss: 1082137.9993 - val_loss: 445049.7522\n",
      "Epoch 795/1000\n",
      "127/127 [==============================] - 0s - loss: 1070782.9219 - val_loss: 444404.1719\n",
      "Epoch 796/1000\n",
      "127/127 [==============================] - 0s - loss: 1152188.6213 - val_loss: 443784.7411\n",
      "Epoch 797/1000\n",
      "127/127 [==============================] - 0s - loss: 1087367.8736 - val_loss: 443042.4219\n",
      "Epoch 798/1000\n",
      "127/127 [==============================] - 0s - loss: 1092988.2486 - val_loss: 442408.8036\n",
      "Epoch 799/1000\n",
      "127/127 [==============================] - 0s - loss: 1082052.8927 - val_loss: 441759.1496\n",
      "Epoch 800/1000\n",
      "127/127 [==============================] - 0s - loss: 1094782.6619 - val_loss: 441206.5982\n",
      "Epoch 801/1000\n",
      "127/127 [==============================] - 0s - loss: 1114029.7329 - val_loss: 440683.9040\n",
      "Epoch 802/1000\n",
      "127/127 [==============================] - 0s - loss: 1115439.0410 - val_loss: 440030.5893\n",
      "Epoch 803/1000\n",
      "127/127 [==============================] - 0s - loss: 1121855.3241 - val_loss: 439435.3772\n",
      "Epoch 804/1000\n",
      "127/127 [==============================] - 0s - loss: 1071961.1435 - val_loss: 438711.8951\n",
      "Epoch 805/1000\n",
      "127/127 [==============================] - 0s - loss: 1098502.8166 - val_loss: 438135.8147\n",
      "Epoch 806/1000\n",
      "127/127 [==============================] - 0s - loss: 1083012.6594 - val_loss: 437637.7522\n",
      "Epoch 807/1000\n",
      "127/127 [==============================] - 0s - loss: 1094890.9339 - val_loss: 436977.8237\n",
      "Epoch 808/1000\n",
      "127/127 [==============================] - 0s - loss: 1102629.7258 - val_loss: 436383.1451\n",
      "Epoch 809/1000\n",
      "127/127 [==============================] - 0s - loss: 1105161.4309 - val_loss: 435884.8594\n",
      "Epoch 810/1000\n",
      "127/127 [==============================] - 0s - loss: 1110592.8816 - val_loss: 435221.4621\n",
      "Epoch 811/1000\n",
      "127/127 [==============================] - 0s - loss: 1106622.0999 - val_loss: 434650.6362\n",
      "Epoch 812/1000\n",
      "127/127 [==============================] - 0s - loss: 1091033.5750 - val_loss: 434065.5804\n",
      "Epoch 813/1000\n",
      "127/127 [==============================] - 0s - loss: 1088460.3892 - val_loss: 433412.6830\n",
      "Epoch 814/1000\n",
      "127/127 [==============================] - 0s - loss: 1139731.8277 - val_loss: 432823.9487\n",
      "Epoch 815/1000\n",
      "127/127 [==============================] - 0s - loss: 1106728.1004 - val_loss: 432295.1049\n",
      "Epoch 816/1000\n",
      "127/127 [==============================] - 0s - loss: 1093864.2271 - val_loss: 431695.4085\n",
      "Epoch 817/1000\n",
      "127/127 [==============================] - 0s - loss: 1083182.9516 - val_loss: 431163.8170\n",
      "Epoch 818/1000\n",
      "127/127 [==============================] - 0s - loss: 1114979.6298 - val_loss: 430737.6339\n",
      "Epoch 819/1000\n",
      "127/127 [==============================] - 0s - loss: 1093753.8069 - val_loss: 430157.6897\n",
      "Epoch 820/1000\n",
      "127/127 [==============================] - 0s - loss: 1123708.4534 - val_loss: 429620.9821\n",
      "Epoch 821/1000\n",
      "127/127 [==============================] - 0s - loss: 1088228.1563 - val_loss: 429071.2210\n",
      "Epoch 822/1000\n",
      "127/127 [==============================] - 0s - loss: 1061771.6907 - val_loss: 428519.2857\n",
      "Epoch 823/1000\n",
      "127/127 [==============================] - 0s - loss: 1085708.4270 - val_loss: 428052.8772\n",
      "Epoch 824/1000\n",
      "127/127 [==============================] - 0s - loss: 1051877.0507 - val_loss: 427534.9129\n",
      "Epoch 825/1000\n",
      "127/127 [==============================] - 0s - loss: 1096354.3789 - val_loss: 427072.2388\n",
      "Epoch 826/1000\n",
      "127/127 [==============================] - 0s - loss: 1102661.6369 - val_loss: 426643.8862\n",
      "Epoch 827/1000\n",
      "127/127 [==============================] - 0s - loss: 1100276.7255 - val_loss: 426171.0112\n",
      "Epoch 828/1000\n",
      "127/127 [==============================] - 0s - loss: 1102443.1126 - val_loss: 425766.9621\n",
      "Epoch 829/1000\n",
      "127/127 [==============================] - 0s - loss: 1095188.9900 - val_loss: 425217.9040\n",
      "Epoch 830/1000\n",
      "127/127 [==============================] - 0s - loss: 1072119.1725 - val_loss: 424791.4844\n",
      "Epoch 831/1000\n",
      "127/127 [==============================] - 0s - loss: 1051257.6766 - val_loss: 424315.2746\n",
      "Epoch 832/1000\n",
      "127/127 [==============================] - 0s - loss: 1076959.4156 - val_loss: 423904.4174\n",
      "Epoch 833/1000\n",
      "127/127 [==============================] - 0s - loss: 1086614.1751 - val_loss: 423494.7433\n",
      "Epoch 834/1000\n",
      "127/127 [==============================] - 0s - loss: 1120789.4110 - val_loss: 423016.3638\n",
      "Epoch 835/1000\n",
      "127/127 [==============================] - 0s - loss: 1066713.0034 - val_loss: 422561.3705\n",
      "Epoch 836/1000\n",
      "127/127 [==============================] - 0s - loss: 1084244.7864 - val_loss: 422079.7879\n",
      "Epoch 837/1000\n",
      "127/127 [==============================] - 0s - loss: 1040578.4662 - val_loss: 421598.2701\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 1069333.6905 - val_loss: 421093.2299\n",
      "Epoch 839/1000\n",
      "127/127 [==============================] - 0s - loss: 1116688.3273 - val_loss: 420721.1987\n",
      "Epoch 840/1000\n",
      "127/127 [==============================] - 0s - loss: 1078640.7888 - val_loss: 420335.5603\n",
      "Epoch 841/1000\n",
      "127/127 [==============================] - 0s - loss: 1071645.8923 - val_loss: 419924.3281\n",
      "Epoch 842/1000\n",
      "127/127 [==============================] - 0s - loss: 1054360.6918 - val_loss: 419481.2165\n",
      "Epoch 843/1000\n",
      "127/127 [==============================] - 0s - loss: 1059445.5594 - val_loss: 419092.5335\n",
      "Epoch 844/1000\n",
      "127/127 [==============================] - 0s - loss: 1077904.7348 - val_loss: 418736.8906\n",
      "Epoch 845/1000\n",
      "127/127 [==============================] - 0s - loss: 1058428.2769 - val_loss: 418387.4844\n",
      "Epoch 846/1000\n",
      "127/127 [==============================] - 0s - loss: 1062671.4099 - val_loss: 417953.6272\n",
      "Epoch 847/1000\n",
      "127/127 [==============================] - 0s - loss: 1093638.0046 - val_loss: 417577.2411\n",
      "Epoch 848/1000\n",
      "127/127 [==============================] - 0s - loss: 1074927.1065 - val_loss: 417190.8996\n",
      "Epoch 849/1000\n",
      "127/127 [==============================] - 0s - loss: 1076339.0598 - val_loss: 416787.3304\n",
      "Epoch 850/1000\n",
      "127/127 [==============================] - 0s - loss: 1068984.6676 - val_loss: 416379.0335\n",
      "Epoch 851/1000\n",
      "127/127 [==============================] - 0s - loss: 1102579.4133 - val_loss: 416035.8326\n",
      "Epoch 852/1000\n",
      "127/127 [==============================] - 0s - loss: 1061730.8333 - val_loss: 415677.9665\n",
      "Epoch 853/1000\n",
      "127/127 [==============================] - 0s - loss: 1067482.2424 - val_loss: 415210.8906\n",
      "Epoch 854/1000\n",
      "127/127 [==============================] - 0s - loss: 1081130.7152 - val_loss: 414893.7768\n",
      "Epoch 855/1000\n",
      "127/127 [==============================] - 0s - loss: 1085874.5990 - val_loss: 414518.0513\n",
      "Epoch 856/1000\n",
      "127/127 [==============================] - 0s - loss: 1067269.6911 - val_loss: 414210.8906\n",
      "Epoch 857/1000\n",
      "127/127 [==============================] - 0s - loss: 1075960.8482 - val_loss: 413824.2076\n",
      "Epoch 858/1000\n",
      "127/127 [==============================] - 0s - loss: 1051231.7014 - val_loss: 413463.8371\n",
      "Epoch 859/1000\n",
      "127/127 [==============================] - 0s - loss: 1048854.2836 - val_loss: 413065.8549\n",
      "Epoch 860/1000\n",
      "127/127 [==============================] - 0s - loss: 1100595.8088 - val_loss: 412792.7076\n",
      "Epoch 861/1000\n",
      "127/127 [==============================] - 0s - loss: 1054965.6458 - val_loss: 412445.1964\n",
      "Epoch 862/1000\n",
      "127/127 [==============================] - 0s - loss: 1068523.7369 - val_loss: 412135.9085\n",
      "Epoch 863/1000\n",
      "127/127 [==============================] - 0s - loss: 1059415.3955 - val_loss: 411892.4844\n",
      "Epoch 864/1000\n",
      "127/127 [==============================] - 0s - loss: 1034089.3310 - val_loss: 411603.9308\n",
      "Epoch 865/1000\n",
      "127/127 [==============================] - 0s - loss: 1057527.3609 - val_loss: 411324.9509\n",
      "Epoch 866/1000\n",
      "127/127 [==============================] - 0s - loss: 1048835.1395 - val_loss: 411015.9978\n",
      "Epoch 867/1000\n",
      "127/127 [==============================] - 0s - loss: 1065496.7229 - val_loss: 410715.4353\n",
      "Epoch 868/1000\n",
      "127/127 [==============================] - 0s - loss: 1098580.8227 - val_loss: 410390.8348\n",
      "Epoch 869/1000\n",
      "127/127 [==============================] - 0s - loss: 1070826.5520 - val_loss: 410056.5335\n",
      "Epoch 870/1000\n",
      "127/127 [==============================] - 0s - loss: 1063362.1053 - val_loss: 409775.4040\n",
      "Epoch 871/1000\n",
      "127/127 [==============================] - 0s - loss: 1080845.7436 - val_loss: 409485.9710\n",
      "Epoch 872/1000\n",
      "127/127 [==============================] - 0s - loss: 1047549.2590 - val_loss: 409171.1607\n",
      "Epoch 873/1000\n",
      "127/127 [==============================] - 0s - loss: 1032409.7527 - val_loss: 408858.1451\n",
      "Epoch 874/1000\n",
      "127/127 [==============================] - 0s - loss: 1016802.7008 - val_loss: 408632.6004\n",
      "Epoch 875/1000\n",
      "127/127 [==============================] - 0s - loss: 1067369.1337 - val_loss: 408307.0960\n",
      "Epoch 876/1000\n",
      "127/127 [==============================] - 0s - loss: 1073828.2946 - val_loss: 407989.7857\n",
      "Epoch 877/1000\n",
      "127/127 [==============================] - 0s - loss: 1063321.7700 - val_loss: 407686.0424\n",
      "Epoch 878/1000\n",
      "127/127 [==============================] - 0s - loss: 1054077.7627 - val_loss: 407420.8661\n",
      "Epoch 879/1000\n",
      "127/127 [==============================] - 0s - loss: 1089024.5801 - val_loss: 407128.9085\n",
      "Epoch 880/1000\n",
      "127/127 [==============================] - 0s - loss: 1099391.4241 - val_loss: 406866.4710\n",
      "Epoch 881/1000\n",
      "127/127 [==============================] - 0s - loss: 1054696.9652 - val_loss: 406566.3929\n",
      "Epoch 882/1000\n",
      "127/127 [==============================] - 0s - loss: 1075748.8241 - val_loss: 406271.8103\n",
      "Epoch 883/1000\n",
      "127/127 [==============================] - 0s - loss: 1067796.2118 - val_loss: 405979.1004\n",
      "Epoch 884/1000\n",
      "127/127 [==============================] - 0s - loss: 1066739.5728 - val_loss: 405740.6317\n",
      "Epoch 885/1000\n",
      "127/127 [==============================] - 0s - loss: 1064046.3154 - val_loss: 405503.7835\n",
      "Epoch 886/1000\n",
      "127/127 [==============================] - 0s - loss: 1069515.4047 - val_loss: 405236.1808\n",
      "Epoch 887/1000\n",
      "127/127 [==============================] - 0s - loss: 1072466.2892 - val_loss: 404958.1964\n",
      "Epoch 888/1000\n",
      "127/127 [==============================] - 0s - loss: 1032824.7347 - val_loss: 404703.7455\n",
      "Epoch 889/1000\n",
      "127/127 [==============================] - 0s - loss: 1083734.3802 - val_loss: 404469.0603\n",
      "Epoch 890/1000\n",
      "127/127 [==============================] - 0s - loss: 1037484.3813 - val_loss: 404190.9487\n",
      "Epoch 891/1000\n",
      "127/127 [==============================] - 0s - loss: 1049165.6284 - val_loss: 403949.7076\n",
      "Epoch 892/1000\n",
      "127/127 [==============================] - 0s - loss: 1038094.3422 - val_loss: 403705.5335\n",
      "Epoch 893/1000\n",
      "127/127 [==============================] - 0s - loss: 1043951.0646 - val_loss: 403466.4107\n",
      "Epoch 894/1000\n",
      "127/127 [==============================] - 0s - loss: 1056661.0941 - val_loss: 403252.3638\n",
      "Epoch 895/1000\n",
      "127/127 [==============================] - 0s - loss: 1078492.6676 - val_loss: 403059.0893\n",
      "Epoch 896/1000\n",
      "127/127 [==============================] - 0s - loss: 1067997.7518 - val_loss: 402815.0513\n",
      "Epoch 897/1000\n",
      "127/127 [==============================] - 0s - loss: 1041095.4202 - val_loss: 402623.8772\n",
      "Epoch 898/1000\n",
      "127/127 [==============================] - 0s - loss: 1013966.0632 - val_loss: 402368.0089\n",
      "Epoch 899/1000\n",
      "127/127 [==============================] - 0s - loss: 1047082.5158 - val_loss: 402163.6853\n",
      "Epoch 900/1000\n",
      "127/127 [==============================] - 0s - loss: 1056665.2758 - val_loss: 401935.8839\n",
      "Epoch 901/1000\n",
      "127/127 [==============================] - 0s - loss: 1057551.5867 - val_loss: 401719.8058\n",
      "Epoch 902/1000\n",
      "127/127 [==============================] - 0s - loss: 1071447.6455 - val_loss: 401520.0446\n",
      "Epoch 903/1000\n",
      "127/127 [==============================] - 0s - loss: 1028860.5304 - val_loss: 401316.4933\n",
      "Epoch 904/1000\n",
      "127/127 [==============================] - 0s - loss: 1030607.8388 - val_loss: 401132.5112\n",
      "Epoch 905/1000\n",
      "127/127 [==============================] - 0s - loss: 1078596.1912 - val_loss: 400898.3906\n",
      "Epoch 906/1000\n",
      "127/127 [==============================] - 0s - loss: 1062163.5807 - val_loss: 400674.6250\n",
      "Epoch 907/1000\n",
      "127/127 [==============================] - 0s - loss: 1063339.2522 - val_loss: 400445.0268\n",
      "Epoch 908/1000\n",
      "127/127 [==============================] - 0s - loss: 1053468.4701 - val_loss: 400251.0469\n",
      "Epoch 909/1000\n",
      "127/127 [==============================] - 0s - loss: 1061193.1248 - val_loss: 400029.0692\n",
      "Epoch 910/1000\n",
      "127/127 [==============================] - 0s - loss: 1091374.9029 - val_loss: 399893.8661\n",
      "Epoch 911/1000\n",
      "127/127 [==============================] - 0s - loss: 1030402.6558 - val_loss: 399694.4018038520.562\n",
      "Epoch 912/1000\n",
      "127/127 [==============================] - 0s - loss: 1035114.8125 - val_loss: 399518.4219\n",
      "Epoch 913/1000\n",
      "127/127 [==============================] - 0s - loss: 1025693.6221 - val_loss: 399340.1920\n",
      "Epoch 914/1000\n",
      "127/127 [==============================] - 0s - loss: 1052204.8738 - val_loss: 399119.5469\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 1042853.9906 - val_loss: 398907.5871\n",
      "Epoch 916/1000\n",
      "127/127 [==============================] - 0s - loss: 1051844.2851 - val_loss: 398698.4442\n",
      "Epoch 917/1000\n",
      "127/127 [==============================] - 0s - loss: 1056541.6377 - val_loss: 398555.3192\n",
      "Epoch 918/1000\n",
      "127/127 [==============================] - 0s - loss: 1050940.4279 - val_loss: 398370.6741\n",
      "Epoch 919/1000\n",
      "127/127 [==============================] - 0s - loss: 1088685.4580 - val_loss: 398171.6987\n",
      "Epoch 920/1000\n",
      "127/127 [==============================] - 0s - loss: 1072274.9569 - val_loss: 397998.0915\n",
      "Epoch 921/1000\n",
      "127/127 [==============================] - 0s - loss: 1034315.6713 - val_loss: 397834.2589\n",
      "Epoch 922/1000\n",
      "127/127 [==============================] - 0s - loss: 1060639.9180 - val_loss: 397651.1094\n",
      "Epoch 923/1000\n",
      "127/127 [==============================] - 0s - loss: 1049741.7896 - val_loss: 397460.8772\n",
      "Epoch 924/1000\n",
      "127/127 [==============================] - 0s - loss: 1072301.0583 - val_loss: 397291.6406\n",
      "Epoch 925/1000\n",
      "127/127 [==============================] - 0s - loss: 1049017.0183 - val_loss: 397109.1228\n",
      "Epoch 926/1000\n",
      "127/127 [==============================] - 0s - loss: 1057360.6615 - val_loss: 396926.0982\n",
      "Epoch 927/1000\n",
      "127/127 [==============================] - 0s - loss: 1012357.1090 - val_loss: 396776.9710\n",
      "Epoch 928/1000\n",
      "127/127 [==============================] - 0s - loss: 1038630.6724 - val_loss: 396628.4643\n",
      "Epoch 929/1000\n",
      "127/127 [==============================] - 0s - loss: 1093781.1459 - val_loss: 396513.4107\n",
      "Epoch 930/1000\n",
      "127/127 [==============================] - 0s - loss: 1016969.8422 - val_loss: 396354.7835\n",
      "Epoch 931/1000\n",
      "127/127 [==============================] - 0s - loss: 1025250.8821 - val_loss: 396216.6763\n",
      "Epoch 932/1000\n",
      "127/127 [==============================] - 0s - loss: 1051969.3717 - val_loss: 396111.0536\n",
      "Epoch 933/1000\n",
      "127/127 [==============================] - 0s - loss: 1025185.6403 - val_loss: 395955.2969\n",
      "Epoch 934/1000\n",
      "127/127 [==============================] - 0s - loss: 1025735.7761 - val_loss: 395787.4219\n",
      "Epoch 935/1000\n",
      "127/127 [==============================] - 0s - loss: 1016887.9013 - val_loss: 395674.0893\n",
      "Epoch 936/1000\n",
      "127/127 [==============================] - 0s - loss: 1051553.5111 - val_loss: 395573.6540\n",
      "Epoch 937/1000\n",
      "127/127 [==============================] - 0s - loss: 1033387.5659 - val_loss: 395425.5201\n",
      "Epoch 938/1000\n",
      "127/127 [==============================] - 0s - loss: 1047999.0399 - val_loss: 395317.0424\n",
      "Epoch 939/1000\n",
      "127/127 [==============================] - 0s - loss: 1058591.2041 - val_loss: 395170.8728\n",
      "Epoch 940/1000\n",
      "127/127 [==============================] - 0s - loss: 1052243.9588 - val_loss: 395036.9888\n",
      "Epoch 941/1000\n",
      "127/127 [==============================] - 0s - loss: 1072183.2548 - val_loss: 394920.5982\n",
      "Epoch 942/1000\n",
      "127/127 [==============================] - 0s - loss: 1049768.2429 - val_loss: 394807.3728\n",
      "Epoch 943/1000\n",
      "127/127 [==============================] - 0s - loss: 1056076.2607 - val_loss: 394655.0692\n",
      "Epoch 944/1000\n",
      "127/127 [==============================] - 0s - loss: 1059634.5433 - val_loss: 394528.2946\n",
      "Epoch 945/1000\n",
      "127/127 [==============================] - 0s - loss: 1027492.5209 - val_loss: 394417.5982\n",
      "Epoch 946/1000\n",
      "127/127 [==============================] - 0s - loss: 1035933.8079 - val_loss: 394278.0067\n",
      "Epoch 947/1000\n",
      "127/127 [==============================] - 0s - loss: 1025580.0226 - val_loss: 394180.2054\n",
      "Epoch 948/1000\n",
      "127/127 [==============================] - 0s - loss: 1021630.2111 - val_loss: 394073.9821\n",
      "Epoch 949/1000\n",
      "127/127 [==============================] - 0s - loss: 1050225.0052 - val_loss: 393949.5737\n",
      "Epoch 950/1000\n",
      "127/127 [==============================] - 0s - loss: 1044039.0573 - val_loss: 393854.3214\n",
      "Epoch 951/1000\n",
      "127/127 [==============================] - 0s - loss: 1055246.6679 - val_loss: 393738.7879\n",
      "Epoch 952/1000\n",
      "127/127 [==============================] - 0s - loss: 1053403.6911 - val_loss: 393624.4554\n",
      "Epoch 953/1000\n",
      "127/127 [==============================] - 0s - loss: 1027795.7982 - val_loss: 393493.7254\n",
      "Epoch 954/1000\n",
      "127/127 [==============================] - 0s - loss: 1054707.5453 - val_loss: 393372.6161\n",
      "Epoch 955/1000\n",
      "127/127 [==============================] - 0s - loss: 1028737.0228 - val_loss: 393267.3125\n",
      "Epoch 956/1000\n",
      "127/127 [==============================] - 0s - loss: 1046587.4580 - val_loss: 393162.5179\n",
      "Epoch 957/1000\n",
      "127/127 [==============================] - 0s - loss: 1034448.0351 - val_loss: 393059.48884\n",
      "Epoch 958/1000\n",
      "127/127 [==============================] - 0s - loss: 1026629.4849 - val_loss: 392964.8036\n",
      "Epoch 959/1000\n",
      "127/127 [==============================] - 0s - loss: 1013540.1526 - val_loss: 392872.4933\n",
      "Epoch 960/1000\n",
      "127/127 [==============================] - 0s - loss: 1038576.3280 - val_loss: 392790.3058\n",
      "Epoch 961/1000\n",
      "127/127 [==============================] - 0s - loss: 1016004.0296 - val_loss: 392696.3862\n",
      "Epoch 962/1000\n",
      "127/127 [==============================] - 0s - loss: 1001096.2160 - val_loss: 392625.1964\n",
      "Epoch 963/1000\n",
      "127/127 [==============================] - 0s - loss: 1035493.3380 - val_loss: 392538.0982\n",
      "Epoch 964/1000\n",
      "127/127 [==============================] - 0s - loss: 1032495.3014 - val_loss: 392441.1272144035\n",
      "Epoch 965/1000\n",
      "127/127 [==============================] - 0s - loss: 1031448.5589 - val_loss: 392345.1808\n",
      "Epoch 966/1000\n",
      "127/127 [==============================] - 0s - loss: 1026259.1590 - val_loss: 392256.6496\n",
      "Epoch 967/1000\n",
      "127/127 [==============================] - 0s - loss: 1048399.2233 - val_loss: 392141.2500\n",
      "Epoch 968/1000\n",
      "127/127 [==============================] - 0s - loss: 1027539.8062 - val_loss: 392026.8996\n",
      "Epoch 969/1000\n",
      "127/127 [==============================] - 0s - loss: 1016646.1813 - val_loss: 391943.9665\n",
      "Epoch 970/1000\n",
      "127/127 [==============================] - 0s - loss: 1077410.0488 - val_loss: 391858.7835\n",
      "Epoch 971/1000\n",
      "127/127 [==============================] - 0s - loss: 1060560.7218 - val_loss: 391763.7500\n",
      "Epoch 972/1000\n",
      "127/127 [==============================] - 0s - loss: 1031993.6766 - val_loss: 391683.8036\n",
      "Epoch 973/1000\n",
      "127/127 [==============================] - 0s - loss: 1017298.3138 - val_loss: 391613.9665\n",
      "Epoch 974/1000\n",
      "127/127 [==============================] - 0s - loss: 1009465.2915 - val_loss: 391512.9844\n",
      "Epoch 975/1000\n",
      "127/127 [==============================] - 0s - loss: 1024037.3189 - val_loss: 391428.9397\n",
      "Epoch 976/1000\n",
      "127/127 [==============================] - 0s - loss: 1012137.6922 - val_loss: 391354.7879\n",
      "Epoch 977/1000\n",
      "127/127 [==============================] - 0s - loss: 1041258.1166 - val_loss: 391307.9576\n",
      "Epoch 978/1000\n",
      "127/127 [==============================] - 0s - loss: 1027080.2819 - val_loss: 391211.2299\n",
      "Epoch 979/1000\n",
      "127/127 [==============================] - 0s - loss: 1019926.0953 - val_loss: 391148.9263\n",
      "Epoch 980/1000\n",
      "127/127 [==============================] - 0s - loss: 1045922.6259 - val_loss: 391048.8772\n",
      "Epoch 981/1000\n",
      "127/127 [==============================] - 0s - loss: 1040007.0414 - val_loss: 390954.4196\n",
      "Epoch 982/1000\n",
      "127/127 [==============================] - 0s - loss: 1045584.2480 - val_loss: 390860.9263\n",
      "Epoch 983/1000\n",
      "127/127 [==============================] - 0s - loss: 1056938.9817 - val_loss: 390787.5201\n",
      "Epoch 984/1000\n",
      "127/127 [==============================] - 0s - loss: 1036900.3533 - val_loss: 390714.6585\n",
      "Epoch 985/1000\n",
      "127/127 [==============================] - 0s - loss: 1046956.8184 - val_loss: 390654.6094\n",
      "Epoch 986/1000\n",
      "127/127 [==============================] - 0s - loss: 1022997.2934 - val_loss: 390559.5290\n",
      "Epoch 987/1000\n",
      "127/127 [==============================] - 0s - loss: 1022734.1492 - val_loss: 390493.3594\n",
      "Epoch 988/1000\n",
      "127/127 [==============================] - 0s - loss: 1026071.8461 - val_loss: 390414.1272\n",
      "Epoch 989/1000\n",
      "127/127 [==============================] - 0s - loss: 1042225.7170 - val_loss: 390352.4888\n",
      "Epoch 990/1000\n",
      "127/127 [==============================] - 0s - loss: 1037212.8601 - val_loss: 390284.1987\n",
      "Epoch 991/1000\n",
      "127/127 [==============================] - 0s - loss: 1049476.1176 - val_loss: 390211.9888\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 996228.9625 - val_loss: 390135.4442\n",
      "Epoch 993/1000\n",
      "127/127 [==============================] - 0s - loss: 1056136.8525 - val_loss: 390080.3125\n",
      "Epoch 994/1000\n",
      "127/127 [==============================] - 0s - loss: 1023554.3743 - val_loss: 390024.3415\n",
      "Epoch 995/1000\n",
      "127/127 [==============================] - 0s - loss: 1032216.4574 - val_loss: 389980.1071\n",
      "Epoch 996/1000\n",
      "127/127 [==============================] - 0s - loss: 1053533.4555 - val_loss: 389921.0603\n",
      "Epoch 997/1000\n",
      "127/127 [==============================] - 0s - loss: 1057826.2718 - val_loss: 389847.1607\n",
      "Epoch 998/1000\n",
      "127/127 [==============================] - 0s - loss: 1047326.8834 - val_loss: 389779.1964\n",
      "Epoch 999/1000\n",
      "127/127 [==============================] - 0s - loss: 1020006.1828 - val_loss: 389710.8906\n",
      "Epoch 1000/1000\n",
      "127/127 [==============================] - 0s - loss: 1036709.2964 - val_loss: 389659.2768\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 2292.04907227]\n",
      "result len(data): 163\n",
      "result data.shape: (163,)\n",
      "result len(slicing): 138\n",
      "result slicing_shape: (138, 25)\n",
      "[array([4146, 2386, 2700, 3016, 4059, 1740, 1844, 1900, 1812, 1889, 1794,\n",
      "       2424, 2143, 1631, 1584, 2587, 2284, 2342, 2055, 1885, 2178, 2336,\n",
      "       1781, 1615, 1759])]\n",
      "X_train shape: (137, 24, 1)\n",
      "y_train shape: (137,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 130 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "130/130 [==============================] - 0s - loss: 1186109.0424 - val_loss: 299137.3041\n",
      "Epoch 2/1000\n",
      "130/130 [==============================] - 0s - loss: 1156796.6988 - val_loss: 298699.8510\n",
      "Epoch 3/1000\n",
      "130/130 [==============================] - 0s - loss: 1201579.9792 - val_loss: 298358.0262\n",
      "Epoch 4/1000\n",
      "130/130 [==============================] - 0s - loss: 1186315.2748 - val_loss: 298014.0307\n",
      "Epoch 5/1000\n",
      "130/130 [==============================] - 0s - loss: 1166577.0016 - val_loss: 297696.6708\n",
      "Epoch 6/1000\n",
      "130/130 [==============================] - 0s - loss: 1201422.3851 - val_loss: 297383.0385\n",
      "Epoch 7/1000\n",
      "130/130 [==============================] - 0s - loss: 1164060.1849 - val_loss: 296965.9883\n",
      "Epoch 8/1000\n",
      "130/130 [==============================] - 0s - loss: 1179821.7470 - val_loss: 296715.4799\n",
      "Epoch 9/1000\n",
      "130/130 [==============================] - 0s - loss: 1193601.4666 - val_loss: 296351.6830\n",
      "Epoch 10/1000\n",
      "130/130 [==============================] - 0s - loss: 1173696.3048 - val_loss: 296097.2930\n",
      "Epoch 11/1000\n",
      "130/130 [==============================] - 0s - loss: 1221351.2769 - val_loss: 295832.2561\n",
      "Epoch 12/1000\n",
      "130/130 [==============================] - 0s - loss: 1178910.4306 - val_loss: 295521.1987\n",
      "Epoch 13/1000\n",
      "130/130 [==============================] - 0s - loss: 1184610.9531 - val_loss: 295206.5474\n",
      "Epoch 14/1000\n",
      "130/130 [==============================] - 0s - loss: 1193565.9007 - val_loss: 294882.3772\n",
      "Epoch 15/1000\n",
      "130/130 [==============================] - 0s - loss: 1180779.7242 - val_loss: 294645.6378\n",
      "Epoch 16/1000\n",
      "130/130 [==============================] - 0s - loss: 1153162.9306 - val_loss: 294343.2188\n",
      "Epoch 17/1000\n",
      "130/130 [==============================] - 0s - loss: 1141854.3026 - val_loss: 294070.2807\n",
      "Epoch 18/1000\n",
      "130/130 [==============================] - 0s - loss: 1148548.4206 - val_loss: 293741.4604\n",
      "Epoch 19/1000\n",
      "130/130 [==============================] - 0s - loss: 1133999.9956 - val_loss: 293460.9263\n",
      "Epoch 20/1000\n",
      "130/130 [==============================] - 0s - loss: 1176087.7306 - val_loss: 293212.9263\n",
      "Epoch 21/1000\n",
      "130/130 [==============================] - 0s - loss: 1185794.0330 - val_loss: 292936.0045\n",
      "Epoch 22/1000\n",
      "130/130 [==============================] - 0s - loss: 1143364.0924 - val_loss: 292616.7522\n",
      "Epoch 23/1000\n",
      "130/130 [==============================] - 0s - loss: 1199153.3870 - val_loss: 292289.7790\n",
      "Epoch 24/1000\n",
      "130/130 [==============================] - 0s - loss: 1158045.8090 - val_loss: 291952.8443\n",
      "Epoch 25/1000\n",
      "130/130 [==============================] - 0s - loss: 1163342.6012 - val_loss: 291622.8119\n",
      "Epoch 26/1000\n",
      "130/130 [==============================] - 0s - loss: 1155040.4776 - val_loss: 291414.0095\n",
      "Epoch 27/1000\n",
      "130/130 [==============================] - 0s - loss: 1200461.1034 - val_loss: 291137.6384\n",
      "Epoch 28/1000\n",
      "130/130 [==============================] - 0s - loss: 1159404.8396 - val_loss: 290862.5151\n",
      "Epoch 29/1000\n",
      "130/130 [==============================] - 0s - loss: 1168177.7993 - val_loss: 290551.6629\n",
      "Epoch 30/1000\n",
      "130/130 [==============================] - 0s - loss: 1180456.3921 - val_loss: 290302.4057\n",
      "Epoch 31/1000\n",
      "130/130 [==============================] - 0s - loss: 1193723.8345 - val_loss: 290069.4950\n",
      "Epoch 32/1000\n",
      "130/130 [==============================] - 0s - loss: 1147762.6523 - val_loss: 289824.2969\n",
      "Epoch 33/1000\n",
      "130/130 [==============================] - 0s - loss: 1168756.4847 - val_loss: 289573.1758\n",
      "Epoch 34/1000\n",
      "130/130 [==============================] - 0s - loss: 1193974.5682 - val_loss: 289375.6680\n",
      "Epoch 35/1000\n",
      "130/130 [==============================] - 0s - loss: 1158938.8487 - val_loss: 289147.0352\n",
      "Epoch 36/1000\n",
      "130/130 [==============================] - 0s - loss: 1198416.2215 - val_loss: 288931.5541\n",
      "Epoch 37/1000\n",
      "130/130 [==============================] - 0s - loss: 1141958.4603 - val_loss: 288715.3131\n",
      "Epoch 38/1000\n",
      "130/130 [==============================] - 0s - loss: 1154080.8022 - val_loss: 288500.3929\n",
      "Epoch 39/1000\n",
      "130/130 [==============================] - 0s - loss: 1119472.7365 - val_loss: 288281.0273\n",
      "Epoch 40/1000\n",
      "130/130 [==============================] - 0s - loss: 1158560.7132 - val_loss: 288060.2115\n",
      "Epoch 41/1000\n",
      "130/130 [==============================] - 0s - loss: 1151429.2802 - val_loss: 287827.6786\n",
      "Epoch 42/1000\n",
      "130/130 [==============================] - 0s - loss: 1141689.0612 - val_loss: 287611.8862\n",
      "Epoch 43/1000\n",
      "130/130 [==============================] - 0s - loss: 1182509.8492 - val_loss: 287382.5686\n",
      "Epoch 44/1000\n",
      "130/130 [==============================] - 0s - loss: 1139922.5334 - val_loss: 287146.2143\n",
      "Epoch 45/1000\n",
      "130/130 [==============================] - 0s - loss: 1143044.3416 - val_loss: 286896.3549\n",
      "Epoch 46/1000\n",
      "130/130 [==============================] - 0s - loss: 1165142.6725 - val_loss: 286666.8644\n",
      "Epoch 47/1000\n",
      "130/130 [==============================] - 0s - loss: 1178678.3255 - val_loss: 286447.0218\n",
      "Epoch 48/1000\n",
      "130/130 [==============================] - 0s - loss: 1172499.0458 - val_loss: 286211.7054\n",
      "Epoch 49/1000\n",
      "130/130 [==============================] - 0s - loss: 1126896.0428 - val_loss: 285946.0759\n",
      "Epoch 50/1000\n",
      "130/130 [==============================] - 0s - loss: 1170856.3021 - val_loss: 285786.5407\n",
      "Epoch 51/1000\n",
      "130/130 [==============================] - 0s - loss: 1148573.6603 - val_loss: 285557.7963\n",
      "Epoch 52/1000\n",
      "130/130 [==============================] - 0s - loss: 1163836.7651 - val_loss: 285403.4771\n",
      "Epoch 53/1000\n",
      "130/130 [==============================] - 0s - loss: 1163701.9968 - val_loss: 285202.1540\n",
      "Epoch 54/1000\n",
      "130/130 [==============================] - 0s - loss: 1201785.5832 - val_loss: 285008.8655\n",
      "Epoch 55/1000\n",
      "130/130 [==============================] - 0s - loss: 1152430.5476 - val_loss: 284815.8415\n",
      "Epoch 56/1000\n",
      "130/130 [==============================] - 0s - loss: 1164720.5434 - val_loss: 284665.4911\n",
      "Epoch 57/1000\n",
      "130/130 [==============================] - 0s - loss: 1153767.8858 - val_loss: 284466.5670\n",
      "Epoch 58/1000\n",
      "130/130 [==============================] - 0s - loss: 1139593.1029 - val_loss: 284251.7896\n",
      "Epoch 59/1000\n",
      "130/130 [==============================] - 0s - loss: 1176095.4500 - val_loss: 284096.9821\n",
      "Epoch 60/1000\n",
      "130/130 [==============================] - 0s - loss: 1117268.6181 - val_loss: 283934.6055\n",
      "Epoch 61/1000\n",
      "130/130 [==============================] - 0s - loss: 1158638.8748 - val_loss: 283713.4107\n",
      "Epoch 62/1000\n",
      "130/130 [==============================] - 0s - loss: 1138281.0801 - val_loss: 283566.5251293928\n",
      "Epoch 63/1000\n",
      "130/130 [==============================] - 0s - loss: 1110483.3389 - val_loss: 283388.4174\n",
      "Epoch 64/1000\n",
      "130/130 [==============================] - 0s - loss: 1146922.3747 - val_loss: 283225.0753\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1191205.9837 - val_loss: 283056.4598\n",
      "Epoch 66/1000\n",
      "130/130 [==============================] - 0s - loss: 1160926.8572 - val_loss: 282918.7506\n",
      "Epoch 67/1000\n",
      "130/130 [==============================] - 0s - loss: 1158270.7380 - val_loss: 282739.1367\n",
      "Epoch 68/1000\n",
      "130/130 [==============================] - 0s - loss: 1168037.1689 - val_loss: 282581.0201\n",
      "Epoch 69/1000\n",
      "130/130 [==============================] - 0s - loss: 1149876.3704 - val_loss: 282442.1568\n",
      "Epoch 70/1000\n",
      "130/130 [==============================] - 0s - loss: 1175822.8601 - val_loss: 282289.6936\n",
      "Epoch 71/1000\n",
      "130/130 [==============================] - 0s - loss: 1168137.7990 - val_loss: 282128.6769\n",
      "Epoch 72/1000\n",
      "130/130 [==============================] - 0s - loss: 1183892.4936 - val_loss: 281990.7829\n",
      "Epoch 73/1000\n",
      "130/130 [==============================] - 0s - loss: 1162156.1911 - val_loss: 281841.0525\n",
      "Epoch 74/1000\n",
      "130/130 [==============================] - 0s - loss: 1160591.3000 - val_loss: 281706.7243\n",
      "Epoch 75/1000\n",
      "130/130 [==============================] - 0s - loss: 1153363.0298 - val_loss: 281591.9565\n",
      "Epoch 76/1000\n",
      "130/130 [==============================] - 0s - loss: 1141105.9380 - val_loss: 281422.2868\n",
      "Epoch 77/1000\n",
      "130/130 [==============================] - 0s - loss: 1193116.9189 - val_loss: 281255.3337\n",
      "Epoch 78/1000\n",
      "130/130 [==============================] - 0s - loss: 1194702.0764 - val_loss: 281101.4353\n",
      "Epoch 79/1000\n",
      "130/130 [==============================] - 0s - loss: 1118697.8933 - val_loss: 280969.3996\n",
      "Epoch 80/1000\n",
      "130/130 [==============================] - 0s - loss: 1149412.5427 - val_loss: 280845.3192\n",
      "Epoch 81/1000\n",
      "130/130 [==============================] - 0s - loss: 1150262.9696 - val_loss: 280685.7411\n",
      "Epoch 82/1000\n",
      "130/130 [==============================] - 0s - loss: 1173426.5202 - val_loss: 280535.1763\n",
      "Epoch 83/1000\n",
      "130/130 [==============================] - 0s - loss: 1172111.4036 - val_loss: 280378.9431\n",
      "Epoch 84/1000\n",
      "130/130 [==============================] - 0s - loss: 1150262.1404 - val_loss: 280221.1194\n",
      "Epoch 85/1000\n",
      "130/130 [==============================] - 0s - loss: 1159075.4255 - val_loss: 280101.0145\n",
      "Epoch 86/1000\n",
      "130/130 [==============================] - 0s - loss: 1142448.8147 - val_loss: 279962.6016\n",
      "Epoch 87/1000\n",
      "130/130 [==============================] - 0s - loss: 1147588.5470 - val_loss: 279822.3973\n",
      "Epoch 88/1000\n",
      "130/130 [==============================] - 0s - loss: 1135178.1541 - val_loss: 279723.2734\n",
      "Epoch 89/1000\n",
      "130/130 [==============================] - 0s - loss: 1124181.3012 - val_loss: 279591.7556\n",
      "Epoch 90/1000\n",
      "130/130 [==============================] - 0s - loss: 1136489.6240 - val_loss: 279471.1931\n",
      "Epoch 91/1000\n",
      "130/130 [==============================] - 0s - loss: 1150275.6260 - val_loss: 279357.8717\n",
      "Epoch 92/1000\n",
      "130/130 [==============================] - 0s - loss: 1154846.4906 - val_loss: 279224.3449\n",
      "Epoch 93/1000\n",
      "130/130 [==============================] - 0s - loss: 1166730.1258 - val_loss: 279123.7221\n",
      "Epoch 94/1000\n",
      "130/130 [==============================] - 0s - loss: 1138488.0581 - val_loss: 278977.9152\n",
      "Epoch 95/1000\n",
      "130/130 [==============================] - 0s - loss: 1139501.3540 - val_loss: 278876.7690\n",
      "Epoch 96/1000\n",
      "130/130 [==============================] - 0s - loss: 1143618.8889 - val_loss: 278746.0458\n",
      "Epoch 97/1000\n",
      "130/130 [==============================] - 0s - loss: 1162849.0398 - val_loss: 278658.0525\n",
      "Epoch 98/1000\n",
      "130/130 [==============================] - 0s - loss: 1110148.1733 - val_loss: 278561.1842\n",
      "Epoch 99/1000\n",
      "130/130 [==============================] - 0s - loss: 1118158.7198 - val_loss: 278417.6228\n",
      "Epoch 100/1000\n",
      "130/130 [==============================] - 0s - loss: 1143140.3365 - val_loss: 278309.4364186\n",
      "Epoch 101/1000\n",
      "130/130 [==============================] - 0s - loss: 1142598.2875 - val_loss: 278185.3672\n",
      "Epoch 102/1000\n",
      "130/130 [==============================] - 0s - loss: 1159229.8356 - val_loss: 278071.5301\n",
      "Epoch 103/1000\n",
      "130/130 [==============================] - 0s - loss: 1143546.4162 - val_loss: 277948.6641\n",
      "Epoch 104/1000\n",
      "130/130 [==============================] - 0s - loss: 1136177.6864 - val_loss: 277811.7109\n",
      "Epoch 105/1000\n",
      "130/130 [==============================] - 0s - loss: 1181854.1942 - val_loss: 277699.3717\n",
      "Epoch 106/1000\n",
      "130/130 [==============================] - 0s - loss: 1146596.1442 - val_loss: 277601.3839\n",
      "Epoch 107/1000\n",
      "130/130 [==============================] - 0s - loss: 1141857.8310 - val_loss: 277549.3114\n",
      "Epoch 108/1000\n",
      "130/130 [==============================] - 0s - loss: 1162358.2824 - val_loss: 277435.9922\n",
      "Epoch 109/1000\n",
      "130/130 [==============================] - 0s - loss: 1149753.1062 - val_loss: 277311.3839\n",
      "Epoch 110/1000\n",
      "130/130 [==============================] - 0s - loss: 1147409.6686 - val_loss: 277236.1574\n",
      "Epoch 111/1000\n",
      "130/130 [==============================] - 0s - loss: 1141729.5312 - val_loss: 277132.1350\n",
      "Epoch 112/1000\n",
      "130/130 [==============================] - 0s - loss: 1172394.4244 - val_loss: 277052.3717\n",
      "Epoch 113/1000\n",
      "130/130 [==============================] - 0s - loss: 1189137.3608 - val_loss: 276940.3917\n",
      "Epoch 114/1000\n",
      "130/130 [==============================] - 0s - loss: 1151475.3245 - val_loss: 276847.4230\n",
      "Epoch 115/1000\n",
      "130/130 [==============================] - 0s - loss: 1157625.8952 - val_loss: 276758.3471\n",
      "Epoch 116/1000\n",
      "130/130 [==============================] - 0s - loss: 1156742.0543 - val_loss: 276662.1998\n",
      "Epoch 117/1000\n",
      "130/130 [==============================] - 0s - loss: 1161408.6505 - val_loss: 276587.1172\n",
      "Epoch 118/1000\n",
      "130/130 [==============================] - 0s - loss: 1189095.4675 - val_loss: 276506.0045\n",
      "Epoch 119/1000\n",
      "130/130 [==============================] - 0s - loss: 1165567.2234 - val_loss: 276409.1183\n",
      "Epoch 120/1000\n",
      "130/130 [==============================] - 0s - loss: 1160014.8138 - val_loss: 276353.5346\n",
      "Epoch 121/1000\n",
      "130/130 [==============================] - 0s - loss: 1191623.1099 - val_loss: 276279.0391\n",
      "Epoch 122/1000\n",
      "130/130 [==============================] - 0s - loss: 1166813.0511 - val_loss: 276206.9185\n",
      "Epoch 123/1000\n",
      "130/130 [==============================] - 0s - loss: 1149517.9115 - val_loss: 276139.4621\n",
      "Epoch 124/1000\n",
      "130/130 [==============================] - 0s - loss: 1141842.6173 - val_loss: 276072.8047\n",
      "Epoch 125/1000\n",
      "130/130 [==============================] - 0s - loss: 1106715.4673 - val_loss: 275970.8326\n",
      "Epoch 126/1000\n",
      "130/130 [==============================] - 0s - loss: 1173421.1526 - val_loss: 275896.0279\n",
      "Epoch 127/1000\n",
      "130/130 [==============================] - 0s - loss: 1147617.5296 - val_loss: 275828.8136\n",
      "Epoch 128/1000\n",
      "130/130 [==============================] - 0s - loss: 1160242.4782 - val_loss: 275748.4944\n",
      "Epoch 129/1000\n",
      "130/130 [==============================] - 0s - loss: 1135517.0093 - val_loss: 275685.4330\n",
      "Epoch 130/1000\n",
      "130/130 [==============================] - 0s - loss: 1151919.6743 - val_loss: 275602.5257\n",
      "Epoch 131/1000\n",
      "130/130 [==============================] - 0s - loss: 1193328.6945 - val_loss: 275538.5893\n",
      "Epoch 132/1000\n",
      "130/130 [==============================] - 0s - loss: 1152084.8490 - val_loss: 275467.9275\n",
      "Epoch 133/1000\n",
      "130/130 [==============================] - 0s - loss: 1153854.0799 - val_loss: 275388.2511\n",
      "Epoch 134/1000\n",
      "130/130 [==============================] - 0s - loss: 1187072.9442 - val_loss: 275336.3337\n",
      "Epoch 135/1000\n",
      "130/130 [==============================] - 0s - loss: 1178042.4270 - val_loss: 275275.0703\n",
      "Epoch 136/1000\n",
      "130/130 [==============================] - 0s - loss: 1154440.1798 - val_loss: 275194.9431\n",
      "Epoch 137/1000\n",
      "130/130 [==============================] - 0s - loss: 1133195.6262 - val_loss: 275130.8114\n",
      "Epoch 138/1000\n",
      "130/130 [==============================] - 0s - loss: 1154254.8024 - val_loss: 275090.0949\n",
      "Epoch 139/1000\n",
      "130/130 [==============================] - 0s - loss: 1137409.3073 - val_loss: 275032.0056\n",
      "Epoch 140/1000\n",
      "130/130 [==============================] - 0s - loss: 1127136.8434 - val_loss: 274979.7087\n",
      "Epoch 141/1000\n",
      "130/130 [==============================] - 0s - loss: 1163778.2945 - val_loss: 274913.9542\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1120538.1519 - val_loss: 274845.0525\n",
      "Epoch 143/1000\n",
      "130/130 [==============================] - 0s - loss: 1148995.1091 - val_loss: 274779.8315\n",
      "Epoch 144/1000\n",
      "130/130 [==============================] - 0s - loss: 1130798.4929 - val_loss: 274721.3828\n",
      "Epoch 145/1000\n",
      "130/130 [==============================] - 0s - loss: 1145968.1964 - val_loss: 274663.6652\n",
      "Epoch 146/1000\n",
      "130/130 [==============================] - 0s - loss: 1147336.3288 - val_loss: 274584.7667\n",
      "Epoch 147/1000\n",
      "130/130 [==============================] - 0s - loss: 1132933.7379 - val_loss: 274509.1551\n",
      "Epoch 148/1000\n",
      "130/130 [==============================] - 0s - loss: 1099682.7482 - val_loss: 274454.8315\n",
      "Epoch 149/1000\n",
      "130/130 [==============================] - 0s - loss: 1147190.0975 - val_loss: 274402.5614\n",
      "Epoch 150/1000\n",
      "130/130 [==============================] - 0s - loss: 1127874.8355 - val_loss: 274341.8248\n",
      "Epoch 151/1000\n",
      "130/130 [==============================] - 0s - loss: 1130977.3425 - val_loss: 274305.4275\n",
      "Epoch 152/1000\n",
      "130/130 [==============================] - 0s - loss: 1133004.8601 - val_loss: 274249.5212\n",
      "Epoch 153/1000\n",
      "130/130 [==============================] - 0s - loss: 1161930.7654 - val_loss: 274185.7176\n",
      "Epoch 154/1000\n",
      "130/130 [==============================] - 0s - loss: 1143095.5276 - val_loss: 274140.3025\n",
      "Epoch 155/1000\n",
      "130/130 [==============================] - 0s - loss: 1161158.1353 - val_loss: 274110.4766\n",
      "Epoch 156/1000\n",
      "130/130 [==============================] - 0s - loss: 1166284.2459 - val_loss: 274060.8047\n",
      "Epoch 157/1000\n",
      "130/130 [==============================] - 0s - loss: 1175515.6709 - val_loss: 274011.4598\n",
      "Epoch 158/1000\n",
      "130/130 [==============================] - 0s - loss: 1151259.1315 - val_loss: 273971.1518\n",
      "Epoch 159/1000\n",
      "130/130 [==============================] - 0s - loss: 1145812.9416 - val_loss: 273926.4475\n",
      "Epoch 160/1000\n",
      "130/130 [==============================] - 0s - loss: 1154104.3886 - val_loss: 273891.1127\n",
      "Epoch 161/1000\n",
      "130/130 [==============================] - 0s - loss: 1138800.4038 - val_loss: 273852.3181\n",
      "Epoch 162/1000\n",
      "130/130 [==============================] - 0s - loss: 1120773.5370 - val_loss: 273816.0848\n",
      "Epoch 163/1000\n",
      "130/130 [==============================] - 0s - loss: 1135843.5746 - val_loss: 273775.8795\n",
      "Epoch 164/1000\n",
      "130/130 [==============================] - 0s - loss: 1111403.0367 - val_loss: 273731.0982\n",
      "Epoch 165/1000\n",
      "130/130 [==============================] - 0s - loss: 1097138.8579 - val_loss: 273681.9297\n",
      "Epoch 166/1000\n",
      "130/130 [==============================] - 0s - loss: 1157565.6707 - val_loss: 273657.8080\n",
      "Epoch 167/1000\n",
      "130/130 [==============================] - 0s - loss: 1134022.0938 - val_loss: 273629.4252\n",
      "Epoch 168/1000\n",
      "130/130 [==============================] - 0s - loss: 1159240.9087 - val_loss: 273579.1473\n",
      "Epoch 169/1000\n",
      "130/130 [==============================] - 0s - loss: 1150023.2387 - val_loss: 273549.1652684\n",
      "Epoch 170/1000\n",
      "130/130 [==============================] - 0s - loss: 1128732.4600 - val_loss: 273507.195307935\n",
      "Epoch 171/1000\n",
      "130/130 [==============================] - 0s - loss: 1171088.0659 - val_loss: 273478.3717\n",
      "Epoch 172/1000\n",
      "130/130 [==============================] - 0s - loss: 1122542.2034 - val_loss: 273442.8828143670.802\n",
      "Epoch 173/1000\n",
      "130/130 [==============================] - 0s - loss: 1180350.2825 - val_loss: 273414.6641\n",
      "Epoch 174/1000\n",
      "130/130 [==============================] - 0s - loss: 1153378.7474 - val_loss: 273381.5056\n",
      "Epoch 175/1000\n",
      "130/130 [==============================] - 0s - loss: 1146854.6254 - val_loss: 273337.5190\n",
      "Epoch 176/1000\n",
      "130/130 [==============================] - 0s - loss: 1112111.7041 - val_loss: 273293.4420\n",
      "Epoch 177/1000\n",
      "130/130 [==============================] - 0s - loss: 1130600.0739 - val_loss: 273263.2489\n",
      "Epoch 178/1000\n",
      "130/130 [==============================] - 0s - loss: 1110050.9777 - val_loss: 273216.3739\n",
      "Epoch 179/1000\n",
      "130/130 [==============================] - 0s - loss: 1119089.7618 - val_loss: 273175.6752\n",
      "Epoch 180/1000\n",
      "130/130 [==============================] - 0s - loss: 1139035.2870 - val_loss: 273124.8739\n",
      "Epoch 181/1000\n",
      "130/130 [==============================] - 0s - loss: 1111575.8584 - val_loss: 273091.8248\n",
      "Epoch 182/1000\n",
      "130/130 [==============================] - 0s - loss: 1154155.0721 - val_loss: 273048.5402\n",
      "Epoch 183/1000\n",
      "130/130 [==============================] - 0s - loss: 1158887.3489 - val_loss: 273018.7946\n",
      "Epoch 184/1000\n",
      "130/130 [==============================] - 0s - loss: 1106434.2250 - val_loss: 272976.5167\n",
      "Epoch 185/1000\n",
      "130/130 [==============================] - 0s - loss: 1154291.5308 - val_loss: 272938.6518\n",
      "Epoch 186/1000\n",
      "130/130 [==============================] - 0s - loss: 1085527.3394 - val_loss: 272911.5815\n",
      "Epoch 187/1000\n",
      "130/130 [==============================] - 0s - loss: 1143720.4615 - val_loss: 272889.4911\n",
      "Epoch 188/1000\n",
      "130/130 [==============================] - 0s - loss: 1178171.9863 - val_loss: 272861.2935\n",
      "Epoch 189/1000\n",
      "130/130 [==============================] - 0s - loss: 1156828.4519 - val_loss: 272829.9252\n",
      "Epoch 190/1000\n",
      "130/130 [==============================] - 0s - loss: 1131813.5156 - val_loss: 272794.8359\n",
      "Epoch 191/1000\n",
      "130/130 [==============================] - 0s - loss: 1154124.1357 - val_loss: 272770.3583\n",
      "Epoch 192/1000\n",
      "130/130 [==============================] - 0s - loss: 1138124.3618 - val_loss: 272754.7679\n",
      "Epoch 193/1000\n",
      "130/130 [==============================] - 0s - loss: 1156316.7173 - val_loss: 272732.0435\n",
      "Epoch 194/1000\n",
      "130/130 [==============================] - 0s - loss: 1142049.8142 - val_loss: 272704.9520\n",
      "Epoch 195/1000\n",
      "130/130 [==============================] - 0s - loss: 1123611.7769 - val_loss: 272686.5792\n",
      "Epoch 196/1000\n",
      "130/130 [==============================] - 0s - loss: 1131579.8608 - val_loss: 272671.8203\n",
      "Epoch 197/1000\n",
      "130/130 [==============================] - 0s - loss: 1157036.1603 - val_loss: 272657.6797\n",
      "Epoch 198/1000\n",
      "130/130 [==============================] - 0s - loss: 1175983.3120 - val_loss: 272634.1071\n",
      "Epoch 199/1000\n",
      "130/130 [==============================] - 0s - loss: 1156417.0637 - val_loss: 272608.3516\n",
      "Epoch 200/1000\n",
      "130/130 [==============================] - 0s - loss: 1129731.8097 - val_loss: 272593.8560\n",
      "Epoch 201/1000\n",
      "130/130 [==============================] - 0s - loss: 1187363.0226 - val_loss: 272570.4855\n",
      "Epoch 202/1000\n",
      "130/130 [==============================] - 0s - loss: 1170269.4466 - val_loss: 272549.1395\n",
      "Epoch 203/1000\n",
      "130/130 [==============================] - 0s - loss: 1164266.1530 - val_loss: 272529.8382\n",
      "Epoch 204/1000\n",
      "130/130 [==============================] - 0s - loss: 1111961.6417 - val_loss: 272506.9810\n",
      "Epoch 205/1000\n",
      "130/130 [==============================] - 0s - loss: 1118272.5568 - val_loss: 272496.7913\n",
      "Epoch 206/1000\n",
      "130/130 [==============================] - 0s - loss: 1125784.1937 - val_loss: 272486.0357\n",
      "Epoch 207/1000\n",
      "130/130 [==============================] - 0s - loss: 1153817.2056 - val_loss: 272465.8092\n",
      "Epoch 208/1000\n",
      "130/130 [==============================] - 0s - loss: 1083871.5770 - val_loss: 272441.5391\n",
      "Epoch 209/1000\n",
      "130/130 [==============================] - 0s - loss: 1127798.7519 - val_loss: 272408.2679\n",
      "Epoch 210/1000\n",
      "130/130 [==============================] - 0s - loss: 1099952.6912 - val_loss: 272392.8583\n",
      "Epoch 211/1000\n",
      "130/130 [==============================] - 0s - loss: 1118036.8000 - val_loss: 272373.7288231788.97\n",
      "Epoch 212/1000\n",
      "130/130 [==============================] - 0s - loss: 1156520.3812 - val_loss: 272352.4252\n",
      "Epoch 213/1000\n",
      "130/130 [==============================] - 0s - loss: 1138060.3344 - val_loss: 272332.5636\n",
      "Epoch 214/1000\n",
      "130/130 [==============================] - 0s - loss: 1125677.1885 - val_loss: 272317.0792\n",
      "Epoch 215/1000\n",
      "130/130 [==============================] - 0s - loss: 1119893.0305 - val_loss: 272300.9408\n",
      "Epoch 216/1000\n",
      "130/130 [==============================] - 0s - loss: 1122650.0756 - val_loss: 272287.3493\n",
      "Epoch 217/1000\n",
      "130/130 [==============================] - 0s - loss: 1114319.9606 - val_loss: 272267.7679\n",
      "Epoch 218/1000\n",
      "130/130 [==============================] - 0s - loss: 1129387.7749 - val_loss: 272254.9408\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1135661.0745 - val_loss: 272240.2734\n",
      "Epoch 220/1000\n",
      "130/130 [==============================] - 0s - loss: 1155186.5507 - val_loss: 272223.5346\n",
      "Epoch 221/1000\n",
      "130/130 [==============================] - 0s - loss: 1103279.5921 - val_loss: 272200.4542\n",
      "Epoch 222/1000\n",
      "130/130 [==============================] - 0s - loss: 1155657.0389 - val_loss: 272188.1060\n",
      "Epoch 223/1000\n",
      "130/130 [==============================] - 0s - loss: 1153717.2218 - val_loss: 272176.8337\n",
      "Epoch 224/1000\n",
      "130/130 [==============================] - 0s - loss: 1134331.6498 - val_loss: 272160.5123\n",
      "Epoch 225/1000\n",
      "130/130 [==============================] - 0s - loss: 1174321.6321 - val_loss: 272158.0056\n",
      "Epoch 226/1000\n",
      "130/130 [==============================] - 0s - loss: 1117694.9964 - val_loss: 272156.5167\n",
      "Epoch 227/1000\n",
      "130/130 [==============================] - 0s - loss: 1141906.3928 - val_loss: 272134.5759\n",
      "Epoch 228/1000\n",
      "130/130 [==============================] - 0s - loss: 1145847.6480 - val_loss: 272123.9408\n",
      "Epoch 229/1000\n",
      "130/130 [==============================] - 0s - loss: 1115283.5084 - val_loss: 272113.1261\n",
      "Epoch 230/1000\n",
      "130/130 [==============================] - 0s - loss: 1152224.3893 - val_loss: 272094.8047191193.3\n",
      "Epoch 231/1000\n",
      "130/130 [==============================] - 0s - loss: 1135220.2431 - val_loss: 272077.4509\n",
      "Epoch 232/1000\n",
      "130/130 [==============================] - 0s - loss: 1152561.4442 - val_loss: 272051.4196\n",
      "Epoch 233/1000\n",
      "130/130 [==============================] - 0s - loss: 1144778.3649 - val_loss: 272039.8114\n",
      "Epoch 234/1000\n",
      "130/130 [==============================] - 0s - loss: 1144922.7112 - val_loss: 272029.5089\n",
      "Epoch 235/1000\n",
      "130/130 [==============================] - 0s - loss: 1142078.7569 - val_loss: 272021.9788\n",
      "Epoch 236/1000\n",
      "130/130 [==============================] - 0s - loss: 1136766.4499 - val_loss: 272011.0458\n",
      "Epoch 237/1000\n",
      "130/130 [==============================] - 0s - loss: 1164878.5300 - val_loss: 272000.0312\n",
      "Epoch 238/1000\n",
      "130/130 [==============================] - 0s - loss: 1177883.8476 - val_loss: 271998.0792\n",
      "Epoch 239/1000\n",
      "130/130 [==============================] - 0s - loss: 1133816.2823 - val_loss: 271985.1027\n",
      "Epoch 240/1000\n",
      "130/130 [==============================] - 0s - loss: 1156037.1855 - val_loss: 271974.6953805\n",
      "Epoch 241/1000\n",
      "130/130 [==============================] - 0s - loss: 1108730.1454 - val_loss: 271958.9866\n",
      "Epoch 242/1000\n",
      "130/130 [==============================] - 0s - loss: 1148738.5368 - val_loss: 271945.8661\n",
      "Epoch 243/1000\n",
      "130/130 [==============================] - 0s - loss: 1172583.0386 - val_loss: 271937.6239\n",
      "Epoch 244/1000\n",
      "130/130 [==============================] - 0s - loss: 1158214.4990 - val_loss: 271925.8694\n",
      "Epoch 245/1000\n",
      "130/130 [==============================] - 0s - loss: 1117230.0588 - val_loss: 271916.8761\n",
      "Epoch 246/1000\n",
      "130/130 [==============================] - 0s - loss: 1119157.4061 - val_loss: 271909.3203\n",
      "Epoch 247/1000\n",
      "130/130 [==============================] - 0s - loss: 1135503.5047 - val_loss: 271895.8393\n",
      "Epoch 248/1000\n",
      "130/130 [==============================] - 0s - loss: 1131969.2127 - val_loss: 271890.1373\n",
      "Epoch 249/1000\n",
      "130/130 [==============================] - 0s - loss: 1180275.4315 - val_loss: 271883.0982\n",
      "Epoch 250/1000\n",
      "130/130 [==============================] - 0s - loss: 1180728.1143 - val_loss: 271878.3917\n",
      "Epoch 251/1000\n",
      "130/130 [==============================] - 0s - loss: 1133055.4697 - val_loss: 271868.4007\n",
      "Epoch 252/1000\n",
      "130/130 [==============================] - 0s - loss: 1141700.2999 - val_loss: 271861.1908\n",
      "Epoch 253/1000\n",
      "130/130 [==============================] - 0s - loss: 1131432.0368 - val_loss: 271853.0882\n",
      "Epoch 254/1000\n",
      "130/130 [==============================] - 0s - loss: 1149336.6709 - val_loss: 271845.9598\n",
      "Epoch 255/1000\n",
      "130/130 [==============================] - 0s - loss: 1154223.0837 - val_loss: 271838.1339\n",
      "Epoch 256/1000\n",
      "130/130 [==============================] - 0s - loss: 1146797.5346 - val_loss: 271829.5770\n",
      "Epoch 257/1000\n",
      "130/130 [==============================] - 0s - loss: 1145149.1317 - val_loss: 271823.68759\n",
      "Epoch 258/1000\n",
      "130/130 [==============================] - 0s - loss: 1139819.3445 - val_loss: 271815.9520\n",
      "Epoch 259/1000\n",
      "130/130 [==============================] - 0s - loss: 1136482.6656 - val_loss: 271808.5435\n",
      "Epoch 260/1000\n",
      "130/130 [==============================] - 0s - loss: 1181859.4070 - val_loss: 271803.0145\n",
      "Epoch 261/1000\n",
      "130/130 [==============================] - 0s - loss: 1152866.5123 - val_loss: 271792.6551\n",
      "Epoch 262/1000\n",
      "130/130 [==============================] - 0s - loss: 1150138.1611 - val_loss: 271784.7913369353\n",
      "Epoch 263/1000\n",
      "130/130 [==============================] - 0s - loss: 1128981.7589 - val_loss: 271783.7377\n",
      "Epoch 264/1000\n",
      "130/130 [==============================] - 0s - loss: 1166350.9159 - val_loss: 271783.7087\n",
      "Epoch 265/1000\n",
      "130/130 [==============================] - 0s - loss: 1164654.1026 - val_loss: 271779.4821\n",
      "Epoch 266/1000\n",
      "130/130 [==============================] - 0s - loss: 1178792.6116 - val_loss: 271776.6306\n",
      "Epoch 267/1000\n",
      "130/130 [==============================] - 0s - loss: 1125014.5704 - val_loss: 271773.7422\n",
      "Epoch 268/1000\n",
      "130/130 [==============================] - 0s - loss: 1168854.8757 - val_loss: 271769.4107\n",
      "Epoch 269/1000\n",
      "130/130 [==============================] - 0s - loss: 1117862.7109 - val_loss: 271761.7545\n",
      "Epoch 270/1000\n",
      "130/130 [==============================] - 0s - loss: 1097462.2906 - val_loss: 271753.0223\n",
      "Epoch 271/1000\n",
      "130/130 [==============================] - 0s - loss: 1152079.3986 - val_loss: 271748.0815\n",
      "Epoch 272/1000\n",
      "130/130 [==============================] - 0s - loss: 1152578.4714 - val_loss: 271744.1975\n",
      "Epoch 273/1000\n",
      "130/130 [==============================] - 0s - loss: 1166153.8382 - val_loss: 271741.7411\n",
      "Epoch 274/1000\n",
      "130/130 [==============================] - 0s - loss: 1118019.9411 - val_loss: 271739.0993\n",
      "Epoch 275/1000\n",
      "130/130 [==============================] - 0s - loss: 1125388.2555 - val_loss: 271733.9196\n",
      "Epoch 276/1000\n",
      "130/130 [==============================] - 0s - loss: 1126253.0481 - val_loss: 271730.1953\n",
      "Epoch 277/1000\n",
      "130/130 [==============================] - 0s - loss: 1159241.0260 - val_loss: 271727.1819\n",
      "Epoch 278/1000\n",
      "130/130 [==============================] - 0s - loss: 1136182.5673 - val_loss: 271723.4688\n",
      "Epoch 279/1000\n",
      "130/130 [==============================] - 0s - loss: 1174865.8038 - val_loss: 271721.4286\n",
      "Epoch 280/1000\n",
      "130/130 [==============================] - 0s - loss: 1116663.4304 - val_loss: 271717.1306\n",
      "Epoch 281/1000\n",
      "130/130 [==============================] - 0s - loss: 1128064.1506 - val_loss: 271714.0357\n",
      "Epoch 282/1000\n",
      "130/130 [==============================] - 0s - loss: 1154371.7002 - val_loss: 271708.8382\n",
      "Epoch 283/1000\n",
      "130/130 [==============================] - 0s - loss: 1125332.3440 - val_loss: 271705.6842\n",
      "Epoch 284/1000\n",
      "130/130 [==============================] - 0s - loss: 1123329.2962 - val_loss: 271703.4386\n",
      "Epoch 285/1000\n",
      "130/130 [==============================] - 0s - loss: 1089982.8788 - val_loss: 271699.5000\n",
      "Epoch 286/1000\n",
      "130/130 [==============================] - 0s - loss: 1141513.1118 - val_loss: 271696.7321\n",
      "Epoch 287/1000\n",
      "130/130 [==============================] - 0s - loss: 1141861.2493 - val_loss: 271695.7868\n",
      "Epoch 288/1000\n",
      "130/130 [==============================] - 0s - loss: 1142910.3538 - val_loss: 271694.5446\n",
      "Epoch 289/1000\n",
      "130/130 [==============================] - 0s - loss: 1156644.4748 - val_loss: 271691.9821\n",
      "Epoch 290/1000\n",
      "130/130 [==============================] - 0s - loss: 1148403.9004 - val_loss: 271688.8214\n",
      "Epoch 291/1000\n",
      "130/130 [==============================] - 0s - loss: 1162946.7511 - val_loss: 271686.7623\n",
      "Epoch 292/1000\n",
      "130/130 [==============================] - 0s - loss: 1103445.3341 - val_loss: 271684.1194\n",
      "Epoch 293/1000\n",
      "130/130 [==============================] - 0s - loss: 1130608.1685 - val_loss: 271683.2589\n",
      "Epoch 294/1000\n",
      "130/130 [==============================] - 0s - loss: 1094263.5085 - val_loss: 271681.8661\n",
      "Epoch 295/1000\n",
      "130/130 [==============================] - 0s - loss: 1095537.7537 - val_loss: 271680.8393\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1170896.0743 - val_loss: 271680.0636\n",
      "Epoch 297/1000\n",
      "130/130 [==============================] - 0s - loss: 1166046.1125 - val_loss: 271678.8739\n",
      "Epoch 298/1000\n",
      "130/130 [==============================] - 0s - loss: 1156101.0344 - val_loss: 271678.1875\n",
      "Epoch 299/1000\n",
      "130/130 [==============================] - 0s - loss: 1135137.3799 - val_loss: 271677.5804\n",
      "Epoch 300/1000\n",
      "130/130 [==============================] - 0s - loss: 1143250.9137 - val_loss: 271677.1953\n",
      "Epoch 301/1000\n",
      "130/130 [==============================] - 0s - loss: 1138080.5810 - val_loss: 271676.8080\n",
      "Epoch 302/1000\n",
      "130/130 [==============================] - 0s - loss: 1138736.9401 - val_loss: 271676.4408\n",
      "Epoch 303/1000\n",
      "130/130 [==============================] - 0s - loss: 1136909.6837 - val_loss: 271676.3426\n",
      "Epoch 304/1000\n",
      "130/130 [==============================] - 0s - loss: 1127112.6624 - val_loss: 271676.2600\n",
      "Epoch 305/1000\n",
      "130/130 [==============================] - 0s - loss: 1091120.8281 - val_loss: 271676.4275\n",
      "Epoch 306/1000\n",
      "130/130 [==============================] - 0s - loss: 1164838.8602 - val_loss: 271676.5815\n",
      "Epoch 307/1000\n",
      "130/130 [==============================] - 0s - loss: 1176881.7629 - val_loss: 271677.1295\n",
      "Epoch 308/1000\n",
      "130/130 [==============================] - 0s - loss: 1172986.4316 - val_loss: 271677.5000\n",
      "Epoch 309/1000\n",
      "130/130 [==============================] - 0s - loss: 1122554.2555 - val_loss: 271678.0904\n",
      "Epoch 310/1000\n",
      "130/130 [==============================] - 0s - loss: 1107345.0841 - val_loss: 271678.7500\n",
      "Epoch 311/1000\n",
      "130/130 [==============================] - 0s - loss: 1155589.8428 - val_loss: 271679.3739\n",
      "Epoch 312/1000\n",
      "130/130 [==============================] - 0s - loss: 1181751.5940 - val_loss: 271679.8750\n",
      "Epoch 313/1000\n",
      "130/130 [==============================] - 0s - loss: 1098394.9232 - val_loss: 271681.4632\n",
      "Epoch 314/1000\n",
      "130/130 [==============================] - 0s - loss: 1125459.1148 - val_loss: 271682.3471\n",
      "Epoch 315/1000\n",
      "130/130 [==============================] - 0s - loss: 1139734.0389 - val_loss: 271683.4810\n",
      "Epoch 316/1000\n",
      "130/130 [==============================] - 0s - loss: 1146997.4606 - val_loss: 271684.1775\n",
      "Epoch 317/1000\n",
      "130/130 [==============================] - 0s - loss: 1135283.9069 - val_loss: 271685.0636\n",
      "Epoch 318/1000\n",
      "130/130 [==============================] - 0s - loss: 1142264.5385 - val_loss: 271686.2991\n",
      "Epoch 319/1000\n",
      "130/130 [==============================] - 0s - loss: 1147224.9800 - val_loss: 271688.0714\n",
      "Epoch 320/1000\n",
      "130/130 [==============================] - 0s - loss: 1122465.4267 - val_loss: 271689.6484\n",
      "Epoch 321/1000\n",
      "130/130 [==============================] - 0s - loss: 1133675.3704 - val_loss: 271691.9453\n",
      "Epoch 322/1000\n",
      "130/130 [==============================] - 0s - loss: 1102146.6837 - val_loss: 271694.0882\n",
      "Epoch 323/1000\n",
      "130/130 [==============================] - 0s - loss: 1111188.7309 - val_loss: 271694.9498\n",
      "Epoch 324/1000\n",
      "130/130 [==============================] - 0s - loss: 1142455.7019 - val_loss: 271695.4029\n",
      "Epoch 325/1000\n",
      "130/130 [==============================] - 0s - loss: 1137837.6430 - val_loss: 271695.8761\n",
      "Epoch 326/1000\n",
      "130/130 [==============================] - 0s - loss: 1107478.2543 - val_loss: 271698.0123\n",
      "Epoch 327/1000\n",
      "130/130 [==============================] - 0s - loss: 1164203.1621 - val_loss: 271699.5223\n",
      "Epoch 328/1000\n",
      "130/130 [==============================] - 0s - loss: 1109539.8514 - val_loss: 271700.1797\n",
      "Epoch 329/1000\n",
      "130/130 [==============================] - 0s - loss: 1135250.9325 - val_loss: 271700.2679\n",
      "Epoch 330/1000\n",
      "130/130 [==============================] - 0s - loss: 1115279.0680 - val_loss: 271702.2310\n",
      "Epoch 331/1000\n",
      "130/130 [==============================] - 0s - loss: 1114162.9151 - val_loss: 271705.8962\n",
      "Epoch 332/1000\n",
      "130/130 [==============================] - 0s - loss: 1154752.9953 - val_loss: 271706.0435\n",
      "Epoch 333/1000\n",
      "130/130 [==============================] - 0s - loss: 1178401.2721 - val_loss: 271709.4967\n",
      "Epoch 334/1000\n",
      "130/130 [==============================] - 0s - loss: 1153985.2127 - val_loss: 271710.8471\n",
      "Epoch 335/1000\n",
      "130/130 [==============================] - 0s - loss: 1132818.9536 - val_loss: 271714.8092\n",
      "Epoch 336/1000\n",
      "130/130 [==============================] - 0s - loss: 1138221.2169 - val_loss: 271717.2913\n",
      "Epoch 337/1000\n",
      "130/130 [==============================] - 0s - loss: 1144237.0808 - val_loss: 271716.1596\n",
      "Epoch 338/1000\n",
      "130/130 [==============================] - 0s - loss: 1126431.2014 - val_loss: 271718.6071\n",
      "Epoch 339/1000\n",
      "130/130 [==============================] - 0s - loss: 1121092.2379 - val_loss: 271721.1975\n",
      "Epoch 340/1000\n",
      "130/130 [==============================] - 0s - loss: 1172564.8320 - val_loss: 271722.9989\n",
      "Epoch 341/1000\n",
      "130/130 [==============================] - 0s - loss: 1139113.0178 - val_loss: 271723.7422\n",
      "Epoch 342/1000\n",
      "130/130 [==============================] - 0s - loss: 1156431.7320 - val_loss: 271727.5368\n",
      "Epoch 343/1000\n",
      "130/130 [==============================] - 0s - loss: 1141713.3544 - val_loss: 271729.4788\n",
      "Epoch 344/1000\n",
      "130/130 [==============================] - 0s - loss: 1141052.2275 - val_loss: 271732.8650\n",
      "Epoch 345/1000\n",
      "130/130 [==============================] - 0s - loss: 1185104.3048 - val_loss: 271733.1161\n",
      "Epoch 346/1000\n",
      "130/130 [==============================] - 0s - loss: 1134351.6579 - val_loss: 271735.0078\n",
      "Epoch 347/1000\n",
      "130/130 [==============================] - 0s - loss: 1137112.1230 - val_loss: 271738.2891\n",
      "Epoch 348/1000\n",
      "130/130 [==============================] - 0s - loss: 1146833.1322 - val_loss: 271742.4375\n",
      "Epoch 349/1000\n",
      "130/130 [==============================] - 0s - loss: 1151317.1327 - val_loss: 271746.6518\n",
      "Epoch 350/1000\n",
      "130/130 [==============================] - 0s - loss: 1127174.7617 - val_loss: 271747.7623\n",
      "Epoch 351/1000\n",
      "130/130 [==============================] - 0s - loss: 1132274.3846 - val_loss: 271751.2734\n",
      "Epoch 352/1000\n",
      "130/130 [==============================] - 0s - loss: 1140838.5697 - val_loss: 271754.6741\n",
      "Epoch 353/1000\n",
      "130/130 [==============================] - 0s - loss: 1114246.7438 - val_loss: 271762.0301\n",
      "Epoch 354/1000\n",
      "130/130 [==============================] - 0s - loss: 1157580.6793 - val_loss: 271766.0089\n",
      "Epoch 355/1000\n",
      "130/130 [==============================] - 0s - loss: 1132569.5392 - val_loss: 271770.1641\n",
      "Epoch 356/1000\n",
      "130/130 [==============================] - 0s - loss: 1128893.4067 - val_loss: 271770.4810\n",
      "Epoch 357/1000\n",
      "130/130 [==============================] - 0s - loss: 1122504.4287 - val_loss: 271771.5179\n",
      "Epoch 358/1000\n",
      "130/130 [==============================] - 0s - loss: 1148209.9292 - val_loss: 271774.6685\n",
      "Epoch 359/1000\n",
      "130/130 [==============================] - 0s - loss: 1127090.6501 - val_loss: 271776.2589\n",
      "Epoch 360/1000\n",
      "130/130 [==============================] - 0s - loss: 1147680.6550 - val_loss: 271780.2321\n",
      "Epoch 361/1000\n",
      "130/130 [==============================] - 0s - loss: 1120097.4831 - val_loss: 271786.2991\n",
      "Epoch 362/1000\n",
      "130/130 [==============================] - 0s - loss: 1106097.9998 - val_loss: 271787.2243\n",
      "Epoch 363/1000\n",
      "130/130 [==============================] - 0s - loss: 1135290.8000 - val_loss: 271794.6239\n",
      "Epoch 364/1000\n",
      "130/130 [==============================] - 0s - loss: 1149878.1483 - val_loss: 271794.2333\n",
      "Epoch 365/1000\n",
      "130/130 [==============================] - 0s - loss: 1128355.4035 - val_loss: 271799.3225\n",
      "Epoch 366/1000\n",
      "130/130 [==============================] - 0s - loss: 1145701.5774 - val_loss: 271803.4051\n",
      "Epoch 367/1000\n",
      "130/130 [==============================] - 0s - loss: 1139340.7896 - val_loss: 271805.2935\n",
      "Epoch 368/1000\n",
      "130/130 [==============================] - 0s - loss: 1146917.5297 - val_loss: 271809.3650\n",
      "Epoch 369/1000\n",
      "130/130 [==============================] - 0s - loss: 1115686.0623 - val_loss: 271814.2154\n",
      "Epoch 370/1000\n",
      "130/130 [==============================] - 0s - loss: 1114747.7832 - val_loss: 271817.6384\n",
      "Epoch 371/1000\n",
      "130/130 [==============================] - 0s - loss: 1076733.9648 - val_loss: 271823.2958\n",
      "Epoch 372/1000\n",
      "130/130 [==============================] - 0s - loss: 1185522.6179 - val_loss: 271827.3080\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1124077.6008 - val_loss: 271830.8661\n",
      "Epoch 374/1000\n",
      "130/130 [==============================] - 0s - loss: 1110147.0654 - val_loss: 271834.8884\n",
      "Epoch 375/1000\n",
      "130/130 [==============================] - 0s - loss: 1139061.4565 - val_loss: 271837.1607\n",
      "Epoch 376/1000\n",
      "130/130 [==============================] - 0s - loss: 1111053.6668 - val_loss: 271840.0525\n",
      "Epoch 377/1000\n",
      "130/130 [==============================] - 0s - loss: 1150486.9529 - val_loss: 271842.5748\n",
      "Epoch 378/1000\n",
      "130/130 [==============================] - 0s - loss: 1097058.1584 - val_loss: 271850.0179\n",
      "Epoch 379/1000\n",
      "130/130 [==============================] - 0s - loss: 1177124.4108 - val_loss: 271851.2623\n",
      "Epoch 380/1000\n",
      "130/130 [==============================] - 0s - loss: 1191716.2433 - val_loss: 271850.9241\n",
      "Epoch 381/1000\n",
      "130/130 [==============================] - 0s - loss: 1170920.1647 - val_loss: 271852.7009\n",
      "Epoch 382/1000\n",
      "130/130 [==============================] - 0s - loss: 1118413.7423 - val_loss: 271851.8404\n",
      "Epoch 383/1000\n",
      "130/130 [==============================] - 0s - loss: 1122313.8845 - val_loss: 271860.4464\n",
      "Epoch 384/1000\n",
      "130/130 [==============================] - 0s - loss: 1171264.7196 - val_loss: 271860.85277082\n",
      "Epoch 385/1000\n",
      "130/130 [==============================] - 0s - loss: 1130985.9418 - val_loss: 271864.2455206590.46\n",
      "Epoch 386/1000\n",
      "130/130 [==============================] - 0s - loss: 1114030.3240 - val_loss: 271866.9542\n",
      "Epoch 387/1000\n",
      "130/130 [==============================] - 0s - loss: 1139284.5225 - val_loss: 271870.1417\n",
      "Epoch 388/1000\n",
      "130/130 [==============================] - 0s - loss: 1100094.9852 - val_loss: 271877.3471\n",
      "Epoch 389/1000\n",
      "130/130 [==============================] - 0s - loss: 1114570.5940 - val_loss: 271879.2132\n",
      "Epoch 390/1000\n",
      "130/130 [==============================] - 0s - loss: 1101140.0512 - val_loss: 271890.6574\n",
      "Epoch 391/1000\n",
      "130/130 [==============================] - 0s - loss: 1147114.3122 - val_loss: 271894.9732\n",
      "Epoch 392/1000\n",
      "130/130 [==============================] - 0s - loss: 1157866.8968 - val_loss: 271891.9542\n",
      "Epoch 393/1000\n",
      "130/130 [==============================] - 0s - loss: 1143016.4541 - val_loss: 271895.5636\n",
      "Epoch 394/1000\n",
      "130/130 [==============================] - 0s - loss: 1105182.3454 - val_loss: 271892.5089\n",
      "Epoch 395/1000\n",
      "130/130 [==============================] - 0s - loss: 1152758.8481 - val_loss: 271895.7243\n",
      "Epoch 396/1000\n",
      "130/130 [==============================] - 0s - loss: 1130066.8029 - val_loss: 271895.4989\n",
      "Epoch 397/1000\n",
      "130/130 [==============================] - 0s - loss: 1150923.5393 - val_loss: 271897.4598\n",
      "Epoch 398/1000\n",
      "130/130 [==============================] - 0s - loss: 1150168.3678 - val_loss: 271895.4464\n",
      "Epoch 399/1000\n",
      "130/130 [==============================] - 0s - loss: 1126781.1103 - val_loss: 271897.4833\n",
      "Epoch 400/1000\n",
      "130/130 [==============================] - 0s - loss: 1122334.1134 - val_loss: 271904.6975\n",
      "Epoch 401/1000\n",
      "130/130 [==============================] - 0s - loss: 1150066.1020 - val_loss: 271908.8047600\n",
      "Epoch 402/1000\n",
      "130/130 [==============================] - 0s - loss: 1142928.7141 - val_loss: 271915.4732\n",
      "Epoch 403/1000\n",
      "130/130 [==============================] - 0s - loss: 1169442.6678 - val_loss: 271925.0792\n",
      "Epoch 404/1000\n",
      "130/130 [==============================] - 0s - loss: 1115785.3555 - val_loss: 271931.8538\n",
      "Epoch 405/1000\n",
      "130/130 [==============================] - 0s - loss: 1145741.3149 - val_loss: 271938.1350\n",
      "Epoch 406/1000\n",
      "130/130 [==============================] - 0s - loss: 1134162.2842 - val_loss: 271939.1842\n",
      "Epoch 407/1000\n",
      "130/130 [==============================] - 0s - loss: 1141749.4472 - val_loss: 271946.6384\n",
      "Epoch 408/1000\n",
      "130/130 [==============================] - 0s - loss: 1151308.9245 - val_loss: 271954.8404\n",
      "Epoch 409/1000\n",
      "130/130 [==============================] - 0s - loss: 1139957.0410 - val_loss: 271959.8270\n",
      "Epoch 410/1000\n",
      "130/130 [==============================] - 0s - loss: 1114434.0360 - val_loss: 271964.8002\n",
      "Epoch 411/1000\n",
      "130/130 [==============================] - 0s - loss: 1156417.7904 - val_loss: 271961.3560\n",
      "Epoch 412/1000\n",
      "130/130 [==============================] - 0s - loss: 1136976.3500 - val_loss: 271966.8661\n",
      "Epoch 413/1000\n",
      "130/130 [==============================] - 0s - loss: 1138094.0655 - val_loss: 271976.5190\n",
      "Epoch 414/1000\n",
      "130/130 [==============================] - 0s - loss: 1139812.9512 - val_loss: 271984.6875\n",
      "Epoch 415/1000\n",
      "130/130 [==============================] - 0s - loss: 1150486.1996 - val_loss: 271987.3482\n",
      "Epoch 416/1000\n",
      "130/130 [==============================] - 0s - loss: 1138747.7053 - val_loss: 271993.2545\n",
      "Epoch 417/1000\n",
      "130/130 [==============================] - 0s - loss: 1137324.6139 - val_loss: 271995.5156\n",
      "Epoch 418/1000\n",
      "130/130 [==============================] - 0s - loss: 1135845.7017 - val_loss: 271996.1406\n",
      "Epoch 419/1000\n",
      "130/130 [==============================] - 0s - loss: 1150884.9541 - val_loss: 271998.9062\n",
      "Epoch 420/1000\n",
      "130/130 [==============================] - 0s - loss: 1097105.9873 - val_loss: 272003.9464\n",
      "Epoch 421/1000\n",
      "130/130 [==============================] - 0s - loss: 1154446.1483 - val_loss: 272002.6138\n",
      "Epoch 422/1000\n",
      "130/130 [==============================] - 0s - loss: 1141805.9938 - val_loss: 272005.8705180636.043\n",
      "Epoch 423/1000\n",
      "130/130 [==============================] - 0s - loss: 1126780.6935 - val_loss: 272009.5960\n",
      "Epoch 424/1000\n",
      "130/130 [==============================] - 0s - loss: 1101506.0671 - val_loss: 272014.3638\n",
      "Epoch 425/1000\n",
      "130/130 [==============================] - 0s - loss: 1142259.3087 - val_loss: 272016.5915\n",
      "Epoch 426/1000\n",
      "130/130 [==============================] - 0s - loss: 1182935.4808 - val_loss: 272024.4576\n",
      "Epoch 427/1000\n",
      "130/130 [==============================] - 0s - loss: 1147479.5125 - val_loss: 272026.6049\n",
      "Epoch 428/1000\n",
      "130/130 [==============================] - 0s - loss: 1131123.2022 - val_loss: 272035.9554\n",
      "Epoch 429/1000\n",
      "130/130 [==============================] - 0s - loss: 1143506.5370 - val_loss: 272032.7656\n",
      "Epoch 430/1000\n",
      "130/130 [==============================] - 0s - loss: 1122420.8803 - val_loss: 272042.6942\n",
      "Epoch 431/1000\n",
      "130/130 [==============================] - 0s - loss: 1151938.1012 - val_loss: 272042.2165\n",
      "Epoch 432/1000\n",
      "130/130 [==============================] - 0s - loss: 1128951.9529 - val_loss: 272045.2076\n",
      "Epoch 433/1000\n",
      "130/130 [==============================] - 0s - loss: 1145014.8983 - val_loss: 272043.5134\n",
      "Epoch 434/1000\n",
      "130/130 [==============================] - 0s - loss: 1161459.9385 - val_loss: 272044.7902\n",
      "Epoch 435/1000\n",
      "130/130 [==============================] - 0s - loss: 1112245.0070 - val_loss: 272054.7210\n",
      "Epoch 436/1000\n",
      "130/130 [==============================] - 0s - loss: 1161639.3774 - val_loss: 272057.5826\n",
      "Epoch 437/1000\n",
      "130/130 [==============================] - 0s - loss: 1159259.2356 - val_loss: 272059.83711012.827\n",
      "Epoch 438/1000\n",
      "130/130 [==============================] - 0s - loss: 1140367.8744 - val_loss: 272063.2567\n",
      "Epoch 439/1000\n",
      "130/130 [==============================] - 0s - loss: 1153372.9500 - val_loss: 272064.4129\n",
      "Epoch 440/1000\n",
      "130/130 [==============================] - 0s - loss: 1120114.4007 - val_loss: 272069.2589\n",
      "Epoch 441/1000\n",
      "130/130 [==============================] - 0s - loss: 1153054.6894 - val_loss: 272076.1942\n",
      "Epoch 442/1000\n",
      "130/130 [==============================] - 0s - loss: 1139320.4357 - val_loss: 272085.1116\n",
      "Epoch 443/1000\n",
      "130/130 [==============================] - 0s - loss: 1134668.6800 - val_loss: 272087.8214\n",
      "Epoch 444/1000\n",
      "130/130 [==============================] - 0s - loss: 1129433.1760 - val_loss: 272092.6540\n",
      "Epoch 445/1000\n",
      "130/130 [==============================] - 0s - loss: 1158572.8850 - val_loss: 272094.1451\n",
      "Epoch 446/1000\n",
      "130/130 [==============================] - 0s - loss: 1119055.3561 - val_loss: 272095.6629\n",
      "Epoch 447/1000\n",
      "130/130 [==============================] - 0s - loss: 1114405.2380 - val_loss: 272107.4978\n",
      "Epoch 448/1000\n",
      "130/130 [==============================] - 0s - loss: 1162021.5018 - val_loss: 272107.5737\n",
      "Epoch 449/1000\n",
      "130/130 [==============================] - 0s - loss: 1138251.9070 - val_loss: 272112.49782483\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1115185.8346 - val_loss: 272111.3862\n",
      "Epoch 451/1000\n",
      "130/130 [==============================] - 0s - loss: 1142633.0659 - val_loss: 272116.8683\n",
      "Epoch 452/1000\n",
      "130/130 [==============================] - 0s - loss: 1131465.3287 - val_loss: 272125.9978\n",
      "Epoch 453/1000\n",
      "130/130 [==============================] - 0s - loss: 1174515.6757 - val_loss: 272129.4219\n",
      "Epoch 454/1000\n",
      "130/130 [==============================] - 0s - loss: 1124846.2353 - val_loss: 272126.2545\n",
      "Epoch 455/1000\n",
      "130/130 [==============================] - 0s - loss: 1161487.1082 - val_loss: 272134.0960\n",
      "Epoch 456/1000\n",
      "130/130 [==============================] - 0s - loss: 1143660.1750 - val_loss: 272143.9442\n",
      "Epoch 457/1000\n",
      "130/130 [==============================] - 0s - loss: 1123348.2349 - val_loss: 272148.6897\n",
      "Epoch 458/1000\n",
      "130/130 [==============================] - 0s - loss: 1139524.0339 - val_loss: 272149.0045\n",
      "Epoch 459/1000\n",
      "130/130 [==============================] - 0s - loss: 1148837.7732 - val_loss: 272155.5513\n",
      "Epoch 460/1000\n",
      "130/130 [==============================] - 0s - loss: 1132550.1637 - val_loss: 272161.9710\n",
      "Epoch 461/1000\n",
      "130/130 [==============================] - 0s - loss: 1113169.6668 - val_loss: 272169.0714\n",
      "Epoch 462/1000\n",
      "130/130 [==============================] - 0s - loss: 1121545.5241 - val_loss: 272182.0424\n",
      "Epoch 463/1000\n",
      "130/130 [==============================] - 0s - loss: 1138004.8603 - val_loss: 272178.8638\n",
      "Epoch 464/1000\n",
      "130/130 [==============================] - 0s - loss: 1135357.9137 - val_loss: 272192.0022\n",
      "Epoch 465/1000\n",
      "130/130 [==============================] - 0s - loss: 1123389.1204 - val_loss: 272196.9219\n",
      "Epoch 466/1000\n",
      "130/130 [==============================] - 0s - loss: 1139047.2594 - val_loss: 272202.9621\n",
      "Epoch 467/1000\n",
      "130/130 [==============================] - 0s - loss: 1142484.5874 - val_loss: 272211.7969\n",
      "Epoch 468/1000\n",
      "130/130 [==============================] - 0s - loss: 1126532.2531 - val_loss: 272223.8304\n",
      "Epoch 469/1000\n",
      "130/130 [==============================] - 0s - loss: 1102482.0673 - val_loss: 272227.4888\n",
      "Epoch 470/1000\n",
      "130/130 [==============================] - 0s - loss: 1099974.4956 - val_loss: 272237.7232\n",
      "Epoch 471/1000\n",
      "130/130 [==============================] - 0s - loss: 1134423.2587 - val_loss: 272243.8839\n",
      "Epoch 472/1000\n",
      "130/130 [==============================] - 0s - loss: 1126817.1328 - val_loss: 272252.9777\n",
      "Epoch 473/1000\n",
      "130/130 [==============================] - 0s - loss: 1155450.9131 - val_loss: 272251.0982\n",
      "Epoch 474/1000\n",
      "130/130 [==============================] - 0s - loss: 1147811.0716 - val_loss: 272254.0201\n",
      "Epoch 475/1000\n",
      "130/130 [==============================] - 0s - loss: 1138240.9057 - val_loss: 272255.0246\n",
      "Epoch 476/1000\n",
      "130/130 [==============================] - 0s - loss: 1159518.3450 - val_loss: 272252.2254\n",
      "Epoch 477/1000\n",
      "130/130 [==============================] - 0s - loss: 1151080.9587 - val_loss: 272242.2567\n",
      "Epoch 478/1000\n",
      "130/130 [==============================] - 0s - loss: 1133327.6763 - val_loss: 272249.5246\n",
      "Epoch 479/1000\n",
      "130/130 [==============================] - 0s - loss: 1130244.7053 - val_loss: 272252.6942\n",
      "Epoch 480/1000\n",
      "130/130 [==============================] - 0s - loss: 1111830.0774 - val_loss: 272255.3683\n",
      "Epoch 481/1000\n",
      "130/130 [==============================] - 0s - loss: 1130353.8296 - val_loss: 272262.9754\n",
      "Epoch 482/1000\n",
      "130/130 [==============================] - 0s - loss: 1160070.1512 - val_loss: 272265.8906\n",
      "Epoch 483/1000\n",
      "130/130 [==============================] - 0s - loss: 1145627.2834 - val_loss: 272272.3839\n",
      "Epoch 484/1000\n",
      "130/130 [==============================] - 0s - loss: 1140627.6549 - val_loss: 272277.8125\n",
      "Epoch 485/1000\n",
      "130/130 [==============================] - 0s - loss: 1149155.6534 - val_loss: 272277.6629\n",
      "Epoch 486/1000\n",
      "130/130 [==============================] - 0s - loss: 1122165.3719 - val_loss: 272285.8772\n",
      "Epoch 487/1000\n",
      "130/130 [==============================] - 0s - loss: 1124031.4282 - val_loss: 272280.2143\n",
      "Epoch 488/1000\n",
      "130/130 [==============================] - 0s - loss: 1086847.1250 - val_loss: 272286.1138\n",
      "Epoch 489/1000\n",
      "130/130 [==============================] - 0s - loss: 1145660.1375 - val_loss: 272292.8683\n",
      "Epoch 490/1000\n",
      "130/130 [==============================] - 0s - loss: 1120838.9327 - val_loss: 272300.6674\n",
      "Epoch 491/1000\n",
      "130/130 [==============================] - 0s - loss: 1181817.1357 - val_loss: 272303.6808\n",
      "Epoch 492/1000\n",
      "130/130 [==============================] - 0s - loss: 1150046.8549 - val_loss: 272310.7522\n",
      "Epoch 493/1000\n",
      "130/130 [==============================] - 0s - loss: 1143129.4825 - val_loss: 272315.0960\n",
      "Epoch 494/1000\n",
      "130/130 [==============================] - 0s - loss: 1169371.1615 - val_loss: 272317.2946\n",
      "Epoch 495/1000\n",
      "130/130 [==============================] - 0s - loss: 1129613.7865 - val_loss: 272321.6272\n",
      "Epoch 496/1000\n",
      "130/130 [==============================] - 0s - loss: 1099473.4380 - val_loss: 272328.9844\n",
      "Epoch 497/1000\n",
      "130/130 [==============================] - 0s - loss: 1106302.2793 - val_loss: 272325.3951\n",
      "Epoch 498/1000\n",
      "130/130 [==============================] - 0s - loss: 1113287.6510 - val_loss: 272329.3661\n",
      "Epoch 499/1000\n",
      "130/130 [==============================] - 0s - loss: 1140519.0328 - val_loss: 272331.8393\n",
      "Epoch 500/1000\n",
      "130/130 [==============================] - 0s - loss: 1106676.9347 - val_loss: 272335.7857\n",
      "Epoch 501/1000\n",
      "130/130 [==============================] - 0s - loss: 1125633.3775 - val_loss: 272341.2299\n",
      "Epoch 502/1000\n",
      "130/130 [==============================] - 0s - loss: 1141017.3870 - val_loss: 272346.4442\n",
      "Epoch 503/1000\n",
      "130/130 [==============================] - 0s - loss: 1119331.8695 - val_loss: 272340.8951\n",
      "Epoch 504/1000\n",
      "130/130 [==============================] - 0s - loss: 1083443.9005 - val_loss: 272355.0112\n",
      "Epoch 505/1000\n",
      "130/130 [==============================] - 0s - loss: 1131193.7103 - val_loss: 272364.6674\n",
      "Epoch 506/1000\n",
      "130/130 [==============================] - 0s - loss: 1086938.8582 - val_loss: 272374.4754\n",
      "Epoch 507/1000\n",
      "130/130 [==============================] - 0s - loss: 1101237.7267 - val_loss: 272379.8103\n",
      "Epoch 508/1000\n",
      "130/130 [==============================] - 0s - loss: 1122501.5096 - val_loss: 272384.8103\n",
      "Epoch 509/1000\n",
      "130/130 [==============================] - 0s - loss: 1125291.5581 - val_loss: 272387.8951\n",
      "Epoch 510/1000\n",
      "130/130 [==============================] - 0s - loss: 1163546.7834 - val_loss: 272381.3237\n",
      "Epoch 511/1000\n",
      "130/130 [==============================] - 0s - loss: 1175004.2125 - val_loss: 272384.6205\n",
      "Epoch 512/1000\n",
      "130/130 [==============================] - 0s - loss: 1176159.3871 - val_loss: 272381.9085\n",
      "Epoch 513/1000\n",
      "130/130 [==============================] - 0s - loss: 1118046.0425 - val_loss: 272395.5647\n",
      "Epoch 514/1000\n",
      "130/130 [==============================] - 0s - loss: 1147106.4812 - val_loss: 272394.9085\n",
      "Epoch 515/1000\n",
      "130/130 [==============================] - 0s - loss: 1139551.5856 - val_loss: 272400.1161\n",
      "Epoch 516/1000\n",
      "130/130 [==============================] - 0s - loss: 1135469.5279 - val_loss: 272398.6496\n",
      "Epoch 517/1000\n",
      "130/130 [==============================] - 0s - loss: 1130540.7476 - val_loss: 272400.5268\n",
      "Epoch 518/1000\n",
      "130/130 [==============================] - 0s - loss: 1160544.4300 - val_loss: 272410.5804\n",
      "Epoch 519/1000\n",
      "130/130 [==============================] - 0s - loss: 1131537.1332 - val_loss: 272410.0893\n",
      "Epoch 520/1000\n",
      "130/130 [==============================] - 0s - loss: 1100434.4328 - val_loss: 272416.8817\n",
      "Epoch 521/1000\n",
      "130/130 [==============================] - 0s - loss: 1135216.7598 - val_loss: 272421.3951\n",
      "Epoch 522/1000\n",
      "130/130 [==============================] - 0s - loss: 1087884.2950 - val_loss: 272410.27681206.37\n",
      "Epoch 523/1000\n",
      "130/130 [==============================] - 0s - loss: 1115802.7623 - val_loss: 272405.9107\n",
      "Epoch 524/1000\n",
      "130/130 [==============================] - 0s - loss: 1132563.2180 - val_loss: 272413.2589\n",
      "Epoch 525/1000\n",
      "130/130 [==============================] - 0s - loss: 1134571.7183 - val_loss: 272409.6049\n",
      "Epoch 526/1000\n",
      "130/130 [==============================] - 0s - loss: 1177093.1898 - val_loss: 272419.7701\n",
      "Epoch 527/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1157912.0225 - val_loss: 272415.7121\n",
      "Epoch 528/1000\n",
      "130/130 [==============================] - 0s - loss: 1171526.6887 - val_loss: 272414.4286\n",
      "Epoch 529/1000\n",
      "130/130 [==============================] - 0s - loss: 1150004.8677 - val_loss: 272413.8594\n",
      "Epoch 530/1000\n",
      "130/130 [==============================] - 0s - loss: 1106101.9667 - val_loss: 272420.3214\n",
      "Epoch 531/1000\n",
      "130/130 [==============================] - 0s - loss: 1117201.6692 - val_loss: 272423.7232\n",
      "Epoch 532/1000\n",
      "130/130 [==============================] - 0s - loss: 1132790.2636 - val_loss: 272422.3996\n",
      "Epoch 533/1000\n",
      "130/130 [==============================] - 0s - loss: 1132957.1981 - val_loss: 272428.1004\n",
      "Epoch 534/1000\n",
      "130/130 [==============================] - 0s - loss: 1105054.6266 - val_loss: 272433.9219\n",
      "Epoch 535/1000\n",
      "130/130 [==============================] - 0s - loss: 1135624.3401 - val_loss: 272439.8192\n",
      "Epoch 536/1000\n",
      "130/130 [==============================] - 0s - loss: 1135998.7656 - val_loss: 272450.7031\n",
      "Epoch 537/1000\n",
      "130/130 [==============================] - 0s - loss: 1105126.9387 - val_loss: 272449.1987\n",
      "Epoch 538/1000\n",
      "130/130 [==============================] - 0s - loss: 1132402.0341 - val_loss: 272456.2321\n",
      "Epoch 539/1000\n",
      "130/130 [==============================] - 0s - loss: 1121223.6613 - val_loss: 272462.1875\n",
      "Epoch 540/1000\n",
      "130/130 [==============================] - 0s - loss: 1154290.7888 - val_loss: 272462.5871\n",
      "Epoch 541/1000\n",
      "130/130 [==============================] - 0s - loss: 1121622.4272 - val_loss: 272467.1786\n",
      "Epoch 542/1000\n",
      "130/130 [==============================] - 0s - loss: 1085519.9601 - val_loss: 272484.5469\n",
      "Epoch 543/1000\n",
      "130/130 [==============================] - 0s - loss: 1096481.6430 - val_loss: 272490.3080\n",
      "Epoch 544/1000\n",
      "130/130 [==============================] - 0s - loss: 1121079.4736 - val_loss: 272492.4799\n",
      "Epoch 545/1000\n",
      "130/130 [==============================] - 0s - loss: 1150156.0284 - val_loss: 272495.8504\n",
      "Epoch 546/1000\n",
      "130/130 [==============================] - 0s - loss: 1150968.6349 - val_loss: 272500.8862\n",
      "Epoch 547/1000\n",
      "130/130 [==============================] - 0s - loss: 1109276.9377 - val_loss: 272493.2344\n",
      "Epoch 548/1000\n",
      "130/130 [==============================] - 0s - loss: 1123134.3299 - val_loss: 272504.6451\n",
      "Epoch 549/1000\n",
      "130/130 [==============================] - 0s - loss: 1134942.4358 - val_loss: 272505.6094\n",
      "Epoch 550/1000\n",
      "130/130 [==============================] - 0s - loss: 1136198.3700 - val_loss: 272511.2679\n",
      "Epoch 551/1000\n",
      "130/130 [==============================] - 0s - loss: 1139677.4493 - val_loss: 272525.0022\n",
      "Epoch 552/1000\n",
      "130/130 [==============================] - 0s - loss: 1093189.4310 - val_loss: 272536.4107\n",
      "Epoch 553/1000\n",
      "130/130 [==============================] - 0s - loss: 1104193.7353 - val_loss: 272537.5424\n",
      "Epoch 554/1000\n",
      "130/130 [==============================] - 0s - loss: 1101779.5032 - val_loss: 272539.1339\n",
      "Epoch 555/1000\n",
      "130/130 [==============================] - 0s - loss: 1114660.9257 - val_loss: 272542.8326\n",
      "Epoch 556/1000\n",
      "130/130 [==============================] - 0s - loss: 1111995.4594 - val_loss: 272561.5781\n",
      "Epoch 557/1000\n",
      "130/130 [==============================] - 0s - loss: 1111064.4796 - val_loss: 272569.1674\n",
      "Epoch 558/1000\n",
      "130/130 [==============================] - 0s - loss: 1152692.8659 - val_loss: 272573.3125\n",
      "Epoch 559/1000\n",
      "130/130 [==============================] - 0s - loss: 1105567.1965 - val_loss: 272580.8259\n",
      "Epoch 560/1000\n",
      "130/130 [==============================] - 0s - loss: 1155738.0274 - val_loss: 272577.1763\n",
      "Epoch 561/1000\n",
      "130/130 [==============================] - 0s - loss: 1108888.8918 - val_loss: 272579.6719\n",
      "Epoch 562/1000\n",
      "130/130 [==============================] - 0s - loss: 1151375.2644 - val_loss: 272578.1138\n",
      "Epoch 563/1000\n",
      "130/130 [==============================] - 0s - loss: 1137923.3462 - val_loss: 272579.8237\n",
      "Epoch 564/1000\n",
      "130/130 [==============================] - 0s - loss: 1120218.1565 - val_loss: 272574.0446\n",
      "Epoch 565/1000\n",
      "130/130 [==============================] - 0s - loss: 1160664.4625 - val_loss: 272570.2054\n",
      "Epoch 566/1000\n",
      "130/130 [==============================] - 0s - loss: 1085398.1731 - val_loss: 272580.3929\n",
      "Epoch 567/1000\n",
      "130/130 [==============================] - 0s - loss: 1146903.1576 - val_loss: 272580.4754\n",
      "Epoch 568/1000\n",
      "130/130 [==============================] - 0s - loss: 1164764.7457 - val_loss: 272579.0603\n",
      "Epoch 569/1000\n",
      "130/130 [==============================] - 0s - loss: 1112779.0486 - val_loss: 272591.1317\n",
      "Epoch 570/1000\n",
      "130/130 [==============================] - 0s - loss: 1134861.2475 - val_loss: 272583.7277\n",
      "Epoch 571/1000\n",
      "130/130 [==============================] - 0s - loss: 1082099.3581 - val_loss: 272589.5692\n",
      "Epoch 572/1000\n",
      "130/130 [==============================] - 0s - loss: 1148828.1642 - val_loss: 272588.1540\n",
      "Epoch 573/1000\n",
      "130/130 [==============================] - 0s - loss: 1116662.9471 - val_loss: 272598.3415\n",
      "Epoch 574/1000\n",
      "130/130 [==============================] - 0s - loss: 1140591.5938 - val_loss: 272607.7232\n",
      "Epoch 575/1000\n",
      "130/130 [==============================] - 0s - loss: 1140412.3921 - val_loss: 272610.7656\n",
      "Epoch 576/1000\n",
      "130/130 [==============================] - 0s - loss: 1102668.2370 - val_loss: 272617.4196\n",
      "Epoch 577/1000\n",
      "130/130 [==============================] - 0s - loss: 1096287.5495 - val_loss: 272633.5737\n",
      "Epoch 578/1000\n",
      "130/130 [==============================] - 0s - loss: 1194521.9358 - val_loss: 272635.4754\n",
      "Epoch 579/1000\n",
      "130/130 [==============================] - 0s - loss: 1147655.7123 - val_loss: 272635.8415\n",
      "Epoch 580/1000\n",
      "130/130 [==============================] - 0s - loss: 1065683.5353 - val_loss: 272638.0201\n",
      "Epoch 581/1000\n",
      "130/130 [==============================] - 0s - loss: 1153128.4651 - val_loss: 272627.3326445752\n",
      "Epoch 582/1000\n",
      "130/130 [==============================] - 0s - loss: 1126991.7474 - val_loss: 272627.4911\n",
      "Epoch 583/1000\n",
      "130/130 [==============================] - 0s - loss: 1124022.8861 - val_loss: 272634.0134\n",
      "Epoch 584/1000\n",
      "130/130 [==============================] - 0s - loss: 1130434.8567 - val_loss: 272651.6518\n",
      "Epoch 585/1000\n",
      "130/130 [==============================] - 0s - loss: 1178744.1535 - val_loss: 272640.9576\n",
      "Epoch 586/1000\n",
      "130/130 [==============================] - 0s - loss: 1096723.2288 - val_loss: 272643.7589\n",
      "Epoch 587/1000\n",
      "130/130 [==============================] - 0s - loss: 1149612.9707 - val_loss: 272648.5112\n",
      "Epoch 588/1000\n",
      "130/130 [==============================] - 0s - loss: 1123006.0613 - val_loss: 272642.8013\n",
      "Epoch 589/1000\n",
      "130/130 [==============================] - 0s - loss: 1145149.8262 - val_loss: 272650.6920\n",
      "Epoch 590/1000\n",
      "130/130 [==============================] - 0s - loss: 1125429.5582 - val_loss: 272642.8415\n",
      "Epoch 591/1000\n",
      "130/130 [==============================] - 0s - loss: 1167724.4620 - val_loss: 272639.5290\n",
      "Epoch 592/1000\n",
      "130/130 [==============================] - 0s - loss: 1164217.3123 - val_loss: 272633.6942\n",
      "Epoch 593/1000\n",
      "130/130 [==============================] - 0s - loss: 1137020.7481 - val_loss: 272637.0067\n",
      "Epoch 594/1000\n",
      "130/130 [==============================] - 0s - loss: 1149061.3804 - val_loss: 272637.1696\n",
      "Epoch 595/1000\n",
      "130/130 [==============================] - 0s - loss: 1147180.6933 - val_loss: 272641.8929\n",
      "Epoch 596/1000\n",
      "130/130 [==============================] - 0s - loss: 1116044.3885 - val_loss: 272647.2790\n",
      "Epoch 597/1000\n",
      "130/130 [==============================] - 0s - loss: 1157310.1571 - val_loss: 272654.8125\n",
      "Epoch 598/1000\n",
      "130/130 [==============================] - 0s - loss: 1140377.7948 - val_loss: 272658.1830\n",
      "Epoch 599/1000\n",
      "130/130 [==============================] - 0s - loss: 1106225.6731 - val_loss: 272674.2188\n",
      "Epoch 600/1000\n",
      "130/130 [==============================] - 0s - loss: 1090274.3582 - val_loss: 272666.7924\n",
      "Epoch 601/1000\n",
      "130/130 [==============================] - 0s - loss: 1136937.3303 - val_loss: 272666.7478\n",
      "Epoch 602/1000\n",
      "130/130 [==============================] - 0s - loss: 1168085.8216 - val_loss: 272680.2366\n",
      "Epoch 603/1000\n",
      "130/130 [==============================] - 0s - loss: 1136518.9945 - val_loss: 272686.4442\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1126166.8635 - val_loss: 272697.6853\n",
      "Epoch 605/1000\n",
      "130/130 [==============================] - 0s - loss: 1122660.2743 - val_loss: 272697.9621\n",
      "Epoch 606/1000\n",
      "130/130 [==============================] - 0s - loss: 1157170.2980 - val_loss: 272706.2433\n",
      "Epoch 607/1000\n",
      "130/130 [==============================] - 0s - loss: 1155664.2594 - val_loss: 272716.4353\n",
      "Epoch 608/1000\n",
      "130/130 [==============================] - 0s - loss: 1141187.9704 - val_loss: 272722.3326\n",
      "Epoch 609/1000\n",
      "130/130 [==============================] - 0s - loss: 1106967.8581 - val_loss: 272725.3951\n",
      "Epoch 610/1000\n",
      "130/130 [==============================] - 0s - loss: 1141235.4519 - val_loss: 272722.4308\n",
      "Epoch 611/1000\n",
      "130/130 [==============================] - 0s - loss: 1144150.5626 - val_loss: 272731.3638\n",
      "Epoch 612/1000\n",
      "130/130 [==============================] - 0s - loss: 1086732.8177 - val_loss: 272732.7411\n",
      "Epoch 613/1000\n",
      "130/130 [==============================] - 0s - loss: 1100305.2748 - val_loss: 272730.8214\n",
      "Epoch 614/1000\n",
      "130/130 [==============================] - 0s - loss: 1172341.5296 - val_loss: 272728.0580\n",
      "Epoch 615/1000\n",
      "130/130 [==============================] - 0s - loss: 1166023.2754 - val_loss: 272725.8638\n",
      "Epoch 616/1000\n",
      "130/130 [==============================] - 0s - loss: 1152348.2043 - val_loss: 272723.2188\n",
      "Epoch 617/1000\n",
      "130/130 [==============================] - 0s - loss: 1164646.4138 - val_loss: 272725.9799\n",
      "Epoch 618/1000\n",
      "130/130 [==============================] - 0s - loss: 1114542.2814 - val_loss: 272738.3103\n",
      "Epoch 619/1000\n",
      "130/130 [==============================] - 0s - loss: 1137262.2679 - val_loss: 272747.9710\n",
      "Epoch 620/1000\n",
      "130/130 [==============================] - 0s - loss: 1131384.4959 - val_loss: 272742.9018\n",
      "Epoch 621/1000\n",
      "130/130 [==============================] - 0s - loss: 1132133.7139 - val_loss: 272752.0424\n",
      "Epoch 622/1000\n",
      "130/130 [==============================] - 0s - loss: 1114853.0264 - val_loss: 272762.3862274.\n",
      "Epoch 623/1000\n",
      "130/130 [==============================] - 0s - loss: 1150036.8422 - val_loss: 272761.8549\n",
      "Epoch 624/1000\n",
      "130/130 [==============================] - 0s - loss: 1161995.4406 - val_loss: 272750.7656\n",
      "Epoch 625/1000\n",
      "130/130 [==============================] - 0s - loss: 1157900.0317 - val_loss: 272748.5848\n",
      "Epoch 626/1000\n",
      "130/130 [==============================] - 0s - loss: 1132589.3673 - val_loss: 272761.9576\n",
      "Epoch 627/1000\n",
      "130/130 [==============================] - 0s - loss: 1154841.3426 - val_loss: 272760.1696\n",
      "Epoch 628/1000\n",
      "130/130 [==============================] - 0s - loss: 1125137.6493 - val_loss: 272753.9531\n",
      "Epoch 629/1000\n",
      "130/130 [==============================] - 0s - loss: 1104707.9022 - val_loss: 272757.9598\n",
      "Epoch 630/1000\n",
      "130/130 [==============================] - 0s - loss: 1144468.6114 - val_loss: 272764.9375192640.067\n",
      "Epoch 631/1000\n",
      "130/130 [==============================] - 0s - loss: 1147616.5166 - val_loss: 272749.8415\n",
      "Epoch 632/1000\n",
      "130/130 [==============================] - 0s - loss: 1157205.6638 - val_loss: 272743.0804\n",
      "Epoch 633/1000\n",
      "130/130 [==============================] - 0s - loss: 1128371.4638 - val_loss: 272751.5781\n",
      "Epoch 634/1000\n",
      "130/130 [==============================] - 0s - loss: 1152550.8317 - val_loss: 272746.2388\n",
      "Epoch 635/1000\n",
      "130/130 [==============================] - 0s - loss: 1114163.7452 - val_loss: 272740.2143\n",
      "Epoch 636/1000\n",
      "130/130 [==============================] - 0s - loss: 1121934.5661 - val_loss: 272740.7790\n",
      "Epoch 637/1000\n",
      "130/130 [==============================] - 0s - loss: 1143698.7505 - val_loss: 272737.3839152470.0\n",
      "Epoch 638/1000\n",
      "130/130 [==============================] - 0s - loss: 1116045.4364 - val_loss: 272740.9531\n",
      "Epoch 639/1000\n",
      "130/130 [==============================] - 0s - loss: 1127548.4291 - val_loss: 272742.4375\n",
      "Epoch 640/1000\n",
      "130/130 [==============================] - 0s - loss: 1120006.5862 - val_loss: 272741.6272\n",
      "Epoch 641/1000\n",
      "130/130 [==============================] - 0s - loss: 1119102.1762 - val_loss: 272744.1183\n",
      "Epoch 642/1000\n",
      "130/130 [==============================] - 0s - loss: 1136865.4514 - val_loss: 272751.319275850.1\n",
      "Epoch 643/1000\n",
      "130/130 [==============================] - 0s - loss: 1136479.7762 - val_loss: 272754.2969\n",
      "Epoch 644/1000\n",
      "130/130 [==============================] - 0s - loss: 1107822.0757 - val_loss: 272761.0000\n",
      "Epoch 645/1000\n",
      "130/130 [==============================] - 0s - loss: 1163480.3486 - val_loss: 272760.6763\n",
      "Epoch 646/1000\n",
      "130/130 [==============================] - 0s - loss: 1137420.3858 - val_loss: 272762.7433\n",
      "Epoch 647/1000\n",
      "130/130 [==============================] - 0s - loss: 1112045.1569 - val_loss: 272763.0692\n",
      "Epoch 648/1000\n",
      "130/130 [==============================] - 0s - loss: 1134903.4756 - val_loss: 272760.9844\n",
      "Epoch 649/1000\n",
      "130/130 [==============================] - 0s - loss: 1157862.4683 - val_loss: 272763.6384\n",
      "Epoch 650/1000\n",
      "130/130 [==============================] - 0s - loss: 1127980.2960 - val_loss: 272765.8103\n",
      "Epoch 651/1000\n",
      "130/130 [==============================] - 0s - loss: 1137060.1942 - val_loss: 272773.2411\n",
      "Epoch 652/1000\n",
      "130/130 [==============================] - 0s - loss: 1102789.3156 - val_loss: 272770.9688\n",
      "Epoch 653/1000\n",
      "130/130 [==============================] - 0s - loss: 1157289.6132 - val_loss: 272781.5580\n",
      "Epoch 654/1000\n",
      "130/130 [==============================] - 0s - loss: 1122945.2739 - val_loss: 272790.0268\n",
      "Epoch 655/1000\n",
      "130/130 [==============================] - 0s - loss: 1114211.9500 - val_loss: 272794.9978\n",
      "Epoch 656/1000\n",
      "130/130 [==============================] - 0s - loss: 1163472.8608 - val_loss: 272795.0379\n",
      "Epoch 657/1000\n",
      "130/130 [==============================] - 0s - loss: 1104603.6917 - val_loss: 272799.7746\n",
      "Epoch 658/1000\n",
      "130/130 [==============================] - 0s - loss: 1063140.7103 - val_loss: 272805.2165\n",
      "Epoch 659/1000\n",
      "130/130 [==============================] - 0s - loss: 1121082.0389 - val_loss: 272816.5067\n",
      "Epoch 660/1000\n",
      "130/130 [==============================] - 0s - loss: 1145210.5644 - val_loss: 272816.7701\n",
      "Epoch 661/1000\n",
      "130/130 [==============================] - 0s - loss: 1131831.3635 - val_loss: 272816.6272\n",
      "Epoch 662/1000\n",
      "130/130 [==============================] - 0s - loss: 1106571.2675 - val_loss: 272834.2746\n",
      "Epoch 663/1000\n",
      "130/130 [==============================] - 0s - loss: 1111967.2209 - val_loss: 272839.5335\n",
      "Epoch 664/1000\n",
      "130/130 [==============================] - 0s - loss: 1144316.5216 - val_loss: 272842.9777\n",
      "Epoch 665/1000\n",
      "130/130 [==============================] - 0s - loss: 1115663.4077 - val_loss: 272835.1607\n",
      "Epoch 666/1000\n",
      "130/130 [==============================] - 0s - loss: 1148621.5913 - val_loss: 272844.7031\n",
      "Epoch 667/1000\n",
      "130/130 [==============================] - 0s - loss: 1112065.1587 - val_loss: 272848.5558\n",
      "Epoch 668/1000\n",
      "130/130 [==============================] - 0s - loss: 1113148.3303 - val_loss: 272855.5826\n",
      "Epoch 669/1000\n",
      "130/130 [==============================] - 0s - loss: 1132351.0022 - val_loss: 272856.3237\n",
      "Epoch 670/1000\n",
      "130/130 [==============================] - 0s - loss: 1122304.9567 - val_loss: 272865.9397\n",
      "Epoch 671/1000\n",
      "130/130 [==============================] - 0s - loss: 1153758.5615 - val_loss: 272862.4799\n",
      "Epoch 672/1000\n",
      "130/130 [==============================] - 0s - loss: 1117209.1210 - val_loss: 272865.7344\n",
      "Epoch 673/1000\n",
      "130/130 [==============================] - 0s - loss: 1105363.6087 - val_loss: 272872.5379\n",
      "Epoch 674/1000\n",
      "130/130 [==============================] - 0s - loss: 1121893.2087 - val_loss: 272872.4107\n",
      "Epoch 675/1000\n",
      "130/130 [==============================] - 0s - loss: 1166023.1038 - val_loss: 272880.895158246.895\n",
      "Epoch 676/1000\n",
      "130/130 [==============================] - 0s - loss: 1141359.8828 - val_loss: 272884.6317\n",
      "Epoch 677/1000\n",
      "130/130 [==============================] - 0s - loss: 1117412.7547 - val_loss: 272886.1138\n",
      "Epoch 678/1000\n",
      "130/130 [==============================] - 0s - loss: 1158294.3541 - val_loss: 272876.4353\n",
      "Epoch 679/1000\n",
      "130/130 [==============================] - 0s - loss: 1096308.1708 - val_loss: 272889.9799\n",
      "Epoch 680/1000\n",
      "130/130 [==============================] - 0s - loss: 1136433.7174 - val_loss: 272888.2232\n",
      "Epoch 681/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1131030.8894 - val_loss: 272895.2768\n",
      "Epoch 682/1000\n",
      "130/130 [==============================] - 0s - loss: 1153496.0151 - val_loss: 272902.3281\n",
      "Epoch 683/1000\n",
      "130/130 [==============================] - 0s - loss: 1123866.6362 - val_loss: 272904.5714\n",
      "Epoch 684/1000\n",
      "130/130 [==============================] - 0s - loss: 1145955.8849 - val_loss: 272902.0424\n",
      "Epoch 685/1000\n",
      "130/130 [==============================] - 0s - loss: 1140207.7332 - val_loss: 272907.9286\n",
      "Epoch 686/1000\n",
      "130/130 [==============================] - 0s - loss: 1148140.3606 - val_loss: 272907.5781\n",
      "Epoch 687/1000\n",
      "130/130 [==============================] - 0s - loss: 1132792.3923 - val_loss: 272894.7366\n",
      "Epoch 688/1000\n",
      "130/130 [==============================] - 0s - loss: 1144237.3715 - val_loss: 272901.5692\n",
      "Epoch 689/1000\n",
      "130/130 [==============================] - 0s - loss: 1103473.9447 - val_loss: 272907.8906\n",
      "Epoch 690/1000\n",
      "130/130 [==============================] - 0s - loss: 1135281.1394 - val_loss: 272910.6696\n",
      "Epoch 691/1000\n",
      "130/130 [==============================] - 0s - loss: 1134679.1335 - val_loss: 272913.7612\n",
      "Epoch 692/1000\n",
      "130/130 [==============================] - 0s - loss: 1136717.7605 - val_loss: 272460.6808\n",
      "Epoch 693/1000\n",
      "130/130 [==============================] - 0s - loss: 1130193.7151 - val_loss: 272674.7165\n",
      "Epoch 694/1000\n",
      "130/130 [==============================] - 0s - loss: 1143207.5382 - val_loss: 272755.4554\n",
      "Epoch 695/1000\n",
      "130/130 [==============================] - 0s - loss: 1148028.0861 - val_loss: 272782.5871\n",
      "Epoch 696/1000\n",
      "130/130 [==============================] - 0s - loss: 1114249.7084 - val_loss: 272589.8638\n",
      "Epoch 697/1000\n",
      "130/130 [==============================] - 0s - loss: 1135302.5007 - val_loss: 272547.1049\n",
      "Epoch 698/1000\n",
      "130/130 [==============================] - 0s - loss: 1122033.9190 - val_loss: 303832.9023276359.5\n",
      "Epoch 699/1000\n",
      "130/130 [==============================] - 0s - loss: 1193494.9531 - val_loss: 276331.3806\n",
      "Epoch 700/1000\n",
      "130/130 [==============================] - 0s - loss: 1161511.1000 - val_loss: 285339.9933\n",
      "Epoch 701/1000\n",
      "130/130 [==============================] - 0s - loss: 1122721.4712 - val_loss: 272340.1239\n",
      "Epoch 702/1000\n",
      "130/130 [==============================] - 0s - loss: 1169172.8012 - val_loss: 272034.8393\n",
      "Epoch 703/1000\n",
      "130/130 [==============================] - 0s - loss: 1143978.1950 - val_loss: 274648.0725\n",
      "Epoch 704/1000\n",
      "130/130 [==============================] - 0s - loss: 1161372.2760 - val_loss: 271960.1607\n",
      "Epoch 705/1000\n",
      "130/130 [==============================] - 0s - loss: 1135305.7149 - val_loss: 272278.5882\n",
      "Epoch 706/1000\n",
      "130/130 [==============================] - 0s - loss: 1131338.6984 - val_loss: 271952.7054\n",
      "Epoch 707/1000\n",
      "130/130 [==============================] - 0s - loss: 1131479.2178 - val_loss: 271858.2054\n",
      "Epoch 708/1000\n",
      "130/130 [==============================] - 0s - loss: 1186376.1701 - val_loss: 272059.8929\n",
      "Epoch 709/1000\n",
      "130/130 [==============================] - 0s - loss: 1108516.9952 - val_loss: 272251.5938\n",
      "Epoch 710/1000\n",
      "130/130 [==============================] - 0s - loss: 1105007.8228 - val_loss: 271722.9007\n",
      "Epoch 711/1000\n",
      "130/130 [==============================] - 0s - loss: 1129526.5660 - val_loss: 271746.0234\n",
      "Epoch 712/1000\n",
      "130/130 [==============================] - 0s - loss: 1122336.1507 - val_loss: 271770.7891\n",
      "Epoch 713/1000\n",
      "130/130 [==============================] - 0s - loss: 1128252.7639 - val_loss: 271997.9096\n",
      "Epoch 714/1000\n",
      "130/130 [==============================] - 0s - loss: 1139527.1218 - val_loss: 272045.7600\n",
      "Epoch 715/1000\n",
      "130/130 [==============================] - 0s - loss: 1127622.7179 - val_loss: 271970.9185\n",
      "Epoch 716/1000\n",
      "130/130 [==============================] - 0s - loss: 1180163.9339 - val_loss: 272112.4833\n",
      "Epoch 717/1000\n",
      "130/130 [==============================] - 0s - loss: 1152115.3885 - val_loss: 271955.606000\n",
      "Epoch 718/1000\n",
      "130/130 [==============================] - 0s - loss: 1146326.0137 - val_loss: 272055.9364\n",
      "Epoch 719/1000\n",
      "130/130 [==============================] - 0s - loss: 1134315.3690 - val_loss: 272300.4375\n",
      "Epoch 720/1000\n",
      "130/130 [==============================] - 0s - loss: 1105586.4688 - val_loss: 272523.1406\n",
      "Epoch 721/1000\n",
      "130/130 [==============================] - 0s - loss: 1163437.1230 - val_loss: 273383.0971\n",
      "Epoch 722/1000\n",
      "130/130 [==============================] - 0s - loss: 1161200.5139 - val_loss: 274589.9676\n",
      "Epoch 723/1000\n",
      "130/130 [==============================] - 0s - loss: 1144407.3337 - val_loss: 272471.1975\n",
      "Epoch 724/1000\n",
      "130/130 [==============================] - 0s - loss: 1160717.3845 - val_loss: 274260.0670\n",
      "Epoch 725/1000\n",
      "130/130 [==============================] - 0s - loss: 1158050.1994 - val_loss: 271962.6529\n",
      "Epoch 726/1000\n",
      "130/130 [==============================] - 0s - loss: 1090874.2668 - val_loss: 271980.5480\n",
      "Epoch 727/1000\n",
      "130/130 [==============================] - 0s - loss: 1149552.3894 - val_loss: 272143.1350\n",
      "Epoch 728/1000\n",
      "130/130 [==============================] - 0s - loss: 1147705.2772 - val_loss: 302291.6479\n",
      "Epoch 729/1000\n",
      "130/130 [==============================] - ETA: 0s - loss: 1203506.156 - 0s - loss: 1199488.4002 - val_loss: 273143.5268\n",
      "Epoch 730/1000\n",
      "130/130 [==============================] - 0s - loss: 1139543.7933 - val_loss: 272091.0458\n",
      "Epoch 731/1000\n",
      "130/130 [==============================] - 0s - loss: 1143560.2380 - val_loss: 278553.3862\n",
      "Epoch 732/1000\n",
      "130/130 [==============================] - 0s - loss: 1127563.6918 - val_loss: 272643.3292\n",
      "Epoch 733/1000\n",
      "130/130 [==============================] - 0s - loss: 1149296.9752 - val_loss: 272778.9554\n",
      "Epoch 734/1000\n",
      "130/130 [==============================] - 0s - loss: 1117534.8588 - val_loss: 272153.2232\n",
      "Epoch 735/1000\n",
      "130/130 [==============================] - 0s - loss: 1121296.5218 - val_loss: 275672.1775\n",
      "Epoch 736/1000\n",
      "130/130 [==============================] - 0s - loss: 1117121.5798 - val_loss: 273796.1328\n",
      "Epoch 737/1000\n",
      "130/130 [==============================] - 0s - loss: 1131310.2252 - val_loss: 272285.5625\n",
      "Epoch 738/1000\n",
      "130/130 [==============================] - 0s - loss: 1125160.8421 - val_loss: 272089.4420\n",
      "Epoch 739/1000\n",
      "130/130 [==============================] - 0s - loss: 1140277.1641 - val_loss: 272628.1775\n",
      "Epoch 740/1000\n",
      "130/130 [==============================] - 0s - loss: 1169633.8431 - val_loss: 272696.6250\n",
      "Epoch 741/1000\n",
      "130/130 [==============================] - 0s - loss: 1142541.3316 - val_loss: 271170.8627\n",
      "Epoch 742/1000\n",
      "130/130 [==============================] - 0s - loss: 1121768.0918 - val_loss: 271433.8036\n",
      "Epoch 743/1000\n",
      "130/130 [==============================] - 0s - loss: 1130238.6453 - val_loss: 271542.2221\n",
      "Epoch 744/1000\n",
      "130/130 [==============================] - 0s - loss: 1138491.2101 - val_loss: 271704.7578\n",
      "Epoch 745/1000\n",
      "130/130 [==============================] - 0s - loss: 1180773.6142 - val_loss: 271741.1696311505.70\n",
      "Epoch 746/1000\n",
      "130/130 [==============================] - 0s - loss: 1129570.8447 - val_loss: 272039.4219\n",
      "Epoch 747/1000\n",
      "130/130 [==============================] - 0s - loss: 1124210.1951 - val_loss: 271935.3281047479.16 - ETA: 0s - loss: 957678.\n",
      "Epoch 748/1000\n",
      "130/130 [==============================] - 0s - loss: 1133312.3221 - val_loss: 272887.7891\n",
      "Epoch 749/1000\n",
      "130/130 [==============================] - 0s - loss: 1138975.9264 - val_loss: 272345.1931\n",
      "Epoch 750/1000\n",
      "130/130 [==============================] - 0s - loss: 1185666.7608 - val_loss: 272322.6864\n",
      "Epoch 751/1000\n",
      "130/130 [==============================] - 0s - loss: 1133074.5698 - val_loss: 272425.7723\n",
      "Epoch 752/1000\n",
      "130/130 [==============================] - 0s - loss: 1136667.8746 - val_loss: 272608.8828\n",
      "Epoch 753/1000\n",
      "130/130 [==============================] - 0s - loss: 1129106.1913 - val_loss: 272156.9721\n",
      "Epoch 754/1000\n",
      "130/130 [==============================] - 0s - loss: 1165584.6898 - val_loss: 283752.0273\n",
      "Epoch 755/1000\n",
      "130/130 [==============================] - 0s - loss: 1176470.3714 - val_loss: 276227.7857\n",
      "Epoch 756/1000\n",
      "130/130 [==============================] - 0s - loss: 1154513.2385 - val_loss: 271923.9855\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1084803.0043 - val_loss: 271923.3929\n",
      "Epoch 758/1000\n",
      "130/130 [==============================] - 0s - loss: 1118292.1388 - val_loss: 271875.9386\n",
      "Epoch 759/1000\n",
      "130/130 [==============================] - 0s - loss: 1141782.3435 - val_loss: 272023.6629\n",
      "Epoch 760/1000\n",
      "130/130 [==============================] - 0s - loss: 1153702.2019 - val_loss: 272296.4732\n",
      "Epoch 761/1000\n",
      "130/130 [==============================] - 0s - loss: 1149660.1882 - val_loss: 272059.6507\n",
      "Epoch 762/1000\n",
      "130/130 [==============================] - 0s - loss: 1156109.7738 - val_loss: 272015.6183\n",
      "Epoch 763/1000\n",
      "130/130 [==============================] - 0s - loss: 1142390.7113 - val_loss: 273084.3125\n",
      "Epoch 764/1000\n",
      "130/130 [==============================] - 0s - loss: 1117245.5967 - val_loss: 271585.1429\n",
      "Epoch 765/1000\n",
      "130/130 [==============================] - 0s - loss: 1156183.4065 - val_loss: 272959.0938\n",
      "Epoch 766/1000\n",
      "130/130 [==============================] - 0s - loss: 1150507.0745 - val_loss: 272154.0792\n",
      "Epoch 767/1000\n",
      "130/130 [==============================] - 0s - loss: 1138266.6191 - val_loss: 272524.7065\n",
      "Epoch 768/1000\n",
      "130/130 [==============================] - 0s - loss: 1130992.5126 - val_loss: 272509.6261\n",
      "Epoch 769/1000\n",
      "130/130 [==============================] - 0s - loss: 1171230.6534 - val_loss: 272760.5391\n",
      "Epoch 770/1000\n",
      "130/130 [==============================] - 0s - loss: 1127031.5319 - val_loss: 272201.4676\n",
      "Epoch 771/1000\n",
      "130/130 [==============================] - 0s - loss: 1139616.2627 - val_loss: 272071.7846\n",
      "Epoch 772/1000\n",
      "130/130 [==============================] - 0s - loss: 1146657.5988 - val_loss: 272005.1060\n",
      "Epoch 773/1000\n",
      "130/130 [==============================] - 0s - loss: 1160298.4389 - val_loss: 272062.1641\n",
      "Epoch 774/1000\n",
      "130/130 [==============================] - 0s - loss: 1115445.2305 - val_loss: 271987.7009\n",
      "Epoch 775/1000\n",
      "130/130 [==============================] - 0s - loss: 1114605.5906 - val_loss: 272080.2679\n",
      "Epoch 776/1000\n",
      "130/130 [==============================] - 0s - loss: 1096280.7457 - val_loss: 271902.4252\n",
      "Epoch 777/1000\n",
      "130/130 [==============================] - 0s - loss: 1119901.7681 - val_loss: 272188.5938\n",
      "Epoch 778/1000\n",
      "130/130 [==============================] - 0s - loss: 1149503.3534 - val_loss: 271998.0391\n",
      "Epoch 779/1000\n",
      "130/130 [==============================] - 0s - loss: 1141003.3543 - val_loss: 272163.7310\n",
      "Epoch 780/1000\n",
      "130/130 [==============================] - 0s - loss: 1221118.4780 - val_loss: 271859.3136\n",
      "Epoch 781/1000\n",
      "130/130 [==============================] - 0s - loss: 1137624.9024 - val_loss: 271853.8393\n",
      "Epoch 782/1000\n",
      "130/130 [==============================] - 0s - loss: 1163760.7697 - val_loss: 271964.1797\n",
      "Epoch 783/1000\n",
      "130/130 [==============================] - 0s - loss: 1155677.1853 - val_loss: 272041.4230\n",
      "Epoch 784/1000\n",
      "130/130 [==============================] - 0s - loss: 1131762.1695 - val_loss: 271828.1696430424.\n",
      "Epoch 785/1000\n",
      "130/130 [==============================] - 0s - loss: 1135694.2296 - val_loss: 271819.9375\n",
      "Epoch 786/1000\n",
      "130/130 [==============================] - 0s - loss: 1164880.0755 - val_loss: 271794.6797\n",
      "Epoch 787/1000\n",
      "130/130 [==============================] - 0s - loss: 1145750.3642 - val_loss: 271807.7511\n",
      "Epoch 788/1000\n",
      "130/130 [==============================] - 0s - loss: 1150443.9051 - val_loss: 271803.8527\n",
      "Epoch 789/1000\n",
      "130/130 [==============================] - 0s - loss: 1115512.7712 - val_loss: 271801.6975\n",
      "Epoch 790/1000\n",
      "130/130 [==============================] - 0s - loss: 1104001.4810 - val_loss: 271941.5949\n",
      "Epoch 791/1000\n",
      "130/130 [==============================] - 0s - loss: 1096351.7593 - val_loss: 281500.8069\n",
      "Epoch 792/1000\n",
      "130/130 [==============================] - 0s - loss: 1156094.7421 - val_loss: 280768.7734\n",
      "Epoch 793/1000\n",
      "130/130 [==============================] - 0s - loss: 1138469.3228 - val_loss: 279325.712129404\n",
      "Epoch 794/1000\n",
      "130/130 [==============================] - 0s - loss: 1123223.5755 - val_loss: 272880.2679\n",
      "Epoch 795/1000\n",
      "130/130 [==============================] - 0s - loss: 1152385.0288 - val_loss: 272068.1708\n",
      "Epoch 796/1000\n",
      "130/130 [==============================] - 0s - loss: 1117457.5548 - val_loss: 271640.2411\n",
      "Epoch 797/1000\n",
      "130/130 [==============================] - 0s - loss: 1197293.3623 - val_loss: 271889.8761\n",
      "Epoch 798/1000\n",
      "130/130 [==============================] - 0s - loss: 1114091.1026 - val_loss: 271826.9766\n",
      "Epoch 799/1000\n",
      "130/130 [==============================] - 0s - loss: 1164645.7209 - val_loss: 271829.0714\n",
      "Epoch 800/1000\n",
      "130/130 [==============================] - 0s - loss: 1181641.3018 - val_loss: 271898.8292\n",
      "Epoch 801/1000\n",
      "130/130 [==============================] - 0s - loss: 1152429.4472 - val_loss: 272043.6507\n",
      "Epoch 802/1000\n",
      "130/130 [==============================] - 0s - loss: 1131034.3306 - val_loss: 271969.8013\n",
      "Epoch 803/1000\n",
      "130/130 [==============================] - 0s - loss: 1133558.5817 - val_loss: 272020.7254\n",
      "Epoch 804/1000\n",
      "130/130 [==============================] - 0s - loss: 1139366.7079 - val_loss: 273588.7042\n",
      "Epoch 805/1000\n",
      "130/130 [==============================] - 0s - loss: 1176934.9738 - val_loss: 272965.0190\n",
      "Epoch 806/1000\n",
      "130/130 [==============================] - 0s - loss: 1183324.0966 - val_loss: 272173.4933\n",
      "Epoch 807/1000\n",
      "130/130 [==============================] - 0s - loss: 1172011.0558 - val_loss: 272053.7746\n",
      "Epoch 808/1000\n",
      "130/130 [==============================] - 0s - loss: 1128292.9962 - val_loss: 272043.8772\n",
      "Epoch 809/1000\n",
      "130/130 [==============================] - 0s - loss: 1125944.9611 - val_loss: 272012.6540\n",
      "Epoch 810/1000\n",
      "130/130 [==============================] - 0s - loss: 1157051.1968 - val_loss: 272890.2634\n",
      "Epoch 811/1000\n",
      "130/130 [==============================] - 0s - loss: 1145027.0957 - val_loss: 278049.7511\n",
      "Epoch 812/1000\n",
      "130/130 [==============================] - 0s - loss: 1123141.8516 - val_loss: 276521.4743\n",
      "Epoch 813/1000\n",
      "130/130 [==============================] - 0s - loss: 1163677.0058 - val_loss: 273872.7310\n",
      "Epoch 814/1000\n",
      "130/130 [==============================] - 0s - loss: 1132989.0365 - val_loss: 273538.4542\n",
      "Epoch 815/1000\n",
      "130/130 [==============================] - 0s - loss: 1116725.9868 - val_loss: 273744.5446\n",
      "Epoch 816/1000\n",
      "130/130 [==============================] - 0s - loss: 1146152.4604 - val_loss: 277082.5458\n",
      "Epoch 817/1000\n",
      "130/130 [==============================] - 0s - loss: 1208299.3940 - val_loss: 273397.9196\n",
      "Epoch 818/1000\n",
      "130/130 [==============================] - 0s - loss: 1135686.3268 - val_loss: 272468.6518\n",
      "Epoch 819/1000\n",
      "130/130 [==============================] - 0s - loss: 1150292.7284 - val_loss: 272019.6239\n",
      "Epoch 820/1000\n",
      "130/130 [==============================] - 0s - loss: 1146143.5466 - val_loss: 272300.0949\n",
      "Epoch 821/1000\n",
      "130/130 [==============================] - 0s - loss: 1169836.6159 - val_loss: 272416.0480\n",
      "Epoch 822/1000\n",
      "130/130 [==============================] - 0s - loss: 1154757.7318 - val_loss: 272306.6897\n",
      "Epoch 823/1000\n",
      "130/130 [==============================] - 0s - loss: 1118659.6993 - val_loss: 272263.6295\n",
      "Epoch 824/1000\n",
      "130/130 [==============================] - 0s - loss: 1172826.9671 - val_loss: 272550.9810\n",
      "Epoch 825/1000\n",
      "130/130 [==============================] - 0s - loss: 1226513.7706 - val_loss: 272892.5949\n",
      "Epoch 826/1000\n",
      "130/130 [==============================] - 0s - loss: 1193752.2214 - val_loss: 272590.4375\n",
      "Epoch 827/1000\n",
      "130/130 [==============================] - 0s - loss: 1163268.3507 - val_loss: 272551.061424759\n",
      "Epoch 828/1000\n",
      "130/130 [==============================] - 0s - loss: 1129005.1433 - val_loss: 275247.3571\n",
      "Epoch 829/1000\n",
      "130/130 [==============================] - 0s - loss: 1188031.9654 - val_loss: 274110.1998\n",
      "Epoch 830/1000\n",
      "130/130 [==============================] - 0s - loss: 1129745.7512 - val_loss: 272256.8449065608.48\n",
      "Epoch 831/1000\n",
      "130/130 [==============================] - 0s - loss: 1144190.0472 - val_loss: 272290.5993\n",
      "Epoch 832/1000\n",
      "130/130 [==============================] - 0s - loss: 1112270.2026 - val_loss: 271949.3929\n",
      "Epoch 833/1000\n",
      "130/130 [==============================] - 0s - loss: 1102556.5951 - val_loss: 271866.2232\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1148091.8784 - val_loss: 271646.0056\n",
      "Epoch 835/1000\n",
      "130/130 [==============================] - 0s - loss: 1101659.3001 - val_loss: 271935.6842\n",
      "Epoch 836/1000\n",
      "130/130 [==============================] - 0s - loss: 1161432.7284 - val_loss: 271957.3292\n",
      "Epoch 837/1000\n",
      "130/130 [==============================] - 0s - loss: 1198709.7274 - val_loss: 271652.8214\n",
      "Epoch 838/1000\n",
      "130/130 [==============================] - 0s - loss: 1140761.2733 - val_loss: 271548.3650\n",
      "Epoch 839/1000\n",
      "130/130 [==============================] - 0s - loss: 1154614.3921 - val_loss: 271562.8806\n",
      "Epoch 840/1000\n",
      "130/130 [==============================] - 0s - loss: 1167172.9008 - val_loss: 271642.9330\n",
      "Epoch 841/1000\n",
      "130/130 [==============================] - 0s - loss: 1100331.9043 - val_loss: 271713.7946\n",
      "Epoch 842/1000\n",
      "130/130 [==============================] - 0s - loss: 1116410.9279 - val_loss: 271839.4777\n",
      "Epoch 843/1000\n",
      "130/130 [==============================] - 0s - loss: 1149250.5000 - val_loss: 271855.4654\n",
      "Epoch 844/1000\n",
      "130/130 [==============================] - 0s - loss: 1171304.4293 - val_loss: 271904.3661\n",
      "Epoch 845/1000\n",
      "130/130 [==============================] - 0s - loss: 1185789.1966 - val_loss: 271998.7254\n",
      "Epoch 846/1000\n",
      "130/130 [==============================] - 0s - loss: 1198000.0665 - val_loss: 271917.1261\n",
      "Epoch 847/1000\n",
      "130/130 [==============================] - 0s - loss: 1149270.7320 - val_loss: 271978.5837\n",
      "Epoch 848/1000\n",
      "130/130 [==============================] - 0s - loss: 1143541.7030 - val_loss: 271813.4375\n",
      "Epoch 849/1000\n",
      "130/130 [==============================] - 0s - loss: 1141108.6233 - val_loss: 272117.9598\n",
      "Epoch 850/1000\n",
      "130/130 [==============================] - 0s - loss: 1131030.9894 - val_loss: 272066.4397\n",
      "Epoch 851/1000\n",
      "130/130 [==============================] - 0s - loss: 1156532.4404 - val_loss: 272101.0871\n",
      "Epoch 852/1000\n",
      "130/130 [==============================] - 0s - loss: 1137738.6758 - val_loss: 272249.6496\n",
      "Epoch 853/1000\n",
      "130/130 [==============================] - 0s - loss: 1152621.2596 - val_loss: 272235.9799\n",
      "Epoch 854/1000\n",
      "130/130 [==============================] - 0s - loss: 1118706.2828 - val_loss: 272379.9821\n",
      "Epoch 855/1000\n",
      "130/130 [==============================] - 0s - loss: 1154221.7416 - val_loss: 272554.6674\n",
      "Epoch 856/1000\n",
      "130/130 [==============================] - 0s - loss: 1132437.2662 - val_loss: 273022.5625\n",
      "Epoch 857/1000\n",
      "130/130 [==============================] - 0s - loss: 1117774.4732 - val_loss: 272396.0513\n",
      "Epoch 858/1000\n",
      "130/130 [==============================] - 0s - loss: 1123717.6751 - val_loss: 272416.5446\n",
      "Epoch 859/1000\n",
      "130/130 [==============================] - 0s - loss: 1156939.3310 - val_loss: 271559.6161\n",
      "Epoch 860/1000\n",
      "130/130 [==============================] - 0s - loss: 1145300.1034 - val_loss: 272692.9732\n",
      "Epoch 861/1000\n",
      "130/130 [==============================] - 0s - loss: 1234574.1166 - val_loss: 272306.4342\n",
      "Epoch 862/1000\n",
      "130/130 [==============================] - 0s - loss: 1134580.7933 - val_loss: 272038.1618\n",
      "Epoch 863/1000\n",
      "130/130 [==============================] - 0s - loss: 1122875.0913 - val_loss: 272124.2623\n",
      "Epoch 864/1000\n",
      "130/130 [==============================] - 0s - loss: 1098443.8144 - val_loss: 272114.7511\n",
      "Epoch 865/1000\n",
      "130/130 [==============================] - 0s - loss: 1161894.5030 - val_loss: 271877.1339\n",
      "Epoch 866/1000\n",
      "130/130 [==============================] - 0s - loss: 1144441.5791 - val_loss: 271788.7288\n",
      "Epoch 867/1000\n",
      "130/130 [==============================] - 0s - loss: 1108437.4654 - val_loss: 271841.1975\n",
      "Epoch 868/1000\n",
      "130/130 [==============================] - 0s - loss: 1131443.5695 - val_loss: 271826.2310\n",
      "Epoch 869/1000\n",
      "130/130 [==============================] - 0s - loss: 1136020.9990 - val_loss: 271969.5714\n",
      "Epoch 870/1000\n",
      "130/130 [==============================] - 0s - loss: 1184881.0365 - val_loss: 271926.6473\n",
      "Epoch 871/1000\n",
      "130/130 [==============================] - 0s - loss: 1136792.0910 - val_loss: 271818.95652232.58\n",
      "Epoch 872/1000\n",
      "130/130 [==============================] - 0s - loss: 1125603.8593 - val_loss: 271729.9464\n",
      "Epoch 873/1000\n",
      "130/130 [==============================] - 0s - loss: 1158825.5583 - val_loss: 274618.6875813\n",
      "Epoch 874/1000\n",
      "130/130 [==============================] - 0s - loss: 1149340.7143 - val_loss: 274442.2768\n",
      "Epoch 875/1000\n",
      "130/130 [==============================] - 0s - loss: 1224742.3529 - val_loss: 274583.0636\n",
      "Epoch 876/1000\n",
      "130/130 [==============================] - 0s - loss: 1192595.1887 - val_loss: 274165.0134\n",
      "Epoch 877/1000\n",
      "130/130 [==============================] - 0s - loss: 1138941.2234 - val_loss: 273846.2143\n",
      "Epoch 878/1000\n",
      "130/130 [==============================] - 0s - loss: 1134710.0142 - val_loss: 273719.5625\n",
      "Epoch 879/1000\n",
      "130/130 [==============================] - 0s - loss: 1172495.9007 - val_loss: 273117.5391\n",
      "Epoch 880/1000\n",
      "130/130 [==============================] - 0s - loss: 1185398.4334 - val_loss: 273060.0011\n",
      "Epoch 881/1000\n",
      "130/130 [==============================] - 0s - loss: 1137578.4672 - val_loss: 273207.1953\n",
      "Epoch 882/1000\n",
      "130/130 [==============================] - 0s - loss: 1133958.8440 - val_loss: 272997.4275\n",
      "Epoch 883/1000\n",
      "130/130 [==============================] - 0s - loss: 1151570.8318 - val_loss: 273108.2266\n",
      "Epoch 884/1000\n",
      "130/130 [==============================] - 0s - loss: 1136073.9820 - val_loss: 274145.4330\n",
      "Epoch 885/1000\n",
      "130/130 [==============================] - 0s - loss: 1291182.9264 - val_loss: 274115.0625\n",
      "Epoch 886/1000\n",
      "130/130 [==============================] - 0s - loss: 1149188.1791 - val_loss: 276692.8315\n",
      "Epoch 887/1000\n",
      "130/130 [==============================] - 0s - loss: 1162931.9723 - val_loss: 278599.0770\n",
      "Epoch 888/1000\n",
      "130/130 [==============================] - 0s - loss: 1364320.8666 - val_loss: 290549.4235\n",
      "Epoch 889/1000\n",
      "130/130 [==============================] - 0s - loss: 1289367.6531 - val_loss: 272915.5167\n",
      "Epoch 890/1000\n",
      "130/130 [==============================] - 0s - loss: 1181264.8156 - val_loss: 272876.8092\n",
      "Epoch 891/1000\n",
      "130/130 [==============================] - 0s - loss: 1164728.7459 - val_loss: 272693.4911\n",
      "Epoch 892/1000\n",
      "130/130 [==============================] - 0s - loss: 1339087.2745 - val_loss: 272696.8850\n",
      "Epoch 893/1000\n",
      "130/130 [==============================] - 0s - loss: 1141186.3249 - val_loss: 272863.5413\n",
      "Epoch 894/1000\n",
      "130/130 [==============================] - 0s - loss: 1190930.2079 - val_loss: 272159.5781\n",
      "Epoch 895/1000\n",
      "130/130 [==============================] - 0s - loss: 1174391.4256 - val_loss: 272827.3828\n",
      "Epoch 896/1000\n",
      "130/130 [==============================] - 0s - loss: 1155088.1601 - val_loss: 273386.2690\n",
      "Epoch 897/1000\n",
      "130/130 [==============================] - 0s - loss: 1093311.7250 - val_loss: 274664.6775192617.2\n",
      "Epoch 898/1000\n",
      "130/130 [==============================] - 0s - loss: 1621814.9974 - val_loss: 279673.5480\n",
      "Epoch 899/1000\n",
      "130/130 [==============================] - 0s - loss: 1146469.1964 - val_loss: 272971.3471\n",
      "Epoch 900/1000\n",
      "130/130 [==============================] - 0s - loss: 1165187.9697 - val_loss: 272679.6161\n",
      "Epoch 901/1000\n",
      "130/130 [==============================] - 0s - loss: 1152998.2734 - val_loss: 272224.2723\n",
      "Epoch 902/1000\n",
      "130/130 [==============================] - 0s - loss: 1132566.2004 - val_loss: 272247.8750\n",
      "Epoch 903/1000\n",
      "130/130 [==============================] - 0s - loss: 1149552.7786 - val_loss: 272612.4408\n",
      "Epoch 904/1000\n",
      "130/130 [==============================] - 0s - loss: 1187892.9803 - val_loss: 274987.477741222.\n",
      "Epoch 905/1000\n",
      "130/130 [==============================] - 0s - loss: 1102306.7070 - val_loss: 272271.3917\n",
      "Epoch 906/1000\n",
      "130/130 [==============================] - 0s - loss: 1928207.9141 - val_loss: 398255.1526\n",
      "Epoch 907/1000\n",
      "130/130 [==============================] - 0s - loss: 1163024.1317 - val_loss: 281425.7634\n",
      "Epoch 908/1000\n",
      "130/130 [==============================] - 0s - loss: 1184173.1597 - val_loss: 284751.8131\n",
      "Epoch 909/1000\n",
      "130/130 [==============================] - 0s - loss: 1149047.5564 - val_loss: 277387.5123\n",
      "Epoch 910/1000\n",
      "130/130 [==============================] - 0s - loss: 1127198.9734 - val_loss: 277291.7578\n",
      "Epoch 911/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1189777.4143 - val_loss: 277192.8449\n",
      "Epoch 912/1000\n",
      "130/130 [==============================] - 0s - loss: 1159652.8255 - val_loss: 277476.3661\n",
      "Epoch 913/1000\n",
      "130/130 [==============================] - 0s - loss: 1192788.8511 - val_loss: 287191.1434\n",
      "Epoch 914/1000\n",
      "130/130 [==============================] - 0s - loss: 1179222.3137 - val_loss: 286643.0206\n",
      "Epoch 915/1000\n",
      "130/130 [==============================] - 0s - loss: 1202780.8070 - val_loss: 286452.2991\n",
      "Epoch 916/1000\n",
      "130/130 [==============================] - 0s - loss: 1189424.8431 - val_loss: 286874.5558\n",
      "Epoch 917/1000\n",
      "130/130 [==============================] - 0s - loss: 1347415.2811 - val_loss: 287802.595497\n",
      "Epoch 918/1000\n",
      "130/130 [==============================] - 0s - loss: 1146676.2514 - val_loss: 277782.4989\n",
      "Epoch 919/1000\n",
      "130/130 [==============================] - 0s - loss: 1152161.2188 - val_loss: 272323.5045\n",
      "Epoch 920/1000\n",
      "130/130 [==============================] - 0s - loss: 1152863.0222 - val_loss: 273051.6161\n",
      "Epoch 921/1000\n",
      "130/130 [==============================] - 0s - loss: 1170577.5409 - val_loss: 285659.3488\n",
      "Epoch 922/1000\n",
      "130/130 [==============================] - 0s - loss: 1173168.1615 - val_loss: 285485.4414\n",
      "Epoch 923/1000\n",
      "130/130 [==============================] - 0s - loss: 1146819.8305 - val_loss: 285227.7818\n",
      "Epoch 924/1000\n",
      "130/130 [==============================] - 0s - loss: 1178542.3773 - val_loss: 299991.4241\n",
      "Epoch 925/1000\n",
      "130/130 [==============================] - 0s - loss: 1190448.3770 - val_loss: 285209.7617177539\n",
      "Epoch 926/1000\n",
      "130/130 [==============================] - 0s - loss: 1187803.7270 - val_loss: 285553.8555\n",
      "Epoch 927/1000\n",
      "130/130 [==============================] - 0s - loss: 1131574.6026 - val_loss: 284568.8080\n",
      "Epoch 928/1000\n",
      "130/130 [==============================] - 0s - loss: 1153355.8726 - val_loss: 275821.2411\n",
      "Epoch 929/1000\n",
      "130/130 [==============================] - 0s - loss: 1167490.0797 - val_loss: 284427.8555\n",
      "Epoch 930/1000\n",
      "130/130 [==============================] - 0s - loss: 1152014.0144 - val_loss: 284074.4241\n",
      "Epoch 931/1000\n",
      "130/130 [==============================] - 0s - loss: 1154345.8505 - val_loss: 283923.5887\n",
      "Epoch 932/1000\n",
      "130/130 [==============================] - 0s - loss: 1173854.2864 - val_loss: 284192.8371\n",
      "Epoch 933/1000\n",
      "130/130 [==============================] - 0s - loss: 1163959.7837 - val_loss: 275311.0446\n",
      "Epoch 934/1000\n",
      "130/130 [==============================] - 0s - loss: 1129609.8453 - val_loss: 275050.4275\n",
      "Epoch 935/1000\n",
      "130/130 [==============================] - 0s - loss: 1153499.9404 - val_loss: 274974.9408\n",
      "Epoch 936/1000\n",
      "130/130 [==============================] - 0s - loss: 1181273.5716 - val_loss: 274914.1116\n",
      "Epoch 937/1000\n",
      "130/130 [==============================] - 0s - loss: 1163559.8310 - val_loss: 274885.0714\n",
      "Epoch 938/1000\n",
      "130/130 [==============================] - 0s - loss: 1159325.3061 - val_loss: 274834.6194\n",
      "Epoch 939/1000\n",
      "130/130 [==============================] - 0s - loss: 1168656.0672 - val_loss: 274784.2768\n",
      "Epoch 940/1000\n",
      "130/130 [==============================] - 0s - loss: 1151371.2113 - val_loss: 282989.8242\n",
      "Epoch 941/1000\n",
      "130/130 [==============================] - 0s - loss: 1144697.9139 - val_loss: 282817.3521\n",
      "Epoch 942/1000\n",
      "130/130 [==============================] - 0s - loss: 1157582.8988 - val_loss: 282874.8058\n",
      "Epoch 943/1000\n",
      "130/130 [==============================] - 0s - loss: 1113981.8238 - val_loss: 282531.8532\n",
      "Epoch 944/1000\n",
      "130/130 [==============================] - 0s - loss: 1176466.7445 - val_loss: 282398.8566\n",
      "Epoch 945/1000\n",
      "130/130 [==============================] - 0s - loss: 1178562.9661 - val_loss: 282260.2907\n",
      "Epoch 946/1000\n",
      "130/130 [==============================] - 0s - loss: 1192549.1637 - val_loss: 282111.7885\n",
      "Epoch 947/1000\n",
      "130/130 [==============================] - 0s - loss: 1171540.5805 - val_loss: 281959.3627\n",
      "Epoch 948/1000\n",
      "130/130 [==============================] - 0s - loss: 1172605.0089 - val_loss: 281806.4051\n",
      "Epoch 949/1000\n",
      "130/130 [==============================] - 0s - loss: 1147415.5089 - val_loss: 281656.5647\n",
      "Epoch 950/1000\n",
      "130/130 [==============================] - 0s - loss: 1193760.6508 - val_loss: 281517.6328\n",
      "Epoch 951/1000\n",
      "130/130 [==============================] - 0s - loss: 1159294.4081 - val_loss: 281383.3337\n",
      "Epoch 952/1000\n",
      "130/130 [==============================] - 0s - loss: 1100091.3025 - val_loss: 281205.5279\n",
      "Epoch 953/1000\n",
      "130/130 [==============================] - 0s - loss: 1160877.1276 - val_loss: 281108.7656\n",
      "Epoch 954/1000\n",
      "130/130 [==============================] - 0s - loss: 1146778.4224 - val_loss: 280970.7109\n",
      "Epoch 955/1000\n",
      "130/130 [==============================] - 0s - loss: 1161163.5847 - val_loss: 293429.7963\n",
      "Epoch 956/1000\n",
      "130/130 [==============================] - 0s - loss: 1166384.7877 - val_loss: 281084.2935\n",
      "Epoch 957/1000\n",
      "130/130 [==============================] - 0s - loss: 1174520.9936 - val_loss: 280947.3270\n",
      "Epoch 958/1000\n",
      "130/130 [==============================] - 0s - loss: 1163622.3187 - val_loss: 280796.0491\n",
      "Epoch 959/1000\n",
      "130/130 [==============================] - 0s - loss: 1173817.3825 - val_loss: 280615.2779\n",
      "Epoch 960/1000\n",
      "130/130 [==============================] - 0s - loss: 1164255.7688 - val_loss: 280479.1641\n",
      "Epoch 961/1000\n",
      "130/130 [==============================] - 0s - loss: 1134881.4296 - val_loss: 280339.3516\n",
      "Epoch 962/1000\n",
      "130/130 [==============================] - 0s - loss: 1170527.2352 - val_loss: 280216.9911\n",
      "Epoch 963/1000\n",
      "130/130 [==============================] - 0s - loss: 1199795.8706 - val_loss: 280119.4375\n",
      "Epoch 964/1000\n",
      "130/130 [==============================] - 0s - loss: 1147551.4147 - val_loss: 280003.9364\n",
      "Epoch 965/1000\n",
      "130/130 [==============================] - 0s - loss: 1203396.5608 - val_loss: 291711.1044\n",
      "Epoch 966/1000\n",
      "130/130 [==============================] - 0s - loss: 1191076.4149 - val_loss: 291446.4888\n",
      "Epoch 967/1000\n",
      "130/130 [==============================] - 0s - loss: 1166808.6647 - val_loss: 308414.9933\n",
      "Epoch 968/1000\n",
      "130/130 [==============================] - 0s - loss: 1159528.8470 - val_loss: 291058.4939\n",
      "Epoch 969/1000\n",
      "130/130 [==============================] - 0s - loss: 1157153.3887 - val_loss: 290714.8153\n",
      "Epoch 970/1000\n",
      "130/130 [==============================] - 0s - loss: 1187290.1742 - val_loss: 290452.9727\n",
      "Epoch 971/1000\n",
      "130/130 [==============================] - 0s - loss: 1109970.7547 - val_loss: 290157.8756\n",
      "Epoch 972/1000\n",
      "130/130 [==============================] - 0s - loss: 1195978.2321 - val_loss: 289888.0977\n",
      "Epoch 973/1000\n",
      "130/130 [==============================] - 0s - loss: 1171904.0918 - val_loss: 289645.5781\n",
      "Epoch 974/1000\n",
      "130/130 [==============================] - 0s - loss: 1197763.8005 - val_loss: 289387.8733\n",
      "Epoch 975/1000\n",
      "130/130 [==============================] - 0s - loss: 1163656.6740 - val_loss: 278406.9018\n",
      "Epoch 976/1000\n",
      "130/130 [==============================] - 0s - loss: 1167867.8561 - val_loss: 278777.1775\n",
      "Epoch 977/1000\n",
      "130/130 [==============================] - 0s - loss: 1177778.6733 - val_loss: 278208.8661\n",
      "Epoch 978/1000\n",
      "130/130 [==============================] - 0s - loss: 1112571.9536 - val_loss: 278080.1808\n",
      "Epoch 979/1000\n",
      "130/130 [==============================] - 0s - loss: 1114270.9079 - val_loss: 272450.1172\n",
      "Epoch 980/1000\n",
      "130/130 [==============================] - 0s - loss: 1161274.7108 - val_loss: 272420.6696\n",
      "Epoch 981/1000\n",
      "130/130 [==============================] - 0s - loss: 1146396.1918 - val_loss: 272411.3694\n",
      "Epoch 982/1000\n",
      "130/130 [==============================] - 0s - loss: 1133086.7455 - val_loss: 272376.8125\n",
      "Epoch 983/1000\n",
      "130/130 [==============================] - 0s - loss: 1118926.0303 - val_loss: 272354.8672\n",
      "Epoch 984/1000\n",
      "130/130 [==============================] - 0s - loss: 1145570.3490 - val_loss: 272336.0402\n",
      "Epoch 985/1000\n",
      "130/130 [==============================] - 0s - loss: 1125967.3411 - val_loss: 272315.7824\n",
      "Epoch 986/1000\n",
      "130/130 [==============================] - 0s - loss: 1158865.2966 - val_loss: 272290.2891\n",
      "Epoch 987/1000\n",
      "130/130 [==============================] - 0s - loss: 1159651.2105 - val_loss: 272276.2812\n",
      "Epoch 988/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s - loss: 1127333.0031 - val_loss: 272257.4587\n",
      "Epoch 989/1000\n",
      "130/130 [==============================] - 0s - loss: 1157853.8840 - val_loss: 277868.9475\n",
      "Epoch 990/1000\n",
      "130/130 [==============================] - 0s - loss: 1156475.0204 - val_loss: 277347.3170\n",
      "Epoch 991/1000\n",
      "130/130 [==============================] - 0s - loss: 1155386.9175 - val_loss: 277218.0993\n",
      "Epoch 992/1000\n",
      "130/130 [==============================] - 0s - loss: 1171762.4772 - val_loss: 287498.7260\n",
      "Epoch 993/1000\n",
      "130/130 [==============================] - 0s - loss: 1127577.2018 - val_loss: 287273.5580\n",
      "Epoch 994/1000\n",
      "130/130 [==============================] - 0s - loss: 1158308.0219 - val_loss: 304759.2762\n",
      "Epoch 995/1000\n",
      "130/130 [==============================] - 0s - loss: 1198585.2431 - val_loss: 302645.6373230419.48\n",
      "Epoch 996/1000\n",
      "130/130 [==============================] - 0s - loss: 1179253.9365 - val_loss: 302230.2985\n",
      "Epoch 997/1000\n",
      "130/130 [==============================] - 0s - loss: 1180218.2881 - val_loss: 301310.1278\n",
      "Epoch 998/1000\n",
      "130/130 [==============================] - 0s - loss: 1178695.2317 - val_loss: 300868.1406\n",
      "Epoch 999/1000\n",
      "130/130 [==============================] - 0s - loss: 1158992.7023 - val_loss: 300504.0965\n",
      "Epoch 1000/1000\n",
      "130/130 [==============================] - 0s - loss: 1174253.8952 - val_loss: 300125.1345\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 2289.90600586]\n",
      "result len(data): 165\n",
      "result data.shape: (165,)\n",
      "result len(slicing): 140\n",
      "result slicing_shape: (140, 25)\n",
      "[array([  68, 3096, 1901, 2700, 2586, 3741, 2563, 1919, 1615, 1763, 1445,\n",
      "       1464, 1959, 1709, 1859, 1449, 2220, 2068, 5581, 1658, 1606, 1539,\n",
      "       1487, 1924, 1558])]\n",
      "X_train shape: (139, 24, 1)\n",
      "y_train shape: (139,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 132 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "132/132 [==============================] - 0s - loss: 732966.9353 - val_loss: 1219540.9107\n",
      "Epoch 2/1000\n",
      "132/132 [==============================] - 0s - loss: 681883.0120 - val_loss: 1256728.7857\n",
      "Epoch 3/1000\n",
      "132/132 [==============================] - 0s - loss: 656562.0727 - val_loss: 1142410.0893\n",
      "Epoch 4/1000\n",
      "132/132 [==============================] - 0s - loss: 671025.7849 - val_loss: 1254500.6607299.\n",
      "Epoch 5/1000\n",
      "132/132 [==============================] - 0s - loss: 637753.5698 - val_loss: 1257887.4107\n",
      "Epoch 6/1000\n",
      "132/132 [==============================] - 0s - loss: 688075.0244 - val_loss: 1278029.3750644.\n",
      "Epoch 7/1000\n",
      "132/132 [==============================] - 0s - loss: 666902.4206 - val_loss: 1280321.1607\n",
      "Epoch 8/1000\n",
      "132/132 [==============================] - 0s - loss: 663925.8188 - val_loss: 1257947.5179\n",
      "Epoch 9/1000\n",
      "132/132 [==============================] - 0s - loss: 679142.0246 - val_loss: 1224758.9286\n",
      "Epoch 10/1000\n",
      "132/132 [==============================] - 0s - loss: 692414.1725 - val_loss: 1566657.5893\n",
      "Epoch 11/1000\n",
      "132/132 [==============================] - 0s - loss: 661341.0286 - val_loss: 1293693.9464\n",
      "Epoch 12/1000\n",
      "132/132 [==============================] - 0s - loss: 683476.4925 - val_loss: 1172721.2321\n",
      "Epoch 13/1000\n",
      "132/132 [==============================] - 0s - loss: 659813.5162 - val_loss: 1261086.1964\n",
      "Epoch 14/1000\n",
      "132/132 [==============================] - 0s - loss: 677621.3745 - val_loss: 1114398.1786\n",
      "Epoch 15/1000\n",
      "132/132 [==============================] - 0s - loss: 667541.5367 - val_loss: 1139375.1964\n",
      "Epoch 16/1000\n",
      "132/132 [==============================] - 0s - loss: 669022.6868 - val_loss: 1200540.6429\n",
      "Epoch 17/1000\n",
      "132/132 [==============================] - 0s - loss: 713084.5821 - val_loss: 1286066.4821\n",
      "Epoch 18/1000\n",
      "132/132 [==============================] - 0s - loss: 683149.0362 - val_loss: 1315524.9464\n",
      "Epoch 19/1000\n",
      "132/132 [==============================] - 0s - loss: 696094.8909 - val_loss: 1069285.6071\n",
      "Epoch 20/1000\n",
      "132/132 [==============================] - 0s - loss: 698704.7774 - val_loss: 1236773.4286\n",
      "Epoch 21/1000\n",
      "132/132 [==============================] - 0s - loss: 698019.0927 - val_loss: 1236648.3750\n",
      "Epoch 22/1000\n",
      "132/132 [==============================] - 0s - loss: 688474.7213 - val_loss: 1164206.5179\n",
      "Epoch 23/1000\n",
      "132/132 [==============================] - 0s - loss: 684462.4580 - val_loss: 1145874.7143\n",
      "Epoch 24/1000\n",
      "132/132 [==============================] - 0s - loss: 719268.5779 - val_loss: 1147585.5536\n",
      "Epoch 25/1000\n",
      "132/132 [==============================] - 0s - loss: 673412.3037 - val_loss: 1068786.1429\n",
      "Epoch 26/1000\n",
      "132/132 [==============================] - 0s - loss: 675779.8317 - val_loss: 1270809.8393\n",
      "Epoch 27/1000\n",
      "132/132 [==============================] - 0s - loss: 667021.1342 - val_loss: 1205145.8571\n",
      "Epoch 28/1000\n",
      "132/132 [==============================] - 0s - loss: 726525.0014 - val_loss: 1246679.4821\n",
      "Epoch 29/1000\n",
      "132/132 [==============================] - 0s - loss: 660488.9880 - val_loss: 1305628.8571\n",
      "Epoch 30/1000\n",
      "132/132 [==============================] - 0s - loss: 654905.8990 - val_loss: 1359269.1964\n",
      "Epoch 31/1000\n",
      "132/132 [==============================] - 0s - loss: 704121.3163 - val_loss: 1435113.5893\n",
      "Epoch 32/1000\n",
      "132/132 [==============================] - 0s - loss: 657740.3042 - val_loss: 1472434.6607\n",
      "Epoch 33/1000\n",
      "132/132 [==============================] - 0s - loss: 682855.5102 - val_loss: 1264235.8393\n",
      "Epoch 34/1000\n",
      "132/132 [==============================] - 0s - loss: 663187.9221 - val_loss: 1269802.3750\n",
      "Epoch 35/1000\n",
      "132/132 [==============================] - 0s - loss: 730130.2013 - val_loss: 1292462.4286\n",
      "Epoch 36/1000\n",
      "132/132 [==============================] - 0s - loss: 641125.9646 - val_loss: 1112857.6786\n",
      "Epoch 37/1000\n",
      "132/132 [==============================] - 0s - loss: 669158.8315 - val_loss: 1419542.2321\n",
      "Epoch 38/1000\n",
      "132/132 [==============================] - 0s - loss: 656328.2786 - val_loss: 1133859.7321\n",
      "Epoch 39/1000\n",
      "132/132 [==============================] - 0s - loss: 702797.4729 - val_loss: 1258965.2143\n",
      "Epoch 40/1000\n",
      "132/132 [==============================] - 0s - loss: 646488.5929 - val_loss: 1407792.5000\n",
      "Epoch 41/1000\n",
      "132/132 [==============================] - 0s - loss: 613975.4455 - val_loss: 1387670.1964\n",
      "Epoch 42/1000\n",
      "132/132 [==============================] - 0s - loss: 639257.9502 - val_loss: 1611496.6250\n",
      "Epoch 43/1000\n",
      "132/132 [==============================] - 0s - loss: 662565.7349 - val_loss: 1420198.9464\n",
      "Epoch 44/1000\n",
      "132/132 [==============================] - 0s - loss: 630542.4300 - val_loss: 1255518.5179\n",
      "Epoch 45/1000\n",
      "132/132 [==============================] - 0s - loss: 671004.9273 - val_loss: 1429704.5714\n",
      "Epoch 46/1000\n",
      "132/132 [==============================] - 0s - loss: 641069.2268 - val_loss: 1200027.0714789.59\n",
      "Epoch 47/1000\n",
      "132/132 [==============================] - 0s - loss: 683665.6738 - val_loss: 1362448.2321\n",
      "Epoch 48/1000\n",
      "132/132 [==============================] - 0s - loss: 648504.5179 - val_loss: 930092.0000\n",
      "Epoch 49/1000\n",
      "132/132 [==============================] - 0s - loss: 729687.8365 - val_loss: 1180101.2143\n",
      "Epoch 50/1000\n",
      "132/132 [==============================] - 0s - loss: 701299.3498 - val_loss: 1373306.8036\n",
      "Epoch 51/1000\n",
      "132/132 [==============================] - 0s - loss: 693629.0343 - val_loss: 1068937.6071\n",
      "Epoch 52/1000\n",
      "132/132 [==============================] - 0s - loss: 666492.4733 - val_loss: 1257489.9107\n",
      "Epoch 53/1000\n",
      "132/132 [==============================] - 0s - loss: 667782.7659 - val_loss: 1269812.4464\n",
      "Epoch 54/1000\n",
      "132/132 [==============================] - 0s - loss: 665775.4834 - val_loss: 1240212.9464\n",
      "Epoch 55/1000\n",
      "132/132 [==============================] - 0s - loss: 657027.3062 - val_loss: 1083876.8393\n",
      "Epoch 56/1000\n",
      "132/132 [==============================] - 0s - loss: 678602.1097 - val_loss: 1257493.6429\n",
      "Epoch 57/1000\n",
      "132/132 [==============================] - 0s - loss: 668785.6188 - val_loss: 1248304.3393\n",
      "Epoch 58/1000\n",
      "132/132 [==============================] - 0s - loss: 660344.9673 - val_loss: 1220461.375042\n",
      "Epoch 59/1000\n",
      "132/132 [==============================] - 0s - loss: 684461.6977 - val_loss: 1154832.1607\n",
      "Epoch 60/1000\n",
      "132/132 [==============================] - 0s - loss: 660534.9255 - val_loss: 1177025.8393\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 659708.0862 - val_loss: 1149396.0714\n",
      "Epoch 62/1000\n",
      "132/132 [==============================] - 0s - loss: 672629.8522 - val_loss: 1291178.3571\n",
      "Epoch 63/1000\n",
      "132/132 [==============================] - 0s - loss: 682176.8905 - val_loss: 1320307.8036\n",
      "Epoch 64/1000\n",
      "132/132 [==============================] - 0s - loss: 667895.2668 - val_loss: 1245844.8750\n",
      "Epoch 65/1000\n",
      "132/132 [==============================] - 0s - loss: 675929.8496 - val_loss: 1387818.7679\n",
      "Epoch 66/1000\n",
      "132/132 [==============================] - 0s - loss: 682081.6525 - val_loss: 1287824.5714\n",
      "Epoch 67/1000\n",
      "132/132 [==============================] - 0s - loss: 645464.1019 - val_loss: 1329630.1429\n",
      "Epoch 68/1000\n",
      "132/132 [==============================] - 0s - loss: 695965.1164 - val_loss: 1327908.0714\n",
      "Epoch 69/1000\n",
      "132/132 [==============================] - 0s - loss: 634124.4478 - val_loss: 1328339.0536\n",
      "Epoch 70/1000\n",
      "132/132 [==============================] - 0s - loss: 650415.9261 - val_loss: 1329092.9107\n",
      "Epoch 71/1000\n",
      "132/132 [==============================] - 0s - loss: 663226.3358 - val_loss: 1148098.2143\n",
      "Epoch 72/1000\n",
      "132/132 [==============================] - 0s - loss: 636144.0161 - val_loss: 1299324.5536\n",
      "Epoch 73/1000\n",
      "132/132 [==============================] - 0s - loss: 701839.0473 - val_loss: 1369775.8571\n",
      "Epoch 74/1000\n",
      "132/132 [==============================] - 0s - loss: 646509.9509 - val_loss: 1333301.5714\n",
      "Epoch 75/1000\n",
      "132/132 [==============================] - 0s - loss: 677104.8122 - val_loss: 1320579.2143\n",
      "Epoch 76/1000\n",
      "132/132 [==============================] - 0s - loss: 637968.4202 - val_loss: 1148001.8393\n",
      "Epoch 77/1000\n",
      "132/132 [==============================] - 0s - loss: 652489.1926 - val_loss: 1166684.8393\n",
      "Epoch 78/1000\n",
      "132/132 [==============================] - 0s - loss: 676885.8249 - val_loss: 1195566.6250\n",
      "Epoch 79/1000\n",
      "132/132 [==============================] - 0s - loss: 681991.2783 - val_loss: 1321056.0179\n",
      "Epoch 80/1000\n",
      "132/132 [==============================] - 0s - loss: 623968.0044 - val_loss: 1272299.6964\n",
      "Epoch 81/1000\n",
      "132/132 [==============================] - 0s - loss: 684227.2762 - val_loss: 1270599.4464\n",
      "Epoch 82/1000\n",
      "132/132 [==============================] - 0s - loss: 693237.6436 - val_loss: 1194420.9821\n",
      "Epoch 83/1000\n",
      "132/132 [==============================] - 0s - loss: 715503.2965 - val_loss: 1164652.4464\n",
      "Epoch 84/1000\n",
      "132/132 [==============================] - 0s - loss: 673398.1518 - val_loss: 1151152.6429\n",
      "Epoch 85/1000\n",
      "132/132 [==============================] - 0s - loss: 672795.4638 - val_loss: 1389702.4107\n",
      "Epoch 86/1000\n",
      "132/132 [==============================] - 0s - loss: 664959.7640 - val_loss: 1168079.8750\n",
      "Epoch 87/1000\n",
      "132/132 [==============================] - 0s - loss: 653792.5643 - val_loss: 1212408.1786\n",
      "Epoch 88/1000\n",
      "132/132 [==============================] - 0s - loss: 639259.3367 - val_loss: 1367791.5893\n",
      "Epoch 89/1000\n",
      "132/132 [==============================] - 0s - loss: 681699.6061 - val_loss: 1356305.7321\n",
      "Epoch 90/1000\n",
      "132/132 [==============================] - 0s - loss: 688383.3374 - val_loss: 1411540.1429\n",
      "Epoch 91/1000\n",
      "132/132 [==============================] - 0s - loss: 680406.2715 - val_loss: 1053037.7679\n",
      "Epoch 92/1000\n",
      "132/132 [==============================] - 0s - loss: 663154.9607 - val_loss: 1365959.8571\n",
      "Epoch 93/1000\n",
      "132/132 [==============================] - 0s - loss: 687036.8677 - val_loss: 1295270.5536\n",
      "Epoch 94/1000\n",
      "132/132 [==============================] - 0s - loss: 654966.0053 - val_loss: 1524800.3036\n",
      "Epoch 95/1000\n",
      "132/132 [==============================] - 0s - loss: 656773.0170 - val_loss: 1318167.4464\n",
      "Epoch 96/1000\n",
      "132/132 [==============================] - 0s - loss: 649845.2543 - val_loss: 1220275.2857\n",
      "Epoch 97/1000\n",
      "132/132 [==============================] - 0s - loss: 647584.4138 - val_loss: 1303553.9464\n",
      "Epoch 98/1000\n",
      "132/132 [==============================] - 0s - loss: 671830.5916 - val_loss: 1095536.9464\n",
      "Epoch 99/1000\n",
      "132/132 [==============================] - 0s - loss: 663922.7733 - val_loss: 1171832.1250\n",
      "Epoch 100/1000\n",
      "132/132 [==============================] - 0s - loss: 672769.5576 - val_loss: 1281397.2679\n",
      "Epoch 101/1000\n",
      "132/132 [==============================] - 0s - loss: 639229.5089 - val_loss: 1199239.8750\n",
      "Epoch 102/1000\n",
      "132/132 [==============================] - 0s - loss: 692077.9778 - val_loss: 1321601.8393\n",
      "Epoch 103/1000\n",
      "132/132 [==============================] - 0s - loss: 692564.2384 - val_loss: 1331985.1964\n",
      "Epoch 104/1000\n",
      "132/132 [==============================] - 0s - loss: 628749.7483 - val_loss: 1059167.7679\n",
      "Epoch 105/1000\n",
      "132/132 [==============================] - 0s - loss: 661663.7750 - val_loss: 1289677.2143\n",
      "Epoch 106/1000\n",
      "132/132 [==============================] - 0s - loss: 679471.7812 - val_loss: 1352351.7679\n",
      "Epoch 107/1000\n",
      "132/132 [==============================] - 0s - loss: 656592.5362 - val_loss: 1371210.8571\n",
      "Epoch 108/1000\n",
      "132/132 [==============================] - 0s - loss: 657149.1304 - val_loss: 1397473.2679\n",
      "Epoch 109/1000\n",
      "132/132 [==============================] - 0s - loss: 640082.0769 - val_loss: 1238501.0714\n",
      "Epoch 110/1000\n",
      "132/132 [==============================] - 0s - loss: 673320.9554 - val_loss: 1398354.8036\n",
      "Epoch 111/1000\n",
      "132/132 [==============================] - 0s - loss: 650888.9819 - val_loss: 1134038.9464\n",
      "Epoch 112/1000\n",
      "132/132 [==============================] - 0s - loss: 679824.5281 - val_loss: 1251869.3571\n",
      "Epoch 113/1000\n",
      "132/132 [==============================] - 0s - loss: 692435.3652 - val_loss: 1330778.5536\n",
      "Epoch 114/1000\n",
      "132/132 [==============================] - 0s - loss: 641802.2061 - val_loss: 1245313.1429\n",
      "Epoch 115/1000\n",
      "132/132 [==============================] - 0s - loss: 659781.5766 - val_loss: 1201727.4464\n",
      "Epoch 116/1000\n",
      "132/132 [==============================] - 0s - loss: 672454.8548 - val_loss: 1234447.3036\n",
      "Epoch 117/1000\n",
      "132/132 [==============================] - 0s - loss: 676292.9528 - val_loss: 1320362.1429\n",
      "Epoch 118/1000\n",
      "132/132 [==============================] - 0s - loss: 657204.5671 - val_loss: 1349619.4821\n",
      "Epoch 119/1000\n",
      "132/132 [==============================] - 0s - loss: 646686.1690 - val_loss: 1098406.0536\n",
      "Epoch 120/1000\n",
      "132/132 [==============================] - 0s - loss: 733321.8878 - val_loss: 1303623.4286\n",
      "Epoch 121/1000\n",
      "132/132 [==============================] - 0s - loss: 660838.0922 - val_loss: 1117824.4821\n",
      "Epoch 122/1000\n",
      "132/132 [==============================] - 0s - loss: 678716.5724 - val_loss: 1300099.8750\n",
      "Epoch 123/1000\n",
      "132/132 [==============================] - 0s - loss: 661963.4047 - val_loss: 1296466.0536\n",
      "Epoch 124/1000\n",
      "132/132 [==============================] - 0s - loss: 664473.7030 - val_loss: 1310908.9821\n",
      "Epoch 125/1000\n",
      "132/132 [==============================] - 0s - loss: 669326.8168 - val_loss: 1363721.1429\n",
      "Epoch 126/1000\n",
      "132/132 [==============================] - 0s - loss: 676765.4226 - val_loss: 1370292.6607\n",
      "Epoch 127/1000\n",
      "132/132 [==============================] - 0s - loss: 674009.4188 - val_loss: 1475015.3393\n",
      "Epoch 128/1000\n",
      "132/132 [==============================] - 0s - loss: 683036.7926 - val_loss: 1303763.6250\n",
      "Epoch 129/1000\n",
      "132/132 [==============================] - 0s - loss: 663085.6503 - val_loss: 1181729.2679\n",
      "Epoch 130/1000\n",
      "132/132 [==============================] - 0s - loss: 644300.1722 - val_loss: 1148787.4643\n",
      "Epoch 131/1000\n",
      "132/132 [==============================] - 0s - loss: 673634.5704 - val_loss: 1235647.0000\n",
      "Epoch 132/1000\n",
      "132/132 [==============================] - 0s - loss: 672492.4877 - val_loss: 1297255.3393\n",
      "Epoch 133/1000\n",
      "132/132 [==============================] - 0s - loss: 665221.3130 - val_loss: 1190468.0536\n",
      "Epoch 134/1000\n",
      "132/132 [==============================] - 0s - loss: 662897.6152 - val_loss: 1146202.5893\n",
      "Epoch 135/1000\n",
      "132/132 [==============================] - 0s - loss: 682907.9851 - val_loss: 1217083.7321\n",
      "Epoch 136/1000\n",
      "132/132 [==============================] - 0s - loss: 647681.8134 - val_loss: 1260671.3750\n",
      "Epoch 137/1000\n",
      "132/132 [==============================] - 0s - loss: 683792.4261 - val_loss: 1275250.6607\n",
      "Epoch 138/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 663773.5566 - val_loss: 1288347.4107\n",
      "Epoch 139/1000\n",
      "132/132 [==============================] - 0s - loss: 677975.9905 - val_loss: 1195745.3214\n",
      "Epoch 140/1000\n",
      "132/132 [==============================] - 0s - loss: 662324.0412 - val_loss: 1255939.8036\n",
      "Epoch 141/1000\n",
      "132/132 [==============================] - 0s - loss: 675590.9825 - val_loss: 1273238.3750\n",
      "Epoch 142/1000\n",
      "132/132 [==============================] - 0s - loss: 666821.3485 - val_loss: 1278757.2143\n",
      "Epoch 143/1000\n",
      "132/132 [==============================] - 0s - loss: 663613.8389 - val_loss: 1279228.2143\n",
      "Epoch 144/1000\n",
      "132/132 [==============================] - 0s - loss: 876387.8132 - val_loss: 1278916.5179\n",
      "Epoch 145/1000\n",
      "132/132 [==============================] - 0s - loss: 644252.9026 - val_loss: 1217644.1607\n",
      "Epoch 146/1000\n",
      "132/132 [==============================] - 0s - loss: 671469.7871 - val_loss: 1219146.7143\n",
      "Epoch 147/1000\n",
      "132/132 [==============================] - 0s - loss: 692992.1458 - val_loss: 1219344.3036\n",
      "Epoch 148/1000\n",
      "132/132 [==============================] - 0s - loss: 662703.4337 - val_loss: 1297716.2857\n",
      "Epoch 149/1000\n",
      "132/132 [==============================] - 0s - loss: 652928.5361 - val_loss: 1229914.4107\n",
      "Epoch 150/1000\n",
      "132/132 [==============================] - 0s - loss: 658889.0270 - val_loss: 1209138.9821\n",
      "Epoch 151/1000\n",
      "132/132 [==============================] - 0s - loss: 671759.5265 - val_loss: 1247101.8036\n",
      "Epoch 152/1000\n",
      "132/132 [==============================] - 0s - loss: 692538.0734 - val_loss: 1331285.0536\n",
      "Epoch 153/1000\n",
      "132/132 [==============================] - 0s - loss: 631999.4477 - val_loss: 1335536.8571\n",
      "Epoch 154/1000\n",
      "132/132 [==============================] - 0s - loss: 663636.2918 - val_loss: 1331461.5893\n",
      "Epoch 155/1000\n",
      "132/132 [==============================] - 0s - loss: 632892.8919 - val_loss: 1272152.1964\n",
      "Epoch 156/1000\n",
      "132/132 [==============================] - 0s - loss: 713876.1011 - val_loss: 1204221.1429\n",
      "Epoch 157/1000\n",
      "132/132 [==============================] - 0s - loss: 660972.4209 - val_loss: 1217320.5893\n",
      "Epoch 158/1000\n",
      "132/132 [==============================] - 0s - loss: 660391.8049 - val_loss: 1222722.8571\n",
      "Epoch 159/1000\n",
      "132/132 [==============================] - 0s - loss: 675596.5705 - val_loss: 1206810.6964\n",
      "Epoch 160/1000\n",
      "132/132 [==============================] - 0s - loss: 648749.7855 - val_loss: 1230951.3571\n",
      "Epoch 161/1000\n",
      "132/132 [==============================] - 0s - loss: 623412.4770 - val_loss: 1230327.3750\n",
      "Epoch 162/1000\n",
      "132/132 [==============================] - 0s - loss: 646317.9374 - val_loss: 1399310.0714\n",
      "Epoch 163/1000\n",
      "132/132 [==============================] - 0s - loss: 659965.1204 - val_loss: 1146426.6607\n",
      "Epoch 164/1000\n",
      "132/132 [==============================] - 0s - loss: 648296.5241 - val_loss: 1361488.5179\n",
      "Epoch 165/1000\n",
      "132/132 [==============================] - 0s - loss: 625277.4358 - val_loss: 1292269.2679\n",
      "Epoch 166/1000\n",
      "132/132 [==============================] - 0s - loss: 651998.9244 - val_loss: 1302680.2321\n",
      "Epoch 167/1000\n",
      "132/132 [==============================] - 0s - loss: 666238.8771 - val_loss: 1295016.1607\n",
      "Epoch 168/1000\n",
      "132/132 [==============================] - 0s - loss: 656841.7389 - val_loss: 1456232.8750\n",
      "Epoch 169/1000\n",
      "132/132 [==============================] - 0s - loss: 611091.5630 - val_loss: 1294554.7857\n",
      "Epoch 170/1000\n",
      "132/132 [==============================] - 0s - loss: 650684.2723 - val_loss: 1292101.9464\n",
      "Epoch 171/1000\n",
      "132/132 [==============================] - 0s - loss: 651895.8770 - val_loss: 1183661.4821\n",
      "Epoch 172/1000\n",
      "132/132 [==============================] - 0s - loss: 666216.9708 - val_loss: 1239589.0893\n",
      "Epoch 173/1000\n",
      "132/132 [==============================] - 0s - loss: 657715.7485 - val_loss: 1327725.6429\n",
      "Epoch 174/1000\n",
      "132/132 [==============================] - 0s - loss: 679355.7753 - val_loss: 1267372.5536\n",
      "Epoch 175/1000\n",
      "132/132 [==============================] - 0s - loss: 676666.7080 - val_loss: 1323864.3036\n",
      "Epoch 176/1000\n",
      "132/132 [==============================] - 0s - loss: 658597.5805 - val_loss: 1337743.9821\n",
      "Epoch 177/1000\n",
      "132/132 [==============================] - 0s - loss: 673702.1837 - val_loss: 1285305.2679\n",
      "Epoch 178/1000\n",
      "132/132 [==============================] - 0s - loss: 647378.8888 - val_loss: 1284253.9107\n",
      "Epoch 179/1000\n",
      "132/132 [==============================] - 0s - loss: 676168.3085 - val_loss: 1265546.6250\n",
      "Epoch 180/1000\n",
      "132/132 [==============================] - 0s - loss: 661952.3255 - val_loss: 1321934.4286\n",
      "Epoch 181/1000\n",
      "132/132 [==============================] - 0s - loss: 658857.5109 - val_loss: 1416180.8750\n",
      "Epoch 182/1000\n",
      "132/132 [==============================] - 0s - loss: 627511.8349 - val_loss: 1308242.1250\n",
      "Epoch 183/1000\n",
      "132/132 [==============================] - 0s - loss: 689299.1973 - val_loss: 1347215.5714\n",
      "Epoch 184/1000\n",
      "132/132 [==============================] - 0s - loss: 676401.7074 - val_loss: 1219661.6607\n",
      "Epoch 185/1000\n",
      "132/132 [==============================] - 0s - loss: 657853.4740 - val_loss: 1290619.1964\n",
      "Epoch 186/1000\n",
      "132/132 [==============================] - 0s - loss: 662083.8490 - val_loss: 1258780.0714\n",
      "Epoch 187/1000\n",
      "132/132 [==============================] - 0s - loss: 673376.5627 - val_loss: 1327699.6250\n",
      "Epoch 188/1000\n",
      "132/132 [==============================] - 0s - loss: 675899.5275 - val_loss: 1337636.2321\n",
      "Epoch 189/1000\n",
      "132/132 [==============================] - 0s - loss: 671327.2739 - val_loss: 1325885.7321\n",
      "Epoch 190/1000\n",
      "132/132 [==============================] - 0s - loss: 654324.8258 - val_loss: 1282864.8571\n",
      "Epoch 191/1000\n",
      "132/132 [==============================] - 0s - loss: 638969.0555 - val_loss: 1451173.6964\n",
      "Epoch 192/1000\n",
      "132/132 [==============================] - 0s - loss: 654749.5539 - val_loss: 1338616.6429\n",
      "Epoch 193/1000\n",
      "132/132 [==============================] - 0s - loss: 658039.5542 - val_loss: 1331483.7321\n",
      "Epoch 194/1000\n",
      "132/132 [==============================] - 0s - loss: 638165.9000 - val_loss: 1349533.4107\n",
      "Epoch 195/1000\n",
      "132/132 [==============================] - 0s - loss: 657369.5089 - val_loss: 1332076.3393\n",
      "Epoch 196/1000\n",
      "132/132 [==============================] - 0s - loss: 661386.4732 - val_loss: 1358533.1250\n",
      "Epoch 197/1000\n",
      "132/132 [==============================] - 0s - loss: 627146.3835 - val_loss: 1347480.9821\n",
      "Epoch 198/1000\n",
      "132/132 [==============================] - 0s - loss: 661307.3017 - val_loss: 1349431.0893\n",
      "Epoch 199/1000\n",
      "132/132 [==============================] - 0s - loss: 676336.4144 - val_loss: 1298229.2679\n",
      "Epoch 200/1000\n",
      "132/132 [==============================] - 0s - loss: 726006.9323 - val_loss: 1171491.3393\n",
      "Epoch 201/1000\n",
      "132/132 [==============================] - 0s - loss: 675920.6096 - val_loss: 1267175.0893\n",
      "Epoch 202/1000\n",
      "132/132 [==============================] - 0s - loss: 666053.6817 - val_loss: 1286713.2321\n",
      "Epoch 203/1000\n",
      "132/132 [==============================] - 0s - loss: 628097.4303 - val_loss: 1250050.9107\n",
      "Epoch 204/1000\n",
      "132/132 [==============================] - 0s - loss: 610163.0324 - val_loss: 1203716.6607\n",
      "Epoch 205/1000\n",
      "132/132 [==============================] - 0s - loss: 649512.9859 - val_loss: 1368680.4464\n",
      "Epoch 206/1000\n",
      "132/132 [==============================] - 0s - loss: 634392.9892 - val_loss: 1278335.5000\n",
      "Epoch 207/1000\n",
      "132/132 [==============================] - 0s - loss: 697671.7010 - val_loss: 1262808.9464\n",
      "Epoch 208/1000\n",
      "132/132 [==============================] - 0s - loss: 641430.0049 - val_loss: 1317104.1429\n",
      "Epoch 209/1000\n",
      "132/132 [==============================] - 0s - loss: 701669.5046 - val_loss: 1275788.0714\n",
      "Epoch 210/1000\n",
      "132/132 [==============================] - 0s - loss: 680911.4677 - val_loss: 1401392.4464\n",
      "Epoch 211/1000\n",
      "132/132 [==============================] - 0s - loss: 674517.3152 - val_loss: 1384788.3750\n",
      "Epoch 212/1000\n",
      "132/132 [==============================] - 0s - loss: 626277.3452 - val_loss: 1302267.2143\n",
      "Epoch 213/1000\n",
      "132/132 [==============================] - 0s - loss: 673130.0288 - val_loss: 1264059.7321\n",
      "Epoch 214/1000\n",
      "132/132 [==============================] - 0s - loss: 679084.3333 - val_loss: 1307376.1250\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 682955.9801 - val_loss: 1266786.4286\n",
      "Epoch 216/1000\n",
      "132/132 [==============================] - 0s - loss: 670286.9357 - val_loss: 1277947.2679\n",
      "Epoch 217/1000\n",
      "132/132 [==============================] - 0s - loss: 634972.0880 - val_loss: 1266500.5536\n",
      "Epoch 218/1000\n",
      "132/132 [==============================] - 0s - loss: 656020.1572 - val_loss: 1095317.3750\n",
      "Epoch 219/1000\n",
      "132/132 [==============================] - 0s - loss: 672841.9370 - val_loss: 1181915.7143\n",
      "Epoch 220/1000\n",
      "132/132 [==============================] - 0s - loss: 656568.6901 - val_loss: 1222075.2321\n",
      "Epoch 221/1000\n",
      "132/132 [==============================] - 0s - loss: 698029.5572 - val_loss: 1243289.6607\n",
      "Epoch 222/1000\n",
      "132/132 [==============================] - 0s - loss: 638084.6907 - val_loss: 1081433.4821\n",
      "Epoch 223/1000\n",
      "132/132 [==============================] - 0s - loss: 682031.8994 - val_loss: 1312691.9286\n",
      "Epoch 224/1000\n",
      "132/132 [==============================] - 0s - loss: 681962.1821 - val_loss: 1453195.3750\n",
      "Epoch 225/1000\n",
      "132/132 [==============================] - 0s - loss: 663640.8904 - val_loss: 1394297.9286\n",
      "Epoch 226/1000\n",
      "132/132 [==============================] - 0s - loss: 606527.2481 - val_loss: 1288551.2321\n",
      "Epoch 227/1000\n",
      "132/132 [==============================] - 0s - loss: 703484.5744 - val_loss: 1347027.0714\n",
      "Epoch 228/1000\n",
      "132/132 [==============================] - 0s - loss: 661307.3407 - val_loss: 1382604.0714\n",
      "Epoch 229/1000\n",
      "132/132 [==============================] - 0s - loss: 646731.3554 - val_loss: 1343972.3750\n",
      "Epoch 230/1000\n",
      "132/132 [==============================] - 0s - loss: 658552.1750 - val_loss: 1402031.4107\n",
      "Epoch 231/1000\n",
      "132/132 [==============================] - 0s - loss: 655925.3182 - val_loss: 1315743.3750\n",
      "Epoch 232/1000\n",
      "132/132 [==============================] - 0s - loss: 668200.0261 - val_loss: 1253524.1429\n",
      "Epoch 233/1000\n",
      "132/132 [==============================] - 0s - loss: 647376.8871 - val_loss: 1342774.6429\n",
      "Epoch 234/1000\n",
      "132/132 [==============================] - 0s - loss: 631570.8316 - val_loss: 1332336.1964\n",
      "Epoch 235/1000\n",
      "132/132 [==============================] - 0s - loss: 618016.3832 - val_loss: 1340535.6250\n",
      "Epoch 236/1000\n",
      "132/132 [==============================] - 0s - loss: 660481.8149 - val_loss: 1307734.9464\n",
      "Epoch 237/1000\n",
      "132/132 [==============================] - 0s - loss: 672049.9287 - val_loss: 1272621.4464\n",
      "Epoch 238/1000\n",
      "132/132 [==============================] - 0s - loss: 723391.4705 - val_loss: 1282850.9286\n",
      "Epoch 239/1000\n",
      "132/132 [==============================] - 0s - loss: 674346.8378 - val_loss: 1210857.2321\n",
      "Epoch 240/1000\n",
      "132/132 [==============================] - 0s - loss: 679897.0823 - val_loss: 1222322.5536\n",
      "Epoch 241/1000\n",
      "132/132 [==============================] - 0s - loss: 644547.9299 - val_loss: 1229473.6607\n",
      "Epoch 242/1000\n",
      "132/132 [==============================] - 0s - loss: 677544.4118 - val_loss: 1299890.8750\n",
      "Epoch 243/1000\n",
      "132/132 [==============================] - 0s - loss: 652144.6858 - val_loss: 1304519.9286\n",
      "Epoch 244/1000\n",
      "132/132 [==============================] - 0s - loss: 656155.0541 - val_loss: 1457046.3571\n",
      "Epoch 245/1000\n",
      "132/132 [==============================] - 0s - loss: 613388.4184 - val_loss: 1363020.7321\n",
      "Epoch 246/1000\n",
      "132/132 [==============================] - 0s - loss: 651655.2830 - val_loss: 1365009.3036\n",
      "Epoch 247/1000\n",
      "132/132 [==============================] - 0s - loss: 663853.9161 - val_loss: 1349797.4286\n",
      "Epoch 248/1000\n",
      "132/132 [==============================] - 0s - loss: 648427.9647 - val_loss: 1354782.5179\n",
      "Epoch 249/1000\n",
      "132/132 [==============================] - 0s - loss: 653887.3455 - val_loss: 1313399.3036\n",
      "Epoch 250/1000\n",
      "132/132 [==============================] - 0s - loss: 627779.2802 - val_loss: 1371292.3571\n",
      "Epoch 251/1000\n",
      "132/132 [==============================] - 0s - loss: 667958.0456 - val_loss: 1239706.2143\n",
      "Epoch 252/1000\n",
      "132/132 [==============================] - 0s - loss: 644349.8340 - val_loss: 1271466.9286\n",
      "Epoch 253/1000\n",
      "132/132 [==============================] - 0s - loss: 639818.5504 - val_loss: 1418299.1964\n",
      "Epoch 254/1000\n",
      "132/132 [==============================] - 0s - loss: 633151.7747 - val_loss: 1299368.7679\n",
      "Epoch 255/1000\n",
      "132/132 [==============================] - 0s - loss: 644586.7111 - val_loss: 1270841.0179\n",
      "Epoch 256/1000\n",
      "132/132 [==============================] - 0s - loss: 635913.2634 - val_loss: 1312898.5179\n",
      "Epoch 257/1000\n",
      "132/132 [==============================] - 0s - loss: 657732.9852 - val_loss: 1245646.8393\n",
      "Epoch 258/1000\n",
      "132/132 [==============================] - 0s - loss: 621547.7745 - val_loss: 1175807.2321\n",
      "Epoch 259/1000\n",
      "132/132 [==============================] - 0s - loss: 654124.1831 - val_loss: 1250182.2679\n",
      "Epoch 260/1000\n",
      "132/132 [==============================] - 0s - loss: 677255.9139 - val_loss: 1166911.9107\n",
      "Epoch 261/1000\n",
      "132/132 [==============================] - 0s - loss: 668355.3204 - val_loss: 1187060.2679\n",
      "Epoch 262/1000\n",
      "132/132 [==============================] - 0s - loss: 643353.8058 - val_loss: 1204602.3929\n",
      "Epoch 263/1000\n",
      "132/132 [==============================] - 0s - loss: 637036.5575 - val_loss: 1281640.6429\n",
      "Epoch 264/1000\n",
      "132/132 [==============================] - 0s - loss: 652107.3809 - val_loss: 1058004.7321\n",
      "Epoch 265/1000\n",
      "132/132 [==============================] - 0s - loss: 641532.5614 - val_loss: 1224670.3571\n",
      "Epoch 266/1000\n",
      "132/132 [==============================] - 0s - loss: 655255.9560 - val_loss: 1183015.3571\n",
      "Epoch 267/1000\n",
      "132/132 [==============================] - 0s - loss: 694508.8130 - val_loss: 1184932.8036\n",
      "Epoch 268/1000\n",
      "132/132 [==============================] - 0s - loss: 657035.5279 - val_loss: 1258783.0893\n",
      "Epoch 269/1000\n",
      "132/132 [==============================] - 0s - loss: 678037.0459 - val_loss: 1056140.5714\n",
      "Epoch 270/1000\n",
      "132/132 [==============================] - 0s - loss: 706338.4957 - val_loss: 1198020.1250\n",
      "Epoch 271/1000\n",
      "132/132 [==============================] - 0s - loss: 677338.3629 - val_loss: 1208096.2321\n",
      "Epoch 272/1000\n",
      "132/132 [==============================] - 0s - loss: 667606.7910 - val_loss: 1218029.3571\n",
      "Epoch 273/1000\n",
      "132/132 [==============================] - 0s - loss: 637770.0810 - val_loss: 1222573.2321\n",
      "Epoch 274/1000\n",
      "132/132 [==============================] - 0s - loss: 682647.0194 - val_loss: 1294003.2857\n",
      "Epoch 275/1000\n",
      "132/132 [==============================] - 0s - loss: 660259.0053 - val_loss: 1305121.8571\n",
      "Epoch 276/1000\n",
      "132/132 [==============================] - 0s - loss: 678596.4176 - val_loss: 1299205.0179\n",
      "Epoch 277/1000\n",
      "132/132 [==============================] - 0s - loss: 633758.3913 - val_loss: 1294924.3036\n",
      "Epoch 278/1000\n",
      "132/132 [==============================] - 0s - loss: 656397.2462 - val_loss: 1297753.2321\n",
      "Epoch 279/1000\n",
      "132/132 [==============================] - 0s - loss: 598435.9124 - val_loss: 1235886.4107\n",
      "Epoch 280/1000\n",
      "132/132 [==============================] - 0s - loss: 639940.6024 - val_loss: 1304178.1429\n",
      "Epoch 281/1000\n",
      "132/132 [==============================] - 0s - loss: 646228.6226 - val_loss: 1300592.9286\n",
      "Epoch 282/1000\n",
      "132/132 [==============================] - 0s - loss: 678210.6642 - val_loss: 1223192.0893\n",
      "Epoch 283/1000\n",
      "132/132 [==============================] - 0s - loss: 678140.2596 - val_loss: 1233993.3393\n",
      "Epoch 284/1000\n",
      "132/132 [==============================] - 0s - loss: 641935.7674 - val_loss: 1244125.6607\n",
      "Epoch 285/1000\n",
      "132/132 [==============================] - 0s - loss: 654284.0108 - val_loss: 1256305.1607\n",
      "Epoch 286/1000\n",
      "132/132 [==============================] - 0s - loss: 662106.4979 - val_loss: 1071433.1071\n",
      "Epoch 287/1000\n",
      "132/132 [==============================] - 0s - loss: 686694.7666 - val_loss: 1221544.8393\n",
      "Epoch 288/1000\n",
      "132/132 [==============================] - 0s - loss: 675230.3706 - val_loss: 1183600.6607\n",
      "Epoch 289/1000\n",
      "132/132 [==============================] - 0s - loss: 657835.1613 - val_loss: 1327422.3750\n",
      "Epoch 290/1000\n",
      "132/132 [==============================] - 0s - loss: 652607.7206 - val_loss: 1336865.0536\n",
      "Epoch 291/1000\n",
      "132/132 [==============================] - 0s - loss: 652347.3147 - val_loss: 1265404.7321\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 644861.8428 - val_loss: 1281805.7679\n",
      "Epoch 293/1000\n",
      "132/132 [==============================] - 0s - loss: 654630.8710 - val_loss: 1283989.7321\n",
      "Epoch 294/1000\n",
      "132/132 [==============================] - 0s - loss: 665568.0903 - val_loss: 1173486.5179\n",
      "Epoch 295/1000\n",
      "132/132 [==============================] - 0s - loss: 667171.0317 - val_loss: 1217909.9286\n",
      "Epoch 296/1000\n",
      "132/132 [==============================] - 0s - loss: 669030.1790 - val_loss: 1222468.0536\n",
      "Epoch 297/1000\n",
      "132/132 [==============================] - 0s - loss: 642523.4083 - val_loss: 1228691.7321\n",
      "Epoch 298/1000\n",
      "132/132 [==============================] - 0s - loss: 621260.0239 - val_loss: 1161187.4107\n",
      "Epoch 299/1000\n",
      "132/132 [==============================] - 0s - loss: 679323.9967 - val_loss: 1165689.4107\n",
      "Epoch 300/1000\n",
      "132/132 [==============================] - 0s - loss: 698582.5903 - val_loss: 1172072.2857\n",
      "Epoch 301/1000\n",
      "132/132 [==============================] - 0s - loss: 667253.5001 - val_loss: 1175615.1250\n",
      "Epoch 302/1000\n",
      "132/132 [==============================] - 0s - loss: 649724.0589 - val_loss: 1176511.7679\n",
      "Epoch 303/1000\n",
      "132/132 [==============================] - 0s - loss: 690122.3659 - val_loss: 1178116.0714\n",
      "Epoch 304/1000\n",
      "132/132 [==============================] - 0s - loss: 703842.2004 - val_loss: 1177903.3750\n",
      "Epoch 305/1000\n",
      "132/132 [==============================] - 0s - loss: 685767.9252 - val_loss: 1251934.7857\n",
      "Epoch 306/1000\n",
      "132/132 [==============================] - 0s - loss: 687027.5251 - val_loss: 1244327.4107\n",
      "Epoch 307/1000\n",
      "132/132 [==============================] - 0s - loss: 636605.1651 - val_loss: 1219766.3393\n",
      "Epoch 308/1000\n",
      "132/132 [==============================] - 0s - loss: 639138.3700 - val_loss: 1255808.5714\n",
      "Epoch 309/1000\n",
      "132/132 [==============================] - 0s - loss: 658754.7987 - val_loss: 1304887.8750\n",
      "Epoch 310/1000\n",
      "132/132 [==============================] - 0s - loss: 655518.7553 - val_loss: 1253197.4286\n",
      "Epoch 311/1000\n",
      "132/132 [==============================] - 0s - loss: 682076.9215 - val_loss: 1306757.4286\n",
      "Epoch 312/1000\n",
      "132/132 [==============================] - 0s - loss: 660957.9777 - val_loss: 1325158.4107\n",
      "Epoch 313/1000\n",
      "132/132 [==============================] - 0s - loss: 672382.4865 - val_loss: 1312338.7679\n",
      "Epoch 314/1000\n",
      "132/132 [==============================] - 0s - loss: 630718.6033 - val_loss: 1309421.2143\n",
      "Epoch 315/1000\n",
      "132/132 [==============================] - 0s - loss: 658442.1907 - val_loss: 1282621.7321\n",
      "Epoch 316/1000\n",
      "132/132 [==============================] - 0s - loss: 634979.0787 - val_loss: 1321210.1964\n",
      "Epoch 317/1000\n",
      "132/132 [==============================] - 0s - loss: 686916.4667 - val_loss: 1320755.0179\n",
      "Epoch 318/1000\n",
      "132/132 [==============================] - 0s - loss: 663523.8698 - val_loss: 1316637.4107\n",
      "Epoch 319/1000\n",
      "132/132 [==============================] - 0s - loss: 647881.9015 - val_loss: 1175549.1607\n",
      "Epoch 320/1000\n",
      "132/132 [==============================] - 0s - loss: 661064.6771 - val_loss: 1227823.7321\n",
      "Epoch 321/1000\n",
      "132/132 [==============================] - 0s - loss: 693583.6450 - val_loss: 1253838.0000\n",
      "Epoch 322/1000\n",
      "132/132 [==============================] - 0s - loss: 636593.8609 - val_loss: 1254490.0893\n",
      "Epoch 323/1000\n",
      "132/132 [==============================] - 0s - loss: 637027.0810 - val_loss: 1258134.1250\n",
      "Epoch 324/1000\n",
      "132/132 [==============================] - 0s - loss: 639411.0289 - val_loss: 1259666.9286\n",
      "Epoch 325/1000\n",
      "132/132 [==============================] - 0s - loss: 632715.1978 - val_loss: 1259300.3750\n",
      "Epoch 326/1000\n",
      "132/132 [==============================] - 0s - loss: 645305.9754 - val_loss: 1259833.8393\n",
      "Epoch 327/1000\n",
      "132/132 [==============================] - 0s - loss: 630331.8369 - val_loss: 1088575.0179\n",
      "Epoch 328/1000\n",
      "132/132 [==============================] - 0s - loss: 621958.9312 - val_loss: 1263782.0179\n",
      "Epoch 329/1000\n",
      "132/132 [==============================] - 0s - loss: 667089.1291 - val_loss: 1256609.0000\n",
      "Epoch 330/1000\n",
      "132/132 [==============================] - 0s - loss: 636088.0766 - val_loss: 1261901.7143\n",
      "Epoch 331/1000\n",
      "132/132 [==============================] - 0s - loss: 651324.6003 - val_loss: 1254787.2857\n",
      "Epoch 332/1000\n",
      "132/132 [==============================] - 0s - loss: 644990.6257 - val_loss: 1324628.5714\n",
      "Epoch 333/1000\n",
      "132/132 [==============================] - 0s - loss: 664743.9254 - val_loss: 1258868.2143\n",
      "Epoch 334/1000\n",
      "132/132 [==============================] - 0s - loss: 657228.3987 - val_loss: 1339414.1250\n",
      "Epoch 335/1000\n",
      "132/132 [==============================] - 0s - loss: 658079.6931 - val_loss: 1254895.5179\n",
      "Epoch 336/1000\n",
      "132/132 [==============================] - 0s - loss: 647009.6866 - val_loss: 1247478.5893\n",
      "Epoch 337/1000\n",
      "132/132 [==============================] - 0s - loss: 660843.9411 - val_loss: 1324404.8393\n",
      "Epoch 338/1000\n",
      "132/132 [==============================] - 0s - loss: 669521.6487 - val_loss: 1339044.1429\n",
      "Epoch 339/1000\n",
      "132/132 [==============================] - 0s - loss: 659597.6262 - val_loss: 1315233.6607\n",
      "Epoch 340/1000\n",
      "132/132 [==============================] - 0s - loss: 656130.8757 - val_loss: 1344000.3393\n",
      "Epoch 341/1000\n",
      "132/132 [==============================] - 0s - loss: 666111.2972 - val_loss: 1356749.6250\n",
      "Epoch 342/1000\n",
      "132/132 [==============================] - 0s - loss: 644121.8977 - val_loss: 1410358.8393\n",
      "Epoch 343/1000\n",
      "132/132 [==============================] - 0s - loss: 668396.5391 - val_loss: 1396850.2679\n",
      "Epoch 344/1000\n",
      "132/132 [==============================] - 0s - loss: 632758.3343 - val_loss: 1377062.7321\n",
      "Epoch 345/1000\n",
      "132/132 [==============================] - 0s - loss: 642953.2583 - val_loss: 1324236.6607\n",
      "Epoch 346/1000\n",
      "132/132 [==============================] - 0s - loss: 674464.4981 - val_loss: 1305765.1429\n",
      "Epoch 347/1000\n",
      "132/132 [==============================] - 0s - loss: 638570.8672 - val_loss: 1345345.5714\n",
      "Epoch 348/1000\n",
      "132/132 [==============================] - 0s - loss: 637330.1662 - val_loss: 1286362.0714\n",
      "Epoch 349/1000\n",
      "132/132 [==============================] - 0s - loss: 635075.7030 - val_loss: 1288382.4286\n",
      "Epoch 350/1000\n",
      "132/132 [==============================] - 0s - loss: 653433.5415 - val_loss: 1282598.1964\n",
      "Epoch 351/1000\n",
      "132/132 [==============================] - 0s - loss: 662349.9928 - val_loss: 1275393.0714\n",
      "Epoch 352/1000\n",
      "132/132 [==============================] - 0s - loss: 623034.4318 - val_loss: 1293246.0893\n",
      "Epoch 353/1000\n",
      "132/132 [==============================] - 0s - loss: 631484.6137 - val_loss: 1266307.3750\n",
      "Epoch 354/1000\n",
      "132/132 [==============================] - 0s - loss: 670174.0108 - val_loss: 1291780.6964\n",
      "Epoch 355/1000\n",
      "132/132 [==============================] - 0s - loss: 620316.1638 - val_loss: 1300366.3036\n",
      "Epoch 356/1000\n",
      "132/132 [==============================] - 0s - loss: 635398.8095 - val_loss: 1296918.2679\n",
      "Epoch 357/1000\n",
      "132/132 [==============================] - 0s - loss: 648355.6192 - val_loss: 1305518.8571\n",
      "Epoch 358/1000\n",
      "132/132 [==============================] - 0s - loss: 658870.3548 - val_loss: 1296792.0000\n",
      "Epoch 359/1000\n",
      "132/132 [==============================] - 0s - loss: 644634.1780 - val_loss: 1298982.7143\n",
      "Epoch 360/1000\n",
      "132/132 [==============================] - 0s - loss: 629866.3284 - val_loss: 1297730.9107\n",
      "Epoch 361/1000\n",
      "132/132 [==============================] - 0s - loss: 666749.6668 - val_loss: 1296030.0536\n",
      "Epoch 362/1000\n",
      "132/132 [==============================] - 0s - loss: 644272.9302 - val_loss: 1300513.6250\n",
      "Epoch 363/1000\n",
      "132/132 [==============================] - 0s - loss: 654934.3682 - val_loss: 1308796.2679\n",
      "Epoch 364/1000\n",
      "132/132 [==============================] - 0s - loss: 684393.6741 - val_loss: 1305605.6250\n",
      "Epoch 365/1000\n",
      "132/132 [==============================] - 0s - loss: 624921.3495 - val_loss: 1311362.4821\n",
      "Epoch 366/1000\n",
      "132/132 [==============================] - 0s - loss: 644484.6228 - val_loss: 1310646.2143\n",
      "Epoch 367/1000\n",
      "132/132 [==============================] - 0s - loss: 639071.2430 - val_loss: 1305377.0179\n",
      "Epoch 368/1000\n",
      "132/132 [==============================] - 0s - loss: 645841.0942 - val_loss: 1296042.2321877.26\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 685540.3610 - val_loss: 1268872.4464\n",
      "Epoch 370/1000\n",
      "132/132 [==============================] - 0s - loss: 679706.2065 - val_loss: 1296082.0000\n",
      "Epoch 371/1000\n",
      "132/132 [==============================] - 0s - loss: 651636.6889 - val_loss: 1295528.5179\n",
      "Epoch 372/1000\n",
      "132/132 [==============================] - 0s - loss: 637902.9794 - val_loss: 1294089.0714\n",
      "Epoch 373/1000\n",
      "132/132 [==============================] - 0s - loss: 630500.3562 - val_loss: 1234049.7857\n",
      "Epoch 374/1000\n",
      "132/132 [==============================] - 0s - loss: 683827.1420 - val_loss: 1249489.4464\n",
      "Epoch 375/1000\n",
      "132/132 [==============================] - 0s - loss: 654549.9184 - val_loss: 1250297.1964\n",
      "Epoch 376/1000\n",
      "132/132 [==============================] - 0s - loss: 652761.6075 - val_loss: 1256490.5536\n",
      "Epoch 377/1000\n",
      "132/132 [==============================] - 0s - loss: 659039.1120 - val_loss: 1261934.0893\n",
      "Epoch 378/1000\n",
      "132/132 [==============================] - 0s - loss: 661790.1880 - val_loss: 1283388.8750\n",
      "Epoch 379/1000\n",
      "132/132 [==============================] - 0s - loss: 682022.8455 - val_loss: 1286605.875030\n",
      "Epoch 380/1000\n",
      "132/132 [==============================] - 0s - loss: 700820.8790 - val_loss: 1291816.9286\n",
      "Epoch 381/1000\n",
      "132/132 [==============================] - 0s - loss: 642179.8171 - val_loss: 1293479.2679\n",
      "Epoch 382/1000\n",
      "132/132 [==============================] - 0s - loss: 634826.8757 - val_loss: 1300719.4286\n",
      "Epoch 383/1000\n",
      "132/132 [==============================] - 0s - loss: 630040.3503 - val_loss: 1223987.4464\n",
      "Epoch 384/1000\n",
      "132/132 [==============================] - 0s - loss: 724856.4892 - val_loss: 711474.0446\n",
      "Epoch 385/1000\n",
      "132/132 [==============================] - 0s - loss: 777305.3803 - val_loss: 1318202.16070124 - ETA: 0s - loss: 72053\n",
      "Epoch 386/1000\n",
      "132/132 [==============================] - 0s - loss: 660458.4562 - val_loss: 1280840.5714\n",
      "Epoch 387/1000\n",
      "132/132 [==============================] - 0s - loss: 621934.8641 - val_loss: 1143043.1607\n",
      "Epoch 388/1000\n",
      "132/132 [==============================] - 0s - loss: 670877.9023 - val_loss: 1172457.9464\n",
      "Epoch 389/1000\n",
      "132/132 [==============================] - 0s - loss: 704748.6514 - val_loss: 1359830.0893\n",
      "Epoch 390/1000\n",
      "132/132 [==============================] - 0s - loss: 676658.6839 - val_loss: 1354494.8393\n",
      "Epoch 391/1000\n",
      "132/132 [==============================] - 0s - loss: 629660.7885 - val_loss: 1272157.9286\n",
      "Epoch 392/1000\n",
      "132/132 [==============================] - 0s - loss: 638483.6088 - val_loss: 1351314.5714\n",
      "Epoch 393/1000\n",
      "132/132 [==============================] - 0s - loss: 655886.5691 - val_loss: 1355007.2321\n",
      "Epoch 394/1000\n",
      "132/132 [==============================] - 0s - loss: 648402.0458 - val_loss: 1347460.5714\n",
      "Epoch 395/1000\n",
      "132/132 [==============================] - 0s - loss: 652039.3131 - val_loss: 1350965.8036\n",
      "Epoch 396/1000\n",
      "132/132 [==============================] - 0s - loss: 655236.6146 - val_loss: 1334424.4286\n",
      "Epoch 397/1000\n",
      "132/132 [==============================] - 0s - loss: 615009.4690 - val_loss: 1267076.8036\n",
      "Epoch 398/1000\n",
      "132/132 [==============================] - 0s - loss: 633775.3414 - val_loss: 1276961.4107\n",
      "Epoch 399/1000\n",
      "132/132 [==============================] - 0s - loss: 679298.1496 - val_loss: 1363210.0536\n",
      "Epoch 400/1000\n",
      "132/132 [==============================] - 0s - loss: 659446.7343 - val_loss: 1341021.3036\n",
      "Epoch 401/1000\n",
      "132/132 [==============================] - 0s - loss: 646153.8962 - val_loss: 1276915.3571\n",
      "Epoch 402/1000\n",
      "132/132 [==============================] - 0s - loss: 641586.5830 - val_loss: 1304010.7857\n",
      "Epoch 403/1000\n",
      "132/132 [==============================] - 0s - loss: 666613.0932 - val_loss: 1370032.9821\n",
      "Epoch 404/1000\n",
      "132/132 [==============================] - 0s - loss: 638735.3540 - val_loss: 1277033.3750\n",
      "Epoch 405/1000\n",
      "132/132 [==============================] - 0s - loss: 666317.9207 - val_loss: 1272501.3571\n",
      "Epoch 406/1000\n",
      "132/132 [==============================] - 0s - loss: 658088.9194 - val_loss: 1278397.6964\n",
      "Epoch 407/1000\n",
      "132/132 [==============================] - 0s - loss: 666314.2387 - val_loss: 1282616.2321\n",
      "Epoch 408/1000\n",
      "132/132 [==============================] - 0s - loss: 664439.5160 - val_loss: 1288707.9107\n",
      "Epoch 409/1000\n",
      "132/132 [==============================] - 0s - loss: 640665.8295 - val_loss: 1367050.2321\n",
      "Epoch 410/1000\n",
      "132/132 [==============================] - 0s - loss: 674558.1931 - val_loss: 1203209.3393\n",
      "Epoch 411/1000\n",
      "132/132 [==============================] - 0s - loss: 653766.9291 - val_loss: 1357630.9286\n",
      "Epoch 412/1000\n",
      "132/132 [==============================] - 0s - loss: 628825.9306 - val_loss: 1347835.6607\n",
      "Epoch 413/1000\n",
      "132/132 [==============================] - 0s - loss: 636413.5980 - val_loss: 1347831.4107\n",
      "Epoch 414/1000\n",
      "132/132 [==============================] - 0s - loss: 696351.1347 - val_loss: 1348899.0536\n",
      "Epoch 415/1000\n",
      "132/132 [==============================] - 0s - loss: 617002.4482 - val_loss: 1275740.1964\n",
      "Epoch 416/1000\n",
      "132/132 [==============================] - 0s - loss: 631990.8389 - val_loss: 1119945.7321\n",
      "Epoch 417/1000\n",
      "132/132 [==============================] - 0s - loss: 679821.8165 - val_loss: 1274737.5000\n",
      "Epoch 418/1000\n",
      "132/132 [==============================] - 0s - loss: 641085.8329 - val_loss: 1373568.3393\n",
      "Epoch 419/1000\n",
      "132/132 [==============================] - 0s - loss: 689443.3879 - val_loss: 1384192.5714\n",
      "Epoch 420/1000\n",
      "132/132 [==============================] - 0s - loss: 634267.7143 - val_loss: 1379162.9821\n",
      "Epoch 421/1000\n",
      "132/132 [==============================] - 0s - loss: 649237.5501 - val_loss: 1387606.2679\n",
      "Epoch 422/1000\n",
      "132/132 [==============================] - 0s - loss: 661620.8253 - val_loss: 1235567.1607\n",
      "Epoch 423/1000\n",
      "132/132 [==============================] - 0s - loss: 666950.4857 - val_loss: 1394281.2143\n",
      "Epoch 424/1000\n",
      "132/132 [==============================] - 0s - loss: 637200.5036 - val_loss: 1422904.9286\n",
      "Epoch 425/1000\n",
      "132/132 [==============================] - 0s - loss: 656793.5901 - val_loss: 1266356.0536\n",
      "Epoch 426/1000\n",
      "132/132 [==============================] - 0s - loss: 646048.8126 - val_loss: 1278314.1429\n",
      "Epoch 427/1000\n",
      "132/132 [==============================] - 0s - loss: 632837.8298 - val_loss: 1298945.660788\n",
      "Epoch 428/1000\n",
      "132/132 [==============================] - 0s - loss: 676729.1276 - val_loss: 1406520.2321\n",
      "Epoch 429/1000\n",
      "132/132 [==============================] - 0s - loss: 622685.8113 - val_loss: 1386327.2321\n",
      "Epoch 430/1000\n",
      "132/132 [==============================] - 0s - loss: 685690.0709 - val_loss: 1335358.8036\n",
      "Epoch 431/1000\n",
      "132/132 [==============================] - 0s - loss: 659518.1049 - val_loss: 1387075.8036\n",
      "Epoch 432/1000\n",
      "132/132 [==============================] - 0s - loss: 643552.9599 - val_loss: 1155102.0000\n",
      "Epoch 433/1000\n",
      "132/132 [==============================] - 0s - loss: 643161.5357 - val_loss: 1416294.1429\n",
      "Epoch 434/1000\n",
      "132/132 [==============================] - 0s - loss: 689617.6110 - val_loss: 1122168.3750\n",
      "Epoch 435/1000\n",
      "132/132 [==============================] - 0s - loss: 644438.2058 - val_loss: 1341590.9821\n",
      "Epoch 436/1000\n",
      "132/132 [==============================] - 0s - loss: 637046.8806 - val_loss: 1301200.0179\n",
      "Epoch 437/1000\n",
      "132/132 [==============================] - 0s - loss: 662945.1494 - val_loss: 1385823.9821\n",
      "Epoch 438/1000\n",
      "132/132 [==============================] - 0s - loss: 671699.5140 - val_loss: 1195930.8393\n",
      "Epoch 439/1000\n",
      "132/132 [==============================] - 0s - loss: 661758.3343 - val_loss: 1273448.6607\n",
      "Epoch 440/1000\n",
      "132/132 [==============================] - 0s - loss: 634864.7624 - val_loss: 1202653.6964\n",
      "Epoch 441/1000\n",
      "132/132 [==============================] - 0s - loss: 644603.7584 - val_loss: 1349800.8571\n",
      "Epoch 442/1000\n",
      "132/132 [==============================] - 0s - loss: 633311.2032 - val_loss: 1297369.7857\n",
      "Epoch 443/1000\n",
      "132/132 [==============================] - 0s - loss: 638776.7445 - val_loss: 1292919.2857\n",
      "Epoch 444/1000\n",
      "132/132 [==============================] - 0s - loss: 642979.8107 - val_loss: 1418539.2321\n",
      "Epoch 445/1000\n",
      "132/132 [==============================] - 0s - loss: 652350.2718 - val_loss: 1266633.8393\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 640613.9652 - val_loss: 1241281.1429\n",
      "Epoch 447/1000\n",
      "132/132 [==============================] - 0s - loss: 657622.5109 - val_loss: 1334769.2143\n",
      "Epoch 448/1000\n",
      "132/132 [==============================] - 0s - loss: 645356.9751 - val_loss: 1214387.7500\n",
      "Epoch 449/1000\n",
      "132/132 [==============================] - 0s - loss: 659216.7036 - val_loss: 1251931.8036\n",
      "Epoch 450/1000\n",
      "132/132 [==============================] - 0s - loss: 643740.3503 - val_loss: 1112664.3036\n",
      "Epoch 451/1000\n",
      "132/132 [==============================] - 0s - loss: 642952.3821 - val_loss: 1394524.2143\n",
      "Epoch 452/1000\n",
      "132/132 [==============================] - 0s - loss: 633882.9450 - val_loss: 1376018.4286\n",
      "Epoch 453/1000\n",
      "132/132 [==============================] - 0s - loss: 646435.6908 - val_loss: 1257910.6071\n",
      "Epoch 454/1000\n",
      "132/132 [==============================] - 0s - loss: 654000.4049 - val_loss: 1419403.8036\n",
      "Epoch 455/1000\n",
      "132/132 [==============================] - 0s - loss: 649926.9250 - val_loss: 1407326.4107\n",
      "Epoch 456/1000\n",
      "132/132 [==============================] - 0s - loss: 618130.3890 - val_loss: 1266821.5536\n",
      "Epoch 457/1000\n",
      "132/132 [==============================] - 0s - loss: 646367.8397 - val_loss: 1282653.4464\n",
      "Epoch 458/1000\n",
      "132/132 [==============================] - 0s - loss: 691485.6006 - val_loss: 1287880.1607\n",
      "Epoch 459/1000\n",
      "132/132 [==============================] - 0s - loss: 616383.7850 - val_loss: 1249160.4286\n",
      "Epoch 460/1000\n",
      "132/132 [==============================] - 0s - loss: 657541.9780 - val_loss: 1442795.1964\n",
      "Epoch 461/1000\n",
      "132/132 [==============================] - 0s - loss: 701046.1548 - val_loss: 1500905.1964\n",
      "Epoch 462/1000\n",
      "132/132 [==============================] - 0s - loss: 634030.1615 - val_loss: 1270011.9821\n",
      "Epoch 463/1000\n",
      "132/132 [==============================] - 0s - loss: 646936.0031 - val_loss: 1394414.3393\n",
      "Epoch 464/1000\n",
      "132/132 [==============================] - 0s - loss: 668200.3932 - val_loss: 1253823.3750\n",
      "Epoch 465/1000\n",
      "132/132 [==============================] - 0s - loss: 628472.2209 - val_loss: 1331790.6607\n",
      "Epoch 466/1000\n",
      "132/132 [==============================] - 0s - loss: 672898.9673 - val_loss: 1379422.6964\n",
      "Epoch 467/1000\n",
      "132/132 [==============================] - 0s - loss: 685944.6457 - val_loss: 1213704.2679\n",
      "Epoch 468/1000\n",
      "132/132 [==============================] - 0s - loss: 625522.4152 - val_loss: 1499377.9286\n",
      "Epoch 469/1000\n",
      "132/132 [==============================] - 0s - loss: 695423.1815 - val_loss: 1209874.7857\n",
      "Epoch 470/1000\n",
      "132/132 [==============================] - 0s - loss: 643321.5430 - val_loss: 1316845.0714\n",
      "Epoch 471/1000\n",
      "132/132 [==============================] - 0s - loss: 656456.7105 - val_loss: 1313136.7143\n",
      "Epoch 472/1000\n",
      "132/132 [==============================] - 0s - loss: 639830.4892 - val_loss: 1478625.1964\n",
      "Epoch 473/1000\n",
      "132/132 [==============================] - 0s - loss: 631772.6442 - val_loss: 1338078.2500\n",
      "Epoch 474/1000\n",
      "132/132 [==============================] - 0s - loss: 633459.1360 - val_loss: 1357005.8393\n",
      "Epoch 475/1000\n",
      "132/132 [==============================] - 0s - loss: 622826.9370 - val_loss: 1423161.1429\n",
      "Epoch 476/1000\n",
      "132/132 [==============================] - 0s - loss: 595863.4209 - val_loss: 1635737.5179\n",
      "Epoch 477/1000\n",
      "132/132 [==============================] - 0s - loss: 591186.9559 - val_loss: 1358997.6786\n",
      "Epoch 478/1000\n",
      "132/132 [==============================] - 0s - loss: 598277.0372 - val_loss: 1369473.8036\n",
      "Epoch 479/1000\n",
      "132/132 [==============================] - 0s - loss: 586877.2821 - val_loss: 1321950.4464\n",
      "Epoch 480/1000\n",
      "132/132 [==============================] - 0s - loss: 867226.7627 - val_loss: 1290346.8036\n",
      "Epoch 481/1000\n",
      "132/132 [==============================] - 0s - loss: 652565.6338 - val_loss: 1280988.7857\n",
      "Epoch 482/1000\n",
      "132/132 [==============================] - 0s - loss: 663116.7443 - val_loss: 1469261.5714\n",
      "Epoch 483/1000\n",
      "132/132 [==============================] - 0s - loss: 688977.1170 - val_loss: 1174487.6607\n",
      "Epoch 484/1000\n",
      "132/132 [==============================] - 0s - loss: 633607.9912 - val_loss: 1269296.8036\n",
      "Epoch 485/1000\n",
      "132/132 [==============================] - 0s - loss: 617658.3928 - val_loss: 1219340.0536\n",
      "Epoch 486/1000\n",
      "132/132 [==============================] - 0s - loss: 689124.0469 - val_loss: 1243527.7857\n",
      "Epoch 487/1000\n",
      "132/132 [==============================] - 0s - loss: 662072.1831 - val_loss: 1202867.0536\n",
      "Epoch 488/1000\n",
      "132/132 [==============================] - 0s - loss: 656832.8993 - val_loss: 1237022.7143\n",
      "Epoch 489/1000\n",
      "132/132 [==============================] - 0s - loss: 656234.1322 - val_loss: 1296221.6607\n",
      "Epoch 490/1000\n",
      "132/132 [==============================] - 0s - loss: 668641.2079 - val_loss: 1264919.0536\n",
      "Epoch 491/1000\n",
      "132/132 [==============================] - 0s - loss: 691992.7582 - val_loss: 1284343.5893\n",
      "Epoch 492/1000\n",
      "132/132 [==============================] - 0s - loss: 647275.0342 - val_loss: 1378961.6607\n",
      "Epoch 493/1000\n",
      "132/132 [==============================] - 0s - loss: 654435.9984 - val_loss: 1361794.5179\n",
      "Epoch 494/1000\n",
      "132/132 [==============================] - 0s - loss: 643632.5393 - val_loss: 1291581.7679\n",
      "Epoch 495/1000\n",
      "132/132 [==============================] - 0s - loss: 673362.4650 - val_loss: 1362603.7321\n",
      "Epoch 496/1000\n",
      "132/132 [==============================] - 0s - loss: 663483.6012 - val_loss: 1292476.5000\n",
      "Epoch 497/1000\n",
      "132/132 [==============================] - 0s - loss: 686685.0798 - val_loss: 1243178.6607\n",
      "Epoch 498/1000\n",
      "132/132 [==============================] - 0s - loss: 681507.5588 - val_loss: 1333400.4286\n",
      "Epoch 499/1000\n",
      "132/132 [==============================] - 0s - loss: 637310.4551 - val_loss: 1346275.0714\n",
      "Epoch 500/1000\n",
      "132/132 [==============================] - 0s - loss: 667260.5147 - val_loss: 1357185.1429\n",
      "Epoch 501/1000\n",
      "132/132 [==============================] - 0s - loss: 665535.3596 - val_loss: 1229133.1964\n",
      "Epoch 502/1000\n",
      "132/132 [==============================] - 0s - loss: 636172.6307 - val_loss: 1258785.2857\n",
      "Epoch 503/1000\n",
      "132/132 [==============================] - 0s - loss: 644094.7467 - val_loss: 1324539.1607\n",
      "Epoch 504/1000\n",
      "132/132 [==============================] - 0s - loss: 639786.1603 - val_loss: 1185464.5357\n",
      "Epoch 505/1000\n",
      "132/132 [==============================] - 0s - loss: 645287.4905 - val_loss: 1245839.3571\n",
      "Epoch 506/1000\n",
      "132/132 [==============================] - 0s - loss: 641140.1323 - val_loss: 1227221.4107\n",
      "Epoch 507/1000\n",
      "132/132 [==============================] - 0s - loss: 680023.9276 - val_loss: 1285756.2679\n",
      "Epoch 508/1000\n",
      "132/132 [==============================] - 0s - loss: 678261.8412 - val_loss: 1364995.0714\n",
      "Epoch 509/1000\n",
      "132/132 [==============================] - 0s - loss: 649362.6601 - val_loss: 1305150.1250\n",
      "Epoch 510/1000\n",
      "132/132 [==============================] - 0s - loss: 662591.4039 - val_loss: 1355748.5536\n",
      "Epoch 511/1000\n",
      "132/132 [==============================] - 0s - loss: 658980.8778 - val_loss: 1252659.8393\n",
      "Epoch 512/1000\n",
      "132/132 [==============================] - 0s - loss: 642631.8308 - val_loss: 1278733.6964\n",
      "Epoch 513/1000\n",
      "132/132 [==============================] - 0s - loss: 658908.2910 - val_loss: 1181741.8036\n",
      "Epoch 514/1000\n",
      "132/132 [==============================] - 0s - loss: 627479.3205 - val_loss: 1237484.4821\n",
      "Epoch 515/1000\n",
      "132/132 [==============================] - 0s - loss: 636123.7873 - val_loss: 1262295.1250\n",
      "Epoch 516/1000\n",
      "132/132 [==============================] - 0s - loss: 705334.0141 - val_loss: 1242570.2500\n",
      "Epoch 517/1000\n",
      "132/132 [==============================] - 0s - loss: 692225.1681 - val_loss: 1295392.4821\n",
      "Epoch 518/1000\n",
      "132/132 [==============================] - 0s - loss: 633193.2125 - val_loss: 1363894.3571\n",
      "Epoch 519/1000\n",
      "132/132 [==============================] - 0s - loss: 641099.1455 - val_loss: 1354281.1429\n",
      "Epoch 520/1000\n",
      "132/132 [==============================] - 0s - loss: 641951.7401 - val_loss: 1270103.3750\n",
      "Epoch 521/1000\n",
      "132/132 [==============================] - 0s - loss: 664572.7512 - val_loss: 1151534.7679\n",
      "Epoch 522/1000\n",
      "132/132 [==============================] - 0s - loss: 671002.9774 - val_loss: 1163106.2321\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 644240.6102 - val_loss: 1206950.1250\n",
      "Epoch 524/1000\n",
      "132/132 [==============================] - 0s - loss: 657923.0975 - val_loss: 1379057.3750\n",
      "Epoch 525/1000\n",
      "132/132 [==============================] - 0s - loss: 656700.2912 - val_loss: 1361386.4464\n",
      "Epoch 526/1000\n",
      "132/132 [==============================] - 0s - loss: 629767.1561 - val_loss: 1094626.6607\n",
      "Epoch 527/1000\n",
      "132/132 [==============================] - 0s - loss: 667040.9665 - val_loss: 1351676.8750\n",
      "Epoch 528/1000\n",
      "132/132 [==============================] - 0s - loss: 632041.4487 - val_loss: 1267730.5179\n",
      "Epoch 529/1000\n",
      "132/132 [==============================] - 0s - loss: 627296.6975 - val_loss: 1175293.3036\n",
      "Epoch 530/1000\n",
      "132/132 [==============================] - 0s - loss: 628771.1499 - val_loss: 1215052.6429\n",
      "Epoch 531/1000\n",
      "132/132 [==============================] - 0s - loss: 674672.1396 - val_loss: 1449800.7143\n",
      "Epoch 532/1000\n",
      "132/132 [==============================] - 0s - loss: 611408.3294 - val_loss: 1342693.2321\n",
      "Epoch 533/1000\n",
      "132/132 [==============================] - 0s - loss: 676645.8066 - val_loss: 1292677.5536\n",
      "Epoch 534/1000\n",
      "132/132 [==============================] - 0s - loss: 617109.6426 - val_loss: 1263470.8393\n",
      "Epoch 535/1000\n",
      "132/132 [==============================] - 0s - loss: 676906.2840 - val_loss: 1202080.1964\n",
      "Epoch 536/1000\n",
      "132/132 [==============================] - 0s - loss: 654361.9799 - val_loss: 1266198.5357\n",
      "Epoch 537/1000\n",
      "132/132 [==============================] - 0s - loss: 671434.4894 - val_loss: 1265907.7857\n",
      "Epoch 538/1000\n",
      "132/132 [==============================] - 0s - loss: 707277.8249 - val_loss: 1389765.1607\n",
      "Epoch 539/1000\n",
      "132/132 [==============================] - 0s - loss: 629220.8767 - val_loss: 1172273.9821\n",
      "Epoch 540/1000\n",
      "132/132 [==============================] - 0s - loss: 681329.2753 - val_loss: 1258694.6429\n",
      "Epoch 541/1000\n",
      "132/132 [==============================] - 0s - loss: 629717.3388 - val_loss: 1290392.9464\n",
      "Epoch 542/1000\n",
      "132/132 [==============================] - 0s - loss: 665197.7004 - val_loss: 1143878.5179\n",
      "Epoch 543/1000\n",
      "132/132 [==============================] - 0s - loss: 633054.1980 - val_loss: 1131395.7321\n",
      "Epoch 544/1000\n",
      "132/132 [==============================] - 0s - loss: 662030.2024 - val_loss: 1154156.2321\n",
      "Epoch 545/1000\n",
      "132/132 [==============================] - 0s - loss: 643572.2609 - val_loss: 1276750.3036\n",
      "Epoch 546/1000\n",
      "132/132 [==============================] - 0s - loss: 662514.6561 - val_loss: 1230458.2679\n",
      "Epoch 547/1000\n",
      "132/132 [==============================] - 0s - loss: 679537.2090 - val_loss: 1282386.4643\n",
      "Epoch 548/1000\n",
      "132/132 [==============================] - 0s - loss: 624500.5429 - val_loss: 1270419.3036\n",
      "Epoch 549/1000\n",
      "132/132 [==============================] - 0s - loss: 691400.7391 - val_loss: 1233895.6607\n",
      "Epoch 550/1000\n",
      "132/132 [==============================] - 0s - loss: 657320.7164 - val_loss: 1455538.0893\n",
      "Epoch 551/1000\n",
      "132/132 [==============================] - 0s - loss: 654566.8055 - val_loss: 1338366.3750\n",
      "Epoch 552/1000\n",
      "132/132 [==============================] - 0s - loss: 653224.0762 - val_loss: 1147302.6964\n",
      "Epoch 553/1000\n",
      "132/132 [==============================] - 0s - loss: 684363.5632 - val_loss: 1491665.6250\n",
      "Epoch 554/1000\n",
      "132/132 [==============================] - 0s - loss: 648509.5819 - val_loss: 1285673.0357\n",
      "Epoch 555/1000\n",
      "132/132 [==============================] - 0s - loss: 596896.9833 - val_loss: 1310710.5179\n",
      "Epoch 556/1000\n",
      "132/132 [==============================] - 0s - loss: 623610.9312 - val_loss: 1380984.8036\n",
      "Epoch 557/1000\n",
      "132/132 [==============================] - 0s - loss: 617533.8625 - val_loss: 1327684.0893\n",
      "Epoch 558/1000\n",
      "132/132 [==============================] - 0s - loss: 642085.0953 - val_loss: 1223671.9643\n",
      "Epoch 559/1000\n",
      "132/132 [==============================] - 0s - loss: 618821.3298 - val_loss: 1223619.2321\n",
      "Epoch 560/1000\n",
      "132/132 [==============================] - 0s - loss: 635382.5201 - val_loss: 1147904.2143\n",
      "Epoch 561/1000\n",
      "132/132 [==============================] - 0s - loss: 615156.3008 - val_loss: 1327060.4107\n",
      "Epoch 562/1000\n",
      "132/132 [==============================] - 0s - loss: 602939.7602 - val_loss: 1244856.3750\n",
      "Epoch 563/1000\n",
      "132/132 [==============================] - 0s - loss: 648749.7385 - val_loss: 1232669.8571\n",
      "Epoch 564/1000\n",
      "132/132 [==============================] - 0s - loss: 657629.9690 - val_loss: 1321499.1429\n",
      "Epoch 565/1000\n",
      "132/132 [==============================] - 0s - loss: 684789.7504 - val_loss: 1306876.0714\n",
      "Epoch 566/1000\n",
      "132/132 [==============================] - 0s - loss: 644243.4254 - val_loss: 1205212.7321\n",
      "Epoch 567/1000\n",
      "132/132 [==============================] - 0s - loss: 654048.7910 - val_loss: 1316123.1250\n",
      "Epoch 568/1000\n",
      "132/132 [==============================] - 0s - loss: 595931.7743 - val_loss: 1171389.9286\n",
      "Epoch 569/1000\n",
      "132/132 [==============================] - 0s - loss: 643750.3435 - val_loss: 1292224.2321\n",
      "Epoch 570/1000\n",
      "132/132 [==============================] - 0s - loss: 638263.8182 - val_loss: 1356960.0893\n",
      "Epoch 571/1000\n",
      "132/132 [==============================] - 0s - loss: 646681.4004 - val_loss: 1358506.0536\n",
      "Epoch 572/1000\n",
      "132/132 [==============================] - 0s - loss: 677472.2019 - val_loss: 1354890.6250\n",
      "Epoch 573/1000\n",
      "132/132 [==============================] - 0s - loss: 669342.5413 - val_loss: 1270961.8393\n",
      "Epoch 574/1000\n",
      "132/132 [==============================] - 0s - loss: 635059.6458 - val_loss: 1215156.7679\n",
      "Epoch 575/1000\n",
      "132/132 [==============================] - 0s - loss: 639743.6845 - val_loss: 1170619.9643\n",
      "Epoch 576/1000\n",
      "132/132 [==============================] - 0s - loss: 639922.5650 - val_loss: 1228659.1429\n",
      "Epoch 577/1000\n",
      "132/132 [==============================] - 0s - loss: 680804.1760 - val_loss: 1279313.3393\n",
      "Epoch 578/1000\n",
      "132/132 [==============================] - 0s - loss: 635437.7107 - val_loss: 1267143.5893\n",
      "Epoch 579/1000\n",
      "132/132 [==============================] - 0s - loss: 609062.8725 - val_loss: 1522902.5893\n",
      "Epoch 580/1000\n",
      "132/132 [==============================] - 0s - loss: 668175.7079 - val_loss: 1202067.6607\n",
      "Epoch 581/1000\n",
      "132/132 [==============================] - 0s - loss: 659946.8606 - val_loss: 1301189.2143\n",
      "Epoch 582/1000\n",
      "132/132 [==============================] - 0s - loss: 665152.7183 - val_loss: 1257644.4286\n",
      "Epoch 583/1000\n",
      "132/132 [==============================] - 0s - loss: 637585.0556 - val_loss: 1254944.8393\n",
      "Epoch 584/1000\n",
      "132/132 [==============================] - 0s - loss: 626712.6454 - val_loss: 1242627.5000\n",
      "Epoch 585/1000\n",
      "132/132 [==============================] - 0s - loss: 601938.9714 - val_loss: 1326636.3036\n",
      "Epoch 586/1000\n",
      "132/132 [==============================] - 0s - loss: 654208.0391 - val_loss: 1180634.6429\n",
      "Epoch 587/1000\n",
      "132/132 [==============================] - 0s - loss: 650860.2785 - val_loss: 1150918.9643\n",
      "Epoch 588/1000\n",
      "132/132 [==============================] - 0s - loss: 593206.3791 - val_loss: 1323890.7143\n",
      "Epoch 589/1000\n",
      "132/132 [==============================] - 0s - loss: 628850.7666 - val_loss: 1333343.4107\n",
      "Epoch 590/1000\n",
      "132/132 [==============================] - 0s - loss: 667828.9012 - val_loss: 1365240.9286\n",
      "Epoch 591/1000\n",
      "132/132 [==============================] - 0s - loss: 637282.0198 - val_loss: 1355603.2679\n",
      "Epoch 592/1000\n",
      "132/132 [==============================] - 0s - loss: 636802.4386 - val_loss: 1260787.2679\n",
      "Epoch 593/1000\n",
      "132/132 [==============================] - 0s - loss: 614458.1630 - val_loss: 1500750.0893\n",
      "Epoch 594/1000\n",
      "132/132 [==============================] - 0s - loss: 701308.5027 - val_loss: 1484770.2679\n",
      "Epoch 595/1000\n",
      "132/132 [==============================] - 0s - loss: 656189.5623 - val_loss: 1201888.6607\n",
      "Epoch 596/1000\n",
      "132/132 [==============================] - 0s - loss: 629768.2204 - val_loss: 1204991.0893\n",
      "Epoch 597/1000\n",
      "132/132 [==============================] - 0s - loss: 644604.5810 - val_loss: 1343587.0714\n",
      "Epoch 598/1000\n",
      "132/132 [==============================] - 0s - loss: 673822.0878 - val_loss: 1314217.7857\n",
      "Epoch 599/1000\n",
      "132/132 [==============================] - 0s - loss: 649303.1623 - val_loss: 1306220.3393\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 651384.3620 - val_loss: 1386575.6607\n",
      "Epoch 601/1000\n",
      "132/132 [==============================] - 0s - loss: 664151.8909 - val_loss: 1254135.9464\n",
      "Epoch 602/1000\n",
      "132/132 [==============================] - 0s - loss: 630769.2154 - val_loss: 1289496.8929\n",
      "Epoch 603/1000\n",
      "132/132 [==============================] - 0s - loss: 594579.3333 - val_loss: 1156964.3571\n",
      "Epoch 604/1000\n",
      "132/132 [==============================] - 0s - loss: 658590.5381 - val_loss: 1285510.1964\n",
      "Epoch 605/1000\n",
      "132/132 [==============================] - 0s - loss: 668507.7311 - val_loss: 1442499.9286\n",
      "Epoch 606/1000\n",
      "132/132 [==============================] - 0s - loss: 644451.9622 - val_loss: 1265218.7857\n",
      "Epoch 607/1000\n",
      "132/132 [==============================] - 0s - loss: 632111.2358 - val_loss: 1266538.2500\n",
      "Epoch 608/1000\n",
      "132/132 [==============================] - 0s - loss: 645052.0159 - val_loss: 1196805.3393\n",
      "Epoch 609/1000\n",
      "132/132 [==============================] - 0s - loss: 649554.6032 - val_loss: 1302136.8036\n",
      "Epoch 610/1000\n",
      "132/132 [==============================] - 0s - loss: 624300.8312 - val_loss: 1364797.9107\n",
      "Epoch 611/1000\n",
      "132/132 [==============================] - 0s - loss: 584889.5305 - val_loss: 1505650.0179\n",
      "Epoch 612/1000\n",
      "132/132 [==============================] - 0s - loss: 632679.4061 - val_loss: 1297706.8393442.\n",
      "Epoch 613/1000\n",
      "132/132 [==============================] - 0s - loss: 631603.1238 - val_loss: 1291273.1786\n",
      "Epoch 614/1000\n",
      "132/132 [==============================] - 0s - loss: 625965.2195 - val_loss: 1228552.9821\n",
      "Epoch 615/1000\n",
      "132/132 [==============================] - 0s - loss: 642893.4084 - val_loss: 1603422.1964\n",
      "Epoch 616/1000\n",
      "132/132 [==============================] - 0s - loss: 609746.6450 - val_loss: 1360289.8929\n",
      "Epoch 617/1000\n",
      "132/132 [==============================] - 0s - loss: 599299.5388 - val_loss: 1321285.4643\n",
      "Epoch 618/1000\n",
      "132/132 [==============================] - 0s - loss: 606554.7631 - val_loss: 1327849.0179\n",
      "Epoch 619/1000\n",
      "132/132 [==============================] - 0s - loss: 621788.1413 - val_loss: 1521591.9107\n",
      "Epoch 620/1000\n",
      "132/132 [==============================] - 0s - loss: 686367.0147 - val_loss: 1303454.6071\n",
      "Epoch 621/1000\n",
      "132/132 [==============================] - 0s - loss: 632068.4818 - val_loss: 1207361.6250\n",
      "Epoch 622/1000\n",
      "132/132 [==============================] - 0s - loss: 624228.0422 - val_loss: 1206599.3571\n",
      "Epoch 623/1000\n",
      "132/132 [==============================] - 0s - loss: 632310.8686 - val_loss: 1246675.2679\n",
      "Epoch 624/1000\n",
      "132/132 [==============================] - 0s - loss: 635150.1065 - val_loss: 1380208.1964\n",
      "Epoch 625/1000\n",
      "132/132 [==============================] - 0s - loss: 620140.0088 - val_loss: 1218041.5000\n",
      "Epoch 626/1000\n",
      "132/132 [==============================] - 0s - loss: 654661.8766 - val_loss: 1275272.1071\n",
      "Epoch 627/1000\n",
      "132/132 [==============================] - 0s - loss: 624015.4631 - val_loss: 1279034.4464\n",
      "Epoch 628/1000\n",
      "132/132 [==============================] - 0s - loss: 633137.3177 - val_loss: 1142968.7500\n",
      "Epoch 629/1000\n",
      "132/132 [==============================] - 0s - loss: 669578.9982 - val_loss: 1302452.8929\n",
      "Epoch 630/1000\n",
      "132/132 [==============================] - 0s - loss: 593040.9950 - val_loss: 1170414.6607\n",
      "Epoch 631/1000\n",
      "132/132 [==============================] - 0s - loss: 606140.9915 - val_loss: 1292056.4643\n",
      "Epoch 632/1000\n",
      "132/132 [==============================] - 0s - loss: 613348.4484 - val_loss: 1239046.6607\n",
      "Epoch 633/1000\n",
      "132/132 [==============================] - 0s - loss: 620282.2089 - val_loss: 1252914.3036\n",
      "Epoch 634/1000\n",
      "132/132 [==============================] - 0s - loss: 629726.0360 - val_loss: 1457356.5000\n",
      "Epoch 635/1000\n",
      "132/132 [==============================] - 0s - loss: 590823.3556 - val_loss: 1259335.8750\n",
      "Epoch 636/1000\n",
      "132/132 [==============================] - 0s - loss: 633066.0185 - val_loss: 1552208.7857\n",
      "Epoch 637/1000\n",
      "132/132 [==============================] - 0s - loss: 568947.4961 - val_loss: 1318232.3036\n",
      "Epoch 638/1000\n",
      "132/132 [==============================] - 0s - loss: 619851.7347 - val_loss: 1315423.0714\n",
      "Epoch 639/1000\n",
      "132/132 [==============================] - 0s - loss: 593109.7053 - val_loss: 1353847.5000\n",
      "Epoch 640/1000\n",
      "132/132 [==============================] - 0s - loss: 571630.8440 - val_loss: 1573384.6607\n",
      "Epoch 641/1000\n",
      "132/132 [==============================] - 0s - loss: 605688.3584 - val_loss: 1420132.9464\n",
      "Epoch 642/1000\n",
      "132/132 [==============================] - 0s - loss: 604635.3970 - val_loss: 1382451.5893\n",
      "Epoch 643/1000\n",
      "132/132 [==============================] - 0s - loss: 583797.3901 - val_loss: 1364138.7321\n",
      "Epoch 644/1000\n",
      "132/132 [==============================] - 0s - loss: 607073.1535 - val_loss: 1302021.9821\n",
      "Epoch 645/1000\n",
      "132/132 [==============================] - 0s - loss: 611337.7598 - val_loss: 1262344.7321\n",
      "Epoch 646/1000\n",
      "132/132 [==============================] - 0s - loss: 634040.9318 - val_loss: 1316626.8036\n",
      "Epoch 647/1000\n",
      "132/132 [==============================] - 0s - loss: 618961.7165 - val_loss: 1307469.6964\n",
      "Epoch 648/1000\n",
      "132/132 [==============================] - 0s - loss: 568968.5118 - val_loss: 1361232.3750\n",
      "Epoch 649/1000\n",
      "132/132 [==============================] - 0s - loss: 611874.3456 - val_loss: 1291001.2143\n",
      "Epoch 650/1000\n",
      "132/132 [==============================] - 0s - loss: 618625.1393 - val_loss: 1299083.8393\n",
      "Epoch 651/1000\n",
      "132/132 [==============================] - 0s - loss: 575303.3638 - val_loss: 1266559.0893\n",
      "Epoch 652/1000\n",
      "132/132 [==============================] - 0s - loss: 618377.9321 - val_loss: 1303377.5000\n",
      "Epoch 653/1000\n",
      "132/132 [==============================] - 0s - loss: 584929.2144 - val_loss: 1320641.8750\n",
      "Epoch 654/1000\n",
      "132/132 [==============================] - 0s - loss: 569316.2493 - val_loss: 1351511.4821\n",
      "Epoch 655/1000\n",
      "132/132 [==============================] - 0s - loss: 575787.7377 - val_loss: 1326603.5536\n",
      "Epoch 656/1000\n",
      "132/132 [==============================] - 0s - loss: 625502.1344 - val_loss: 1378971.0357\n",
      "Epoch 657/1000\n",
      "132/132 [==============================] - 0s - loss: 574522.7343 - val_loss: 1322953.6964\n",
      "Epoch 658/1000\n",
      "132/132 [==============================] - 0s - loss: 645422.7759 - val_loss: 1382541.9821\n",
      "Epoch 659/1000\n",
      "132/132 [==============================] - 0s - loss: 610375.8620 - val_loss: 1418691.9107\n",
      "Epoch 660/1000\n",
      "132/132 [==============================] - 0s - loss: 537896.0473 - val_loss: 1271751.2857\n",
      "Epoch 661/1000\n",
      "132/132 [==============================] - 0s - loss: 591929.0097 - val_loss: 1342220.3393\n",
      "Epoch 662/1000\n",
      "132/132 [==============================] - 0s - loss: 572386.6418 - val_loss: 1342310.4464\n",
      "Epoch 663/1000\n",
      "132/132 [==============================] - 0s - loss: 606836.5627 - val_loss: 1333785.3750\n",
      "Epoch 664/1000\n",
      "132/132 [==============================] - 0s - loss: 596144.9593 - val_loss: 1288173.0893\n",
      "Epoch 665/1000\n",
      "132/132 [==============================] - 0s - loss: 581849.0735 - val_loss: 1506719.4464\n",
      "Epoch 666/1000\n",
      "132/132 [==============================] - 0s - loss: 632271.1834 - val_loss: 1302716.6250\n",
      "Epoch 667/1000\n",
      "132/132 [==============================] - 0s - loss: 607855.6278 - val_loss: 1302896.9464\n",
      "Epoch 668/1000\n",
      "132/132 [==============================] - 0s - loss: 583953.0740 - val_loss: 1303006.2321\n",
      "Epoch 669/1000\n",
      "132/132 [==============================] - 0s - loss: 649108.6976 - val_loss: 1266150.4286\n",
      "Epoch 670/1000\n",
      "132/132 [==============================] - 0s - loss: 571504.1333 - val_loss: 1368126.2679\n",
      "Epoch 671/1000\n",
      "132/132 [==============================] - 0s - loss: 603886.5788 - val_loss: 1436540.5179\n",
      "Epoch 672/1000\n",
      "132/132 [==============================] - 0s - loss: 593171.0707 - val_loss: 1525856.1964\n",
      "Epoch 673/1000\n",
      "132/132 [==============================] - 0s - loss: 600484.5633 - val_loss: 1301491.8214\n",
      "Epoch 674/1000\n",
      "132/132 [==============================] - 0s - loss: 631679.2652 - val_loss: 1306480.2321\n",
      "Epoch 675/1000\n",
      "132/132 [==============================] - 0s - loss: 589466.6167 - val_loss: 1352569.0893\n",
      "Epoch 676/1000\n",
      "132/132 [==============================] - 0s - loss: 584824.6662 - val_loss: 1341477.5536\n",
      "Epoch 677/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 586913.3771 - val_loss: 1242006.3393\n",
      "Epoch 678/1000\n",
      "132/132 [==============================] - 0s - loss: 601730.3163 - val_loss: 1293876.4464\n",
      "Epoch 679/1000\n",
      "132/132 [==============================] - 0s - loss: 585050.5716 - val_loss: 1315251.3393\n",
      "Epoch 680/1000\n",
      "132/132 [==============================] - 0s - loss: 569304.5182 - val_loss: 1247684.5625\n",
      "Epoch 681/1000\n",
      "132/132 [==============================] - 0s - loss: 611598.6421 - val_loss: 1342451.2857\n",
      "Epoch 682/1000\n",
      "132/132 [==============================] - 0s - loss: 570673.6203 - val_loss: 1520380.2679\n",
      "Epoch 683/1000\n",
      "132/132 [==============================] - 0s - loss: 604111.3335 - val_loss: 1334245.8571\n",
      "Epoch 684/1000\n",
      "132/132 [==============================] - 0s - loss: 610075.1745 - val_loss: 1375543.6964\n",
      "Epoch 685/1000\n",
      "132/132 [==============================] - 0s - loss: 621374.4016 - val_loss: 1344262.1250\n",
      "Epoch 686/1000\n",
      "132/132 [==============================] - 0s - loss: 600086.9364 - val_loss: 1335019.2679\n",
      "Epoch 687/1000\n",
      "132/132 [==============================] - 0s - loss: 604448.0554 - val_loss: 1410644.4821\n",
      "Epoch 688/1000\n",
      "132/132 [==============================] - 0s - loss: 539790.2533 - val_loss: 1401904.0714\n",
      "Epoch 689/1000\n",
      "132/132 [==============================] - 0s - loss: 588974.6025 - val_loss: 1282855.6250\n",
      "Epoch 690/1000\n",
      "132/132 [==============================] - 0s - loss: 589285.6798 - val_loss: 1285551.4286\n",
      "Epoch 691/1000\n",
      "132/132 [==============================] - 0s - loss: 575338.6876 - val_loss: 1263509.8304\n",
      "Epoch 692/1000\n",
      "132/132 [==============================] - 0s - loss: 563091.4764 - val_loss: 1275850.5893\n",
      "Epoch 693/1000\n",
      "132/132 [==============================] - 0s - loss: 628748.6724 - val_loss: 1326717.8393\n",
      "Epoch 694/1000\n",
      "132/132 [==============================] - 0s - loss: 630346.4857 - val_loss: 1261586.5536\n",
      "Epoch 695/1000\n",
      "132/132 [==============================] - 0s - loss: 648744.1284 - val_loss: 1303147.9821\n",
      "Epoch 696/1000\n",
      "132/132 [==============================] - 0s - loss: 629158.0112 - val_loss: 1314370.4464\n",
      "Epoch 697/1000\n",
      "132/132 [==============================] - 0s - loss: 613403.1973 - val_loss: 1554201.9821\n",
      "Epoch 698/1000\n",
      "132/132 [==============================] - 0s - loss: 596868.1842 - val_loss: 1259164.3750\n",
      "Epoch 699/1000\n",
      "132/132 [==============================] - 0s - loss: 652608.2714 - val_loss: 1273154.1964\n",
      "Epoch 700/1000\n",
      "132/132 [==============================] - 0s - loss: 601363.5616 - val_loss: 1407094.9464\n",
      "Epoch 701/1000\n",
      "132/132 [==============================] - 0s - loss: 624644.7089 - val_loss: 1310876.1607\n",
      "Epoch 702/1000\n",
      "132/132 [==============================] - 0s - loss: 638840.4738 - val_loss: 1255055.2679\n",
      "Epoch 703/1000\n",
      "132/132 [==============================] - 0s - loss: 596006.0052 - val_loss: 1245897.8929\n",
      "Epoch 704/1000\n",
      "132/132 [==============================] - 0s - loss: 589696.7969 - val_loss: 1626243.8750\n",
      "Epoch 705/1000\n",
      "132/132 [==============================] - 0s - loss: 637260.4297 - val_loss: 1299088.2679\n",
      "Epoch 706/1000\n",
      "132/132 [==============================] - 0s - loss: 596885.0401 - val_loss: 1340743.1786\n",
      "Epoch 707/1000\n",
      "132/132 [==============================] - 0s - loss: 651019.4183 - val_loss: 1370481.0536\n",
      "Epoch 708/1000\n",
      "132/132 [==============================] - 0s - loss: 640966.6143 - val_loss: 1329795.5714\n",
      "Epoch 709/1000\n",
      "132/132 [==============================] - 0s - loss: 653066.6046 - val_loss: 1311833.3571\n",
      "Epoch 710/1000\n",
      "132/132 [==============================] - 0s - loss: 608294.5040 - val_loss: 1294247.8571\n",
      "Epoch 711/1000\n",
      "132/132 [==============================] - 0s - loss: 587135.6042 - val_loss: 1256590.1429\n",
      "Epoch 712/1000\n",
      "132/132 [==============================] - 0s - loss: 634640.6607 - val_loss: 1345681.0714\n",
      "Epoch 713/1000\n",
      "132/132 [==============================] - 0s - loss: 613833.0666 - val_loss: 1332457.5000\n",
      "Epoch 714/1000\n",
      "132/132 [==============================] - 0s - loss: 602519.5767 - val_loss: 1264705.6607\n",
      "Epoch 715/1000\n",
      "132/132 [==============================] - 0s - loss: 634103.3957 - val_loss: 1274651.0357\n",
      "Epoch 716/1000\n",
      "132/132 [==============================] - 0s - loss: 579235.8466 - val_loss: 1302389.9821\n",
      "Epoch 717/1000\n",
      "132/132 [==============================] - 0s - loss: 608838.0237 - val_loss: 1279265.4643\n",
      "Epoch 718/1000\n",
      "132/132 [==============================] - 0s - loss: 626574.0968 - val_loss: 1270040.2143\n",
      "Epoch 719/1000\n",
      "132/132 [==============================] - 0s - loss: 531130.2167 - val_loss: 1278734.1071\n",
      "Epoch 720/1000\n",
      "132/132 [==============================] - 0s - loss: 631285.6505 - val_loss: 1232916.0625\n",
      "Epoch 721/1000\n",
      "132/132 [==============================] - 0s - loss: 604569.5452 - val_loss: 1381504.5893\n",
      "Epoch 722/1000\n",
      "132/132 [==============================] - 0s - loss: 599754.3624 - val_loss: 1262810.9286\n",
      "Epoch 723/1000\n",
      "132/132 [==============================] - 0s - loss: 664679.0192 - val_loss: 1296281.3929\n",
      "Epoch 724/1000\n",
      "132/132 [==============================] - 0s - loss: 592186.3345 - val_loss: 1272693.4821\n",
      "Epoch 725/1000\n",
      "132/132 [==============================] - 0s - loss: 594978.8695 - val_loss: 1289056.9107\n",
      "Epoch 726/1000\n",
      "132/132 [==============================] - 0s - loss: 576842.0779 - val_loss: 1290350.7679\n",
      "Epoch 727/1000\n",
      "132/132 [==============================] - 0s - loss: 581529.7550 - val_loss: 1264940.9821\n",
      "Epoch 728/1000\n",
      "132/132 [==============================] - 0s - loss: 613997.5647 - val_loss: 1282522.8036\n",
      "Epoch 729/1000\n",
      "132/132 [==============================] - 0s - loss: 571139.8266 - val_loss: 1465251.9107\n",
      "Epoch 730/1000\n",
      "132/132 [==============================] - 0s - loss: 579132.7128 - val_loss: 1293791.7857\n",
      "Epoch 731/1000\n",
      "132/132 [==============================] - 0s - loss: 563066.2065 - val_loss: 1233558.1786\n",
      "Epoch 732/1000\n",
      "132/132 [==============================] - 0s - loss: 591402.5135 - val_loss: 1227080.5268\n",
      "Epoch 733/1000\n",
      "132/132 [==============================] - 0s - loss: 568395.7496 - val_loss: 1369564.6250\n",
      "Epoch 734/1000\n",
      "132/132 [==============================] - 0s - loss: 598291.9714 - val_loss: 1457849.2679\n",
      "Epoch 735/1000\n",
      "132/132 [==============================] - 0s - loss: 594946.6117 - val_loss: 1295386.6964\n",
      "Epoch 736/1000\n",
      "132/132 [==============================] - 0s - loss: 564518.2494 - val_loss: 1307389.3214\n",
      "Epoch 737/1000\n",
      "132/132 [==============================] - 0s - loss: 558577.5526 - val_loss: 1351606.1429\n",
      "Epoch 738/1000\n",
      "132/132 [==============================] - 0s - loss: 604366.5502 - val_loss: 1254084.5089\n",
      "Epoch 739/1000\n",
      "132/132 [==============================] - 0s - loss: 588331.8459 - val_loss: 1053730.8929\n",
      "Epoch 740/1000\n",
      "132/132 [==============================] - 0s - loss: 611644.0665 - val_loss: 1515662.2857\n",
      "Epoch 741/1000\n",
      "132/132 [==============================] - 0s - loss: 614749.8253 - val_loss: 1289035.8750\n",
      "Epoch 742/1000\n",
      "132/132 [==============================] - 0s - loss: 559236.4484 - val_loss: 1287817.8036785.\n",
      "Epoch 743/1000\n",
      "132/132 [==============================] - 0s - loss: 601530.2512 - val_loss: 1311798.4286\n",
      "Epoch 744/1000\n",
      "132/132 [==============================] - 0s - loss: 577846.3574 - val_loss: 1274938.6607\n",
      "Epoch 745/1000\n",
      "132/132 [==============================] - 0s - loss: 606023.3294 - val_loss: 1342392.6429\n",
      "Epoch 746/1000\n",
      "132/132 [==============================] - 0s - loss: 580982.1985 - val_loss: 1676937.8571\n",
      "Epoch 747/1000\n",
      "132/132 [==============================] - 0s - loss: 615451.0960 - val_loss: 1265776.0893\n",
      "Epoch 748/1000\n",
      "132/132 [==============================] - 0s - loss: 579319.1383 - val_loss: 1627305.5000\n",
      "Epoch 749/1000\n",
      "132/132 [==============================] - 0s - loss: 567149.7055 - val_loss: 1288738.6607\n",
      "Epoch 750/1000\n",
      "132/132 [==============================] - 0s - loss: 603289.4316 - val_loss: 1267372.3214\n",
      "Epoch 751/1000\n",
      "132/132 [==============================] - 0s - loss: 593986.9773 - val_loss: 1399213.8036\n",
      "Epoch 752/1000\n",
      "132/132 [==============================] - 0s - loss: 604903.7646 - val_loss: 1301536.285779\n",
      "Epoch 753/1000\n",
      "132/132 [==============================] - 0s - loss: 572139.2859 - val_loss: 1337890.5893\n",
      "Epoch 754/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 570457.1893 - val_loss: 1318098.9643\n",
      "Epoch 755/1000\n",
      "132/132 [==============================] - 0s - loss: 554016.9656 - val_loss: 1351494.7679\n",
      "Epoch 756/1000\n",
      "132/132 [==============================] - 0s - loss: 599507.0076 - val_loss: 1382566.3929\n",
      "Epoch 757/1000\n",
      "132/132 [==============================] - 0s - loss: 534134.7619 - val_loss: 1320955.7321\n",
      "Epoch 758/1000\n",
      "132/132 [==============================] - 0s - loss: 612135.4060 - val_loss: 1316448.5714\n",
      "Epoch 759/1000\n",
      "132/132 [==============================] - 0s - loss: 603059.8374 - val_loss: 1336321.9107\n",
      "Epoch 760/1000\n",
      "132/132 [==============================] - 0s - loss: 620216.6907 - val_loss: 1340944.9643\n",
      "Epoch 761/1000\n",
      "132/132 [==============================] - 0s - loss: 566217.7813 - val_loss: 1357011.3214\n",
      "Epoch 762/1000\n",
      "132/132 [==============================] - 0s - loss: 515702.3346 - val_loss: 1290620.0714\n",
      "Epoch 763/1000\n",
      "132/132 [==============================] - 0s - loss: 517065.7074 - val_loss: 1280998.1429\n",
      "Epoch 764/1000\n",
      "132/132 [==============================] - 0s - loss: 520046.9451 - val_loss: 1267249.4018\n",
      "Epoch 765/1000\n",
      "132/132 [==============================] - 0s - loss: 606373.0104 - val_loss: 1424437.3571\n",
      "Epoch 766/1000\n",
      "132/132 [==============================] - 0s - loss: 635324.6061 - val_loss: 1465039.6429\n",
      "Epoch 767/1000\n",
      "132/132 [==============================] - 0s - loss: 574398.4350 - val_loss: 1347041.3571\n",
      "Epoch 768/1000\n",
      "132/132 [==============================] - 0s - loss: 655419.9744 - val_loss: 1230681.3036\n",
      "Epoch 769/1000\n",
      "132/132 [==============================] - 0s - loss: 570245.7484 - val_loss: 1264534.2143\n",
      "Epoch 770/1000\n",
      "132/132 [==============================] - 0s - loss: 629001.1916 - val_loss: 1381634.8036\n",
      "Epoch 771/1000\n",
      "132/132 [==============================] - 0s - loss: 570529.4854 - val_loss: 1413773.2857\n",
      "Epoch 772/1000\n",
      "132/132 [==============================] - 0s - loss: 609174.6719 - val_loss: 1325951.2679\n",
      "Epoch 773/1000\n",
      "132/132 [==============================] - 0s - loss: 610690.7884 - val_loss: 1326239.3929\n",
      "Epoch 774/1000\n",
      "132/132 [==============================] - 0s - loss: 605467.8310 - val_loss: 1329067.7679\n",
      "Epoch 775/1000\n",
      "132/132 [==============================] - 0s - loss: 605381.1805 - val_loss: 1553512.9107\n",
      "Epoch 776/1000\n",
      "132/132 [==============================] - 0s - loss: 562569.4361 - val_loss: 1289502.9464\n",
      "Epoch 777/1000\n",
      "132/132 [==============================] - 0s - loss: 592979.3026 - val_loss: 1377521.4821\n",
      "Epoch 778/1000\n",
      "132/132 [==============================] - 0s - loss: 605945.2369 - val_loss: 1373244.4821\n",
      "Epoch 779/1000\n",
      "132/132 [==============================] - 0s - loss: 605044.8333 - val_loss: 1369169.6786\n",
      "Epoch 780/1000\n",
      "132/132 [==============================] - 0s - loss: 570452.2917 - val_loss: 1560643.6964\n",
      "Epoch 781/1000\n",
      "132/132 [==============================] - 0s - loss: 632595.1274 - val_loss: 1455638.0536\n",
      "Epoch 782/1000\n",
      "132/132 [==============================] - 0s - loss: 550549.9716 - val_loss: 1364702.2857\n",
      "Epoch 783/1000\n",
      "132/132 [==============================] - 0s - loss: 562037.2481 - val_loss: 1349177.4464\n",
      "Epoch 784/1000\n",
      "132/132 [==============================] - 0s - loss: 678007.2045 - val_loss: 1409944.1964\n",
      "Epoch 785/1000\n",
      "132/132 [==============================] - 0s - loss: 604671.6643 - val_loss: 1146112.4107\n",
      "Epoch 786/1000\n",
      "132/132 [==============================] - 0s - loss: 624395.2285 - val_loss: 1335933.4821\n",
      "Epoch 787/1000\n",
      "132/132 [==============================] - 0s - loss: 661594.9871 - val_loss: 1266197.1607\n",
      "Epoch 788/1000\n",
      "132/132 [==============================] - 0s - loss: 633031.9541 - val_loss: 1394187.1607\n",
      "Epoch 789/1000\n",
      "132/132 [==============================] - 0s - loss: 625672.8149 - val_loss: 1448837.2321\n",
      "Epoch 790/1000\n",
      "132/132 [==============================] - 0s - loss: 553055.5812 - val_loss: 1414897.1429\n",
      "Epoch 791/1000\n",
      "132/132 [==============================] - 0s - loss: 567401.8281 - val_loss: 1463833.0536\n",
      "Epoch 792/1000\n",
      "132/132 [==============================] - 0s - loss: 578411.5052 - val_loss: 1369789.9464\n",
      "Epoch 793/1000\n",
      "132/132 [==============================] - 0s - loss: 607486.8600 - val_loss: 1386401.5536\n",
      "Epoch 794/1000\n",
      "132/132 [==============================] - 0s - loss: 537998.6369 - val_loss: 1309206.6875\n",
      "Epoch 795/1000\n",
      "132/132 [==============================] - 0s - loss: 579804.9858 - val_loss: 1352416.3214\n",
      "Epoch 796/1000\n",
      "132/132 [==============================] - 0s - loss: 612246.8700 - val_loss: 1387496.0714\n",
      "Epoch 797/1000\n",
      "132/132 [==============================] - 0s - loss: 547083.5669 - val_loss: 1571048.3571\n",
      "Epoch 798/1000\n",
      "132/132 [==============================] - 0s - loss: 562342.5149 - val_loss: 1310981.6429\n",
      "Epoch 799/1000\n",
      "132/132 [==============================] - 0s - loss: 617057.5167 - val_loss: 1385676.4286\n",
      "Epoch 800/1000\n",
      "132/132 [==============================] - 0s - loss: 612657.2623 - val_loss: 1376108.4286\n",
      "Epoch 801/1000\n",
      "132/132 [==============================] - 0s - loss: 555070.9072 - val_loss: 1351288.5179\n",
      "Epoch 802/1000\n",
      "132/132 [==============================] - 0s - loss: 595129.0373 - val_loss: 1377389.5893\n",
      "Epoch 803/1000\n",
      "132/132 [==============================] - 0s - loss: 604039.1895 - val_loss: 1436895.1071\n",
      "Epoch 804/1000\n",
      "132/132 [==============================] - 0s - loss: 524327.0328 - val_loss: 1373122.7857\n",
      "Epoch 805/1000\n",
      "132/132 [==============================] - 0s - loss: 576571.5279 - val_loss: 1388637.4821\n",
      "Epoch 806/1000\n",
      "132/132 [==============================] - 0s - loss: 586666.5359 - val_loss: 1391066.5179\n",
      "Epoch 807/1000\n",
      "132/132 [==============================] - 0s - loss: 628184.8091 - val_loss: 1479930.6607\n",
      "Epoch 808/1000\n",
      "132/132 [==============================] - 0s - loss: 592888.9569 - val_loss: 1397736.6964\n",
      "Epoch 809/1000\n",
      "132/132 [==============================] - 0s - loss: 577060.0860 - val_loss: 1666906.9107\n",
      "Epoch 810/1000\n",
      "132/132 [==============================] - 0s - loss: 592220.0308 - val_loss: 1184333.6607\n",
      "Epoch 811/1000\n",
      "132/132 [==============================] - 0s - loss: 616673.1106 - val_loss: 1412921.9821\n",
      "Epoch 812/1000\n",
      "132/132 [==============================] - 0s - loss: 596479.1579 - val_loss: 1462642.1964\n",
      "Epoch 813/1000\n",
      "132/132 [==============================] - 0s - loss: 605200.2950 - val_loss: 1406285.0179\n",
      "Epoch 814/1000\n",
      "132/132 [==============================] - 0s - loss: 563424.9075 - val_loss: 1360702.6607\n",
      "Epoch 815/1000\n",
      "132/132 [==============================] - 0s - loss: 544826.2654 - val_loss: 1345136.7857\n",
      "Epoch 816/1000\n",
      "132/132 [==============================] - 0s - loss: 618897.7978 - val_loss: 1351780.1607\n",
      "Epoch 817/1000\n",
      "132/132 [==============================] - 0s - loss: 593469.0220 - val_loss: 1424629.4821\n",
      "Epoch 818/1000\n",
      "132/132 [==============================] - 0s - loss: 534601.4493 - val_loss: 1417250.8750\n",
      "Epoch 819/1000\n",
      "132/132 [==============================] - 0s - loss: 557913.2667 - val_loss: 1276483.6875\n",
      "Epoch 820/1000\n",
      "132/132 [==============================] - 0s - loss: 573894.6270 - val_loss: 1314563.7679\n",
      "Epoch 821/1000\n",
      "132/132 [==============================] - 0s - loss: 595716.5248 - val_loss: 1435304.3393\n",
      "Epoch 822/1000\n",
      "132/132 [==============================] - 0s - loss: 591603.7514 - val_loss: 1430489.0179\n",
      "Epoch 823/1000\n",
      "132/132 [==============================] - 0s - loss: 554385.7219 - val_loss: 1416983.4821\n",
      "Epoch 824/1000\n",
      "132/132 [==============================] - 0s - loss: 597895.6838 - val_loss: 1398539.6964\n",
      "Epoch 825/1000\n",
      "132/132 [==============================] - 0s - loss: 601264.2564 - val_loss: 1379752.6964\n",
      "Epoch 826/1000\n",
      "132/132 [==============================] - 0s - loss: 552144.1016 - val_loss: 1373239.6964\n",
      "Epoch 827/1000\n",
      "132/132 [==============================] - 0s - loss: 589038.7608 - val_loss: 1398688.0536\n",
      "Epoch 828/1000\n",
      "132/132 [==============================] - 0s - loss: 587767.3191 - val_loss: 1379522.1250\n",
      "Epoch 829/1000\n",
      "132/132 [==============================] - 0s - loss: 568864.7418 - val_loss: 1370650.3393\n",
      "Epoch 830/1000\n",
      "132/132 [==============================] - 0s - loss: 524467.3711 - val_loss: 1425459.3393\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 537056.4061 - val_loss: 1402300.3036\n",
      "Epoch 832/1000\n",
      "132/132 [==============================] - 0s - loss: 561044.0978 - val_loss: 1386647.0893\n",
      "Epoch 833/1000\n",
      "132/132 [==============================] - 0s - loss: 535134.5284 - val_loss: 1365507.1786\n",
      "Epoch 834/1000\n",
      "132/132 [==============================] - 0s - loss: 563513.3987 - val_loss: 1428290.6250\n",
      "Epoch 835/1000\n",
      "132/132 [==============================] - 0s - loss: 575376.2311 - val_loss: 1454445.6964\n",
      "Epoch 836/1000\n",
      "132/132 [==============================] - 0s - loss: 565483.2672 - val_loss: 1647965.1964\n",
      "Epoch 837/1000\n",
      "132/132 [==============================] - 0s - loss: 570732.0424 - val_loss: 1455099.5179\n",
      "Epoch 838/1000\n",
      "132/132 [==============================] - 0s - loss: 538409.2354 - val_loss: 1436501.3929\n",
      "Epoch 839/1000\n",
      "132/132 [==============================] - 0s - loss: 541622.2154 - val_loss: 1368567.3393\n",
      "Epoch 840/1000\n",
      "132/132 [==============================] - 0s - loss: 557254.4252 - val_loss: 1344962.0893\n",
      "Epoch 841/1000\n",
      "132/132 [==============================] - 0s - loss: 570645.0894 - val_loss: 1367887.1607\n",
      "Epoch 842/1000\n",
      "132/132 [==============================] - 0s - loss: 538346.2385 - val_loss: 1377741.9821\n",
      "Epoch 843/1000\n",
      "132/132 [==============================] - 0s - loss: 550808.9859 - val_loss: 1365992.5536\n",
      "Epoch 844/1000\n",
      "132/132 [==============================] - 0s - loss: 546307.2389 - val_loss: 1356330.8571\n",
      "Epoch 845/1000\n",
      "132/132 [==============================] - 0s - loss: 542531.1794 - val_loss: 1362973.5536\n",
      "Epoch 846/1000\n",
      "132/132 [==============================] - 0s - loss: 550991.5755 - val_loss: 1406556.2143\n",
      "Epoch 847/1000\n",
      "132/132 [==============================] - 0s - loss: 560959.8259 - val_loss: 1388681.0714\n",
      "Epoch 848/1000\n",
      "132/132 [==============================] - 0s - loss: 537047.8153 - val_loss: 1347227.2679\n",
      "Epoch 849/1000\n",
      "132/132 [==============================] - 0s - loss: 540420.6880 - val_loss: 1364464.1607\n",
      "Epoch 850/1000\n",
      "132/132 [==============================] - 0s - loss: 549791.2871 - val_loss: 1355440.4107\n",
      "Epoch 851/1000\n",
      "132/132 [==============================] - 0s - loss: 545548.8337 - val_loss: 1372734.2321\n",
      "Epoch 852/1000\n",
      "132/132 [==============================] - 0s - loss: 533627.6908 - val_loss: 1379858.0714\n",
      "Epoch 853/1000\n",
      "132/132 [==============================] - 0s - loss: 548908.2761 - val_loss: 1378804.4464\n",
      "Epoch 854/1000\n",
      "132/132 [==============================] - 0s - loss: 551397.6845 - val_loss: 1390193.4821\n",
      "Epoch 855/1000\n",
      "132/132 [==============================] - 0s - loss: 541094.5674 - val_loss: 1386746.0357\n",
      "Epoch 856/1000\n",
      "132/132 [==============================] - 0s - loss: 540444.6931 - val_loss: 1409751.2857\n",
      "Epoch 857/1000\n",
      "132/132 [==============================] - 0s - loss: 559125.3182 - val_loss: 1412828.5893\n",
      "Epoch 858/1000\n",
      "132/132 [==============================] - 0s - loss: 511413.6872 - val_loss: 1386893.1786\n",
      "Epoch 859/1000\n",
      "132/132 [==============================] - 0s - loss: 518983.1887 - val_loss: 1397345.8036\n",
      "Epoch 860/1000\n",
      "132/132 [==============================] - 0s - loss: 530433.3583 - val_loss: 1401103.2143\n",
      "Epoch 861/1000\n",
      "132/132 [==============================] - 0s - loss: 573455.9662 - val_loss: 1493873.7321\n",
      "Epoch 862/1000\n",
      "132/132 [==============================] - 0s - loss: 546535.7562 - val_loss: 1379386.1250\n",
      "Epoch 863/1000\n",
      "132/132 [==============================] - 0s - loss: 621379.6874 - val_loss: 1571036.1429\n",
      "Epoch 864/1000\n",
      "132/132 [==============================] - 0s - loss: 601397.6188 - val_loss: 1354174.7679\n",
      "Epoch 865/1000\n",
      "132/132 [==============================] - 0s - loss: 545985.8976 - val_loss: 1367332.3571\n",
      "Epoch 866/1000\n",
      "132/132 [==============================] - 0s - loss: 554207.0146 - val_loss: 1412699.8750\n",
      "Epoch 867/1000\n",
      "132/132 [==============================] - 0s - loss: 577894.8332 - val_loss: 1537402.2321\n",
      "Epoch 868/1000\n",
      "132/132 [==============================] - 0s - loss: 573684.7936 - val_loss: 1467126.4286\n",
      "Epoch 869/1000\n",
      "132/132 [==============================] - 0s - loss: 526045.2791 - val_loss: 1358710.4286\n",
      "Epoch 870/1000\n",
      "132/132 [==============================] - 0s - loss: 561425.8326 - val_loss: 1396794.9107\n",
      "Epoch 871/1000\n",
      "132/132 [==============================] - 0s - loss: 530510.7633 - val_loss: 1320827.4643\n",
      "Epoch 872/1000\n",
      "132/132 [==============================] - 0s - loss: 573399.0378 - val_loss: 1345217.4107\n",
      "Epoch 873/1000\n",
      "132/132 [==============================] - 0s - loss: 574858.8118 - val_loss: 1396972.2321\n",
      "Epoch 874/1000\n",
      "132/132 [==============================] - 0s - loss: 556711.7724 - val_loss: 1546257.9821\n",
      "Epoch 875/1000\n",
      "132/132 [==============================] - 0s - loss: 522753.4611 - val_loss: 1440756.2321\n",
      "Epoch 876/1000\n",
      "132/132 [==============================] - 0s - loss: 541296.9299 - val_loss: 1374067.8036\n",
      "Epoch 877/1000\n",
      "132/132 [==============================] - 0s - loss: 576775.1023 - val_loss: 1469979.7500\n",
      "Epoch 878/1000\n",
      "132/132 [==============================] - 0s - loss: 532335.1175 - val_loss: 1425425.4643\n",
      "Epoch 879/1000\n",
      "132/132 [==============================] - 0s - loss: 597831.8597 - val_loss: 1498681.5893\n",
      "Epoch 880/1000\n",
      "132/132 [==============================] - 0s - loss: 518875.8997 - val_loss: 1355269.2589\n",
      "Epoch 881/1000\n",
      "132/132 [==============================] - 0s - loss: 553816.9500 - val_loss: 1381514.8571\n",
      "Epoch 882/1000\n",
      "132/132 [==============================] - 0s - loss: 565150.5288 - val_loss: 1377876.6607\n",
      "Epoch 883/1000\n",
      "132/132 [==============================] - 0s - loss: 560349.0865 - val_loss: 1377299.4464\n",
      "Epoch 884/1000\n",
      "132/132 [==============================] - 0s - loss: 575446.6409 - val_loss: 1364484.0893\n",
      "Epoch 885/1000\n",
      "132/132 [==============================] - 0s - loss: 542536.3587 - val_loss: 1393235.9286\n",
      "Epoch 886/1000\n",
      "132/132 [==============================] - 0s - loss: 560887.1068 - val_loss: 1366421.6607\n",
      "Epoch 887/1000\n",
      "132/132 [==============================] - 0s - loss: 553512.8340 - val_loss: 1375650.1429\n",
      "Epoch 888/1000\n",
      "132/132 [==============================] - 0s - loss: 524298.0045 - val_loss: 1459837.5179\n",
      "Epoch 889/1000\n",
      "132/132 [==============================] - 0s - loss: 508572.9856 - val_loss: 1381521.8036\n",
      "Epoch 890/1000\n",
      "132/132 [==============================] - 0s - loss: 594585.6874 - val_loss: 1373692.1071\n",
      "Epoch 891/1000\n",
      "132/132 [==============================] - 0s - loss: 532474.2255 - val_loss: 1400886.4464\n",
      "Epoch 892/1000\n",
      "132/132 [==============================] - 0s - loss: 517179.7135 - val_loss: 1374626.5000\n",
      "Epoch 893/1000\n",
      "132/132 [==============================] - 0s - loss: 539546.0148 - val_loss: 1407796.5893\n",
      "Epoch 894/1000\n",
      "132/132 [==============================] - 0s - loss: 553012.3161 - val_loss: 1424070.7857\n",
      "Epoch 895/1000\n",
      "132/132 [==============================] - 0s - loss: 560078.2882 - val_loss: 1430436.2500\n",
      "Epoch 896/1000\n",
      "132/132 [==============================] - 0s - loss: 532006.0706 - val_loss: 1400236.5893\n",
      "Epoch 897/1000\n",
      "132/132 [==============================] - 0s - loss: 617746.7596 - val_loss: 1437454.3571\n",
      "Epoch 898/1000\n",
      "132/132 [==============================] - 0s - loss: 554236.3763 - val_loss: 1444938.4464\n",
      "Epoch 899/1000\n",
      "132/132 [==============================] - 0s - loss: 529878.6977 - val_loss: 1396980.1607\n",
      "Epoch 900/1000\n",
      "132/132 [==============================] - 0s - loss: 537780.1950 - val_loss: 1437788.7321\n",
      "Epoch 901/1000\n",
      "132/132 [==============================] - 0s - loss: 550790.5144 - val_loss: 1420376.8750\n",
      "Epoch 902/1000\n",
      "132/132 [==============================] - 0s - loss: 527993.1088 - val_loss: 1438187.9464\n",
      "Epoch 903/1000\n",
      "132/132 [==============================] - 0s - loss: 588675.7589 - val_loss: 1415816.5000\n",
      "Epoch 904/1000\n",
      "132/132 [==============================] - 0s - loss: 565738.2788 - val_loss: 1402292.1250\n",
      "Epoch 905/1000\n",
      "132/132 [==============================] - 0s - loss: 570451.0739 - val_loss: 1416130.5179\n",
      "Epoch 906/1000\n",
      "132/132 [==============================] - 0s - loss: 543900.6867 - val_loss: 1438608.2857\n",
      "Epoch 907/1000\n",
      "132/132 [==============================] - 0s - loss: 560411.9583 - val_loss: 1375676.8393\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 573346.5665 - val_loss: 1435126.3929\n",
      "Epoch 909/1000\n",
      "132/132 [==============================] - 0s - loss: 529215.6107 - val_loss: 1406926.8750\n",
      "Epoch 910/1000\n",
      "132/132 [==============================] - 0s - loss: 548713.7112 - val_loss: 1403650.9464\n",
      "Epoch 911/1000\n",
      "132/132 [==============================] - 0s - loss: 562766.0593 - val_loss: 1455775.8750\n",
      "Epoch 912/1000\n",
      "132/132 [==============================] - 0s - loss: 546215.0142 - val_loss: 1459998.4464\n",
      "Epoch 913/1000\n",
      "132/132 [==============================] - 0s - loss: 566870.9165 - val_loss: 1388664.1429\n",
      "Epoch 914/1000\n",
      "132/132 [==============================] - 0s - loss: 498201.6603 - val_loss: 1406805.7321\n",
      "Epoch 915/1000\n",
      "132/132 [==============================] - 0s - loss: 555922.6169 - val_loss: 1185121.3571\n",
      "Epoch 916/1000\n",
      "132/132 [==============================] - 0s - loss: 548448.0093 - val_loss: 1419922.9821\n",
      "Epoch 917/1000\n",
      "132/132 [==============================] - 0s - loss: 527267.4378 - val_loss: 1368595.8036\n",
      "Epoch 918/1000\n",
      "132/132 [==============================] - 0s - loss: 511634.4497 - val_loss: 1417777.2679\n",
      "Epoch 919/1000\n",
      "132/132 [==============================] - 0s - loss: 499132.0149 - val_loss: 1407170.8393\n",
      "Epoch 920/1000\n",
      "132/132 [==============================] - 0s - loss: 543765.9413 - val_loss: 1396442.6607\n",
      "Epoch 921/1000\n",
      "132/132 [==============================] - 0s - loss: 551481.6546 - val_loss: 1416442.0893373.03\n",
      "Epoch 922/1000\n",
      "132/132 [==============================] - 0s - loss: 545149.5049 - val_loss: 1408961.6250\n",
      "Epoch 923/1000\n",
      "132/132 [==============================] - 0s - loss: 554536.2385 - val_loss: 1466086.0536\n",
      "Epoch 924/1000\n",
      "132/132 [==============================] - 0s - loss: 514976.8146 - val_loss: 1426144.2321\n",
      "Epoch 925/1000\n",
      "132/132 [==============================] - 0s - loss: 525130.7515 - val_loss: 1445713.0536\n",
      "Epoch 926/1000\n",
      "132/132 [==============================] - 0s - loss: 510899.8335 - val_loss: 1444272.5536\n",
      "Epoch 927/1000\n",
      "132/132 [==============================] - 0s - loss: 523560.3609 - val_loss: 1407316.7321\n",
      "Epoch 928/1000\n",
      "132/132 [==============================] - 0s - loss: 528636.8001 - val_loss: 1443176.5357\n",
      "Epoch 929/1000\n",
      "132/132 [==============================] - 0s - loss: 473904.6638 - val_loss: 1395835.2143\n",
      "Epoch 930/1000\n",
      "132/132 [==============================] - 0s - loss: 541299.7794 - val_loss: 1385926.0714910.09\n",
      "Epoch 931/1000\n",
      "132/132 [==============================] - 0s - loss: 536875.7618 - val_loss: 1414605.0179\n",
      "Epoch 932/1000\n",
      "132/132 [==============================] - 0s - loss: 521208.5961 - val_loss: 1424142.3393\n",
      "Epoch 933/1000\n",
      "132/132 [==============================] - 0s - loss: 489799.0616 - val_loss: 1438249.3750\n",
      "Epoch 934/1000\n",
      "132/132 [==============================] - 0s - loss: 568488.3775 - val_loss: 1431803.0893\n",
      "Epoch 935/1000\n",
      "132/132 [==============================] - 0s - loss: 541325.0285 - val_loss: 1440667.2143\n",
      "Epoch 936/1000\n",
      "132/132 [==============================] - 0s - loss: 493598.2634 - val_loss: 1417218.9821\n",
      "Epoch 937/1000\n",
      "132/132 [==============================] - 0s - loss: 515394.0792 - val_loss: 1461115.5893\n",
      "Epoch 938/1000\n",
      "132/132 [==============================] - 0s - loss: 552222.3712 - val_loss: 1461960.9821\n",
      "Epoch 939/1000\n",
      "132/132 [==============================] - 0s - loss: 513595.6764 - val_loss: 1433131.7679\n",
      "Epoch 940/1000\n",
      "132/132 [==============================] - 0s - loss: 551274.1518 - val_loss: 1422870.3750\n",
      "Epoch 941/1000\n",
      "132/132 [==============================] - 0s - loss: 503597.8898 - val_loss: 1405713.0536\n",
      "Epoch 942/1000\n",
      "132/132 [==============================] - 0s - loss: 491040.5331 - val_loss: 1417974.3750\n",
      "Epoch 943/1000\n",
      "132/132 [==============================] - 0s - loss: 545137.2492 - val_loss: 1460638.2679\n",
      "Epoch 944/1000\n",
      "132/132 [==============================] - 0s - loss: 490322.3462 - val_loss: 1407464.1964\n",
      "Epoch 945/1000\n",
      "132/132 [==============================] - 0s - loss: 508522.5648 - val_loss: 1176026.7143\n",
      "Epoch 946/1000\n",
      "132/132 [==============================] - 0s - loss: 529056.8980 - val_loss: 1417379.1607\n",
      "Epoch 947/1000\n",
      "132/132 [==============================] - 0s - loss: 549917.1748 - val_loss: 1391221.6339\n",
      "Epoch 948/1000\n",
      "132/132 [==============================] - 0s - loss: 510282.6955 - val_loss: 1393013.0982\n",
      "Epoch 949/1000\n",
      "132/132 [==============================] - 0s - loss: 507901.4084 - val_loss: 1437569.4643\n",
      "Epoch 950/1000\n",
      "132/132 [==============================] - 0s - loss: 516795.8846 - val_loss: 1431459.6964\n",
      "Epoch 951/1000\n",
      "132/132 [==============================] - 0s - loss: 483955.4998 - val_loss: 1446055.1607\n",
      "Epoch 952/1000\n",
      "132/132 [==============================] - 0s - loss: 476199.9308 - val_loss: 1409920.2768\n",
      "Epoch 953/1000\n",
      "132/132 [==============================] - 0s - loss: 531835.6439 - val_loss: 1415257.6429\n",
      "Epoch 954/1000\n",
      "132/132 [==============================] - 0s - loss: 500599.9871 - val_loss: 1430974.5536\n",
      "Epoch 955/1000\n",
      "132/132 [==============================] - 0s - loss: 504640.9090 - val_loss: 1433690.4107\n",
      "Epoch 956/1000\n",
      "132/132 [==============================] - 0s - loss: 541505.0577 - val_loss: 1434867.3750\n",
      "Epoch 957/1000\n",
      "132/132 [==============================] - 0s - loss: 526127.3424 - val_loss: 1443491.4643\n",
      "Epoch 958/1000\n",
      "132/132 [==============================] - 0s - loss: 500217.8586 - val_loss: 1466178.6250\n",
      "Epoch 959/1000\n",
      "132/132 [==============================] - 0s - loss: 522776.9806 - val_loss: 1434166.0714\n",
      "Epoch 960/1000\n",
      "132/132 [==============================] - 0s - loss: 497121.7276 - val_loss: 1415841.8214\n",
      "Epoch 961/1000\n",
      "132/132 [==============================] - 0s - loss: 522160.5374 - val_loss: 1439597.4464\n",
      "Epoch 962/1000\n",
      "132/132 [==============================] - 0s - loss: 516513.4302 - val_loss: 1437757.2679\n",
      "Epoch 963/1000\n",
      "132/132 [==============================] - 0s - loss: 552846.5446 - val_loss: 1442989.9821\n",
      "Epoch 964/1000\n",
      "132/132 [==============================] - 0s - loss: 531282.6873 - val_loss: 1449138.7857\n",
      "Epoch 965/1000\n",
      "132/132 [==============================] - 0s - loss: 502177.6283 - val_loss: 1436829.4821\n",
      "Epoch 966/1000\n",
      "132/132 [==============================] - 0s - loss: 457797.7341 - val_loss: 1418894.3750\n",
      "Epoch 967/1000\n",
      "132/132 [==============================] - 0s - loss: 512144.8532 - val_loss: 1420769.1786\n",
      "Epoch 968/1000\n",
      "132/132 [==============================] - 0s - loss: 520406.2655 - val_loss: 1417744.2143\n",
      "Epoch 969/1000\n",
      "132/132 [==============================] - 0s - loss: 529195.1142 - val_loss: 1450885.3571\n",
      "Epoch 970/1000\n",
      "132/132 [==============================] - 0s - loss: 530837.4684 - val_loss: 1435808.9821\n",
      "Epoch 971/1000\n",
      "132/132 [==============================] - 0s - loss: 516254.2510 - val_loss: 1445206.8571\n",
      "Epoch 972/1000\n",
      "132/132 [==============================] - 0s - loss: 551850.9703 - val_loss: 1478864.5536\n",
      "Epoch 973/1000\n",
      "132/132 [==============================] - 0s - loss: 525243.7207 - val_loss: 1454385.0000\n",
      "Epoch 974/1000\n",
      "132/132 [==============================] - 0s - loss: 478203.1537 - val_loss: 1511494.9286\n",
      "Epoch 975/1000\n",
      "132/132 [==============================] - 0s - loss: 497407.4512 - val_loss: 1459409.2679\n",
      "Epoch 976/1000\n",
      "132/132 [==============================] - 0s - loss: 476306.7505 - val_loss: 1462571.1964\n",
      "Epoch 977/1000\n",
      "132/132 [==============================] - 0s - loss: 471960.1326 - val_loss: 1462433.8571\n",
      "Epoch 978/1000\n",
      "132/132 [==============================] - 0s - loss: 490569.6277 - val_loss: 1495397.6607\n",
      "Epoch 979/1000\n",
      "132/132 [==============================] - 0s - loss: 458361.7644 - val_loss: 1433812.6786\n",
      "Epoch 980/1000\n",
      "132/132 [==============================] - 0s - loss: 523373.7427 - val_loss: 1512423.3393\n",
      "Epoch 981/1000\n",
      "132/132 [==============================] - 0s - loss: 475933.9241 - val_loss: 1450583.4911\n",
      "Epoch 982/1000\n",
      "132/132 [==============================] - 0s - loss: 499651.2493 - val_loss: 1514750.0000\n",
      "Epoch 983/1000\n",
      "132/132 [==============================] - 0s - loss: 516856.7841 - val_loss: 1511630.5179\n",
      "Epoch 984/1000\n",
      "132/132 [==============================] - 0s - loss: 486792.9711 - val_loss: 1444167.3214\n",
      "Epoch 985/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s - loss: 543872.5240 - val_loss: 1500202.9464\n",
      "Epoch 986/1000\n",
      "132/132 [==============================] - 0s - loss: 525739.1676 - val_loss: 1390528.2321\n",
      "Epoch 987/1000\n",
      "132/132 [==============================] - 0s - loss: 453723.4221 - val_loss: 1468915.9107\n",
      "Epoch 988/1000\n",
      "132/132 [==============================] - 0s - loss: 485623.5197 - val_loss: 1495504.1429\n",
      "Epoch 989/1000\n",
      "132/132 [==============================] - 0s - loss: 474021.5127 - val_loss: 1489091.8393\n",
      "Epoch 990/1000\n",
      "132/132 [==============================] - 0s - loss: 517481.0476 - val_loss: 1459473.3929\n",
      "Epoch 991/1000\n",
      "132/132 [==============================] - 0s - loss: 541254.5289 - val_loss: 1506096.0893\n",
      "Epoch 992/1000\n",
      "132/132 [==============================] - 0s - loss: 509366.2763 - val_loss: 1445061.8929\n",
      "Epoch 993/1000\n",
      "132/132 [==============================] - 0s - loss: 476674.4901 - val_loss: 1510148.5893\n",
      "Epoch 994/1000\n",
      "132/132 [==============================] - 0s - loss: 448871.8190 - val_loss: 1453313.9196\n",
      "Epoch 995/1000\n",
      "132/132 [==============================] - 0s - loss: 530259.6358 - val_loss: 1499389.9821\n",
      "Epoch 996/1000\n",
      "132/132 [==============================] - 0s - loss: 468357.4467 - val_loss: 1491040.3393\n",
      "Epoch 997/1000\n",
      "132/132 [==============================] - 0s - loss: 541247.5050 - val_loss: 1481051.0179\n",
      "Epoch 998/1000\n",
      "132/132 [==============================] - 0s - loss: 510683.0198 - val_loss: 1486874.1607\n",
      "Epoch 999/1000\n",
      "132/132 [==============================] - 0s - loss: 515241.9145 - val_loss: 1481098.4464\n",
      "Epoch 1000/1000\n",
      "132/132 [==============================] - 0s - loss: 490139.3137 - val_loss: 1479104.7857\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 1890.81542969]\n",
      "result len(data): 166\n",
      "result data.shape: (166,)\n",
      "result len(slicing): 141\n",
      "result slicing_shape: (141, 25)\n",
      "[array([  36, 2713, 6072, 2073, 1652, 2567,   19, 1896, 1191, 1461, 1386,\n",
      "       1452, 1279,   60, 1294, 1447, 1102, 2484, 1142, 1088, 2333, 1497,\n",
      "       1690, 2265, 1067])]\n",
      "X_train shape: (140, 24, 1)\n",
      "y_train shape: (140,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 133 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "133/133 [==============================] - 0s - loss: 740852.8818 - val_loss: 108593.6016\n",
      "Epoch 2/1000\n",
      "133/133 [==============================] - 0s - loss: 729286.8108 - val_loss: 118896.8549\n",
      "Epoch 3/1000\n",
      "133/133 [==============================] - 0s - loss: 757269.3018 - val_loss: 88834.4922\n",
      "Epoch 4/1000\n",
      "133/133 [==============================] - 0s - loss: 707109.1871 - val_loss: 106948.1049\n",
      "Epoch 5/1000\n",
      "133/133 [==============================] - 0s - loss: 709149.2203 - val_loss: 127753.6808\n",
      "Epoch 6/1000\n",
      "133/133 [==============================] - 0s - loss: 756196.7974 - val_loss: 117610.5290\n",
      "Epoch 7/1000\n",
      "133/133 [==============================] - 0s - loss: 695817.4885 - val_loss: 100992.1060\n",
      "Epoch 8/1000\n",
      "133/133 [==============================] - 0s - loss: 708194.1672 - val_loss: 103776.0770\n",
      "Epoch 9/1000\n",
      "133/133 [==============================] - 0s - loss: 726492.4875 - val_loss: 175393.2054\n",
      "Epoch 10/1000\n",
      "133/133 [==============================] - 0s - loss: 743155.9301 - val_loss: 120788.8192\n",
      "Epoch 11/1000\n",
      "133/133 [==============================] - 0s - loss: 727427.0415 - val_loss: 115882.3973\n",
      "Epoch 12/1000\n",
      "133/133 [==============================] - 0s - loss: 690224.5695 - val_loss: 120143.1473\n",
      "Epoch 13/1000\n",
      "133/133 [==============================] - 0s - loss: 758092.2977 - val_loss: 95816.4967\n",
      "Epoch 14/1000\n",
      "133/133 [==============================] - 0s - loss: 741219.1477 - val_loss: 89137.9286\n",
      "Epoch 15/1000\n",
      "133/133 [==============================] - 0s - loss: 695786.7731 - val_loss: 93123.5391\n",
      "Epoch 16/1000\n",
      "133/133 [==============================] - 0s - loss: 730292.0583 - val_loss: 80184.2042\n",
      "Epoch 17/1000\n",
      "133/133 [==============================] - 0s - loss: 742638.3108 - val_loss: 90485.9018\n",
      "Epoch 18/1000\n",
      "133/133 [==============================] - 0s - loss: 694862.6760 - val_loss: 105919.6295\n",
      "Epoch 19/1000\n",
      "133/133 [==============================] - 0s - loss: 706770.2593 - val_loss: 97691.3527\n",
      "Epoch 20/1000\n",
      "133/133 [==============================] - 0s - loss: 724006.1769 - val_loss: 88894.6429\n",
      "Epoch 21/1000\n",
      "133/133 [==============================] - 0s - loss: 713070.9017 - val_loss: 106743.0022\n",
      "Epoch 22/1000\n",
      "133/133 [==============================] - 0s - loss: 696651.1019 - val_loss: 117543.3371\n",
      "Epoch 23/1000\n",
      "133/133 [==============================] - 0s - loss: 698028.2254 - val_loss: 99418.1183\n",
      "Epoch 24/1000\n",
      "133/133 [==============================] - 0s - loss: 718355.4281 - val_loss: 97904.7333\n",
      "Epoch 25/1000\n",
      "133/133 [==============================] - 0s - loss: 689221.2542 - val_loss: 89565.5324\n",
      "Epoch 26/1000\n",
      "133/133 [==============================] - 0s - loss: 686038.8351 - val_loss: 87231.1440\n",
      "Epoch 27/1000\n",
      "133/133 [==============================] - 0s - loss: 694831.0763 - val_loss: 100417.4721\n",
      "Epoch 28/1000\n",
      "133/133 [==============================] - 0s - loss: 680682.9942 - val_loss: 99697.7589\n",
      "Epoch 29/1000\n",
      "133/133 [==============================] - 0s - loss: 694801.0791 - val_loss: 78099.7366\n",
      "Epoch 30/1000\n",
      "133/133 [==============================] - 0s - loss: 720142.3782 - val_loss: 91966.3739\n",
      "Epoch 31/1000\n",
      "133/133 [==============================] - 0s - loss: 663711.1854 - val_loss: 107736.6730\n",
      "Epoch 32/1000\n",
      "133/133 [==============================] - 0s - loss: 662481.8848 - val_loss: 105077.7980\n",
      "Epoch 33/1000\n",
      "133/133 [==============================] - 0s - loss: 681696.6013 - val_loss: 194281.5491\n",
      "Epoch 34/1000\n",
      "133/133 [==============================] - 0s - loss: 698077.8543 - val_loss: 102980.6797\n",
      "Epoch 35/1000\n",
      "133/133 [==============================] - 0s - loss: 732074.1990 - val_loss: 231521.1384\n",
      "Epoch 36/1000\n",
      "133/133 [==============================] - 0s - loss: 731642.3758 - val_loss: 94795.2176\n",
      "Epoch 37/1000\n",
      "133/133 [==============================] - 0s - loss: 686166.7990 - val_loss: 104358.8783\n",
      "Epoch 38/1000\n",
      "133/133 [==============================] - 0s - loss: 690343.1068 - val_loss: 100701.6652\n",
      "Epoch 39/1000\n",
      "133/133 [==============================] - 0s - loss: 688812.4999 - val_loss: 1055700.4107\n",
      "Epoch 40/1000\n",
      "133/133 [==============================] - 0s - loss: 692640.3159 - val_loss: 92472.9777\n",
      "Epoch 41/1000\n",
      "133/133 [==============================] - 0s - loss: 688982.1400 - val_loss: 101430.4174\n",
      "Epoch 42/1000\n",
      "133/133 [==============================] - 0s - loss: 664475.7405 - val_loss: 76899.4029\n",
      "Epoch 43/1000\n",
      "133/133 [==============================] - 0s - loss: 640451.2056 - val_loss: 110436.3594\n",
      "Epoch 44/1000\n",
      "133/133 [==============================] - 0s - loss: 683684.3132 - val_loss: 89288.5123\n",
      "Epoch 45/1000\n",
      "133/133 [==============================] - 0s - loss: 666252.2284 - val_loss: 81484.8214\n",
      "Epoch 46/1000\n",
      "133/133 [==============================] - 0s - loss: 759552.4264 - val_loss: 100208.5491\n",
      "Epoch 47/1000\n",
      "133/133 [==============================] - 0s - loss: 646920.3676 - val_loss: 81127.4782\n",
      "Epoch 48/1000\n",
      "133/133 [==============================] - 0s - loss: 741814.2532 - val_loss: 119029.6138\n",
      "Epoch 49/1000\n",
      "133/133 [==============================] - 0s - loss: 677997.3040 - val_loss: 96648.7467\n",
      "Epoch 50/1000\n",
      "133/133 [==============================] - 0s - loss: 693403.2032 - val_loss: 113365.7176\n",
      "Epoch 51/1000\n",
      "133/133 [==============================] - 0s - loss: 682793.1250 - val_loss: 161270.1518\n",
      "Epoch 52/1000\n",
      "133/133 [==============================] - 0s - loss: 718539.5242 - val_loss: 88085.8973\n",
      "Epoch 53/1000\n",
      "133/133 [==============================] - 0s - loss: 709236.2499 - val_loss: 105680.0792\n",
      "Epoch 54/1000\n",
      "133/133 [==============================] - 0s - loss: 677039.2402 - val_loss: 115270.3772\n",
      "Epoch 55/1000\n",
      "133/133 [==============================] - 0s - loss: 728483.2445 - val_loss: 118398.2835\n",
      "Epoch 56/1000\n",
      "133/133 [==============================] - 0s - loss: 753146.5283 - val_loss: 91323.3538\n",
      "Epoch 57/1000\n",
      "133/133 [==============================] - 0s - loss: 675403.2445 - val_loss: 102488.7946\n",
      "Epoch 58/1000\n",
      "133/133 [==============================] - 0s - loss: 677852.4490 - val_loss: 74755.9431\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 678413.0257 - val_loss: 93976.7132\n",
      "Epoch 60/1000\n",
      "133/133 [==============================] - 0s - loss: 650621.5216 - val_loss: 91521.7500\n",
      "Epoch 61/1000\n",
      "133/133 [==============================] - 0s - loss: 649489.0086 - val_loss: 79085.5301\n",
      "Epoch 62/1000\n",
      "133/133 [==============================] - 0s - loss: 702613.1062 - val_loss: 106597.1920\n",
      "Epoch 63/1000\n",
      "133/133 [==============================] - 0s - loss: 688638.6897 - val_loss: 85010.5859\n",
      "Epoch 64/1000\n",
      "133/133 [==============================] - 0s - loss: 699263.9057 - val_loss: 125258.1674\n",
      "Epoch 65/1000\n",
      "133/133 [==============================] - 0s - loss: 727498.0883 - val_loss: 99605.2054\n",
      "Epoch 66/1000\n",
      "133/133 [==============================] - 0s - loss: 728984.4046 - val_loss: 134537.3772\n",
      "Epoch 67/1000\n",
      "133/133 [==============================] - 0s - loss: 711080.3903 - val_loss: 110326.4900\n",
      "Epoch 68/1000\n",
      "133/133 [==============================] - 0s - loss: 686413.1287 - val_loss: 145773.2455\n",
      "Epoch 69/1000\n",
      "133/133 [==============================] - 0s - loss: 702048.5378 - val_loss: 130656.0692\n",
      "Epoch 70/1000\n",
      "133/133 [==============================] - 0s - loss: 720085.3200 - val_loss: 91367.0547\n",
      "Epoch 71/1000\n",
      "133/133 [==============================] - 0s - loss: 675897.4250 - val_loss: 92722.6060\n",
      "Epoch 72/1000\n",
      "133/133 [==============================] - 0s - loss: 712443.6340 - val_loss: 98423.3750\n",
      "Epoch 73/1000\n",
      "133/133 [==============================] - 0s - loss: 686720.1726 - val_loss: 101879.1317\n",
      "Epoch 74/1000\n",
      "133/133 [==============================] - 0s - loss: 717825.0461 - val_loss: 99897.3393\n",
      "Epoch 75/1000\n",
      "133/133 [==============================] - 0s - loss: 751022.0508 - val_loss: 100119.5123\n",
      "Epoch 76/1000\n",
      "133/133 [==============================] - 0s - loss: 689212.5735 - val_loss: 113534.6696\n",
      "Epoch 77/1000\n",
      "133/133 [==============================] - 0s - loss: 722193.3384 - val_loss: 96594.2310\n",
      "Epoch 78/1000\n",
      "133/133 [==============================] - 0s - loss: 673574.9872 - val_loss: 100174.5770\n",
      "Epoch 79/1000\n",
      "133/133 [==============================] - 0s - loss: 714061.2958 - val_loss: 113131.6049\n",
      "Epoch 80/1000\n",
      "133/133 [==============================] - 0s - loss: 700718.6693 - val_loss: 125023.8281\n",
      "Epoch 81/1000\n",
      "133/133 [==============================] - 0s - loss: 717369.4066 - val_loss: 112434.33827181.23 - ETA: 0s - loss:\n",
      "Epoch 82/1000\n",
      "133/133 [==============================] - 0s - loss: 675064.1678 - val_loss: 108179.0290\n",
      "Epoch 83/1000\n",
      "133/133 [==============================] - 0s - loss: 721635.1279 - val_loss: 87811.8382\n",
      "Epoch 84/1000\n",
      "133/133 [==============================] - 0s - loss: 693489.4080 - val_loss: 81973.8359\n",
      "Epoch 85/1000\n",
      "133/133 [==============================] - 0s - loss: 767739.3576 - val_loss: 118561.9252\n",
      "Epoch 86/1000\n",
      "133/133 [==============================] - 0s - loss: 724005.7197 - val_loss: 119243.0123\n",
      "Epoch 87/1000\n",
      "133/133 [==============================] - 0s - loss: 692506.1008 - val_loss: 126057.4866\n",
      "Epoch 88/1000\n",
      "133/133 [==============================] - 0s - loss: 679360.7928 - val_loss: 124855.1808\n",
      "Epoch 89/1000\n",
      "133/133 [==============================] - 0s - loss: 718946.2976 - val_loss: 131496.3237\n",
      "Epoch 90/1000\n",
      "133/133 [==============================] - 0s - loss: 731704.7973 - val_loss: 123289.6719\n",
      "Epoch 91/1000\n",
      "133/133 [==============================] - 0s - loss: 700468.9696 - val_loss: 135580.3013\n",
      "Epoch 92/1000\n",
      "133/133 [==============================] - 0s - loss: 670383.0084 - val_loss: 106770.5435\n",
      "Epoch 93/1000\n",
      "133/133 [==============================] - 0s - loss: 689866.3148 - val_loss: 92547.8359\n",
      "Epoch 94/1000\n",
      "133/133 [==============================] - 0s - loss: 697170.7594 - val_loss: 124727.6529\n",
      "Epoch 95/1000\n",
      "133/133 [==============================] - 0s - loss: 739544.1963 - val_loss: 126691.9375\n",
      "Epoch 96/1000\n",
      "133/133 [==============================] - 0s - loss: 688272.9922 - val_loss: 107767.3527\n",
      "Epoch 97/1000\n",
      "133/133 [==============================] - 0s - loss: 729398.7791 - val_loss: 100310.8873\n",
      "Epoch 98/1000\n",
      "133/133 [==============================] - 0s - loss: 684946.4705 - val_loss: 114236.1696\n",
      "Epoch 99/1000\n",
      "133/133 [==============================] - 0s - loss: 692806.4367 - val_loss: 105911.2065\n",
      "Epoch 100/1000\n",
      "133/133 [==============================] - 0s - loss: 713156.6773 - val_loss: 123179.2109\n",
      "Epoch 101/1000\n",
      "133/133 [==============================] - 0s - loss: 668804.9312 - val_loss: 114057.5391\n",
      "Epoch 102/1000\n",
      "133/133 [==============================] - 0s - loss: 708349.2148 - val_loss: 123817.4152\n",
      "Epoch 103/1000\n",
      "133/133 [==============================] - 0s - loss: 666589.2306 - val_loss: 112440.8047\n",
      "Epoch 104/1000\n",
      "133/133 [==============================] - 0s - loss: 689256.9444 - val_loss: 109062.7935\n",
      "Epoch 105/1000\n",
      "133/133 [==============================] - 0s - loss: 719169.6816 - val_loss: 137699.0558\n",
      "Epoch 106/1000\n",
      "133/133 [==============================] - 0s - loss: 649135.8905 - val_loss: 101742.0781\n",
      "Epoch 107/1000\n",
      "133/133 [==============================] - 0s - loss: 633690.9297 - val_loss: 105417.1507\n",
      "Epoch 108/1000\n",
      "133/133 [==============================] - 0s - loss: 710945.0938 - val_loss: 121221.5033\n",
      "Epoch 109/1000\n",
      "133/133 [==============================] - 0s - loss: 703072.6128 - val_loss: 129815.5960\n",
      "Epoch 110/1000\n",
      "133/133 [==============================] - 0s - loss: 698169.8987 - val_loss: 105226.7723\n",
      "Epoch 111/1000\n",
      "133/133 [==============================] - 0s - loss: 684709.1297 - val_loss: 89626.474356195.95\n",
      "Epoch 112/1000\n",
      "133/133 [==============================] - 0s - loss: 740805.8982 - val_loss: 128638.4219\n",
      "Epoch 113/1000\n",
      "133/133 [==============================] - 0s - loss: 711094.8782 - val_loss: 92508.0279\n",
      "Epoch 114/1000\n",
      "133/133 [==============================] - 0s - loss: 701715.8818 - val_loss: 113580.5804\n",
      "Epoch 115/1000\n",
      "133/133 [==============================] - 0s - loss: 679451.8704 - val_loss: 132446.1786\n",
      "Epoch 116/1000\n",
      "133/133 [==============================] - 0s - loss: 685426.2329 - val_loss: 98898.0212\n",
      "Epoch 117/1000\n",
      "133/133 [==============================] - 0s - loss: 716049.8151 - val_loss: 117441.3225\n",
      "Epoch 118/1000\n",
      "133/133 [==============================] - 0s - loss: 678292.5674 - val_loss: 99728.1842\n",
      "Epoch 119/1000\n",
      "133/133 [==============================] - 0s - loss: 664962.8312 - val_loss: 84551.5312\n",
      "Epoch 120/1000\n",
      "133/133 [==============================] - 0s - loss: 691225.1360 - val_loss: 123376.5089\n",
      "Epoch 121/1000\n",
      "133/133 [==============================] - 0s - loss: 702831.8977 - val_loss: 114038.3214\n",
      "Epoch 122/1000\n",
      "133/133 [==============================] - 0s - loss: 663387.8975 - val_loss: 84449.3348\n",
      "Epoch 123/1000\n",
      "133/133 [==============================] - 0s - loss: 687534.2536 - val_loss: 99854.4643\n",
      "Epoch 124/1000\n",
      "133/133 [==============================] - 0s - loss: 661365.5603 - val_loss: 81206.3225\n",
      "Epoch 125/1000\n",
      "133/133 [==============================] - 0s - loss: 672340.2045 - val_loss: 77689.3917\n",
      "Epoch 126/1000\n",
      "133/133 [==============================] - 0s - loss: 665015.2737 - val_loss: 80815.6942\n",
      "Epoch 127/1000\n",
      "133/133 [==============================] - 0s - loss: 656136.7999 - val_loss: 96602.5848\n",
      "Epoch 128/1000\n",
      "133/133 [==============================] - 0s - loss: 657253.4803 - val_loss: 146426.7969\n",
      "Epoch 129/1000\n",
      "133/133 [==============================] - 0s - loss: 638171.9608 - val_loss: 135586.0469\n",
      "Epoch 130/1000\n",
      "133/133 [==============================] - 0s - loss: 679383.5896 - val_loss: 96796.3393\n",
      "Epoch 131/1000\n",
      "133/133 [==============================] - 0s - loss: 700473.8597 - val_loss: 99156.9721\n",
      "Epoch 132/1000\n",
      "133/133 [==============================] - 0s - loss: 706725.3734 - val_loss: 106042.9152\n",
      "Epoch 133/1000\n",
      "133/133 [==============================] - 0s - loss: 678739.0414 - val_loss: 154345.8504\n",
      "Epoch 134/1000\n",
      "133/133 [==============================] - 0s - loss: 677301.3147 - val_loss: 126841.5357\n",
      "Epoch 135/1000\n",
      "133/133 [==============================] - 0s - loss: 671910.4370 - val_loss: 149226.8192\n",
      "Epoch 136/1000\n",
      "133/133 [==============================] - 0s - loss: 687972.4467 - val_loss: 133453.0201\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 706499.4514 - val_loss: 142804.1607\n",
      "Epoch 138/1000\n",
      "133/133 [==============================] - 0s - loss: 655865.8661 - val_loss: 105363.6875\n",
      "Epoch 139/1000\n",
      "133/133 [==============================] - 0s - loss: 657705.1612 - val_loss: 124285.3415\n",
      "Epoch 140/1000\n",
      "133/133 [==============================] - 0s - loss: 677115.1366 - val_loss: 105370.7545\n",
      "Epoch 141/1000\n",
      "133/133 [==============================] - 0s - loss: 670976.4204 - val_loss: 128869.7612\n",
      "Epoch 142/1000\n",
      "133/133 [==============================] - 0s - loss: 665998.6852 - val_loss: 95518.7924\n",
      "Epoch 143/1000\n",
      "133/133 [==============================] - 0s - loss: 645621.9889 - val_loss: 157352.1964\n",
      "Epoch 144/1000\n",
      "133/133 [==============================] - 0s - loss: 647323.9484 - val_loss: 100366.4643\n",
      "Epoch 145/1000\n",
      "133/133 [==============================] - 0s - loss: 684612.4750 - val_loss: 87064.5056\n",
      "Epoch 146/1000\n",
      "133/133 [==============================] - 0s - loss: 661954.1498 - val_loss: 93520.9040\n",
      "Epoch 147/1000\n",
      "133/133 [==============================] - 0s - loss: 662861.6425 - val_loss: 97297.5714\n",
      "Epoch 148/1000\n",
      "133/133 [==============================] - 0s - loss: 671021.7047 - val_loss: 150014.3560\n",
      "Epoch 149/1000\n",
      "133/133 [==============================] - 0s - loss: 650020.1735 - val_loss: 166331.2455\n",
      "Epoch 150/1000\n",
      "133/133 [==============================] - 0s - loss: 664582.6083 - val_loss: 120214.8638\n",
      "Epoch 151/1000\n",
      "133/133 [==============================] - 0s - loss: 688520.0821 - val_loss: 103447.8304\n",
      "Epoch 152/1000\n",
      "133/133 [==============================] - 0s - loss: 671159.0267 - val_loss: 153569.7411\n",
      "Epoch 153/1000\n",
      "133/133 [==============================] - 0s - loss: 648866.3216 - val_loss: 141021.2433\n",
      "Epoch 154/1000\n",
      "133/133 [==============================] - 0s - loss: 654200.7615 - val_loss: 122412.4275\n",
      "Epoch 155/1000\n",
      "133/133 [==============================] - 0s - loss: 658084.5211 - val_loss: 121779.5625\n",
      "Epoch 156/1000\n",
      "133/133 [==============================] - 0s - loss: 608753.1608 - val_loss: 98460.5257\n",
      "Epoch 157/1000\n",
      "133/133 [==============================] - 0s - loss: 622966.4395 - val_loss: 93921.4688\n",
      "Epoch 158/1000\n",
      "133/133 [==============================] - 0s - loss: 712024.8880 - val_loss: 104753.2388\n",
      "Epoch 159/1000\n",
      "133/133 [==============================] - 0s - loss: 664551.9497 - val_loss: 85510.3259\n",
      "Epoch 160/1000\n",
      "133/133 [==============================] - 0s - loss: 683597.1799 - val_loss: 91852.6808\n",
      "Epoch 161/1000\n",
      "133/133 [==============================] - 0s - loss: 724364.8391 - val_loss: 128792.9609\n",
      "Epoch 162/1000\n",
      "133/133 [==============================] - 0s - loss: 645814.3913 - val_loss: 107105.0636\n",
      "Epoch 163/1000\n",
      "133/133 [==============================] - 0s - loss: 656754.3944 - val_loss: 89655.7645\n",
      "Epoch 164/1000\n",
      "133/133 [==============================] - 0s - loss: 648951.8239 - val_loss: 92959.0212\n",
      "Epoch 165/1000\n",
      "133/133 [==============================] - 0s - loss: 654182.4817 - val_loss: 132061.5246\n",
      "Epoch 166/1000\n",
      "133/133 [==============================] - 0s - loss: 672400.3833 - val_loss: 139037.5871\n",
      "Epoch 167/1000\n",
      "133/133 [==============================] - 0s - loss: 678607.1986 - val_loss: 85963.4219\n",
      "Epoch 168/1000\n",
      "133/133 [==============================] - 0s - loss: 690964.7902 - val_loss: 83253.0692\n",
      "Epoch 169/1000\n",
      "133/133 [==============================] - 0s - loss: 664287.4271 - val_loss: 94304.2188\n",
      "Epoch 170/1000\n",
      "133/133 [==============================] - 0s - loss: 630691.9370 - val_loss: 91192.5871\n",
      "Epoch 171/1000\n",
      "133/133 [==============================] - 0s - loss: 644397.0949 - val_loss: 117722.3616\n",
      "Epoch 172/1000\n",
      "133/133 [==============================] - 0s - loss: 654226.2088 - val_loss: 76435.1741\n",
      "Epoch 173/1000\n",
      "133/133 [==============================] - 0s - loss: 621397.3103 - val_loss: 108545.6362\n",
      "Epoch 174/1000\n",
      "133/133 [==============================] - 0s - loss: 668879.4685 - val_loss: 108480.2723\n",
      "Epoch 175/1000\n",
      "133/133 [==============================] - 0s - loss: 697711.3976 - val_loss: 81234.0703\n",
      "Epoch 176/1000\n",
      "133/133 [==============================] - 0s - loss: 622368.3570 - val_loss: 73691.6752\n",
      "Epoch 177/1000\n",
      "133/133 [==============================] - 0s - loss: 684046.6086 - val_loss: 88478.4710\n",
      "Epoch 178/1000\n",
      "133/133 [==============================] - 0s - loss: 648716.0179 - val_loss: 93206.6830\n",
      "Epoch 179/1000\n",
      "133/133 [==============================] - 0s - loss: 646257.1868 - val_loss: 87675.5379\n",
      "Epoch 180/1000\n",
      "133/133 [==============================] - 0s - loss: 661427.4254 - val_loss: 72796.0112\n",
      "Epoch 181/1000\n",
      "133/133 [==============================] - 0s - loss: 681631.1152 - val_loss: 63453.7400\n",
      "Epoch 182/1000\n",
      "133/133 [==============================] - 0s - loss: 700882.3915 - val_loss: 89307.1585\n",
      "Epoch 183/1000\n",
      "133/133 [==============================] - 0s - loss: 644476.0433 - val_loss: 84931.2388\n",
      "Epoch 184/1000\n",
      "133/133 [==============================] - 0s - loss: 658530.3835 - val_loss: 99694.6897\n",
      "Epoch 185/1000\n",
      "133/133 [==============================] - 0s - loss: 645317.7735 - val_loss: 68230.4810\n",
      "Epoch 186/1000\n",
      "133/133 [==============================] - 0s - loss: 652477.4951 - val_loss: 101951.5826\n",
      "Epoch 187/1000\n",
      "133/133 [==============================] - 0s - loss: 645780.5064 - val_loss: 95853.2835\n",
      "Epoch 188/1000\n",
      "133/133 [==============================] - 0s - loss: 625906.7388 - val_loss: 103300.4330\n",
      "Epoch 189/1000\n",
      "133/133 [==============================] - 0s - loss: 698671.9933 - val_loss: 150583.7344\n",
      "Epoch 190/1000\n",
      "133/133 [==============================] - 0s - loss: 658479.5261 - val_loss: 92592.5279\n",
      "Epoch 191/1000\n",
      "133/133 [==============================] - 0s - loss: 644038.9882 - val_loss: 90397.4319\n",
      "Epoch 192/1000\n",
      "133/133 [==============================] - 0s - loss: 588901.3636 - val_loss: 70823.4062\n",
      "Epoch 193/1000\n",
      "133/133 [==============================] - 0s - loss: 704247.5157 - val_loss: 85312.6507\n",
      "Epoch 194/1000\n",
      "133/133 [==============================] - 0s - loss: 645615.1547 - val_loss: 98869.3426\n",
      "Epoch 195/1000\n",
      "133/133 [==============================] - 0s - loss: 694907.7813 - val_loss: 63182.0190\n",
      "Epoch 196/1000\n",
      "133/133 [==============================] - 0s - loss: 648234.6311 - val_loss: 92192.808018\n",
      "Epoch 197/1000\n",
      "133/133 [==============================] - 0s - loss: 649661.4832 - val_loss: 110982.8438\n",
      "Epoch 198/1000\n",
      "133/133 [==============================] - 0s - loss: 653483.3160 - val_loss: 84916.2924\n",
      "Epoch 199/1000\n",
      "133/133 [==============================] - 0s - loss: 665772.0810 - val_loss: 161595.5759\n",
      "Epoch 200/1000\n",
      "133/133 [==============================] - 0s - loss: 630983.7022 - val_loss: 102805.7132\n",
      "Epoch 201/1000\n",
      "133/133 [==============================] - 0s - loss: 612139.4873 - val_loss: 109221.1987\n",
      "Epoch 202/1000\n",
      "133/133 [==============================] - 0s - loss: 693037.6809 - val_loss: 115599.8504\n",
      "Epoch 203/1000\n",
      "133/133 [==============================] - 0s - loss: 723292.8547 - val_loss: 76288.9319\n",
      "Epoch 204/1000\n",
      "133/133 [==============================] - 0s - loss: 652947.0452 - val_loss: 75769.5770\n",
      "Epoch 205/1000\n",
      "133/133 [==============================] - 0s - loss: 662427.2027 - val_loss: 86410.7031\n",
      "Epoch 206/1000\n",
      "133/133 [==============================] - 0s - loss: 642904.3621 - val_loss: 102029.4888\n",
      "Epoch 207/1000\n",
      "133/133 [==============================] - 0s - loss: 653746.9974 - val_loss: 85565.4475\n",
      "Epoch 208/1000\n",
      "133/133 [==============================] - 0s - loss: 603283.3477 - val_loss: 89441.9241\n",
      "Epoch 209/1000\n",
      "133/133 [==============================] - 0s - loss: 640593.9529 - val_loss: 179232.1964\n",
      "Epoch 210/1000\n",
      "133/133 [==============================] - 0s - loss: 706438.1512 - val_loss: 121481.3996\n",
      "Epoch 211/1000\n",
      "133/133 [==============================] - 0s - loss: 662292.0679 - val_loss: 112428.7701\n",
      "Epoch 212/1000\n",
      "133/133 [==============================] - 0s - loss: 626755.9380 - val_loss: 117798.7232\n",
      "Epoch 213/1000\n",
      "133/133 [==============================] - 0s - loss: 658567.8453 - val_loss: 109836.6897\n",
      "Epoch 214/1000\n",
      "133/133 [==============================] - 0s - loss: 650368.3208 - val_loss: 171149.4062\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 587366.0748 - val_loss: 132401.2723\n",
      "Epoch 216/1000\n",
      "133/133 [==============================] - 0s - loss: 639623.8755 - val_loss: 107293.0915\n",
      "Epoch 217/1000\n",
      "133/133 [==============================] - 0s - loss: 685031.6641 - val_loss: 89982.4665\n",
      "Epoch 218/1000\n",
      "133/133 [==============================] - 0s - loss: 675799.4867 - val_loss: 147015.9464\n",
      "Epoch 219/1000\n",
      "133/133 [==============================] - 0s - loss: 632614.1155 - val_loss: 86419.6094\n",
      "Epoch 220/1000\n",
      "133/133 [==============================] - 0s - loss: 733043.4916 - val_loss: 156506.7143\n",
      "Epoch 221/1000\n",
      "133/133 [==============================] - 0s - loss: 713050.4944 - val_loss: 145590.3415\n",
      "Epoch 222/1000\n",
      "133/133 [==============================] - 0s - loss: 671709.5025 - val_loss: 85292.9330\n",
      "Epoch 223/1000\n",
      "133/133 [==============================] - 0s - loss: 634221.5754 - val_loss: 161564.6808\n",
      "Epoch 224/1000\n",
      "133/133 [==============================] - 0s - loss: 656820.1131 - val_loss: 179428.3683\n",
      "Epoch 225/1000\n",
      "133/133 [==============================] - 0s - loss: 607663.1464 - val_loss: 181912.3348638\n",
      "Epoch 226/1000\n",
      "133/133 [==============================] - 0s - loss: 678012.0367 - val_loss: 184777.79241420.\n",
      "Epoch 227/1000\n",
      "133/133 [==============================] - 0s - loss: 619417.0542 - val_loss: 174921.1652\n",
      "Epoch 228/1000\n",
      "133/133 [==============================] - 0s - loss: 646056.6794 - val_loss: 76996.9096\n",
      "Epoch 229/1000\n",
      "133/133 [==============================] - 0s - loss: 695534.5466 - val_loss: 130662.3103\n",
      "Epoch 230/1000\n",
      "133/133 [==============================] - 0s - loss: 631974.3526 - val_loss: 104065.3583\n",
      "Epoch 231/1000\n",
      "133/133 [==============================] - 0s - loss: 705875.7805 - val_loss: 93043.4565\n",
      "Epoch 232/1000\n",
      "133/133 [==============================] - 0s - loss: 628913.5950 - val_loss: 142578.9821\n",
      "Epoch 233/1000\n",
      "133/133 [==============================] - 0s - loss: 660265.0957 - val_loss: 108389.9621\n",
      "Epoch 234/1000\n",
      "133/133 [==============================] - 0s - loss: 638201.3788 - val_loss: 115239.7210\n",
      "Epoch 235/1000\n",
      "133/133 [==============================] - 0s - loss: 651533.9053 - val_loss: 103613.9866\n",
      "Epoch 236/1000\n",
      "133/133 [==============================] - 0s - loss: 648975.5861 - val_loss: 112281.6830\n",
      "Epoch 237/1000\n",
      "133/133 [==============================] - 0s - loss: 607304.3971 - val_loss: 183281.3415\n",
      "Epoch 238/1000\n",
      "133/133 [==============================] - 0s - loss: 666186.5906 - val_loss: 141301.0692\n",
      "Epoch 239/1000\n",
      "133/133 [==============================] - 0s - loss: 619705.7800 - val_loss: 118670.4777\n",
      "Epoch 240/1000\n",
      "133/133 [==============================] - 0s - loss: 631218.2752 - val_loss: 157264.0826\n",
      "Epoch 241/1000\n",
      "133/133 [==============================] - 0s - loss: 612816.2814 - val_loss: 123361.6071\n",
      "Epoch 242/1000\n",
      "133/133 [==============================] - 0s - loss: 666604.9501 - val_loss: 142114.0067\n",
      "Epoch 243/1000\n",
      "133/133 [==============================] - 0s - loss: 604792.7543 - val_loss: 139617.6585\n",
      "Epoch 244/1000\n",
      "133/133 [==============================] - 0s - loss: 582268.4559 - val_loss: 129118.5223\n",
      "Epoch 245/1000\n",
      "133/133 [==============================] - 0s - loss: 656932.2979 - val_loss: 146084.2656\n",
      "Epoch 246/1000\n",
      "133/133 [==============================] - 0s - loss: 688081.4106 - val_loss: 150026.7969\n",
      "Epoch 247/1000\n",
      "133/133 [==============================] - 0s - loss: 655178.5560 - val_loss: 111923.7835\n",
      "Epoch 248/1000\n",
      "133/133 [==============================] - 0s - loss: 645354.8245 - val_loss: 150261.8929\n",
      "Epoch 249/1000\n",
      "133/133 [==============================] - 0s - loss: 671306.5345 - val_loss: 111747.8527\n",
      "Epoch 250/1000\n",
      "133/133 [==============================] - 0s - loss: 635103.8288 - val_loss: 149798.6027\n",
      "Epoch 251/1000\n",
      "133/133 [==============================] - 0s - loss: 676561.0782 - val_loss: 117790.2388\n",
      "Epoch 252/1000\n",
      "133/133 [==============================] - 0s - loss: 641706.4611 - val_loss: 122860.1964\n",
      "Epoch 253/1000\n",
      "133/133 [==============================] - 0s - loss: 630232.2636 - val_loss: 87681.7087\n",
      "Epoch 254/1000\n",
      "133/133 [==============================] - 0s - loss: 630687.5851 - val_loss: 179864.0469\n",
      "Epoch 255/1000\n",
      "133/133 [==============================] - 0s - loss: 591431.7452 - val_loss: 167773.9598\n",
      "Epoch 256/1000\n",
      "133/133 [==============================] - 0s - loss: 662212.7431 - val_loss: 155499.2098\n",
      "Epoch 257/1000\n",
      "133/133 [==============================] - 0s - loss: 698598.1507 - val_loss: 115975.3393\n",
      "Epoch 258/1000\n",
      "133/133 [==============================] - 0s - loss: 656122.4123 - val_loss: 109894.2902\n",
      "Epoch 259/1000\n",
      "133/133 [==============================] - 0s - loss: 645559.0334 - val_loss: 128322.8996\n",
      "Epoch 260/1000\n",
      "133/133 [==============================] - 0s - loss: 652634.2618 - val_loss: 131361.2321\n",
      "Epoch 261/1000\n",
      "133/133 [==============================] - 0s - loss: 629887.4587 - val_loss: 158602.4509\n",
      "Epoch 262/1000\n",
      "133/133 [==============================] - 0s - loss: 625391.0412 - val_loss: 122474.0201\n",
      "Epoch 263/1000\n",
      "133/133 [==============================] - 0s - loss: 577935.5304 - val_loss: 168621.2009\n",
      "Epoch 264/1000\n",
      "133/133 [==============================] - 0s - loss: 644785.4733 - val_loss: 144295.0402\n",
      "Epoch 265/1000\n",
      "133/133 [==============================] - 0s - loss: 621801.5974 - val_loss: 185769.72109858.05\n",
      "Epoch 266/1000\n",
      "133/133 [==============================] - 0s - loss: 618439.3202 - val_loss: 188124.3304\n",
      "Epoch 267/1000\n",
      "133/133 [==============================] - 0s - loss: 585697.9174 - val_loss: 230024.8929\n",
      "Epoch 268/1000\n",
      "133/133 [==============================] - 0s - loss: 644961.9383 - val_loss: 168237.6696\n",
      "Epoch 269/1000\n",
      "133/133 [==============================] - 0s - loss: 590561.7274 - val_loss: 201600.9777\n",
      "Epoch 270/1000\n",
      "133/133 [==============================] - 0s - loss: 652858.0471 - val_loss: 161689.3929\n",
      "Epoch 271/1000\n",
      "133/133 [==============================] - 0s - loss: 623713.8035 - val_loss: 163797.5022\n",
      "Epoch 272/1000\n",
      "133/133 [==============================] - 0s - loss: 647853.7447 - val_loss: 160530.8661\n",
      "Epoch 273/1000\n",
      "133/133 [==============================] - 0s - loss: 624693.2075 - val_loss: 183681.4777\n",
      "Epoch 274/1000\n",
      "133/133 [==============================] - 0s - loss: 563390.1669 - val_loss: 164754.4152\n",
      "Epoch 275/1000\n",
      "133/133 [==============================] - 0s - loss: 592063.4924 - val_loss: 210166.4464\n",
      "Epoch 276/1000\n",
      "133/133 [==============================] - 0s - loss: 551080.8484 - val_loss: 185495.2946\n",
      "Epoch 277/1000\n",
      "133/133 [==============================] - 0s - loss: 627514.6038 - val_loss: 161417.6451\n",
      "Epoch 278/1000\n",
      "133/133 [==============================] - 0s - loss: 610448.4343 - val_loss: 116550.9219\n",
      "Epoch 279/1000\n",
      "133/133 [==============================] - 0s - loss: 583928.8724 - val_loss: 139638.1875\n",
      "Epoch 280/1000\n",
      "133/133 [==============================] - 0s - loss: 594702.2579 - val_loss: 154133.3527\n",
      "Epoch 281/1000\n",
      "133/133 [==============================] - 0s - loss: 636273.7860 - val_loss: 141586.3147\n",
      "Epoch 282/1000\n",
      "133/133 [==============================] - 0s - loss: 589453.9997 - val_loss: 166258.3170\n",
      "Epoch 283/1000\n",
      "133/133 [==============================] - 0s - loss: 595981.6676 - val_loss: 236334.5714\n",
      "Epoch 284/1000\n",
      "133/133 [==============================] - 0s - loss: 664434.2434 - val_loss: 254042.2679\n",
      "Epoch 285/1000\n",
      "133/133 [==============================] - 0s - loss: 575737.1362 - val_loss: 188136.0714\n",
      "Epoch 286/1000\n",
      "133/133 [==============================] - 0s - loss: 608735.1026 - val_loss: 198235.4821\n",
      "Epoch 287/1000\n",
      "133/133 [==============================] - 0s - loss: 606562.6503 - val_loss: 188624.9866\n",
      "Epoch 288/1000\n",
      "133/133 [==============================] - 0s - loss: 581037.2054 - val_loss: 181988.6607\n",
      "Epoch 289/1000\n",
      "133/133 [==============================] - 0s - loss: 579075.6534 - val_loss: 173694.1518\n",
      "Epoch 290/1000\n",
      "133/133 [==============================] - 0s - loss: 615324.4828 - val_loss: 186687.7723\n",
      "Epoch 291/1000\n",
      "133/133 [==============================] - 0s - loss: 612717.5816 - val_loss: 181970.5625\n",
      "Epoch 292/1000\n",
      "133/133 [==============================] - 0s - loss: 599734.5709 - val_loss: 196201.7589\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 589515.2597 - val_loss: 147532.1339\n",
      "Epoch 294/1000\n",
      "133/133 [==============================] - 0s - loss: 586241.1454 - val_loss: 181182.0000\n",
      "Epoch 295/1000\n",
      "133/133 [==============================] - 0s - loss: 604432.8177 - val_loss: 186963.9196\n",
      "Epoch 296/1000\n",
      "133/133 [==============================] - 0s - loss: 609310.5583 - val_loss: 164844.7188\n",
      "Epoch 297/1000\n",
      "133/133 [==============================] - 0s - loss: 601707.2666 - val_loss: 168536.5312\n",
      "Epoch 298/1000\n",
      "133/133 [==============================] - 0s - loss: 597903.4895 - val_loss: 171543.4420\n",
      "Epoch 299/1000\n",
      "133/133 [==============================] - 0s - loss: 578942.3204 - val_loss: 166936.6451\n",
      "Epoch 300/1000\n",
      "133/133 [==============================] - 0s - loss: 587571.2771 - val_loss: 169445.6808\n",
      "Epoch 301/1000\n",
      "133/133 [==============================] - 0s - loss: 554569.7271 - val_loss: 163363.5625\n",
      "Epoch 302/1000\n",
      "133/133 [==============================] - 0s - loss: 573516.3117 - val_loss: 142109.8393\n",
      "Epoch 303/1000\n",
      "133/133 [==============================] - 0s - loss: 563225.1158 - val_loss: 162560.6406\n",
      "Epoch 304/1000\n",
      "133/133 [==============================] - 0s - loss: 544472.5532 - val_loss: 168321.9353\n",
      "Epoch 305/1000\n",
      "133/133 [==============================] - 0s - loss: 538507.1513 - val_loss: 177428.7902\n",
      "Epoch 306/1000\n",
      "133/133 [==============================] - 0s - loss: 534100.2768 - val_loss: 169549.6071\n",
      "Epoch 307/1000\n",
      "133/133 [==============================] - 0s - loss: 547493.4991 - val_loss: 179598.8527\n",
      "Epoch 308/1000\n",
      "133/133 [==============================] - 0s - loss: 543154.4732 - val_loss: 173634.8147\n",
      "Epoch 309/1000\n",
      "133/133 [==============================] - 0s - loss: 582386.9912 - val_loss: 166055.9062\n",
      "Epoch 310/1000\n",
      "133/133 [==============================] - 0s - loss: 552764.0456 - val_loss: 159784.1830\n",
      "Epoch 311/1000\n",
      "133/133 [==============================] - 0s - loss: 548330.1708 - val_loss: 194139.0848\n",
      "Epoch 312/1000\n",
      "133/133 [==============================] - 0s - loss: 529367.9898 - val_loss: 186936.7589\n",
      "Epoch 313/1000\n",
      "133/133 [==============================] - 0s - loss: 556552.6353 - val_loss: 181422.2634\n",
      "Epoch 314/1000\n",
      "133/133 [==============================] - 0s - loss: 563534.5620 - val_loss: 165919.0045\n",
      "Epoch 315/1000\n",
      "133/133 [==============================] - 0s - loss: 575770.5399 - val_loss: 189092.3393\n",
      "Epoch 316/1000\n",
      "133/133 [==============================] - 0s - loss: 559251.8902 - val_loss: 222869.8125\n",
      "Epoch 317/1000\n",
      "133/133 [==============================] - 0s - loss: 582072.2137 - val_loss: 157592.8817\n",
      "Epoch 318/1000\n",
      "133/133 [==============================] - 0s - loss: 576527.5554 - val_loss: 186886.0134\n",
      "Epoch 319/1000\n",
      "133/133 [==============================] - 0s - loss: 591830.4984 - val_loss: 199242.6205\n",
      "Epoch 320/1000\n",
      "133/133 [==============================] - 0s - loss: 561375.4687 - val_loss: 194731.0759\n",
      "Epoch 321/1000\n",
      "133/133 [==============================] - 0s - loss: 570036.0348 - val_loss: 162496.2969\n",
      "Epoch 322/1000\n",
      "133/133 [==============================] - 0s - loss: 557790.3507 - val_loss: 169220.3661\n",
      "Epoch 323/1000\n",
      "133/133 [==============================] - 0s - loss: 559573.4045 - val_loss: 202426.6741\n",
      "Epoch 324/1000\n",
      "133/133 [==============================] - 0s - loss: 536208.3117 - val_loss: 169783.9509\n",
      "Epoch 325/1000\n",
      "133/133 [==============================] - 0s - loss: 541932.0661 - val_loss: 173772.1205\n",
      "Epoch 326/1000\n",
      "133/133 [==============================] - 0s - loss: 582407.2929 - val_loss: 222320.0446\n",
      "Epoch 327/1000\n",
      "133/133 [==============================] - 0s - loss: 510603.9436 - val_loss: 182434.3884\n",
      "Epoch 328/1000\n",
      "133/133 [==============================] - 0s - loss: 519025.9210 - val_loss: 181685.8973\n",
      "Epoch 329/1000\n",
      "133/133 [==============================] - 0s - loss: 583327.2506 - val_loss: 165556.4978\n",
      "Epoch 330/1000\n",
      "133/133 [==============================] - 0s - loss: 540848.4905 - val_loss: 192189.7366\n",
      "Epoch 331/1000\n",
      "133/133 [==============================] - 0s - loss: 520958.2213 - val_loss: 192501.4107\n",
      "Epoch 332/1000\n",
      "133/133 [==============================] - 0s - loss: 561076.7067 - val_loss: 178772.4062\n",
      "Epoch 333/1000\n",
      "133/133 [==============================] - 0s - loss: 512675.9110 - val_loss: 219280.4420\n",
      "Epoch 334/1000\n",
      "133/133 [==============================] - 0s - loss: 528444.5444 - val_loss: 166426.9821\n",
      "Epoch 335/1000\n",
      "133/133 [==============================] - 0s - loss: 515502.3177 - val_loss: 217131.0826\n",
      "Epoch 336/1000\n",
      "133/133 [==============================] - 0s - loss: 554020.7579 - val_loss: 150906.4732\n",
      "Epoch 337/1000\n",
      "133/133 [==============================] - 0s - loss: 572607.1996 - val_loss: 144619.2879\n",
      "Epoch 338/1000\n",
      "133/133 [==============================] - 0s - loss: 525970.0959 - val_loss: 145448.0201\n",
      "Epoch 339/1000\n",
      "133/133 [==============================] - 0s - loss: 559926.1645 - val_loss: 175338.1205\n",
      "Epoch 340/1000\n",
      "133/133 [==============================] - 0s - loss: 522852.8327 - val_loss: 212312.3482\n",
      "Epoch 341/1000\n",
      "133/133 [==============================] - 0s - loss: 521470.8457 - val_loss: 159648.9129\n",
      "Epoch 342/1000\n",
      "133/133 [==============================] - 0s - loss: 534850.4858 - val_loss: 161492.7812\n",
      "Epoch 343/1000\n",
      "133/133 [==============================] - 0s - loss: 543861.5765 - val_loss: 163476.6272\n",
      "Epoch 344/1000\n",
      "133/133 [==============================] - 0s - loss: 511093.8525 - val_loss: 193687.3705\n",
      "Epoch 345/1000\n",
      "133/133 [==============================] - 0s - loss: 526777.6718 - val_loss: 229194.3973\n",
      "Epoch 346/1000\n",
      "133/133 [==============================] - 0s - loss: 528891.3983 - val_loss: 199990.6964\n",
      "Epoch 347/1000\n",
      "133/133 [==============================] - 0s - loss: 528842.8257 - val_loss: 184587.7121006\n",
      "Epoch 348/1000\n",
      "133/133 [==============================] - 0s - loss: 518019.0716 - val_loss: 197235.7946\n",
      "Epoch 349/1000\n",
      "133/133 [==============================] - 0s - loss: 522351.5647 - val_loss: 216171.3795\n",
      "Epoch 350/1000\n",
      "133/133 [==============================] - 0s - loss: 499248.5599 - val_loss: 211731.5848\n",
      "Epoch 351/1000\n",
      "133/133 [==============================] - 0s - loss: 505622.4875 - val_loss: 181283.7478\n",
      "Epoch 352/1000\n",
      "133/133 [==============================] - 0s - loss: 590039.0344 - val_loss: 178569.4375\n",
      "Epoch 353/1000\n",
      "133/133 [==============================] - 0s - loss: 495728.3827 - val_loss: 216845.8906\n",
      "Epoch 354/1000\n",
      "133/133 [==============================] - 0s - loss: 548505.2777 - val_loss: 198071.4353\n",
      "Epoch 355/1000\n",
      "133/133 [==============================] - 0s - loss: 507510.3597 - val_loss: 202584.3371\n",
      "Epoch 356/1000\n",
      "133/133 [==============================] - 0s - loss: 520895.0731 - val_loss: 174965.7210\n",
      "Epoch 357/1000\n",
      "133/133 [==============================] - 0s - loss: 484918.6065 - val_loss: 116113.2277\n",
      "Epoch 358/1000\n",
      "133/133 [==============================] - 0s - loss: 530359.1446 - val_loss: 162741.8326\n",
      "Epoch 359/1000\n",
      "133/133 [==============================] - 0s - loss: 517783.1318 - val_loss: 168413.2433\n",
      "Epoch 360/1000\n",
      "133/133 [==============================] - 0s - loss: 529259.1110 - val_loss: 199261.3862\n",
      "Epoch 361/1000\n",
      "133/133 [==============================] - 0s - loss: 502402.8649 - val_loss: 202705.4933\n",
      "Epoch 362/1000\n",
      "133/133 [==============================] - 0s - loss: 465979.2605 - val_loss: 153196.1205\n",
      "Epoch 363/1000\n",
      "133/133 [==============================] - 0s - loss: 480551.3073 - val_loss: 210035.8951\n",
      "Epoch 364/1000\n",
      "133/133 [==============================] - 0s - loss: 539654.3280 - val_loss: 290389.0513\n",
      "Epoch 365/1000\n",
      "133/133 [==============================] - 0s - loss: 533364.9559 - val_loss: 124951.6250\n",
      "Epoch 366/1000\n",
      "133/133 [==============================] - 0s - loss: 559957.7572 - val_loss: 197490.2344\n",
      "Epoch 367/1000\n",
      "133/133 [==============================] - 0s - loss: 513974.0959 - val_loss: 174267.3036\n",
      "Epoch 368/1000\n",
      "133/133 [==============================] - 0s - loss: 499532.5231 - val_loss: 176981.1384\n",
      "Epoch 369/1000\n",
      "133/133 [==============================] - 0s - loss: 550193.5361 - val_loss: 181916.6295\n",
      "Epoch 370/1000\n",
      "133/133 [==============================] - 0s - loss: 513646.8629 - val_loss: 144442.5201\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 526354.8283 - val_loss: 163097.9531\n",
      "Epoch 372/1000\n",
      "133/133 [==============================] - 0s - loss: 474503.5156 - val_loss: 178309.2411\n",
      "Epoch 373/1000\n",
      "133/133 [==============================] - 0s - loss: 545392.0942 - val_loss: 170487.6116\n",
      "Epoch 374/1000\n",
      "133/133 [==============================] - 0s - loss: 503810.3266 - val_loss: 191781.9598\n",
      "Epoch 375/1000\n",
      "133/133 [==============================] - 0s - loss: 496868.4167 - val_loss: 147569.6004\n",
      "Epoch 376/1000\n",
      "133/133 [==============================] - 0s - loss: 535119.2165 - val_loss: 186737.5402\n",
      "Epoch 377/1000\n",
      "133/133 [==============================] - 0s - loss: 570767.6191 - val_loss: 149412.1808\n",
      "Epoch 378/1000\n",
      "133/133 [==============================] - 0s - loss: 577162.6199 - val_loss: 148993.8839\n",
      "Epoch 379/1000\n",
      "133/133 [==============================] - 0s - loss: 514524.1920 - val_loss: 180368.5112\n",
      "Epoch 380/1000\n",
      "133/133 [==============================] - 0s - loss: 506351.6207 - val_loss: 214620.2366\n",
      "Epoch 381/1000\n",
      "133/133 [==============================] - 0s - loss: 512800.6544 - val_loss: 254842.0558\n",
      "Epoch 382/1000\n",
      "133/133 [==============================] - 0s - loss: 507048.2257 - val_loss: 183176.6964\n",
      "Epoch 383/1000\n",
      "133/133 [==============================] - 0s - loss: 478125.6308 - val_loss: 189707.5000\n",
      "Epoch 384/1000\n",
      "133/133 [==============================] - 0s - loss: 495365.5801 - val_loss: 194611.3192\n",
      "Epoch 385/1000\n",
      "133/133 [==============================] - 0s - loss: 508115.6292 - val_loss: 182331.0335\n",
      "Epoch 386/1000\n",
      "133/133 [==============================] - 0s - loss: 514687.5394 - val_loss: 193647.3638\n",
      "Epoch 387/1000\n",
      "133/133 [==============================] - 0s - loss: 512381.2348 - val_loss: 149376.1607\n",
      "Epoch 388/1000\n",
      "133/133 [==============================] - 0s - loss: 489314.6748 - val_loss: 173148.9018\n",
      "Epoch 389/1000\n",
      "133/133 [==============================] - 0s - loss: 500014.1107 - val_loss: 155206.6830\n",
      "Epoch 390/1000\n",
      "133/133 [==============================] - 0s - loss: 535516.3642 - val_loss: 170904.2522\n",
      "Epoch 391/1000\n",
      "133/133 [==============================] - 0s - loss: 531925.0506 - val_loss: 148921.8460\n",
      "Epoch 392/1000\n",
      "133/133 [==============================] - 0s - loss: 493676.3307 - val_loss: 256584.2835\n",
      "Epoch 393/1000\n",
      "133/133 [==============================] - 0s - loss: 550303.6546 - val_loss: 149737.2567\n",
      "Epoch 394/1000\n",
      "133/133 [==============================] - 0s - loss: 559355.4683 - val_loss: 217654.6228\n",
      "Epoch 395/1000\n",
      "133/133 [==============================] - 0s - loss: 502395.9174 - val_loss: 197378.9107\n",
      "Epoch 396/1000\n",
      "133/133 [==============================] - 0s - loss: 556558.0343 - val_loss: 201848.4487\n",
      "Epoch 397/1000\n",
      "133/133 [==============================] - 0s - loss: 495501.6234 - val_loss: 199101.5201\n",
      "Epoch 398/1000\n",
      "133/133 [==============================] - 0s - loss: 514908.9555 - val_loss: 179173.3147\n",
      "Epoch 399/1000\n",
      "133/133 [==============================] - 0s - loss: 506662.4754 - val_loss: 190223.4844\n",
      "Epoch 400/1000\n",
      "133/133 [==============================] - 0s - loss: 517391.6749 - val_loss: 282179.9085\n",
      "Epoch 401/1000\n",
      "133/133 [==============================] - 0s - loss: 470306.6331 - val_loss: 180398.0692\n",
      "Epoch 402/1000\n",
      "133/133 [==============================] - 0s - loss: 498535.7203 - val_loss: 208893.2411\n",
      "Epoch 403/1000\n",
      "133/133 [==============================] - 0s - loss: 481461.6128 - val_loss: 197436.0692\n",
      "Epoch 404/1000\n",
      "133/133 [==============================] - 0s - loss: 568389.8633 - val_loss: 248747.0893\n",
      "Epoch 405/1000\n",
      "133/133 [==============================] - 0s - loss: 484807.2368 - val_loss: 222277.1004\n",
      "Epoch 406/1000\n",
      "133/133 [==============================] - 0s - loss: 462706.6932 - val_loss: 170726.9487\n",
      "Epoch 407/1000\n",
      "133/133 [==============================] - 0s - loss: 453002.8755 - val_loss: 208349.1451\n",
      "Epoch 408/1000\n",
      "133/133 [==============================] - 0s - loss: 558553.8647 - val_loss: 282358.7455\n",
      "Epoch 409/1000\n",
      "133/133 [==============================] - 0s - loss: 558964.6398 - val_loss: 174816.2165\n",
      "Epoch 410/1000\n",
      "133/133 [==============================] - 0s - loss: 485248.8487 - val_loss: 172949.6897\n",
      "Epoch 411/1000\n",
      "133/133 [==============================] - 0s - loss: 483816.3752 - val_loss: 203147.0179\n",
      "Epoch 412/1000\n",
      "133/133 [==============================] - 0s - loss: 511750.3740 - val_loss: 235430.5335\n",
      "Epoch 413/1000\n",
      "133/133 [==============================] - 0s - loss: 494320.8636 - val_loss: 215789.7321\n",
      "Epoch 414/1000\n",
      "133/133 [==============================] - 0s - loss: 514067.0976 - val_loss: 335664.62723\n",
      "Epoch 415/1000\n",
      "133/133 [==============================] - 0s - loss: 503424.0055 - val_loss: 292454.4710\n",
      "Epoch 416/1000\n",
      "133/133 [==============================] - 0s - loss: 522496.1841 - val_loss: 267584.07817\n",
      "Epoch 417/1000\n",
      "133/133 [==============================] - 0s - loss: 503864.9578 - val_loss: 190534.5804\n",
      "Epoch 418/1000\n",
      "133/133 [==============================] - 0s - loss: 519998.0919 - val_loss: 247722.0871\n",
      "Epoch 419/1000\n",
      "133/133 [==============================] - 0s - loss: 524781.1309 - val_loss: 227226.8013\n",
      "Epoch 420/1000\n",
      "133/133 [==============================] - 0s - loss: 475116.1167 - val_loss: 158178.8638\n",
      "Epoch 421/1000\n",
      "133/133 [==============================] - 0s - loss: 494513.9857 - val_loss: 239069.5737\n",
      "Epoch 422/1000\n",
      "133/133 [==============================] - 0s - loss: 477951.3443 - val_loss: 284503.1406\n",
      "Epoch 423/1000\n",
      "133/133 [==============================] - 0s - loss: 456975.6626 - val_loss: 182830.1429\n",
      "Epoch 424/1000\n",
      "133/133 [==============================] - 0s - loss: 505462.1846 - val_loss: 196750.4196\n",
      "Epoch 425/1000\n",
      "133/133 [==============================] - 0s - loss: 546908.3305 - val_loss: 293868.3237\n",
      "Epoch 426/1000\n",
      "133/133 [==============================] - 0s - loss: 465163.4452 - val_loss: 163048.9330\n",
      "Epoch 427/1000\n",
      "133/133 [==============================] - 0s - loss: 545567.7785 - val_loss: 238289.9152\n",
      "Epoch 428/1000\n",
      "133/133 [==============================] - 0s - loss: 462449.0197 - val_loss: 229418.6562\n",
      "Epoch 429/1000\n",
      "133/133 [==============================] - 0s - loss: 473170.7320 - val_loss: 194073.9107\n",
      "Epoch 430/1000\n",
      "133/133 [==============================] - 0s - loss: 478235.6101 - val_loss: 251122.8817\n",
      "Epoch 431/1000\n",
      "133/133 [==============================] - 0s - loss: 454735.5582 - val_loss: 202306.2790\n",
      "Epoch 432/1000\n",
      "133/133 [==============================] - 0s - loss: 515212.0509 - val_loss: 207483.1674\n",
      "Epoch 433/1000\n",
      "133/133 [==============================] - 0s - loss: 545514.4702 - val_loss: 185858.5469\n",
      "Epoch 434/1000\n",
      "133/133 [==============================] - 0s - loss: 476308.0279 - val_loss: 215388.8549\n",
      "Epoch 435/1000\n",
      "133/133 [==============================] - 0s - loss: 487449.7567 - val_loss: 221876.4933\n",
      "Epoch 436/1000\n",
      "133/133 [==============================] - 0s - loss: 498847.6434 - val_loss: 167712.8371\n",
      "Epoch 437/1000\n",
      "133/133 [==============================] - 0s - loss: 473700.1478 - val_loss: 312167.4799\n",
      "Epoch 438/1000\n",
      "133/133 [==============================] - 0s - loss: 575913.1651 - val_loss: 259590.9196\n",
      "Epoch 439/1000\n",
      "133/133 [==============================] - 0s - loss: 494708.8130 - val_loss: 194248.3951\n",
      "Epoch 440/1000\n",
      "133/133 [==============================] - 0s - loss: 467127.7456 - val_loss: 192597.6138\n",
      "Epoch 441/1000\n",
      "133/133 [==============================] - 0s - loss: 450816.6437 - val_loss: 265756.8661\n",
      "Epoch 442/1000\n",
      "133/133 [==============================] - 0s - loss: 464078.9333 - val_loss: 257036.8237\n",
      "Epoch 443/1000\n",
      "133/133 [==============================] - 0s - loss: 448262.7250 - val_loss: 280335.3750\n",
      "Epoch 444/1000\n",
      "133/133 [==============================] - 0s - loss: 503914.0772 - val_loss: 249287.8839\n",
      "Epoch 445/1000\n",
      "133/133 [==============================] - 0s - loss: 467356.4213 - val_loss: 223164.1585\n",
      "Epoch 446/1000\n",
      "133/133 [==============================] - 0s - loss: 481131.1617 - val_loss: 239021.8571\n",
      "Epoch 447/1000\n",
      "133/133 [==============================] - 0s - loss: 472439.3152 - val_loss: 211160.15853\n",
      "Epoch 448/1000\n",
      "133/133 [==============================] - 0s - loss: 459414.6049 - val_loss: 243202.9576\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 431031.0741 - val_loss: 223298.1429\n",
      "Epoch 450/1000\n",
      "133/133 [==============================] - 0s - loss: 539722.3773 - val_loss: 271573.0424\n",
      "Epoch 451/1000\n",
      "133/133 [==============================] - 0s - loss: 491222.1530 - val_loss: 270794.5737\n",
      "Epoch 452/1000\n",
      "133/133 [==============================] - 0s - loss: 513654.4821 - val_loss: 228334.6272\n",
      "Epoch 453/1000\n",
      "133/133 [==============================] - 0s - loss: 503378.9203 - val_loss: 267795.0513\n",
      "Epoch 454/1000\n",
      "133/133 [==============================] - 0s - loss: 491217.1471 - val_loss: 249133.0804\n",
      "Epoch 455/1000\n",
      "133/133 [==============================] - 0s - loss: 446368.1926 - val_loss: 239944.4487906\n",
      "Epoch 456/1000\n",
      "133/133 [==============================] - 0s - loss: 490130.2960 - val_loss: 309414.7232\n",
      "Epoch 457/1000\n",
      "133/133 [==============================] - 0s - loss: 507239.9207 - val_loss: 272881.8862\n",
      "Epoch 458/1000\n",
      "133/133 [==============================] - 0s - loss: 500437.0326 - val_loss: 175308.8906\n",
      "Epoch 459/1000\n",
      "133/133 [==============================] - 0s - loss: 518645.2627 - val_loss: 255034.8371\n",
      "Epoch 460/1000\n",
      "133/133 [==============================] - 0s - loss: 460949.9677 - val_loss: 242385.8281\n",
      "Epoch 461/1000\n",
      "133/133 [==============================] - 0s - loss: 501686.7545 - val_loss: 242446.5000\n",
      "Epoch 462/1000\n",
      "133/133 [==============================] - 0s - loss: 428220.3075 - val_loss: 229956.6674\n",
      "Epoch 463/1000\n",
      "133/133 [==============================] - 0s - loss: 504515.4957 - val_loss: 238884.7835\n",
      "Epoch 464/1000\n",
      "133/133 [==============================] - 0s - loss: 410834.7135 - val_loss: 387054.4531\n",
      "Epoch 465/1000\n",
      "133/133 [==============================] - 0s - loss: 502774.1227 - val_loss: 207526.8571\n",
      "Epoch 466/1000\n",
      "133/133 [==============================] - 0s - loss: 511409.7274 - val_loss: 253027.8750\n",
      "Epoch 467/1000\n",
      "133/133 [==============================] - 0s - loss: 486639.4491 - val_loss: 277744.5290\n",
      "Epoch 468/1000\n",
      "133/133 [==============================] - 0s - loss: 433931.9681 - val_loss: 209094.0893\n",
      "Epoch 469/1000\n",
      "133/133 [==============================] - 0s - loss: 530330.1170 - val_loss: 246159.6830\n",
      "Epoch 470/1000\n",
      "133/133 [==============================] - 0s - loss: 455737.1373 - val_loss: 226132.2478\n",
      "Epoch 471/1000\n",
      "133/133 [==============================] - 0s - loss: 485662.6583 - val_loss: 234689.9085\n",
      "Epoch 472/1000\n",
      "133/133 [==============================] - 0s - loss: 460624.9951 - val_loss: 203415.7790\n",
      "Epoch 473/1000\n",
      "133/133 [==============================] - 0s - loss: 493847.5189 - val_loss: 267741.7790\n",
      "Epoch 474/1000\n",
      "133/133 [==============================] - 0s - loss: 480357.0209 - val_loss: 200491.9286\n",
      "Epoch 475/1000\n",
      "133/133 [==============================] - 0s - loss: 484192.3771 - val_loss: 167702.2210\n",
      "Epoch 476/1000\n",
      "133/133 [==============================] - 0s - loss: 473292.5736 - val_loss: 200458.2143\n",
      "Epoch 477/1000\n",
      "133/133 [==============================] - 0s - loss: 447789.5438 - val_loss: 237120.3482\n",
      "Epoch 478/1000\n",
      "133/133 [==============================] - 0s - loss: 493836.8592 - val_loss: 282011.8147\n",
      "Epoch 479/1000\n",
      "133/133 [==============================] - 0s - loss: 514159.5875 - val_loss: 241164.4665\n",
      "Epoch 480/1000\n",
      "133/133 [==============================] - 0s - loss: 488541.9593 - val_loss: 225619.7254\n",
      "Epoch 481/1000\n",
      "133/133 [==============================] - 0s - loss: 478031.4104 - val_loss: 192157.9754\n",
      "Epoch 482/1000\n",
      "133/133 [==============================] - 0s - loss: 415673.6762 - val_loss: 181686.1161\n",
      "Epoch 483/1000\n",
      "133/133 [==============================] - 0s - loss: 464957.0811 - val_loss: 246507.8750\n",
      "Epoch 484/1000\n",
      "133/133 [==============================] - 0s - loss: 427234.2037 - val_loss: 232882.6987\n",
      "Epoch 485/1000\n",
      "133/133 [==============================] - 0s - loss: 448194.6277 - val_loss: 277303.4799\n",
      "Epoch 486/1000\n",
      "133/133 [==============================] - 0s - loss: 475406.3616 - val_loss: 228020.6161\n",
      "Epoch 487/1000\n",
      "133/133 [==============================] - 0s - loss: 472748.4795 - val_loss: 221732.7790\n",
      "Epoch 488/1000\n",
      "133/133 [==============================] - 0s - loss: 419329.1466 - val_loss: 244391.9710\n",
      "Epoch 489/1000\n",
      "133/133 [==============================] - 0s - loss: 454533.0503 - val_loss: 269608.0804\n",
      "Epoch 490/1000\n",
      "133/133 [==============================] - 0s - loss: 481302.4832 - val_loss: 277454.9821\n",
      "Epoch 491/1000\n",
      "133/133 [==============================] - 0s - loss: 466313.9309 - val_loss: 296639.2879\n",
      "Epoch 492/1000\n",
      "133/133 [==============================] - 0s - loss: 462013.9776 - val_loss: 303310.6875\n",
      "Epoch 493/1000\n",
      "133/133 [==============================] - 0s - loss: 503798.5053 - val_loss: 228645.2946\n",
      "Epoch 494/1000\n",
      "133/133 [==============================] - 0s - loss: 464997.1366 - val_loss: 276151.3661\n",
      "Epoch 495/1000\n",
      "133/133 [==============================] - 0s - loss: 439750.9430 - val_loss: 245428.4844\n",
      "Epoch 496/1000\n",
      "133/133 [==============================] - 0s - loss: 476844.9293 - val_loss: 257685.3638\n",
      "Epoch 497/1000\n",
      "133/133 [==============================] - 0s - loss: 464754.2443 - val_loss: 222772.3772\n",
      "Epoch 498/1000\n",
      "133/133 [==============================] - 0s - loss: 409449.1426 - val_loss: 239040.7701\n",
      "Epoch 499/1000\n",
      "133/133 [==============================] - 0s - loss: 462731.1232 - val_loss: 335049.19425794.\n",
      "Epoch 500/1000\n",
      "133/133 [==============================] - 0s - loss: 434010.3619 - val_loss: 263762.7165\n",
      "Epoch 501/1000\n",
      "133/133 [==============================] - 0s - loss: 443089.1109 - val_loss: 275336.6071\n",
      "Epoch 502/1000\n",
      "133/133 [==============================] - 0s - loss: 471200.0296 - val_loss: 219090.7589\n",
      "Epoch 503/1000\n",
      "133/133 [==============================] - 0s - loss: 446424.4788 - val_loss: 216606.8750\n",
      "Epoch 504/1000\n",
      "133/133 [==============================] - 0s - loss: 472419.7020 - val_loss: 264176.5335\n",
      "Epoch 505/1000\n",
      "133/133 [==============================] - 0s - loss: 465103.5777 - val_loss: 227205.0804014 - ETA: 0s - loss: 428\n",
      "Epoch 506/1000\n",
      "133/133 [==============================] - 0s - loss: 510567.8946 - val_loss: 183347.7031\n",
      "Epoch 507/1000\n",
      "133/133 [==============================] - 0s - loss: 520810.0341 - val_loss: 212712.7076\n",
      "Epoch 508/1000\n",
      "133/133 [==============================] - 0s - loss: 445582.7059 - val_loss: 234579.8661\n",
      "Epoch 509/1000\n",
      "133/133 [==============================] - 0s - loss: 437459.2072 - val_loss: 218927.19649912.\n",
      "Epoch 510/1000\n",
      "133/133 [==============================] - 0s - loss: 453878.9304 - val_loss: 341502.6540\n",
      "Epoch 511/1000\n",
      "133/133 [==============================] - 0s - loss: 451432.6165 - val_loss: 255726.6674\n",
      "Epoch 512/1000\n",
      "133/133 [==============================] - 0s - loss: 449285.0371 - val_loss: 219071.8192\n",
      "Epoch 513/1000\n",
      "133/133 [==============================] - 0s - loss: 462869.9286 - val_loss: 234471.9554\n",
      "Epoch 514/1000\n",
      "133/133 [==============================] - 0s - loss: 484375.9247 - val_loss: 236141.6228\n",
      "Epoch 515/1000\n",
      "133/133 [==============================] - 0s - loss: 483040.6826 - val_loss: 236886.2924\n",
      "Epoch 516/1000\n",
      "133/133 [==============================] - 0s - loss: 472206.4698 - val_loss: 240480.2969\n",
      "Epoch 517/1000\n",
      "133/133 [==============================] - 0s - loss: 462227.3073 - val_loss: 132984.3125\n",
      "Epoch 518/1000\n",
      "133/133 [==============================] - 0s - loss: 475293.1278 - val_loss: 143256.9777\n",
      "Epoch 519/1000\n",
      "133/133 [==============================] - 0s - loss: 461734.3239 - val_loss: 203819.8571\n",
      "Epoch 520/1000\n",
      "133/133 [==============================] - 0s - loss: 416551.7123 - val_loss: 184945.3281\n",
      "Epoch 521/1000\n",
      "133/133 [==============================] - 0s - loss: 467749.7642 - val_loss: 275097.4911\n",
      "Epoch 522/1000\n",
      "133/133 [==============================] - 0s - loss: 486123.2625 - val_loss: 209531.6317\n",
      "Epoch 523/1000\n",
      "133/133 [==============================] - 0s - loss: 476576.0532 - val_loss: 313871.9129\n",
      "Epoch 524/1000\n",
      "133/133 [==============================] - 0s - loss: 444330.5419 - val_loss: 228913.7656\n",
      "Epoch 525/1000\n",
      "133/133 [==============================] - 0s - loss: 486223.2639 - val_loss: 184869.2946\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 454297.6617 - val_loss: 184290.3906\n",
      "Epoch 527/1000\n",
      "133/133 [==============================] - 0s - loss: 472383.4774 - val_loss: 200701.1473\n",
      "Epoch 528/1000\n",
      "133/133 [==============================] - 0s - loss: 510223.6609 - val_loss: 262544.2589\n",
      "Epoch 529/1000\n",
      "133/133 [==============================] - 0s - loss: 476005.5235 - val_loss: 269062.4107\n",
      "Epoch 530/1000\n",
      "133/133 [==============================] - 0s - loss: 454692.6185 - val_loss: 227234.8817\n",
      "Epoch 531/1000\n",
      "133/133 [==============================] - 0s - loss: 515599.3706 - val_loss: 285981.7210\n",
      "Epoch 532/1000\n",
      "133/133 [==============================] - 0s - loss: 475481.0515 - val_loss: 232424.1317\n",
      "Epoch 533/1000\n",
      "133/133 [==============================] - 0s - loss: 428992.6902 - val_loss: 239087.5781\n",
      "Epoch 534/1000\n",
      "133/133 [==============================] - 0s - loss: 498642.8650 - val_loss: 243057.8728\n",
      "Epoch 535/1000\n",
      "133/133 [==============================] - 0s - loss: 517486.4753 - val_loss: 220658.87503318.81\n",
      "Epoch 536/1000\n",
      "133/133 [==============================] - 0s - loss: 417092.9849 - val_loss: 239310.7991\n",
      "Epoch 537/1000\n",
      "133/133 [==============================] - 0s - loss: 424153.1304 - val_loss: 352820.2411\n",
      "Epoch 538/1000\n",
      "133/133 [==============================] - 0s - loss: 449197.2165 - val_loss: 338861.0268\n",
      "Epoch 539/1000\n",
      "133/133 [==============================] - 0s - loss: 429727.5851 - val_loss: 213350.0714\n",
      "Epoch 540/1000\n",
      "133/133 [==============================] - 0s - loss: 521445.6512 - val_loss: 192501.0156\n",
      "Epoch 541/1000\n",
      "133/133 [==============================] - 0s - loss: 427521.2321 - val_loss: 273515.8393\n",
      "Epoch 542/1000\n",
      "133/133 [==============================] - 0s - loss: 453371.0329 - val_loss: 203422.2143\n",
      "Epoch 543/1000\n",
      "133/133 [==============================] - 0s - loss: 463691.1735 - val_loss: 270979.5781\n",
      "Epoch 544/1000\n",
      "133/133 [==============================] - 0s - loss: 455421.3322 - val_loss: 312974.4576\n",
      "Epoch 545/1000\n",
      "133/133 [==============================] - 0s - loss: 509592.1295 - val_loss: 338626.4643\n",
      "Epoch 546/1000\n",
      "133/133 [==============================] - 0s - loss: 471512.9618 - val_loss: 343239.8237\n",
      "Epoch 547/1000\n",
      "133/133 [==============================] - 0s - loss: 467866.6695 - val_loss: 376500.3504\n",
      "Epoch 548/1000\n",
      "133/133 [==============================] - 0s - loss: 482538.0233 - val_loss: 207856.2924\n",
      "Epoch 549/1000\n",
      "133/133 [==============================] - 0s - loss: 479908.9277 - val_loss: 350298.4040\n",
      "Epoch 550/1000\n",
      "133/133 [==============================] - 0s - loss: 511101.2219 - val_loss: 231610.9464\n",
      "Epoch 551/1000\n",
      "133/133 [==============================] - 0s - loss: 466002.9020 - val_loss: 339021.8661\n",
      "Epoch 552/1000\n",
      "133/133 [==============================] - 0s - loss: 478575.4468 - val_loss: 359151.7143\n",
      "Epoch 553/1000\n",
      "133/133 [==============================] - 0s - loss: 497566.4186 - val_loss: 207428.7924\n",
      "Epoch 554/1000\n",
      "133/133 [==============================] - 0s - loss: 562488.9530 - val_loss: 318819.8750\n",
      "Epoch 555/1000\n",
      "133/133 [==============================] - 0s - loss: 440301.6366 - val_loss: 296266.6138\n",
      "Epoch 556/1000\n",
      "133/133 [==============================] - 0s - loss: 512307.8593 - val_loss: 295662.8036\n",
      "Epoch 557/1000\n",
      "133/133 [==============================] - 0s - loss: 511231.4930 - val_loss: 311718.5223\n",
      "Epoch 558/1000\n",
      "133/133 [==============================] - 0s - loss: 439902.8224 - val_loss: 349144.4018\n",
      "Epoch 559/1000\n",
      "133/133 [==============================] - 0s - loss: 490493.8063 - val_loss: 311845.1585\n",
      "Epoch 560/1000\n",
      "133/133 [==============================] - 0s - loss: 501090.0665 - val_loss: 251813.2165\n",
      "Epoch 561/1000\n",
      "133/133 [==============================] - 0s - loss: 564366.4482 - val_loss: 319797.96214850.\n",
      "Epoch 562/1000\n",
      "133/133 [==============================] - 0s - loss: 391173.7229 - val_loss: 238820.3482\n",
      "Epoch 563/1000\n",
      "133/133 [==============================] - 0s - loss: 509426.4946 - val_loss: 316755.5469\n",
      "Epoch 564/1000\n",
      "133/133 [==============================] - 0s - loss: 526014.0431 - val_loss: 246408.6004\n",
      "Epoch 565/1000\n",
      "133/133 [==============================] - 0s - loss: 458237.5754 - val_loss: 212775.2321\n",
      "Epoch 566/1000\n",
      "133/133 [==============================] - 0s - loss: 468515.4047 - val_loss: 218644.9732\n",
      "Epoch 567/1000\n",
      "133/133 [==============================] - 0s - loss: 422035.3393 - val_loss: 206621.3817\n",
      "Epoch 568/1000\n",
      "133/133 [==============================] - 0s - loss: 486169.7059 - val_loss: 234410.8058\n",
      "Epoch 569/1000\n",
      "133/133 [==============================] - 0s - loss: 487198.0048 - val_loss: 352968.1629\n",
      "Epoch 570/1000\n",
      "133/133 [==============================] - 0s - loss: 460488.2171 - val_loss: 291897.8237\n",
      "Epoch 571/1000\n",
      "133/133 [==============================] - 0s - loss: 443619.3147 - val_loss: 320381.4732\n",
      "Epoch 572/1000\n",
      "133/133 [==============================] - 0s - loss: 445080.7196 - val_loss: 351552.2143\n",
      "Epoch 573/1000\n",
      "133/133 [==============================] - 0s - loss: 477840.0888 - val_loss: 215525.0335\n",
      "Epoch 574/1000\n",
      "133/133 [==============================] - 0s - loss: 420316.2671 - val_loss: 272169.2812\n",
      "Epoch 575/1000\n",
      "133/133 [==============================] - 0s - loss: 481779.6197 - val_loss: 313937.8080\n",
      "Epoch 576/1000\n",
      "133/133 [==============================] - 0s - loss: 428337.4825 - val_loss: 310337.4286\n",
      "Epoch 577/1000\n",
      "133/133 [==============================] - 0s - loss: 421439.1599 - val_loss: 237838.7411\n",
      "Epoch 578/1000\n",
      "133/133 [==============================] - 0s - loss: 484798.5872 - val_loss: 342308.1964\n",
      "Epoch 579/1000\n",
      "133/133 [==============================] - 0s - loss: 460115.6963 - val_loss: 325761.1317\n",
      "Epoch 580/1000\n",
      "133/133 [==============================] - 0s - loss: 534693.4464 - val_loss: 228492.4174\n",
      "Epoch 581/1000\n",
      "133/133 [==============================] - 0s - loss: 428568.3518 - val_loss: 234896.1138\n",
      "Epoch 582/1000\n",
      "133/133 [==============================] - 0s - loss: 445043.7918 - val_loss: 211746.2790\n",
      "Epoch 583/1000\n",
      "133/133 [==============================] - 0s - loss: 450803.6571 - val_loss: 195162.6205\n",
      "Epoch 584/1000\n",
      "133/133 [==============================] - 0s - loss: 552272.1128 - val_loss: 266833.7143\n",
      "Epoch 585/1000\n",
      "133/133 [==============================] - 0s - loss: 412440.6629 - val_loss: 212060.5737\n",
      "Epoch 586/1000\n",
      "133/133 [==============================] - 0s - loss: 521117.7201 - val_loss: 294919.9330\n",
      "Epoch 587/1000\n",
      "133/133 [==============================] - 0s - loss: 517987.4061 - val_loss: 269606.3929\n",
      "Epoch 588/1000\n",
      "133/133 [==============================] - 0s - loss: 462925.7340 - val_loss: 216563.1987\n",
      "Epoch 589/1000\n",
      "133/133 [==============================] - 0s - loss: 453769.3747 - val_loss: 210801.1339\n",
      "Epoch 590/1000\n",
      "133/133 [==============================] - 0s - loss: 427357.9538 - val_loss: 221849.0112\n",
      "Epoch 591/1000\n",
      "133/133 [==============================] - 0s - loss: 447179.8187 - val_loss: 192336.7656\n",
      "Epoch 592/1000\n",
      "133/133 [==============================] - 0s - loss: 429146.4209 - val_loss: 264918.3036\n",
      "Epoch 593/1000\n",
      "133/133 [==============================] - 0s - loss: 462680.2445 - val_loss: 239233.6228\n",
      "Epoch 594/1000\n",
      "133/133 [==============================] - 0s - loss: 468759.2908 - val_loss: 302116.0781\n",
      "Epoch 595/1000\n",
      "133/133 [==============================] - 0s - loss: 527755.5352 - val_loss: 226619.7701\n",
      "Epoch 596/1000\n",
      "133/133 [==============================] - 0s - loss: 537958.6324 - val_loss: 349977.5893\n",
      "Epoch 597/1000\n",
      "133/133 [==============================] - 0s - loss: 445720.9784 - val_loss: 199519.7612\n",
      "Epoch 598/1000\n",
      "133/133 [==============================] - 0s - loss: 528400.5578 - val_loss: 288136.3393\n",
      "Epoch 599/1000\n",
      "133/133 [==============================] - 0s - loss: 494133.9920 - val_loss: 195502.0312\n",
      "Epoch 600/1000\n",
      "133/133 [==============================] - 0s - loss: 490603.3373 - val_loss: 205793.4442\n",
      "Epoch 601/1000\n",
      "133/133 [==============================] - 0s - loss: 483482.9408 - val_loss: 250507.1585\n",
      "Epoch 602/1000\n",
      "133/133 [==============================] - 0s - loss: 416555.8904 - val_loss: 279168.3237\n",
      "Epoch 603/1000\n",
      "133/133 [==============================] - 0s - loss: 389271.2320 - val_loss: 262130.9442\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 472314.2060 - val_loss: 233566.8594\n",
      "Epoch 605/1000\n",
      "133/133 [==============================] - 0s - loss: 443544.8795 - val_loss: 247487.7500\n",
      "Epoch 606/1000\n",
      "133/133 [==============================] - 0s - loss: 416648.5218 - val_loss: 256156.6228\n",
      "Epoch 607/1000\n",
      "133/133 [==============================] - 0s - loss: 481167.7494 - val_loss: 182253.0558\n",
      "Epoch 608/1000\n",
      "133/133 [==============================] - 0s - loss: 517504.4309 - val_loss: 217917.8304\n",
      "Epoch 609/1000\n",
      "133/133 [==============================] - 0s - loss: 465887.3442 - val_loss: 206188.9643\n",
      "Epoch 610/1000\n",
      "133/133 [==============================] - 0s - loss: 434493.7750 - val_loss: 204032.2790\n",
      "Epoch 611/1000\n",
      "133/133 [==============================] - 0s - loss: 418341.8429 - val_loss: 195146.7790\n",
      "Epoch 612/1000\n",
      "133/133 [==============================] - 0s - loss: 372227.6508 - val_loss: 172979.7879\n",
      "Epoch 613/1000\n",
      "133/133 [==============================] - 0s - loss: 432823.9777 - val_loss: 206113.7746\n",
      "Epoch 614/1000\n",
      "133/133 [==============================] - 0s - loss: 467414.4222 - val_loss: 191773.0982\n",
      "Epoch 615/1000\n",
      "133/133 [==============================] - 0s - loss: 455231.5018 - val_loss: 185714.1451\n",
      "Epoch 616/1000\n",
      "133/133 [==============================] - 0s - loss: 464549.8283 - val_loss: 192982.9710\n",
      "Epoch 617/1000\n",
      "133/133 [==============================] - 0s - loss: 503679.4301 - val_loss: 210107.7433\n",
      "Epoch 618/1000\n",
      "133/133 [==============================] - 0s - loss: 478546.6859 - val_loss: 183905.6763\n",
      "Epoch 619/1000\n",
      "133/133 [==============================] - 0s - loss: 458197.6538 - val_loss: 191957.3839\n",
      "Epoch 620/1000\n",
      "133/133 [==============================] - 0s - loss: 454274.5089 - val_loss: 229129.9643\n",
      "Epoch 621/1000\n",
      "133/133 [==============================] - 0s - loss: 405266.7747 - val_loss: 229177.4263\n",
      "Epoch 622/1000\n",
      "133/133 [==============================] - 0s - loss: 436797.0785 - val_loss: 235141.1384\n",
      "Epoch 623/1000\n",
      "133/133 [==============================] - 0s - loss: 458419.5358 - val_loss: 245263.6094\n",
      "Epoch 624/1000\n",
      "133/133 [==============================] - 0s - loss: 440452.9256 - val_loss: 319956.2210\n",
      "Epoch 625/1000\n",
      "133/133 [==============================] - 0s - loss: 445331.0789 - val_loss: 241963.5335\n",
      "Epoch 626/1000\n",
      "133/133 [==============================] - 0s - loss: 394828.1193 - val_loss: 225111.7567\n",
      "Epoch 627/1000\n",
      "133/133 [==============================] - 0s - loss: 421528.9053 - val_loss: 289929.73883486.57\n",
      "Epoch 628/1000\n",
      "133/133 [==============================] - 0s - loss: 468163.0077 - val_loss: 226602.0893\n",
      "Epoch 629/1000\n",
      "133/133 [==============================] - 0s - loss: 429638.8996 - val_loss: 242958.4665\n",
      "Epoch 630/1000\n",
      "133/133 [==============================] - 0s - loss: 458422.3511 - val_loss: 196430.4576\n",
      "Epoch 631/1000\n",
      "133/133 [==============================] - 0s - loss: 430907.3182 - val_loss: 241958.6116\n",
      "Epoch 632/1000\n",
      "133/133 [==============================] - 0s - loss: 394933.8245 - val_loss: 289448.0647\n",
      "Epoch 633/1000\n",
      "133/133 [==============================] - 0s - loss: 445429.2293 - val_loss: 217272.0603\n",
      "Epoch 634/1000\n",
      "133/133 [==============================] - 0s - loss: 421785.1815 - val_loss: 280054.1585\n",
      "Epoch 635/1000\n",
      "133/133 [==============================] - 0s - loss: 439866.5362 - val_loss: 270392.3750\n",
      "Epoch 636/1000\n",
      "133/133 [==============================] - 0s - loss: 428477.4207 - val_loss: 180689.2567\n",
      "Epoch 637/1000\n",
      "133/133 [==============================] - 0s - loss: 408145.5407 - val_loss: 230983.7879\n",
      "Epoch 638/1000\n",
      "133/133 [==============================] - 0s - loss: 454443.6710 - val_loss: 203802.7210\n",
      "Epoch 639/1000\n",
      "133/133 [==============================] - 0s - loss: 433516.0776 - val_loss: 279038.5469\n",
      "Epoch 640/1000\n",
      "133/133 [==============================] - 0s - loss: 472779.3637 - val_loss: 227780.0335\n",
      "Epoch 641/1000\n",
      "133/133 [==============================] - 0s - loss: 469044.3012 - val_loss: 239192.3750\n",
      "Epoch 642/1000\n",
      "133/133 [==============================] - 0s - loss: 415778.7192 - val_loss: 265990.9487\n",
      "Epoch 643/1000\n",
      "133/133 [==============================] - 0s - loss: 431782.0740 - val_loss: 209414.3393\n",
      "Epoch 644/1000\n",
      "133/133 [==============================] - 0s - loss: 362544.4353 - val_loss: 327190.2188\n",
      "Epoch 645/1000\n",
      "133/133 [==============================] - 0s - loss: 399083.8801 - val_loss: 261654.4821\n",
      "Epoch 646/1000\n",
      "133/133 [==============================] - 0s - loss: 442054.4201 - val_loss: 269445.0357\n",
      "Epoch 647/1000\n",
      "133/133 [==============================] - 0s - loss: 428114.5759 - val_loss: 289661.1094\n",
      "Epoch 648/1000\n",
      "133/133 [==============================] - 0s - loss: 458356.7903 - val_loss: 277644.6004\n",
      "Epoch 649/1000\n",
      "133/133 [==============================] - 0s - loss: 413285.1330 - val_loss: 302929.5357\n",
      "Epoch 650/1000\n",
      "133/133 [==============================] - 0s - loss: 407060.7227 - val_loss: 249273.0781739\n",
      "Epoch 651/1000\n",
      "133/133 [==============================] - 0s - loss: 329119.6221 - val_loss: 260172.8996\n",
      "Epoch 652/1000\n",
      "133/133 [==============================] - 0s - loss: 478368.4991 - val_loss: 223910.2902\n",
      "Epoch 653/1000\n",
      "133/133 [==============================] - 0s - loss: 555587.4116 - val_loss: 178354.2946\n",
      "Epoch 654/1000\n",
      "133/133 [==============================] - 0s - loss: 419670.0305 - val_loss: 236383.0737\n",
      "Epoch 655/1000\n",
      "133/133 [==============================] - 0s - loss: 455295.4350 - val_loss: 215791.2522\n",
      "Epoch 656/1000\n",
      "133/133 [==============================] - 0s - loss: 424589.6259 - val_loss: 225757.6004\n",
      "Epoch 657/1000\n",
      "133/133 [==============================] - 0s - loss: 347041.8281 - val_loss: 194224.2946\n",
      "Epoch 658/1000\n",
      "133/133 [==============================] - 0s - loss: 431918.0550 - val_loss: 240777.4353\n",
      "Epoch 659/1000\n",
      "133/133 [==============================] - 0s - loss: 431289.0655 - val_loss: 207602.8772\n",
      "Epoch 660/1000\n",
      "133/133 [==============================] - 0s - loss: 467008.9094 - val_loss: 242383.1897\n",
      "Epoch 661/1000\n",
      "133/133 [==============================] - 0s - loss: 413353.2604 - val_loss: 221936.5469\n",
      "Epoch 662/1000\n",
      "133/133 [==============================] - 0s - loss: 438699.7798 - val_loss: 237420.7589\n",
      "Epoch 663/1000\n",
      "133/133 [==============================] - 0s - loss: 427677.1140 - val_loss: 207685.8281\n",
      "Epoch 664/1000\n",
      "133/133 [==============================] - 0s - loss: 457450.9924 - val_loss: 239204.7701\n",
      "Epoch 665/1000\n",
      "133/133 [==============================] - 0s - loss: 402007.6999 - val_loss: 248543.1228\n",
      "Epoch 666/1000\n",
      "133/133 [==============================] - 0s - loss: 395846.3016 - val_loss: 262338.8772\n",
      "Epoch 667/1000\n",
      "133/133 [==============================] - 0s - loss: 381285.6055 - val_loss: 282391.1004\n",
      "Epoch 668/1000\n",
      "133/133 [==============================] - 0s - loss: 384976.7426 - val_loss: 282965.8549\n",
      "Epoch 669/1000\n",
      "133/133 [==============================] - 0s - loss: 379005.0405 - val_loss: 230512.4196\n",
      "Epoch 670/1000\n",
      "133/133 [==============================] - 0s - loss: 372738.5897 - val_loss: 213656.1786\n",
      "Epoch 671/1000\n",
      "133/133 [==============================] - 0s - loss: 413336.9887 - val_loss: 252691.9263\n",
      "Epoch 672/1000\n",
      "133/133 [==============================] - 0s - loss: 412982.1195 - val_loss: 278040.6496\n",
      "Epoch 673/1000\n",
      "133/133 [==============================] - 0s - loss: 427790.9524 - val_loss: 302140.6696\n",
      "Epoch 674/1000\n",
      "133/133 [==============================] - 0s - loss: 404635.5146 - val_loss: 256181.5089\n",
      "Epoch 675/1000\n",
      "133/133 [==============================] - 0s - loss: 411306.9275 - val_loss: 296464.8772\n",
      "Epoch 676/1000\n",
      "133/133 [==============================] - 0s - loss: 391968.0364 - val_loss: 225994.5357\n",
      "Epoch 677/1000\n",
      "133/133 [==============================] - 0s - loss: 436008.3748 - val_loss: 216667.2835\n",
      "Epoch 678/1000\n",
      "133/133 [==============================] - 0s - loss: 420876.4625 - val_loss: 264586.2054\n",
      "Epoch 679/1000\n",
      "133/133 [==============================] - 0s - loss: 413911.2136 - val_loss: 224824.2478\n",
      "Epoch 680/1000\n",
      "133/133 [==============================] - 0s - loss: 388275.1631 - val_loss: 250433.8504\n",
      "Epoch 681/1000\n",
      "133/133 [==============================] - 0s - loss: 415756.7703 - val_loss: 214205.3371\n",
      "Epoch 682/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 419895.2809 - val_loss: 287864.2969\n",
      "Epoch 683/1000\n",
      "133/133 [==============================] - 0s - loss: 447533.1738 - val_loss: 254884.7522\n",
      "Epoch 684/1000\n",
      "133/133 [==============================] - 0s - loss: 378810.7645 - val_loss: 202285.3996\n",
      "Epoch 685/1000\n",
      "133/133 [==============================] - 0s - loss: 424530.5092 - val_loss: 254986.7991\n",
      "Epoch 686/1000\n",
      "133/133 [==============================] - 0s - loss: 419383.6875 - val_loss: 249811.9442\n",
      "Epoch 687/1000\n",
      "133/133 [==============================] - 0s - loss: 461184.8734 - val_loss: 210525.9821\n",
      "Epoch 688/1000\n",
      "133/133 [==============================] - 0s - loss: 427888.7877 - val_loss: 260465.8214\n",
      "Epoch 689/1000\n",
      "133/133 [==============================] - 0s - loss: 451441.8024 - val_loss: 256805.9621\n",
      "Epoch 690/1000\n",
      "133/133 [==============================] - 0s - loss: 459853.8519 - val_loss: 292206.2165\n",
      "Epoch 691/1000\n",
      "133/133 [==============================] - 0s - loss: 501932.9703 - val_loss: 186239.6629\n",
      "Epoch 692/1000\n",
      "133/133 [==============================] - 0s - loss: 578409.9448 - val_loss: 123278.4085\n",
      "Epoch 693/1000\n",
      "133/133 [==============================] - 0s - loss: 520430.8773 - val_loss: 132182.2232\n",
      "Epoch 694/1000\n",
      "133/133 [==============================] - 0s - loss: 414035.3522 - val_loss: 149494.7522\n",
      "Epoch 695/1000\n",
      "133/133 [==============================] - 0s - loss: 449847.8354 - val_loss: 131702.6116\n",
      "Epoch 696/1000\n",
      "133/133 [==============================] - 0s - loss: 480281.5266 - val_loss: 145549.0201\n",
      "Epoch 697/1000\n",
      "133/133 [==============================] - 0s - loss: 453446.4564 - val_loss: 139364.0022\n",
      "Epoch 698/1000\n",
      "133/133 [==============================] - 0s - loss: 396381.3148 - val_loss: 169011.1786\n",
      "Epoch 699/1000\n",
      "133/133 [==============================] - 0s - loss: 477039.2404 - val_loss: 156410.5893\n",
      "Epoch 700/1000\n",
      "133/133 [==============================] - 0s - loss: 508805.9992 - val_loss: 149473.3482\n",
      "Epoch 701/1000\n",
      "133/133 [==============================] - 0s - loss: 444186.0091 - val_loss: 272527.6696\n",
      "Epoch 702/1000\n",
      "133/133 [==============================] - 0s - loss: 451830.7074 - val_loss: 263470.5513\n",
      "Epoch 703/1000\n",
      "133/133 [==============================] - 0s - loss: 482468.0343 - val_loss: 212098.6250\n",
      "Epoch 704/1000\n",
      "133/133 [==============================] - 0s - loss: 431480.9362 - val_loss: 226825.8326\n",
      "Epoch 705/1000\n",
      "133/133 [==============================] - 0s - loss: 410641.0482 - val_loss: 225565.0558\n",
      "Epoch 706/1000\n",
      "133/133 [==============================] - 0s - loss: 380471.5741 - val_loss: 252854.8058\n",
      "Epoch 707/1000\n",
      "133/133 [==============================] - 0s - loss: 403523.4609 - val_loss: 218633.4129\n",
      "Epoch 708/1000\n",
      "133/133 [==============================] - 0s - loss: 453149.4828 - val_loss: 280189.4933\n",
      "Epoch 709/1000\n",
      "133/133 [==============================] - 0s - loss: 458334.1268 - val_loss: 258406.8460\n",
      "Epoch 710/1000\n",
      "133/133 [==============================] - 0s - loss: 510874.3313 - val_loss: 215435.8281\n",
      "Epoch 711/1000\n",
      "133/133 [==============================] - 0s - loss: 478093.6216 - val_loss: 389757.1518\n",
      "Epoch 712/1000\n",
      "133/133 [==============================] - 0s - loss: 499794.3661 - val_loss: 297790.0156\n",
      "Epoch 713/1000\n",
      "133/133 [==============================] - 0s - loss: 428223.8882 - val_loss: 241861.1674\n",
      "Epoch 714/1000\n",
      "133/133 [==============================] - 0s - loss: 499073.2118 - val_loss: 220533.2031\n",
      "Epoch 715/1000\n",
      "133/133 [==============================] - 0s - loss: 448145.5759 - val_loss: 257399.2924\n",
      "Epoch 716/1000\n",
      "133/133 [==============================] - 0s - loss: 434862.5187 - val_loss: 224193.3906\n",
      "Epoch 717/1000\n",
      "133/133 [==============================] - 0s - loss: 420020.4381 - val_loss: 224735.1987\n",
      "Epoch 718/1000\n",
      "133/133 [==============================] - 0s - loss: 526526.8507 - val_loss: 180167.1362\n",
      "Epoch 719/1000\n",
      "133/133 [==============================] - 0s - loss: 503724.3323 - val_loss: 280733.3214\n",
      "Epoch 720/1000\n",
      "133/133 [==============================] - 0s - loss: 513228.0646 - val_loss: 276655.3058\n",
      "Epoch 721/1000\n",
      "133/133 [==============================] - 0s - loss: 455131.6272 - val_loss: 230117.9978\n",
      "Epoch 722/1000\n",
      "133/133 [==============================] - 0s - loss: 515128.6936 - val_loss: 220603.0692\n",
      "Epoch 723/1000\n",
      "133/133 [==============================] - 0s - loss: 451718.8301 - val_loss: 320525.1875\n",
      "Epoch 724/1000\n",
      "133/133 [==============================] - 0s - loss: 467974.7959 - val_loss: 338464.8237\n",
      "Epoch 725/1000\n",
      "133/133 [==============================] - 0s - loss: 486306.2768 - val_loss: 287288.8281\n",
      "Epoch 726/1000\n",
      "133/133 [==============================] - 0s - loss: 466844.6231 - val_loss: 233398.5067\n",
      "Epoch 727/1000\n",
      "133/133 [==============================] - 0s - loss: 499246.9436 - val_loss: 272010.6585\n",
      "Epoch 728/1000\n",
      "133/133 [==============================] - 0s - loss: 494759.9197 - val_loss: 273605.7388\n",
      "Epoch 729/1000\n",
      "133/133 [==============================] - 0s - loss: 403165.9322 - val_loss: 225666.6496\n",
      "Epoch 730/1000\n",
      "133/133 [==============================] - 0s - loss: 408894.9277 - val_loss: 238746.7411\n",
      "Epoch 731/1000\n",
      "133/133 [==============================] - 0s - loss: 475120.6424 - val_loss: 218082.2210\n",
      "Epoch 732/1000\n",
      "133/133 [==============================] - 0s - loss: 428530.6030 - val_loss: 251604.9821\n",
      "Epoch 733/1000\n",
      "133/133 [==============================] - 0s - loss: 417762.1249 - val_loss: 265105.8795\n",
      "Epoch 734/1000\n",
      "133/133 [==============================] - 0s - loss: 455714.0870 - val_loss: 213241.8080\n",
      "Epoch 735/1000\n",
      "133/133 [==============================] - 0s - loss: 458506.5226 - val_loss: 249888.8661\n",
      "Epoch 736/1000\n",
      "133/133 [==============================] - 0s - loss: 433264.4547 - val_loss: 339551.1317\n",
      "Epoch 737/1000\n",
      "133/133 [==============================] - 0s - loss: 445830.9845 - val_loss: 332283.7478\n",
      "Epoch 738/1000\n",
      "133/133 [==============================] - 0s - loss: 433558.7039 - val_loss: 263469.1138\n",
      "Epoch 739/1000\n",
      "133/133 [==============================] - 0s - loss: 461420.9061 - val_loss: 313781.9554\n",
      "Epoch 740/1000\n",
      "133/133 [==============================] - 0s - loss: 462767.2692 - val_loss: 239631.7054\n",
      "Epoch 741/1000\n",
      "133/133 [==============================] - 0s - loss: 423246.2824 - val_loss: 290570.1629\n",
      "Epoch 742/1000\n",
      "133/133 [==============================] - 0s - loss: 424755.0116 - val_loss: 253540.8147\n",
      "Epoch 743/1000\n",
      "133/133 [==============================] - 0s - loss: 421170.1536 - val_loss: 203091.2701\n",
      "Epoch 744/1000\n",
      "133/133 [==============================] - 0s - loss: 456062.8875 - val_loss: 147257.2924\n",
      "Epoch 745/1000\n",
      "133/133 [==============================] - 0s - loss: 561029.3326 - val_loss: 153746.0112\n",
      "Epoch 746/1000\n",
      "133/133 [==============================] - 0s - loss: 432486.6483 - val_loss: 183896.5089\n",
      "Epoch 747/1000\n",
      "133/133 [==============================] - 0s - loss: 492646.9963 - val_loss: 208255.7433\n",
      "Epoch 748/1000\n",
      "133/133 [==============================] - 0s - loss: 402562.1317 - val_loss: 221932.5379\n",
      "Epoch 749/1000\n",
      "133/133 [==============================] - 0s - loss: 395333.2629 - val_loss: 232322.9665\n",
      "Epoch 750/1000\n",
      "133/133 [==============================] - 0s - loss: 433755.0194 - val_loss: 190726.5246\n",
      "Epoch 751/1000\n",
      "133/133 [==============================] - 0s - loss: 436153.1398 - val_loss: 237230.21213021.49\n",
      "Epoch 752/1000\n",
      "133/133 [==============================] - 0s - loss: 360600.6050 - val_loss: 236042.8929\n",
      "Epoch 753/1000\n",
      "133/133 [==============================] - 0s - loss: 449667.5710 - val_loss: 206691.9911\n",
      "Epoch 754/1000\n",
      "133/133 [==============================] - 0s - loss: 454246.2978 - val_loss: 255263.4263\n",
      "Epoch 755/1000\n",
      "133/133 [==============================] - 0s - loss: 464255.0439 - val_loss: 264404.4219\n",
      "Epoch 756/1000\n",
      "133/133 [==============================] - 0s - loss: 389175.7482 - val_loss: 261867.3929\n",
      "Epoch 757/1000\n",
      "133/133 [==============================] - 0s - loss: 429454.1828 - val_loss: 237833.8594\n",
      "Epoch 758/1000\n",
      "133/133 [==============================] - 0s - loss: 442296.4199 - val_loss: 204625.1987\n",
      "Epoch 759/1000\n",
      "133/133 [==============================] - 0s - loss: 428544.1671 - val_loss: 301904.3839\n",
      "Epoch 760/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 382980.3238 - val_loss: 231103.6674\n",
      "Epoch 761/1000\n",
      "133/133 [==============================] - 0s - loss: 397816.0508 - val_loss: 241518.0982\n",
      "Epoch 762/1000\n",
      "133/133 [==============================] - 0s - loss: 463884.1033 - val_loss: 294161.5179\n",
      "Epoch 763/1000\n",
      "133/133 [==============================] - 0s - loss: 439592.0368 - val_loss: 267011.3839\n",
      "Epoch 764/1000\n",
      "133/133 [==============================] - 0s - loss: 412865.0191 - val_loss: 233685.1763\n",
      "Epoch 765/1000\n",
      "133/133 [==============================] - 0s - loss: 405125.3277 - val_loss: 296493.9710\n",
      "Epoch 766/1000\n",
      "133/133 [==============================] - 0s - loss: 473671.6935 - val_loss: 215145.2746\n",
      "Epoch 767/1000\n",
      "133/133 [==============================] - 0s - loss: 401750.1918 - val_loss: 258942.2969\n",
      "Epoch 768/1000\n",
      "133/133 [==============================] - 0s - loss: 419386.4892 - val_loss: 154259.1629\n",
      "Epoch 769/1000\n",
      "133/133 [==============================] - 0s - loss: 445488.9761 - val_loss: 142429.3951\n",
      "Epoch 770/1000\n",
      "133/133 [==============================] - 0s - loss: 425108.0845 - val_loss: 265634.8438\n",
      "Epoch 771/1000\n",
      "133/133 [==============================] - 0s - loss: 394098.6384 - val_loss: 263636.1763\n",
      "Epoch 772/1000\n",
      "133/133 [==============================] - 0s - loss: 425200.9874 - val_loss: 254914.3214\n",
      "Epoch 773/1000\n",
      "133/133 [==============================] - 0s - loss: 379311.3822 - val_loss: 261994.0357\n",
      "Epoch 774/1000\n",
      "133/133 [==============================] - 0s - loss: 382457.4674 - val_loss: 266464.1250\n",
      "Epoch 775/1000\n",
      "133/133 [==============================] - 0s - loss: 425146.2110 - val_loss: 245782.0446\n",
      "Epoch 776/1000\n",
      "133/133 [==============================] - 0s - loss: 503376.9043 - val_loss: 303638.8393\n",
      "Epoch 777/1000\n",
      "133/133 [==============================] - 0s - loss: 440373.0185 - val_loss: 223138.6987\n",
      "Epoch 778/1000\n",
      "133/133 [==============================] - 0s - loss: 479537.2112 - val_loss: 242642.7835\n",
      "Epoch 779/1000\n",
      "133/133 [==============================] - 0s - loss: 391512.1000 - val_loss: 252263.0246\n",
      "Epoch 780/1000\n",
      "133/133 [==============================] - 0s - loss: 423127.1282 - val_loss: 247029.6629\n",
      "Epoch 781/1000\n",
      "133/133 [==============================] - 0s - loss: 375806.0411 - val_loss: 244199.9665\n",
      "Epoch 782/1000\n",
      "133/133 [==============================] - 0s - loss: 442138.9519 - val_loss: 183276.2589\n",
      "Epoch 783/1000\n",
      "133/133 [==============================] - 0s - loss: 475626.4679 - val_loss: 290705.9487\n",
      "Epoch 784/1000\n",
      "133/133 [==============================] - 0s - loss: 457753.1988 - val_loss: 242073.8326\n",
      "Epoch 785/1000\n",
      "133/133 [==============================] - 0s - loss: 429929.4052 - val_loss: 253356.1897\n",
      "Epoch 786/1000\n",
      "133/133 [==============================] - 0s - loss: 412989.1017 - val_loss: 214987.7589\n",
      "Epoch 787/1000\n",
      "133/133 [==============================] - 0s - loss: 425366.3601 - val_loss: 145050.4219\n",
      "Epoch 788/1000\n",
      "133/133 [==============================] - 0s - loss: 423707.4697 - val_loss: 156186.3214\n",
      "Epoch 789/1000\n",
      "133/133 [==============================] - 0s - loss: 395015.5011 - val_loss: 319281.1607\n",
      "Epoch 790/1000\n",
      "133/133 [==============================] - 0s - loss: 467476.8886 - val_loss: 305273.5469\n",
      "Epoch 791/1000\n",
      "133/133 [==============================] - 0s - loss: 410829.8249 - val_loss: 213486.6272\n",
      "Epoch 792/1000\n",
      "133/133 [==============================] - 0s - loss: 432278.6469 - val_loss: 312075.5112\n",
      "Epoch 793/1000\n",
      "133/133 [==============================] - 0s - loss: 437436.7034 - val_loss: 236993.2254\n",
      "Epoch 794/1000\n",
      "133/133 [==============================] - 0s - loss: 402938.4617 - val_loss: 246829.5491\n",
      "Epoch 795/1000\n",
      "133/133 [==============================] - 0s - loss: 372910.3128 - val_loss: 322413.5469\n",
      "Epoch 796/1000\n",
      "133/133 [==============================] - 0s - loss: 408112.1129 - val_loss: 230928.5469\n",
      "Epoch 797/1000\n",
      "133/133 [==============================] - 0s - loss: 406417.8462 - val_loss: 248408.9933\n",
      "Epoch 798/1000\n",
      "133/133 [==============================] - 0s - loss: 364857.9868 - val_loss: 195633.4978\n",
      "Epoch 799/1000\n",
      "133/133 [==============================] - 0s - loss: 373136.9739 - val_loss: 186671.6406\n",
      "Epoch 800/1000\n",
      "133/133 [==============================] - 0s - loss: 440618.1419 - val_loss: 254572.9219\n",
      "Epoch 801/1000\n",
      "133/133 [==============================] - 0s - loss: 401194.9061 - val_loss: 284681.1719\n",
      "Epoch 802/1000\n",
      "133/133 [==============================] - 0s - loss: 355843.3644 - val_loss: 266832.6719\n",
      "Epoch 803/1000\n",
      "133/133 [==============================] - 0s - loss: 377952.0167 - val_loss: 198477.9308\n",
      "Epoch 804/1000\n",
      "133/133 [==============================] - 0s - loss: 442458.2919 - val_loss: 220742.2790\n",
      "Epoch 805/1000\n",
      "133/133 [==============================] - 0s - loss: 413376.4380 - val_loss: 220653.5201\n",
      "Epoch 806/1000\n",
      "133/133 [==============================] - 0s - loss: 479537.4874 - val_loss: 212360.9732\n",
      "Epoch 807/1000\n",
      "133/133 [==============================] - 0s - loss: 482699.8521 - val_loss: 199558.5558\n",
      "Epoch 808/1000\n",
      "133/133 [==============================] - 0s - loss: 396594.1234 - val_loss: 291161.1763\n",
      "Epoch 809/1000\n",
      "133/133 [==============================] - 0s - loss: 480224.7268 - val_loss: 176310.5536\n",
      "Epoch 810/1000\n",
      "133/133 [==============================] - 0s - loss: 453527.0940 - val_loss: 150632.4933\n",
      "Epoch 811/1000\n",
      "133/133 [==============================] - 0s - loss: 449526.6703 - val_loss: 254730.1953\n",
      "Epoch 812/1000\n",
      "133/133 [==============================] - 0s - loss: 435680.2190 - val_loss: 241464.3125\n",
      "Epoch 813/1000\n",
      "133/133 [==============================] - 0s - loss: 415554.0050 - val_loss: 288899.1496\n",
      "Epoch 814/1000\n",
      "133/133 [==============================] - 0s - loss: 443866.3985 - val_loss: 274338.4621\n",
      "Epoch 815/1000\n",
      "133/133 [==============================] - 0s - loss: 388421.4444 - val_loss: 255316.0000\n",
      "Epoch 816/1000\n",
      "133/133 [==============================] - 0s - loss: 421461.2908 - val_loss: 223163.5446\n",
      "Epoch 817/1000\n",
      "133/133 [==============================] - 0s - loss: 366758.1229 - val_loss: 209932.0647\n",
      "Epoch 818/1000\n",
      "133/133 [==============================] - 0s - loss: 413020.0869 - val_loss: 209294.7031\n",
      "Epoch 819/1000\n",
      "133/133 [==============================] - 0s - loss: 360421.2483 - val_loss: 228142.4576\n",
      "Epoch 820/1000\n",
      "133/133 [==============================] - 0s - loss: 424183.7396 - val_loss: 189884.6362\n",
      "Epoch 821/1000\n",
      "133/133 [==============================] - 0s - loss: 408307.0517 - val_loss: 174050.6987\n",
      "Epoch 822/1000\n",
      "133/133 [==============================] - 0s - loss: 445418.7478 - val_loss: 193770.3125\n",
      "Epoch 823/1000\n",
      "133/133 [==============================] - 0s - loss: 346989.4405 - val_loss: 219554.5156\n",
      "Epoch 824/1000\n",
      "133/133 [==============================] - 0s - loss: 361911.6449 - val_loss: 186751.0804\n",
      "Epoch 825/1000\n",
      "133/133 [==============================] - 0s - loss: 376255.7390 - val_loss: 151851.1272\n",
      "Epoch 826/1000\n",
      "133/133 [==============================] - 0s - loss: 464152.7459 - val_loss: 205515.3728\n",
      "Epoch 827/1000\n",
      "133/133 [==============================] - 0s - loss: 467923.5618 - val_loss: 236229.6518\n",
      "Epoch 828/1000\n",
      "133/133 [==============================] - 0s - loss: 390763.5118 - val_loss: 244897.6942\n",
      "Epoch 829/1000\n",
      "133/133 [==============================] - 0s - loss: 402613.9705 - val_loss: 234831.7299\n",
      "Epoch 830/1000\n",
      "133/133 [==============================] - 0s - loss: 385403.3056 - val_loss: 225814.5804\n",
      "Epoch 831/1000\n",
      "133/133 [==============================] - 0s - loss: 434206.0083 - val_loss: 299052.8906\n",
      "Epoch 832/1000\n",
      "133/133 [==============================] - 0s - loss: 415669.3808 - val_loss: 211452.0379\n",
      "Epoch 833/1000\n",
      "133/133 [==============================] - 0s - loss: 392360.0680 - val_loss: 227711.4330\n",
      "Epoch 834/1000\n",
      "133/133 [==============================] - 0s - loss: 433026.2193 - val_loss: 228397.3750\n",
      "Epoch 835/1000\n",
      "133/133 [==============================] - 0s - loss: 399976.2693 - val_loss: 270988.1518\n",
      "Epoch 836/1000\n",
      "133/133 [==============================] - 0s - loss: 406580.5234 - val_loss: 283599.0982\n",
      "Epoch 837/1000\n",
      "133/133 [==============================] - 0s - loss: 454147.7242 - val_loss: 196564.3103\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 417438.1394 - val_loss: 166753.0692\n",
      "Epoch 839/1000\n",
      "133/133 [==============================] - 0s - loss: 434091.4602 - val_loss: 168195.91291117.\n",
      "Epoch 840/1000\n",
      "133/133 [==============================] - 0s - loss: 493153.1836 - val_loss: 187296.7924\n",
      "Epoch 841/1000\n",
      "133/133 [==============================] - 0s - loss: 375151.4030 - val_loss: 263672.4085\n",
      "Epoch 842/1000\n",
      "133/133 [==============================] - 0s - loss: 349747.1603 - val_loss: 260719.4978\n",
      "Epoch 843/1000\n",
      "133/133 [==============================] - 0s - loss: 356128.8791 - val_loss: 236180.6094\n",
      "Epoch 844/1000\n",
      "133/133 [==============================] - 0s - loss: 381289.4767 - val_loss: 391339.9107\n",
      "Epoch 845/1000\n",
      "133/133 [==============================] - 0s - loss: 358776.2571 - val_loss: 446914.4621\n",
      "Epoch 846/1000\n",
      "133/133 [==============================] - 0s - loss: 344935.7387 - val_loss: 206906.5871\n",
      "Epoch 847/1000\n",
      "133/133 [==============================] - 0s - loss: 378800.0962 - val_loss: 264231.1629\n",
      "Epoch 848/1000\n",
      "133/133 [==============================] - 0s - loss: 440147.3603 - val_loss: 257801.0647485\n",
      "Epoch 849/1000\n",
      "133/133 [==============================] - 0s - loss: 407074.8749 - val_loss: 225637.3326\n",
      "Epoch 850/1000\n",
      "133/133 [==============================] - 0s - loss: 385775.3183 - val_loss: 228524.8996\n",
      "Epoch 851/1000\n",
      "133/133 [==============================] - 0s - loss: 419395.5535 - val_loss: 336287.9487\n",
      "Epoch 852/1000\n",
      "133/133 [==============================] - 0s - loss: 390666.2420 - val_loss: 190946.4531\n",
      "Epoch 853/1000\n",
      "133/133 [==============================] - 0s - loss: 427186.8997 - val_loss: 179651.7433\n",
      "Epoch 854/1000\n",
      "133/133 [==============================] - 0s - loss: 460973.8162 - val_loss: 215176.9531\n",
      "Epoch 855/1000\n",
      "133/133 [==============================] - 0s - loss: 379064.6860 - val_loss: 98068.8326\n",
      "Epoch 856/1000\n",
      "133/133 [==============================] - 0s - loss: 491716.8492 - val_loss: 188033.9062\n",
      "Epoch 857/1000\n",
      "133/133 [==============================] - 0s - loss: 454629.9617 - val_loss: 162611.2567\n",
      "Epoch 858/1000\n",
      "133/133 [==============================] - 0s - loss: 443388.5600 - val_loss: 182836.8705\n",
      "Epoch 859/1000\n",
      "133/133 [==============================] - 0s - loss: 398369.7026 - val_loss: 211598.9040\n",
      "Epoch 860/1000\n",
      "133/133 [==============================] - 0s - loss: 374422.6315 - val_loss: 209741.6205\n",
      "Epoch 861/1000\n",
      "133/133 [==============================] - 0s - loss: 407964.2507 - val_loss: 211868.3326\n",
      "Epoch 862/1000\n",
      "133/133 [==============================] - 0s - loss: 458926.2160 - val_loss: 305988.9397\n",
      "Epoch 863/1000\n",
      "133/133 [==============================] - 0s - loss: 476865.6389 - val_loss: 183109.9576\n",
      "Epoch 864/1000\n",
      "133/133 [==============================] - 0s - loss: 442517.2321 - val_loss: 195886.6808\n",
      "Epoch 865/1000\n",
      "133/133 [==============================] - 0s - loss: 347635.5844 - val_loss: 172608.4621\n",
      "Epoch 866/1000\n",
      "133/133 [==============================] - 0s - loss: 443249.5576 - val_loss: 162611.0268\n",
      "Epoch 867/1000\n",
      "133/133 [==============================] - 0s - loss: 411399.4620 - val_loss: 165105.2098\n",
      "Epoch 868/1000\n",
      "133/133 [==============================] - 0s - loss: 425444.4684 - val_loss: 164182.2589\n",
      "Epoch 869/1000\n",
      "133/133 [==============================] - 0s - loss: 412234.1759 - val_loss: 200315.4531\n",
      "Epoch 870/1000\n",
      "133/133 [==============================] - 0s - loss: 425195.1576 - val_loss: 213141.6585\n",
      "Epoch 871/1000\n",
      "133/133 [==============================] - 0s - loss: 412822.2989 - val_loss: 192176.2411\n",
      "Epoch 872/1000\n",
      "133/133 [==============================] - 0s - loss: 386267.8710 - val_loss: 220053.0647\n",
      "Epoch 873/1000\n",
      "133/133 [==============================] - 0s - loss: 396905.8781 - val_loss: 187920.8192\n",
      "Epoch 874/1000\n",
      "133/133 [==============================] - 0s - loss: 364980.4671 - val_loss: 166887.8951\n",
      "Epoch 875/1000\n",
      "133/133 [==============================] - 0s - loss: 405414.1858 - val_loss: 152304.1038\n",
      "Epoch 876/1000\n",
      "133/133 [==============================] - 0s - loss: 385642.4860 - val_loss: 145569.5067\n",
      "Epoch 877/1000\n",
      "133/133 [==============================] - 0s - loss: 367182.6212 - val_loss: 200687.3661\n",
      "Epoch 878/1000\n",
      "133/133 [==============================] - 0s - loss: 406406.3234 - val_loss: 226204.50671015.22\n",
      "Epoch 879/1000\n",
      "133/133 [==============================] - 0s - loss: 382142.7991 - val_loss: 210189.6496\n",
      "Epoch 880/1000\n",
      "133/133 [==============================] - 0s - loss: 426820.5844 - val_loss: 174651.58711\n",
      "Epoch 881/1000\n",
      "133/133 [==============================] - 0s - loss: 465247.2419 - val_loss: 218273.3080\n",
      "Epoch 882/1000\n",
      "133/133 [==============================] - 0s - loss: 372277.2363 - val_loss: 211130.4821\n",
      "Epoch 883/1000\n",
      "133/133 [==============================] - 0s - loss: 483019.4052 - val_loss: 226477.9085\n",
      "Epoch 884/1000\n",
      "133/133 [==============================] - 0s - loss: 407327.9132 - val_loss: 212230.1228\n",
      "Epoch 885/1000\n",
      "133/133 [==============================] - 0s - loss: 388183.1773 - val_loss: 225952.8281\n",
      "Epoch 886/1000\n",
      "133/133 [==============================] - 0s - loss: 380884.9396 - val_loss: 134497.1674\n",
      "Epoch 887/1000\n",
      "133/133 [==============================] - 0s - loss: 389973.4467 - val_loss: 195767.6339\n",
      "Epoch 888/1000\n",
      "133/133 [==============================] - 0s - loss: 446899.6853 - val_loss: 225951.1094\n",
      "Epoch 889/1000\n",
      "133/133 [==============================] - 0s - loss: 368601.5132 - val_loss: 230967.6897\n",
      "Epoch 890/1000\n",
      "133/133 [==============================] - 0s - loss: 359000.0993 - val_loss: 136660.9665\n",
      "Epoch 891/1000\n",
      "133/133 [==============================] - 0s - loss: 392251.9269 - val_loss: 167565.9018\n",
      "Epoch 892/1000\n",
      "133/133 [==============================] - 0s - loss: 411178.9320 - val_loss: 122483.0424\n",
      "Epoch 893/1000\n",
      "133/133 [==============================] - 0s - loss: 447945.5656 - val_loss: 212437.5112\n",
      "Epoch 894/1000\n",
      "133/133 [==============================] - 0s - loss: 449761.4176 - val_loss: 219269.8661\n",
      "Epoch 895/1000\n",
      "133/133 [==============================] - 0s - loss: 421941.3729 - val_loss: 262598.1786\n",
      "Epoch 896/1000\n",
      "133/133 [==============================] - 0s - loss: 401904.6412 - val_loss: 224611.1406\n",
      "Epoch 897/1000\n",
      "133/133 [==============================] - 0s - loss: 382795.5226 - val_loss: 185242.8996\n",
      "Epoch 898/1000\n",
      "133/133 [==============================] - 0s - loss: 322232.3068 - val_loss: 204853.4040\n",
      "Epoch 899/1000\n",
      "133/133 [==============================] - 0s - loss: 361272.5629 - val_loss: 227822.8237\n",
      "Epoch 900/1000\n",
      "133/133 [==============================] - 0s - loss: 414970.7034 - val_loss: 145930.6205\n",
      "Epoch 901/1000\n",
      "133/133 [==============================] - 0s - loss: 392297.9367 - val_loss: 161599.1808\n",
      "Epoch 902/1000\n",
      "133/133 [==============================] - 0s - loss: 364706.2978 - val_loss: 189999.1071\n",
      "Epoch 903/1000\n",
      "133/133 [==============================] - 0s - loss: 397396.4340 - val_loss: 176949.1629\n",
      "Epoch 904/1000\n",
      "133/133 [==============================] - 0s - loss: 385467.5217 - val_loss: 160574.33262528.\n",
      "Epoch 905/1000\n",
      "133/133 [==============================] - 0s - loss: 387543.8342 - val_loss: 260229.5089\n",
      "Epoch 906/1000\n",
      "133/133 [==============================] - 0s - loss: 398316.1210 - val_loss: 200759.0692\n",
      "Epoch 907/1000\n",
      "133/133 [==============================] - 0s - loss: 365504.5277 - val_loss: 264600.3996\n",
      "Epoch 908/1000\n",
      "133/133 [==============================] - 0s - loss: 383765.5030 - val_loss: 272149.3036\n",
      "Epoch 909/1000\n",
      "133/133 [==============================] - 0s - loss: 377895.8171 - val_loss: 218895.6429\n",
      "Epoch 910/1000\n",
      "133/133 [==============================] - 0s - loss: 421095.1766 - val_loss: 407379.8125\n",
      "Epoch 911/1000\n",
      "133/133 [==============================] - 0s - loss: 401800.3254 - val_loss: 309734.4621\n",
      "Epoch 912/1000\n",
      "133/133 [==============================] - 0s - loss: 369632.9287 - val_loss: 263859.7455\n",
      "Epoch 913/1000\n",
      "133/133 [==============================] - 0s - loss: 400297.0790 - val_loss: 271814.7879\n",
      "Epoch 914/1000\n",
      "133/133 [==============================] - 0s - loss: 430270.2247 - val_loss: 180883.5625\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 461798.9138 - val_loss: 278649.3460\n",
      "Epoch 916/1000\n",
      "133/133 [==============================] - 0s - loss: 407893.2021 - val_loss: 211872.6496\n",
      "Epoch 917/1000\n",
      "133/133 [==============================] - 0s - loss: 385727.4632 - val_loss: 238006.1161\n",
      "Epoch 918/1000\n",
      "133/133 [==============================] - 0s - loss: 390108.1581 - val_loss: 236030.8326\n",
      "Epoch 919/1000\n",
      "133/133 [==============================] - 0s - loss: 378070.0221 - val_loss: 176759.4129\n",
      "Epoch 920/1000\n",
      "133/133 [==============================] - 0s - loss: 366925.2461 - val_loss: 190488.9263\n",
      "Epoch 921/1000\n",
      "133/133 [==============================] - 0s - loss: 447301.9035 - val_loss: 195048.2589\n",
      "Epoch 922/1000\n",
      "133/133 [==============================] - 0s - loss: 356958.6486 - val_loss: 253506.5201\n",
      "Epoch 923/1000\n",
      "133/133 [==============================] - 0s - loss: 345625.2234 - val_loss: 239652.3214\n",
      "Epoch 924/1000\n",
      "133/133 [==============================] - 0s - loss: 386317.7580 - val_loss: 217602.9888\n",
      "Epoch 925/1000\n",
      "133/133 [==============================] - 0s - loss: 458237.5623 - val_loss: 157759.1071\n",
      "Epoch 926/1000\n",
      "133/133 [==============================] - 0s - loss: 424054.9545 - val_loss: 247985.0067\n",
      "Epoch 927/1000\n",
      "133/133 [==============================] - 0s - loss: 369793.4964 - val_loss: 268488.7210\n",
      "Epoch 928/1000\n",
      "133/133 [==============================] - 0s - loss: 334988.2116 - val_loss: 243905.8482\n",
      "Epoch 929/1000\n",
      "133/133 [==============================] - 0s - loss: 383995.2830 - val_loss: 246080.8504\n",
      "Epoch 930/1000\n",
      "133/133 [==============================] - 0s - loss: 422613.6385 - val_loss: 188381.2835\n",
      "Epoch 931/1000\n",
      "133/133 [==============================] - 0s - loss: 374356.3247 - val_loss: 272931.0647\n",
      "Epoch 932/1000\n",
      "133/133 [==============================] - 0s - loss: 446715.1641 - val_loss: 218526.2232\n",
      "Epoch 933/1000\n",
      "133/133 [==============================] - 0s - loss: 366066.7268 - val_loss: 282632.8772\n",
      "Epoch 934/1000\n",
      "133/133 [==============================] - 0s - loss: 388487.7888 - val_loss: 283895.0893\n",
      "Epoch 935/1000\n",
      "133/133 [==============================] - 0s - loss: 407818.3860 - val_loss: 228165.1429\n",
      "Epoch 936/1000\n",
      "133/133 [==============================] - 0s - loss: 450772.6528 - val_loss: 246117.3929\n",
      "Epoch 937/1000\n",
      "133/133 [==============================] - 0s - loss: 337042.8732 - val_loss: 233991.0290\n",
      "Epoch 938/1000\n",
      "133/133 [==============================] - 0s - loss: 431733.8917 - val_loss: 252579.3393\n",
      "Epoch 939/1000\n",
      "133/133 [==============================] - 0s - loss: 410231.1872 - val_loss: 200476.9821\n",
      "Epoch 940/1000\n",
      "133/133 [==============================] - 0s - loss: 378556.0935 - val_loss: 175883.9375\n",
      "Epoch 941/1000\n",
      "133/133 [==============================] - 0s - loss: 359885.8386 - val_loss: 237167.4844\n",
      "Epoch 942/1000\n",
      "133/133 [==============================] - 0s - loss: 431478.8650 - val_loss: 177920.6004\n",
      "Epoch 943/1000\n",
      "133/133 [==============================] - 0s - loss: 401559.3496 - val_loss: 308234.9085\n",
      "Epoch 944/1000\n",
      "133/133 [==============================] - 0s - loss: 428816.0511 - val_loss: 284644.0335\n",
      "Epoch 945/1000\n",
      "133/133 [==============================] - 0s - loss: 387253.4149 - val_loss: 225933.6585\n",
      "Epoch 946/1000\n",
      "133/133 [==============================] - 0s - loss: 384918.4461 - val_loss: 307552.3750\n",
      "Epoch 947/1000\n",
      "133/133 [==============================] - 0s - loss: 322811.6502 - val_loss: 244583.6138\n",
      "Epoch 948/1000\n",
      "133/133 [==============================] - 0s - loss: 366916.2431 - val_loss: 208274.1250\n",
      "Epoch 949/1000\n",
      "133/133 [==============================] - 0s - loss: 376973.3286 - val_loss: 268704.3571\n",
      "Epoch 950/1000\n",
      "133/133 [==============================] - 0s - loss: 409326.8586 - val_loss: 264716.5179\n",
      "Epoch 951/1000\n",
      "133/133 [==============================] - 0s - loss: 352961.4904 - val_loss: 287336.6250\n",
      "Epoch 952/1000\n",
      "133/133 [==============================] - 0s - loss: 449142.0284 - val_loss: 317899.4196\n",
      "Epoch 953/1000\n",
      "133/133 [==============================] - 0s - loss: 433444.2280 - val_loss: 222221.6607\n",
      "Epoch 954/1000\n",
      "133/133 [==============================] - 0s - loss: 405874.0543 - val_loss: 261087.0692\n",
      "Epoch 955/1000\n",
      "133/133 [==============================] - 0s - loss: 388748.8423 - val_loss: 277767.9531\n",
      "Epoch 956/1000\n",
      "133/133 [==============================] - 0s - loss: 354517.6732 - val_loss: 208504.8839\n",
      "Epoch 957/1000\n",
      "133/133 [==============================] - 0s - loss: 352662.9604 - val_loss: 196436.5246\n",
      "Epoch 958/1000\n",
      "133/133 [==============================] - 0s - loss: 425564.8686 - val_loss: 264762.2076\n",
      "Epoch 959/1000\n",
      "133/133 [==============================] - 0s - loss: 305466.2809 - val_loss: 252790.1250\n",
      "Epoch 960/1000\n",
      "133/133 [==============================] - 0s - loss: 364493.0669 - val_loss: 201036.2656\n",
      "Epoch 961/1000\n",
      "133/133 [==============================] - 0s - loss: 366816.5691 - val_loss: 172980.0357\n",
      "Epoch 962/1000\n",
      "133/133 [==============================] - 0s - loss: 417900.0829 - val_loss: 221512.8415\n",
      "Epoch 963/1000\n",
      "133/133 [==============================] - 0s - loss: 435896.9208 - val_loss: 268676.2522\n",
      "Epoch 964/1000\n",
      "133/133 [==============================] - 0s - loss: 411541.9260 - val_loss: 263232.3862\n",
      "Epoch 965/1000\n",
      "133/133 [==============================] - 0s - loss: 396830.1408 - val_loss: 204694.8326\n",
      "Epoch 966/1000\n",
      "133/133 [==============================] - 0s - loss: 412584.4115 - val_loss: 322560.6451\n",
      "Epoch 967/1000\n",
      "133/133 [==============================] - 0s - loss: 434524.0339 - val_loss: 293006.3371\n",
      "Epoch 968/1000\n",
      "133/133 [==============================] - 0s - loss: 393848.3123 - val_loss: 241220.3214\n",
      "Epoch 969/1000\n",
      "133/133 [==============================] - 0s - loss: 372526.5882 - val_loss: 188389.1786\n",
      "Epoch 970/1000\n",
      "133/133 [==============================] - 0s - loss: 381234.8624 - val_loss: 252007.0692\n",
      "Epoch 971/1000\n",
      "133/133 [==============================] - 0s - loss: 370135.1291 - val_loss: 297179.6942\n",
      "Epoch 972/1000\n",
      "133/133 [==============================] - 0s - loss: 360367.7866 - val_loss: 200730.4375\n",
      "Epoch 973/1000\n",
      "133/133 [==============================] - 0s - loss: 469263.5170 - val_loss: 219836.1964\n",
      "Epoch 974/1000\n",
      "133/133 [==============================] - 0s - loss: 353640.9528 - val_loss: 196817.0156\n",
      "Epoch 975/1000\n",
      "133/133 [==============================] - 0s - loss: 371354.3649 - val_loss: 221514.7656\n",
      "Epoch 976/1000\n",
      "133/133 [==============================] - 0s - loss: 365277.9586 - val_loss: 123419.9174\n",
      "Epoch 977/1000\n",
      "133/133 [==============================] - 0s - loss: 376163.2148 - val_loss: 171249.9397\n",
      "Epoch 978/1000\n",
      "133/133 [==============================] - 0s - loss: 362130.8252 - val_loss: 204759.6272\n",
      "Epoch 979/1000\n",
      "133/133 [==============================] - 0s - loss: 359268.8137 - val_loss: 311418.9487\n",
      "Epoch 980/1000\n",
      "133/133 [==============================] - 0s - loss: 370691.9684 - val_loss: 235632.6585\n",
      "Epoch 981/1000\n",
      "133/133 [==============================] - 0s - loss: 403079.4156 - val_loss: 251485.4732\n",
      "Epoch 982/1000\n",
      "133/133 [==============================] - 0s - loss: 364447.1332 - val_loss: 278283.1696\n",
      "Epoch 983/1000\n",
      "133/133 [==============================] - 0s - loss: 292387.5638 - val_loss: 212959.7656\n",
      "Epoch 984/1000\n",
      "133/133 [==============================] - 0s - loss: 348916.4388 - val_loss: 211165.7835\n",
      "Epoch 985/1000\n",
      "133/133 [==============================] - 0s - loss: 328974.8835 - val_loss: 208827.1763\n",
      "Epoch 986/1000\n",
      "133/133 [==============================] - 0s - loss: 417096.3708 - val_loss: 172198.3304\n",
      "Epoch 987/1000\n",
      "133/133 [==============================] - 0s - loss: 424525.5784 - val_loss: 190013.4710\n",
      "Epoch 988/1000\n",
      "133/133 [==============================] - 0s - loss: 332735.7736 - val_loss: 202457.0089\n",
      "Epoch 989/1000\n",
      "133/133 [==============================] - 0s - loss: 393547.1267 - val_loss: 205651.2656\n",
      "Epoch 990/1000\n",
      "133/133 [==============================] - 0s - loss: 414963.9883 - val_loss: 176558.1674\n",
      "Epoch 991/1000\n",
      "133/133 [==============================] - 0s - loss: 418446.5270 - val_loss: 155016.3415\n",
      "Epoch 992/1000\n",
      "133/133 [==============================] - 0s - loss: 382892.1802 - val_loss: 225096.6496\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s - loss: 301197.6117 - val_loss: 220360.6763\n",
      "Epoch 994/1000\n",
      "133/133 [==============================] - 0s - loss: 338988.3718 - val_loss: 280863.0000\n",
      "Epoch 995/1000\n",
      "133/133 [==============================] - 0s - loss: 361395.3217 - val_loss: 223527.7254\n",
      "Epoch 996/1000\n",
      "133/133 [==============================] - 0s - loss: 381125.7082 - val_loss: 257967.6071\n",
      "Epoch 997/1000\n",
      "133/133 [==============================] - 0s - loss: 371786.9583 - val_loss: 163649.3929\n",
      "Epoch 998/1000\n",
      "133/133 [==============================] - 0s - loss: 417630.7631 - val_loss: 279529.1071\n",
      "Epoch 999/1000\n",
      "133/133 [==============================] - 0s - loss: 344171.9939 - val_loss: 168404.7656\n",
      "Epoch 1000/1000\n",
      "133/133 [==============================] - 0s - loss: 339320.8063 - val_loss: 195484.3594\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 1444.41516113]\n",
      "result len(data): 164\n",
      "result data.shape: (164,)\n",
      "result len(slicing): 139\n",
      "result slicing_shape: (139, 25)\n",
      "[array([5565, 2409, 2716, 1702, 2726,  761,   13, 1552, 1816, 1514, 1345,\n",
      "       1559, 1601,   51, 1527, 1514, 1774, 1723, 1934, 2030, 1931, 1161,\n",
      "       1354, 1721, 1325])]\n",
      "X_train shape: (138, 24, 1)\n",
      "y_train shape: (138,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 131 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "131/131 [==============================] - 0s - loss: 939929.7290 - val_loss: 344468.6362\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 0s - loss: 780871.5128 - val_loss: 312306.4900\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 0s - loss: 697039.9922 - val_loss: 201294.6853\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 0s - loss: 686762.6552 - val_loss: 298009.8114\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 0s - loss: 677684.7385 - val_loss: 306895.8828\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 0s - loss: 643103.0202 - val_loss: 353281.1618\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 0s - loss: 635198.1246 - val_loss: 290877.8147\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 0s - loss: 663112.9104 - val_loss: 388389.2388\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 0s - loss: 602492.6540 - val_loss: 514688.1853\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 0s - loss: 673573.8602 - val_loss: 394218.5223\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 0s - loss: 611747.7640 - val_loss: 337724.6317\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 0s - loss: 710848.4702 - val_loss: 278295.6328\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 0s - loss: 612763.8637 - val_loss: 306957.5938\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 0s - loss: 546101.5219 - val_loss: 378824.7299\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 0s - loss: 594493.0049 - val_loss: 396368.1942\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 0s - loss: 598605.5247 - val_loss: 275213.0826\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 0s - loss: 637710.3459 - val_loss: 623163.9286\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 0s - loss: 538550.5530 - val_loss: 429980.3103\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 0s - loss: 557144.5079 - val_loss: 494186.9196\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 0s - loss: 609154.0287 - val_loss: 199368.4621\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 0s - loss: 534674.7727 - val_loss: 237569.6518\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 0s - loss: 591915.7465 - val_loss: 279743.8013\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 0s - loss: 604108.1571 - val_loss: 385714.5179\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 0s - loss: 564720.0891 - val_loss: 383377.3973\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 0s - loss: 568824.7368 - val_loss: 279940.4152\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 0s - loss: 562148.5841 - val_loss: 434622.2344\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 0s - loss: 562785.2583 - val_loss: 431651.7054\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 0s - loss: 577227.9725 - val_loss: 380805.2009\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 0s - loss: 558979.1541 - val_loss: 361209.4107\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 0s - loss: 581033.5889 - val_loss: 246676.0379\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 0s - loss: 561361.6671 - val_loss: 304256.4330\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 0s - loss: 552043.2442 - val_loss: 407785.3929\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 0s - loss: 616553.5479 - val_loss: 498111.0424\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 0s - loss: 566635.6893 - val_loss: 271729.2701\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 0s - loss: 594828.3384 - val_loss: 330350.7143\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 0s - loss: 548395.0652 - val_loss: 370184.0067\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 0s - loss: 579345.8360 - val_loss: 593442.2679\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 0s - loss: 643967.9244 - val_loss: 322199.5268\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 0s - loss: 558994.2341 - val_loss: 285144.0871\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 0s - loss: 548365.8366 - val_loss: 378048.8549\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 0s - loss: 591479.4194 - val_loss: 272451.3393\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 0s - loss: 620046.7772 - val_loss: 200708.0246\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 0s - loss: 563867.4711 - val_loss: 304821.3393\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 0s - loss: 578961.0302 - val_loss: 258332.3326\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 0s - loss: 555343.0145 - val_loss: 411649.5290\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 0s - loss: 613283.6792 - val_loss: 417072.3393\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 0s - loss: 594464.0318 - val_loss: 388329.5357\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 0s - loss: 567949.3570 - val_loss: 281128.1607\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 0s - loss: 576293.7199 - val_loss: 238167.5112\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 0s - loss: 553393.1881 - val_loss: 157219.2701\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 0s - loss: 585094.2582 - val_loss: 147675.5871\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 0s - loss: 571606.2277 - val_loss: 177251.8638\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 0s - loss: 610799.3364 - val_loss: 198713.2522\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 0s - loss: 581932.9017 - val_loss: 283206.3996\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 0s - loss: 592906.5155 - val_loss: 367970.2344\n",
      "Epoch 56/1000\n",
      "131/131 [==============================] - 0s - loss: 590170.2560 - val_loss: 379547.2679\n",
      "Epoch 57/1000\n",
      "131/131 [==============================] - 0s - loss: 605589.1257 - val_loss: 403388.8973\n",
      "Epoch 58/1000\n",
      "131/131 [==============================] - 0s - loss: 663715.2793 - val_loss: 290087.8750\n",
      "Epoch 59/1000\n",
      "131/131 [==============================] - 0s - loss: 614666.2154 - val_loss: 271337.6540\n",
      "Epoch 60/1000\n",
      "131/131 [==============================] - 0s - loss: 608274.1654 - val_loss: 168592.9129\n",
      "Epoch 61/1000\n",
      "131/131 [==============================] - 0s - loss: 574789.3034 - val_loss: 235636.4509\n",
      "Epoch 62/1000\n",
      "131/131 [==============================] - 0s - loss: 563869.7890 - val_loss: 162876.5000\n",
      "Epoch 63/1000\n",
      "131/131 [==============================] - 0s - loss: 528175.9058 - val_loss: 143580.8237\n",
      "Epoch 64/1000\n",
      "131/131 [==============================] - 0s - loss: 578569.7245 - val_loss: 277347.0312\n",
      "Epoch 65/1000\n",
      "131/131 [==============================] - 0s - loss: 547185.5451 - val_loss: 256003.5089\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 645716.1929 - val_loss: 265776.6942\n",
      "Epoch 67/1000\n",
      "131/131 [==============================] - 0s - loss: 528171.3638 - val_loss: 355797.7946\n",
      "Epoch 68/1000\n",
      "131/131 [==============================] - 0s - loss: 573491.4115 - val_loss: 522710.1562\n",
      "Epoch 69/1000\n",
      "131/131 [==============================] - 0s - loss: 568172.8022 - val_loss: 243322.4308\n",
      "Epoch 70/1000\n",
      "131/131 [==============================] - 0s - loss: 531125.8019 - val_loss: 223256.0714\n",
      "Epoch 71/1000\n",
      "131/131 [==============================] - 0s - loss: 546089.3210 - val_loss: 266462.9085\n",
      "Epoch 72/1000\n",
      "131/131 [==============================] - 0s - loss: 570468.6292 - val_loss: 297258.4219\n",
      "Epoch 73/1000\n",
      "131/131 [==============================] - 0s - loss: 510747.8193 - val_loss: 245944.6719\n",
      "Epoch 74/1000\n",
      "131/131 [==============================] - 0s - loss: 524950.2018 - val_loss: 390717.9420\n",
      "Epoch 75/1000\n",
      "131/131 [==============================] - 0s - loss: 516960.5349 - val_loss: 587187.3661\n",
      "Epoch 76/1000\n",
      "131/131 [==============================] - 0s - loss: 560823.8601 - val_loss: 419648.7455\n",
      "Epoch 77/1000\n",
      "131/131 [==============================] - 0s - loss: 568593.4386 - val_loss: 339749.8147\n",
      "Epoch 78/1000\n",
      "131/131 [==============================] - 0s - loss: 490998.9808 - val_loss: 258054.5223\n",
      "Epoch 79/1000\n",
      "131/131 [==============================] - 0s - loss: 496326.3175 - val_loss: 348189.4196\n",
      "Epoch 80/1000\n",
      "131/131 [==============================] - 0s - loss: 551931.5742 - val_loss: 301620.6295\n",
      "Epoch 81/1000\n",
      "131/131 [==============================] - 0s - loss: 591334.0861 - val_loss: 266657.6987\n",
      "Epoch 82/1000\n",
      "131/131 [==============================] - 0s - loss: 545165.7758 - val_loss: 212543.0804\n",
      "Epoch 83/1000\n",
      "131/131 [==============================] - 0s - loss: 511244.1865 - val_loss: 503653.5045\n",
      "Epoch 84/1000\n",
      "131/131 [==============================] - 0s - loss: 583386.0348 - val_loss: 319654.2902\n",
      "Epoch 85/1000\n",
      "131/131 [==============================] - 0s - loss: 516939.3083 - val_loss: 311640.76799081.\n",
      "Epoch 86/1000\n",
      "131/131 [==============================] - 0s - loss: 575188.8437 - val_loss: 160989.2500\n",
      "Epoch 87/1000\n",
      "131/131 [==============================] - 0s - loss: 569160.8048 - val_loss: 190767.5469\n",
      "Epoch 88/1000\n",
      "131/131 [==============================] - 0s - loss: 555245.7841 - val_loss: 147753.0179\n",
      "Epoch 89/1000\n",
      "131/131 [==============================] - 0s - loss: 491697.5735 - val_loss: 178245.8438\n",
      "Epoch 90/1000\n",
      "131/131 [==============================] - 0s - loss: 583572.7724 - val_loss: 225549.2991\n",
      "Epoch 91/1000\n",
      "131/131 [==============================] - 0s - loss: 560784.7750 - val_loss: 181555.8482\n",
      "Epoch 92/1000\n",
      "131/131 [==============================] - 0s - loss: 517031.1906 - val_loss: 417161.1786\n",
      "Epoch 93/1000\n",
      "131/131 [==============================] - 0s - loss: 514196.5565 - val_loss: 195157.8080\n",
      "Epoch 94/1000\n",
      "131/131 [==============================] - 0s - loss: 555029.9027 - val_loss: 185065.1205\n",
      "Epoch 95/1000\n",
      "131/131 [==============================] - 0s - loss: 532798.3992 - val_loss: 391006.9420\n",
      "Epoch 96/1000\n",
      "131/131 [==============================] - 0s - loss: 520243.0571 - val_loss: 325239.6027\n",
      "Epoch 97/1000\n",
      "131/131 [==============================] - 0s - loss: 487277.2606 - val_loss: 358550.9152\n",
      "Epoch 98/1000\n",
      "131/131 [==============================] - 0s - loss: 534218.8179 - val_loss: 553596.1875\n",
      "Epoch 99/1000\n",
      "131/131 [==============================] - 0s - loss: 586265.3529 - val_loss: 384730.1920\n",
      "Epoch 100/1000\n",
      "131/131 [==============================] - 0s - loss: 506770.0858 - val_loss: 585335.6786\n",
      "Epoch 101/1000\n",
      "131/131 [==============================] - 0s - loss: 538170.1795 - val_loss: 271435.4509\n",
      "Epoch 102/1000\n",
      "131/131 [==============================] - 0s - loss: 474516.2367 - val_loss: 252962.0357\n",
      "Epoch 103/1000\n",
      "131/131 [==============================] - 0s - loss: 493746.3020 - val_loss: 364902.4420\n",
      "Epoch 104/1000\n",
      "131/131 [==============================] - 0s - loss: 529460.7488 - val_loss: 242867.2366\n",
      "Epoch 105/1000\n",
      "131/131 [==============================] - 0s - loss: 587284.1560 - val_loss: 229376.0670\n",
      "Epoch 106/1000\n",
      "131/131 [==============================] - 0s - loss: 544151.8404 - val_loss: 261191.0982\n",
      "Epoch 107/1000\n",
      "131/131 [==============================] - 0s - loss: 514957.3097 - val_loss: 611948.7946\n",
      "Epoch 108/1000\n",
      "131/131 [==============================] - 0s - loss: 499254.5768 - val_loss: 200623.2545\n",
      "Epoch 109/1000\n",
      "131/131 [==============================] - 0s - loss: 470947.1090 - val_loss: 184348.4018\n",
      "Epoch 110/1000\n",
      "131/131 [==============================] - 0s - loss: 521191.5649 - val_loss: 175550.6473\n",
      "Epoch 111/1000\n",
      "131/131 [==============================] - 0s - loss: 484953.7207 - val_loss: 354219.6473\n",
      "Epoch 112/1000\n",
      "131/131 [==============================] - 0s - loss: 507755.9176 - val_loss: 193568.7321\n",
      "Epoch 113/1000\n",
      "131/131 [==============================] - 0s - loss: 484955.6792 - val_loss: 338752.3839\n",
      "Epoch 114/1000\n",
      "131/131 [==============================] - 0s - loss: 555145.7548 - val_loss: 333321.3080\n",
      "Epoch 115/1000\n",
      "131/131 [==============================] - 0s - loss: 508317.9336 - val_loss: 163365.4286\n",
      "Epoch 116/1000\n",
      "131/131 [==============================] - 0s - loss: 468953.1333 - val_loss: 216494.4688\n",
      "Epoch 117/1000\n",
      "131/131 [==============================] - 0s - loss: 500269.9999 - val_loss: 177459.3080\n",
      "Epoch 118/1000\n",
      "131/131 [==============================] - 0s - loss: 516775.6791 - val_loss: 347941.0134\n",
      "Epoch 119/1000\n",
      "131/131 [==============================] - 0s - loss: 541013.9596 - val_loss: 191910.4062\n",
      "Epoch 120/1000\n",
      "131/131 [==============================] - 0s - loss: 502765.0360 - val_loss: 418493.2143\n",
      "Epoch 121/1000\n",
      "131/131 [==============================] - 0s - loss: 532557.5654 - val_loss: 259611.0804\n",
      "Epoch 122/1000\n",
      "131/131 [==============================] - 0s - loss: 500833.2962 - val_loss: 345753.8170\n",
      "Epoch 123/1000\n",
      "131/131 [==============================] - 0s - loss: 497557.3179 - val_loss: 191572.4509\n",
      "Epoch 124/1000\n",
      "131/131 [==============================] - 0s - loss: 505845.1430 - val_loss: 227727.8482\n",
      "Epoch 125/1000\n",
      "131/131 [==============================] - 0s - loss: 495210.6163 - val_loss: 198267.5804\n",
      "Epoch 126/1000\n",
      "131/131 [==============================] - 0s - loss: 529696.8010 - val_loss: 185338.0580\n",
      "Epoch 127/1000\n",
      "131/131 [==============================] - 0s - loss: 469049.4039 - val_loss: 195622.3929\n",
      "Epoch 128/1000\n",
      "131/131 [==============================] - 0s - loss: 495691.6650 - val_loss: 251501.4420\n",
      "Epoch 129/1000\n",
      "131/131 [==============================] - 0s - loss: 497680.0871 - val_loss: 187564.6295\n",
      "Epoch 130/1000\n",
      "131/131 [==============================] - 0s - loss: 499642.0023 - val_loss: 179765.3839\n",
      "Epoch 131/1000\n",
      "131/131 [==============================] - 0s - loss: 505316.3552 - val_loss: 248530.2946\n",
      "Epoch 132/1000\n",
      "131/131 [==============================] - 0s - loss: 469809.7419 - val_loss: 278180.7545\n",
      "Epoch 133/1000\n",
      "131/131 [==============================] - 0s - loss: 500562.9872 - val_loss: 272586.2054\n",
      "Epoch 134/1000\n",
      "131/131 [==============================] - 0s - loss: 514234.1031 - val_loss: 217228.1384\n",
      "Epoch 135/1000\n",
      "131/131 [==============================] - 0s - loss: 502101.8621 - val_loss: 267456.7455\n",
      "Epoch 136/1000\n",
      "131/131 [==============================] - 0s - loss: 468972.0224 - val_loss: 210040.5625\n",
      "Epoch 137/1000\n",
      "131/131 [==============================] - 0s - loss: 478196.8392 - val_loss: 214711.8214\n",
      "Epoch 138/1000\n",
      "131/131 [==============================] - 0s - loss: 481127.3688 - val_loss: 257683.4554\n",
      "Epoch 139/1000\n",
      "131/131 [==============================] - 0s - loss: 468024.6019 - val_loss: 198164.8214\n",
      "Epoch 140/1000\n",
      "131/131 [==============================] - 0s - loss: 484251.5368 - val_loss: 236639.2723\n",
      "Epoch 141/1000\n",
      "131/131 [==============================] - 0s - loss: 479673.5885 - val_loss: 265714.2589\n",
      "Epoch 142/1000\n",
      "131/131 [==============================] - 0s - loss: 524394.1087 - val_loss: 247833.7188\n",
      "Epoch 143/1000\n",
      "131/131 [==============================] - 0s - loss: 515789.7244 - val_loss: 176434.9821\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 520978.7588 - val_loss: 236203.9107\n",
      "Epoch 145/1000\n",
      "131/131 [==============================] - 0s - loss: 504997.6464 - val_loss: 186825.8705\n",
      "Epoch 146/1000\n",
      "131/131 [==============================] - 0s - loss: 527615.9742 - val_loss: 311785.5714\n",
      "Epoch 147/1000\n",
      "131/131 [==============================] - 0s - loss: 513773.9294 - val_loss: 171575.1362\n",
      "Epoch 148/1000\n",
      "131/131 [==============================] - 0s - loss: 492060.9758 - val_loss: 195377.6964\n",
      "Epoch 149/1000\n",
      "131/131 [==============================] - 0s - loss: 513693.5561 - val_loss: 167838.8884\n",
      "Epoch 150/1000\n",
      "131/131 [==============================] - 0s - loss: 469699.4789 - val_loss: 243086.7768\n",
      "Epoch 151/1000\n",
      "131/131 [==============================] - 0s - loss: 515723.3539 - val_loss: 180184.1920\n",
      "Epoch 152/1000\n",
      "131/131 [==============================] - 0s - loss: 516840.5062 - val_loss: 154815.6875\n",
      "Epoch 153/1000\n",
      "131/131 [==============================] - 0s - loss: 546672.1271 - val_loss: 159391.5893\n",
      "Epoch 154/1000\n",
      "131/131 [==============================] - 0s - loss: 508152.2780 - val_loss: 164882.1562\n",
      "Epoch 155/1000\n",
      "131/131 [==============================] - 0s - loss: 461331.8239 - val_loss: 198264.8304\n",
      "Epoch 156/1000\n",
      "131/131 [==============================] - 0s - loss: 481897.8405 - val_loss: 282619.9509\n",
      "Epoch 157/1000\n",
      "131/131 [==============================] - 0s - loss: 466810.5375 - val_loss: 222616.5759\n",
      "Epoch 158/1000\n",
      "131/131 [==============================] - 0s - loss: 510741.8326 - val_loss: 198822.4420\n",
      "Epoch 159/1000\n",
      "131/131 [==============================] - 0s - loss: 487252.8717 - val_loss: 252422.4464\n",
      "Epoch 160/1000\n",
      "131/131 [==============================] - 0s - loss: 534017.2771 - val_loss: 225072.5000\n",
      "Epoch 161/1000\n",
      "131/131 [==============================] - 0s - loss: 537531.2754 - val_loss: 230282.0268\n",
      "Epoch 162/1000\n",
      "131/131 [==============================] - 0s - loss: 583819.0034 - val_loss: 185045.9911\n",
      "Epoch 163/1000\n",
      "131/131 [==============================] - 0s - loss: 570535.8663 - val_loss: 273431.8125\n",
      "Epoch 164/1000\n",
      "131/131 [==============================] - 0s - loss: 480348.9378 - val_loss: 338090.9286\n",
      "Epoch 165/1000\n",
      "131/131 [==============================] - 0s - loss: 496732.2385 - val_loss: 174609.8438\n",
      "Epoch 166/1000\n",
      "131/131 [==============================] - 0s - loss: 463818.4224 - val_loss: 242217.0893\n",
      "Epoch 167/1000\n",
      "131/131 [==============================] - 0s - loss: 514300.8177 - val_loss: 253879.2321\n",
      "Epoch 168/1000\n",
      "131/131 [==============================] - 0s - loss: 502986.6759 - val_loss: 238514.0893\n",
      "Epoch 169/1000\n",
      "131/131 [==============================] - 0s - loss: 530482.5936 - val_loss: 219984.8393\n",
      "Epoch 170/1000\n",
      "131/131 [==============================] - 0s - loss: 598388.9738 - val_loss: 256527.0804\n",
      "Epoch 171/1000\n",
      "131/131 [==============================] - 0s - loss: 476259.3856 - val_loss: 213777.9866\n",
      "Epoch 172/1000\n",
      "131/131 [==============================] - 0s - loss: 464234.3808 - val_loss: 200143.7991\n",
      "Epoch 173/1000\n",
      "131/131 [==============================] - 0s - loss: 488133.1823 - val_loss: 220760.3438\n",
      "Epoch 174/1000\n",
      "131/131 [==============================] - 0s - loss: 470262.0437 - val_loss: 179901.1964\n",
      "Epoch 175/1000\n",
      "131/131 [==============================] - 0s - loss: 483585.3891 - val_loss: 206042.5357\n",
      "Epoch 176/1000\n",
      "131/131 [==============================] - 0s - loss: 470892.5776 - val_loss: 257434.3929\n",
      "Epoch 177/1000\n",
      "131/131 [==============================] - 0s - loss: 538417.6275 - val_loss: 478205.2589\n",
      "Epoch 178/1000\n",
      "131/131 [==============================] - 0s - loss: 558944.7117 - val_loss: 231579.6071\n",
      "Epoch 179/1000\n",
      "131/131 [==============================] - 0s - loss: 503978.5811 - val_loss: 208068.0804\n",
      "Epoch 180/1000\n",
      "131/131 [==============================] - 0s - loss: 461391.4630 - val_loss: 205089.7009\n",
      "Epoch 181/1000\n",
      "131/131 [==============================] - 0s - loss: 489411.7429 - val_loss: 217593.4107\n",
      "Epoch 182/1000\n",
      "131/131 [==============================] - 0s - loss: 459225.4484 - val_loss: 194743.0089\n",
      "Epoch 183/1000\n",
      "131/131 [==============================] - 0s - loss: 494422.2304 - val_loss: 207582.4598\n",
      "Epoch 184/1000\n",
      "131/131 [==============================] - 0s - loss: 522171.7627 - val_loss: 168747.3326\n",
      "Epoch 185/1000\n",
      "131/131 [==============================] - 0s - loss: 472910.4345 - val_loss: 194532.2411\n",
      "Epoch 186/1000\n",
      "131/131 [==============================] - 0s - loss: 521944.0029 - val_loss: 371626.2812\n",
      "Epoch 187/1000\n",
      "131/131 [==============================] - 0s - loss: 564503.7155 - val_loss: 196785.1116\n",
      "Epoch 188/1000\n",
      "131/131 [==============================] - 0s - loss: 524729.6752 - val_loss: 189735.7902\n",
      "Epoch 189/1000\n",
      "131/131 [==============================] - 0s - loss: 478959.0429 - val_loss: 213005.8348\n",
      "Epoch 190/1000\n",
      "131/131 [==============================] - 0s - loss: 572062.1011 - val_loss: 344597.3304\n",
      "Epoch 191/1000\n",
      "131/131 [==============================] - 0s - loss: 627596.1485 - val_loss: 263540.4576\n",
      "Epoch 192/1000\n",
      "131/131 [==============================] - 0s - loss: 557936.1445 - val_loss: 373969.4219\n",
      "Epoch 193/1000\n",
      "131/131 [==============================] - 0s - loss: 584697.3476 - val_loss: 279561.6875\n",
      "Epoch 194/1000\n",
      "131/131 [==============================] - 0s - loss: 518445.1904 - val_loss: 416407.6674\n",
      "Epoch 195/1000\n",
      "131/131 [==============================] - 0s - loss: 430568.8259 - val_loss: 222976.0759\n",
      "Epoch 196/1000\n",
      "131/131 [==============================] - 0s - loss: 476475.9130 - val_loss: 239612.4688\n",
      "Epoch 197/1000\n",
      "131/131 [==============================] - 0s - loss: 463049.5488 - val_loss: 264667.3750\n",
      "Epoch 198/1000\n",
      "131/131 [==============================] - 0s - loss: 498674.2320 - val_loss: 209266.8214\n",
      "Epoch 199/1000\n",
      "131/131 [==============================] - 0s - loss: 546942.2854 - val_loss: 391285.6295\n",
      "Epoch 200/1000\n",
      "131/131 [==============================] - 0s - loss: 477415.5862 - val_loss: 300246.7679\n",
      "Epoch 201/1000\n",
      "131/131 [==============================] - 0s - loss: 536625.5614 - val_loss: 296843.1518\n",
      "Epoch 202/1000\n",
      "131/131 [==============================] - 0s - loss: 542637.6475 - val_loss: 362660.4777\n",
      "Epoch 203/1000\n",
      "131/131 [==============================] - 0s - loss: 514887.9766 - val_loss: 211911.5580\n",
      "Epoch 204/1000\n",
      "131/131 [==============================] - 0s - loss: 573629.9827 - val_loss: 293602.2009\n",
      "Epoch 205/1000\n",
      "131/131 [==============================] - 0s - loss: 496472.0166 - val_loss: 210817.2143\n",
      "Epoch 206/1000\n",
      "131/131 [==============================] - 0s - loss: 590991.7432 - val_loss: 243374.8393\n",
      "Epoch 207/1000\n",
      "131/131 [==============================] - 0s - loss: 481994.9943 - val_loss: 226780.0982\n",
      "Epoch 208/1000\n",
      "131/131 [==============================] - 0s - loss: 480845.0338 - val_loss: 217651.4464\n",
      "Epoch 209/1000\n",
      "131/131 [==============================] - 0s - loss: 477539.8177 - val_loss: 207480.3259\n",
      "Epoch 210/1000\n",
      "131/131 [==============================] - 0s - loss: 473637.1208 - val_loss: 344471.2902\n",
      "Epoch 211/1000\n",
      "131/131 [==============================] - 0s - loss: 540582.0895 - val_loss: 291879.8304\n",
      "Epoch 212/1000\n",
      "131/131 [==============================] - 0s - loss: 513281.3504 - val_loss: 221783.9241\n",
      "Epoch 213/1000\n",
      "131/131 [==============================] - 0s - loss: 522109.5392 - val_loss: 365068.7098\n",
      "Epoch 214/1000\n",
      "131/131 [==============================] - 0s - loss: 494515.4919 - val_loss: 181780.2679\n",
      "Epoch 215/1000\n",
      "131/131 [==============================] - 0s - loss: 429767.3341 - val_loss: 253156.5045\n",
      "Epoch 216/1000\n",
      "131/131 [==============================] - 0s - loss: 457762.4945 - val_loss: 192907.0312\n",
      "Epoch 217/1000\n",
      "131/131 [==============================] - 0s - loss: 466556.5651 - val_loss: 181523.4688\n",
      "Epoch 218/1000\n",
      "131/131 [==============================] - 0s - loss: 480908.5128 - val_loss: 211838.6741\n",
      "Epoch 219/1000\n",
      "131/131 [==============================] - 0s - loss: 576322.6503 - val_loss: 198213.9732\n",
      "Epoch 220/1000\n",
      "131/131 [==============================] - 0s - loss: 489526.5034 - val_loss: 189862.3616\n",
      "Epoch 221/1000\n",
      "131/131 [==============================] - 0s - loss: 492226.5981 - val_loss: 214053.7545\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 485402.0425 - val_loss: 201786.0625\n",
      "Epoch 223/1000\n",
      "131/131 [==============================] - 0s - loss: 521197.9637 - val_loss: 223085.3884\n",
      "Epoch 224/1000\n",
      "131/131 [==============================] - 0s - loss: 492621.3203 - val_loss: 205789.2098\n",
      "Epoch 225/1000\n",
      "131/131 [==============================] - 0s - loss: 487522.7748 - val_loss: 219643.0402\n",
      "Epoch 226/1000\n",
      "131/131 [==============================] - 0s - loss: 486249.2407 - val_loss: 218988.4375\n",
      "Epoch 227/1000\n",
      "131/131 [==============================] - 0s - loss: 583233.0124 - val_loss: 236569.3080\n",
      "Epoch 228/1000\n",
      "131/131 [==============================] - 0s - loss: 479517.6418 - val_loss: 269115.4554\n",
      "Epoch 229/1000\n",
      "131/131 [==============================] - 0s - loss: 551453.0270 - val_loss: 294836.2143\n",
      "Epoch 230/1000\n",
      "131/131 [==============================] - 0s - loss: 489475.6407 - val_loss: 218577.66078192. - ETA: 0s - loss: 494182.98\n",
      "Epoch 231/1000\n",
      "131/131 [==============================] - 0s - loss: 459972.7829 - val_loss: 220192.9554\n",
      "Epoch 232/1000\n",
      "131/131 [==============================] - 0s - loss: 492278.9287 - val_loss: 218433.7366\n",
      "Epoch 233/1000\n",
      "131/131 [==============================] - 0s - loss: 476738.9588 - val_loss: 282165.6741\n",
      "Epoch 234/1000\n",
      "131/131 [==============================] - 0s - loss: 470020.2130 - val_loss: 228708.4688\n",
      "Epoch 235/1000\n",
      "131/131 [==============================] - 0s - loss: 466026.9034 - val_loss: 189851.8214\n",
      "Epoch 236/1000\n",
      "131/131 [==============================] - 0s - loss: 527242.1650 - val_loss: 273973.5134\n",
      "Epoch 237/1000\n",
      "131/131 [==============================] - 0s - loss: 505617.9143 - val_loss: 228320.3929\n",
      "Epoch 238/1000\n",
      "131/131 [==============================] - 0s - loss: 488499.2579 - val_loss: 195302.5268\n",
      "Epoch 239/1000\n",
      "131/131 [==============================] - 0s - loss: 468443.3508 - val_loss: 209876.8259\n",
      "Epoch 240/1000\n",
      "131/131 [==============================] - 0s - loss: 417884.9003 - val_loss: 188347.4732\n",
      "Epoch 241/1000\n",
      "131/131 [==============================] - 0s - loss: 476437.2521 - val_loss: 196158.9598\n",
      "Epoch 242/1000\n",
      "131/131 [==============================] - 0s - loss: 456741.6008 - val_loss: 211975.6429\n",
      "Epoch 243/1000\n",
      "131/131 [==============================] - 0s - loss: 501191.8204 - val_loss: 227910.1786\n",
      "Epoch 244/1000\n",
      "131/131 [==============================] - 0s - loss: 505451.2734 - val_loss: 232903.9688\n",
      "Epoch 245/1000\n",
      "131/131 [==============================] - 0s - loss: 481360.2353 - val_loss: 206745.9420\n",
      "Epoch 246/1000\n",
      "131/131 [==============================] - 0s - loss: 499727.3101 - val_loss: 212438.3036\n",
      "Epoch 247/1000\n",
      "131/131 [==============================] - 0s - loss: 555866.0351 - val_loss: 302605.0134\n",
      "Epoch 248/1000\n",
      "131/131 [==============================] - 0s - loss: 441591.2447 - val_loss: 219773.20093159.\n",
      "Epoch 249/1000\n",
      "131/131 [==============================] - 0s - loss: 495816.7753 - val_loss: 226498.9152\n",
      "Epoch 250/1000\n",
      "131/131 [==============================] - 0s - loss: 531108.7533 - val_loss: 377652.3393\n",
      "Epoch 251/1000\n",
      "131/131 [==============================] - 0s - loss: 502882.6312 - val_loss: 341261.5089\n",
      "Epoch 252/1000\n",
      "131/131 [==============================] - 0s - loss: 556423.7517 - val_loss: 560880.6607\n",
      "Epoch 253/1000\n",
      "131/131 [==============================] - 0s - loss: 529698.0441 - val_loss: 597414.0179\n",
      "Epoch 254/1000\n",
      "131/131 [==============================] - 0s - loss: 613141.2215 - val_loss: 776392.7054\n",
      "Epoch 255/1000\n",
      "131/131 [==============================] - 0s - loss: 483646.3657 - val_loss: 204199.6205\n",
      "Epoch 256/1000\n",
      "131/131 [==============================] - 0s - loss: 517009.3746 - val_loss: 279572.9420\n",
      "Epoch 257/1000\n",
      "131/131 [==============================] - 0s - loss: 561263.8162 - val_loss: 329210.2232\n",
      "Epoch 258/1000\n",
      "131/131 [==============================] - 0s - loss: 458648.6750 - val_loss: 251813.1652\n",
      "Epoch 259/1000\n",
      "131/131 [==============================] - 0s - loss: 544840.4946 - val_loss: 252987.2232\n",
      "Epoch 260/1000\n",
      "131/131 [==============================] - 0s - loss: 444117.6359 - val_loss: 607100.0089\n",
      "Epoch 261/1000\n",
      "131/131 [==============================] - 0s - loss: 533453.2657 - val_loss: 620320.1964\n",
      "Epoch 262/1000\n",
      "131/131 [==============================] - 0s - loss: 541471.6759 - val_loss: 584644.8304\n",
      "Epoch 263/1000\n",
      "131/131 [==============================] - 0s - loss: 779956.2830 - val_loss: 106900.5949\n",
      "Epoch 264/1000\n",
      "131/131 [==============================] - 0s - loss: 722370.0596 - val_loss: 235412.1596\n",
      "Epoch 265/1000\n",
      "131/131 [==============================] - 0s - loss: 693351.7498 - val_loss: 444728.6272\n",
      "Epoch 266/1000\n",
      "131/131 [==============================] - 0s - loss: 646551.3725 - val_loss: 533009.2879\n",
      "Epoch 267/1000\n",
      "131/131 [==============================] - 0s - loss: 575791.4401 - val_loss: 569652.3304\n",
      "Epoch 268/1000\n",
      "131/131 [==============================] - 0s - loss: 565324.2916 - val_loss: 532702.50896959.\n",
      "Epoch 269/1000\n",
      "131/131 [==============================] - 0s - loss: 635466.0045 - val_loss: 516476.3371\n",
      "Epoch 270/1000\n",
      "131/131 [==============================] - 0s - loss: 579999.0391 - val_loss: 490597.9286\n",
      "Epoch 271/1000\n",
      "131/131 [==============================] - 0s - loss: 556107.2714 - val_loss: 439566.3036\n",
      "Epoch 272/1000\n",
      "131/131 [==============================] - 0s - loss: 555701.9506 - val_loss: 425856.6071\n",
      "Epoch 273/1000\n",
      "131/131 [==============================] - 0s - loss: 590419.8222 - val_loss: 318758.1607\n",
      "Epoch 274/1000\n",
      "131/131 [==============================] - 0s - loss: 611645.6418 - val_loss: 274543.6261\n",
      "Epoch 275/1000\n",
      "131/131 [==============================] - 0s - loss: 617904.9309 - val_loss: 553994.4732\n",
      "Epoch 276/1000\n",
      "131/131 [==============================] - 0s - loss: 546695.4185 - val_loss: 348775.9464\n",
      "Epoch 277/1000\n",
      "131/131 [==============================] - 0s - loss: 528486.9699 - val_loss: 345593.5714\n",
      "Epoch 278/1000\n",
      "131/131 [==============================] - 0s - loss: 462784.6071 - val_loss: 323937.6875\n",
      "Epoch 279/1000\n",
      "131/131 [==============================] - 0s - loss: 562704.1131 - val_loss: 545942.6875\n",
      "Epoch 280/1000\n",
      "131/131 [==============================] - 0s - loss: 541771.3296 - val_loss: 332735.4643\n",
      "Epoch 281/1000\n",
      "131/131 [==============================] - 0s - loss: 484190.6586 - val_loss: 408886.5045\n",
      "Epoch 282/1000\n",
      "131/131 [==============================] - 0s - loss: 518350.2495 - val_loss: 550956.6518\n",
      "Epoch 283/1000\n",
      "131/131 [==============================] - 0s - loss: 592319.2222 - val_loss: 415329.1696\n",
      "Epoch 284/1000\n",
      "131/131 [==============================] - 0s - loss: 544994.4860 - val_loss: 559144.1295\n",
      "Epoch 285/1000\n",
      "131/131 [==============================] - 0s - loss: 566371.9607 - val_loss: 374032.6696\n",
      "Epoch 286/1000\n",
      "131/131 [==============================] - 0s - loss: 533052.3814 - val_loss: 272194.0536\n",
      "Epoch 287/1000\n",
      "131/131 [==============================] - 0s - loss: 544322.1121 - val_loss: 349255.7054\n",
      "Epoch 288/1000\n",
      "131/131 [==============================] - 0s - loss: 467166.3288 - val_loss: 382603.1518\n",
      "Epoch 289/1000\n",
      "131/131 [==============================] - 0s - loss: 485222.3820 - val_loss: 282257.5089\n",
      "Epoch 290/1000\n",
      "131/131 [==============================] - 0s - loss: 603315.7698 - val_loss: 276364.4152\n",
      "Epoch 291/1000\n",
      "131/131 [==============================] - 0s - loss: 507184.4948 - val_loss: 581841.2946\n",
      "Epoch 292/1000\n",
      "131/131 [==============================] - 0s - loss: 546505.0688 - val_loss: 637181.5893\n",
      "Epoch 293/1000\n",
      "131/131 [==============================] - 0s - loss: 485611.8615 - val_loss: 307814.5268\n",
      "Epoch 294/1000\n",
      "131/131 [==============================] - 0s - loss: 497856.6381 - val_loss: 311087.4464\n",
      "Epoch 295/1000\n",
      "131/131 [==============================] - 0s - loss: 525079.9742 - val_loss: 237077.7054\n",
      "Epoch 296/1000\n",
      "131/131 [==============================] - 0s - loss: 487862.6392 - val_loss: 227508.2188\n",
      "Epoch 297/1000\n",
      "131/131 [==============================] - 0s - loss: 564462.8726 - val_loss: 402188.37959998.\n",
      "Epoch 298/1000\n",
      "131/131 [==============================] - 0s - loss: 505050.4436 - val_loss: 237835.4062\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 480747.5423 - val_loss: 273012.2411\n",
      "Epoch 300/1000\n",
      "131/131 [==============================] - 0s - loss: 507566.1687 - val_loss: 307811.4018\n",
      "Epoch 301/1000\n",
      "131/131 [==============================] - 0s - loss: 552219.2498 - val_loss: 256376.80808141.\n",
      "Epoch 302/1000\n",
      "131/131 [==============================] - 0s - loss: 589437.3898 - val_loss: 259961.8482\n",
      "Epoch 303/1000\n",
      "131/131 [==============================] - 0s - loss: 589155.1244 - val_loss: 134394.8996\n",
      "Epoch 304/1000\n",
      "131/131 [==============================] - 0s - loss: 689278.6720 - val_loss: 557735.8571\n",
      "Epoch 305/1000\n",
      "131/131 [==============================] - 0s - loss: 575585.6412 - val_loss: 233625.6429\n",
      "Epoch 306/1000\n",
      "131/131 [==============================] - 0s - loss: 496644.8133 - val_loss: 601078.98213400.96\n",
      "Epoch 307/1000\n",
      "131/131 [==============================] - 0s - loss: 472263.4079 - val_loss: 229848.7232\n",
      "Epoch 308/1000\n",
      "131/131 [==============================] - 0s - loss: 528027.1920 - val_loss: 261913.6161\n",
      "Epoch 309/1000\n",
      "131/131 [==============================] - 0s - loss: 478195.6999 - val_loss: 230076.1920\n",
      "Epoch 310/1000\n",
      "131/131 [==============================] - 0s - loss: 453846.2180 - val_loss: 264639.1964\n",
      "Epoch 311/1000\n",
      "131/131 [==============================] - 0s - loss: 473236.6177 - val_loss: 239760.0402\n",
      "Epoch 312/1000\n",
      "131/131 [==============================] - 0s - loss: 501173.6758 - val_loss: 244869.2857\n",
      "Epoch 313/1000\n",
      "131/131 [==============================] - 0s - loss: 571896.4106 - val_loss: 265988.8438\n",
      "Epoch 314/1000\n",
      "131/131 [==============================] - 0s - loss: 582772.6715 - val_loss: 309656.1830\n",
      "Epoch 315/1000\n",
      "131/131 [==============================] - 0s - loss: 530381.3841 - val_loss: 568907.0670\n",
      "Epoch 316/1000\n",
      "131/131 [==============================] - 0s - loss: 494472.6589 - val_loss: 317658.8348\n",
      "Epoch 317/1000\n",
      "131/131 [==============================] - 0s - loss: 572788.9084 - val_loss: 315989.6875\n",
      "Epoch 318/1000\n",
      "131/131 [==============================] - 0s - loss: 495195.1461 - val_loss: 537474.7277\n",
      "Epoch 319/1000\n",
      "131/131 [==============================] - 0s - loss: 523496.1879 - val_loss: 261926.7411\n",
      "Epoch 320/1000\n",
      "131/131 [==============================] - 0s - loss: 561476.9611 - val_loss: 572658.0670\n",
      "Epoch 321/1000\n",
      "131/131 [==============================] - 0s - loss: 558414.9098 - val_loss: 260091.1964\n",
      "Epoch 322/1000\n",
      "131/131 [==============================] - 0s - loss: 566005.5710 - val_loss: 303295.7054\n",
      "Epoch 323/1000\n",
      "131/131 [==============================] - 0s - loss: 462009.4233 - val_loss: 299408.6250\n",
      "Epoch 324/1000\n",
      "131/131 [==============================] - 0s - loss: 552007.4407 - val_loss: 622170.9509\n",
      "Epoch 325/1000\n",
      "131/131 [==============================] - 0s - loss: 547827.2307 - val_loss: 540455.8281\n",
      "Epoch 326/1000\n",
      "131/131 [==============================] - 0s - loss: 600853.6311 - val_loss: 337293.7366\n",
      "Epoch 327/1000\n",
      "131/131 [==============================] - 0s - loss: 554579.3642 - val_loss: 617925.5893\n",
      "Epoch 328/1000\n",
      "131/131 [==============================] - 0s - loss: 527729.7527 - val_loss: 637046.1786\n",
      "Epoch 329/1000\n",
      "131/131 [==============================] - 0s - loss: 542011.5061 - val_loss: 563564.7946\n",
      "Epoch 330/1000\n",
      "131/131 [==============================] - 0s - loss: 603650.2286 - val_loss: 551381.2991\n",
      "Epoch 331/1000\n",
      "131/131 [==============================] - 0s - loss: 598583.9973 - val_loss: 590463.4196\n",
      "Epoch 332/1000\n",
      "131/131 [==============================] - 0s - loss: 544906.3182 - val_loss: 582983.0714\n",
      "Epoch 333/1000\n",
      "131/131 [==============================] - 0s - loss: 564022.9709 - val_loss: 606950.0714\n",
      "Epoch 334/1000\n",
      "131/131 [==============================] - 0s - loss: 491766.0242 - val_loss: 684564.0089\n",
      "Epoch 335/1000\n",
      "131/131 [==============================] - 0s - loss: 558250.9247 - val_loss: 278169.1429\n",
      "Epoch 336/1000\n",
      "131/131 [==============================] - 0s - loss: 502782.5687 - val_loss: 338641.7232\n",
      "Epoch 337/1000\n",
      "131/131 [==============================] - 0s - loss: 514323.1702 - val_loss: 345403.3839\n",
      "Epoch 338/1000\n",
      "131/131 [==============================] - 0s - loss: 552559.5580 - val_loss: 474117.0089\n",
      "Epoch 339/1000\n",
      "131/131 [==============================] - 0s - loss: 526276.5310 - val_loss: 508011.7500\n",
      "Epoch 340/1000\n",
      "131/131 [==============================] - 0s - loss: 521321.6175 - val_loss: 476663.8348\n",
      "Epoch 341/1000\n",
      "131/131 [==============================] - 0s - loss: 510018.2714 - val_loss: 284737.0179\n",
      "Epoch 342/1000\n",
      "131/131 [==============================] - 0s - loss: 533444.1166 - val_loss: 604438.5848\n",
      "Epoch 343/1000\n",
      "131/131 [==============================] - 0s - loss: 567040.2486 - val_loss: 479240.4598\n",
      "Epoch 344/1000\n",
      "131/131 [==============================] - 0s - loss: 500833.0786 - val_loss: 632898.2500\n",
      "Epoch 345/1000\n",
      "131/131 [==============================] - 0s - loss: 460781.0900 - val_loss: 545980.7411\n",
      "Epoch 346/1000\n",
      "131/131 [==============================] - 0s - loss: 503303.6449 - val_loss: 342834.3750\n",
      "Epoch 347/1000\n",
      "131/131 [==============================] - 0s - loss: 505163.0310 - val_loss: 780317.6161\n",
      "Epoch 348/1000\n",
      "131/131 [==============================] - 0s - loss: 595042.3481 - val_loss: 330822.1205\n",
      "Epoch 349/1000\n",
      "131/131 [==============================] - 0s - loss: 525304.3397 - val_loss: 324888.8571\n",
      "Epoch 350/1000\n",
      "131/131 [==============================] - 0s - loss: 511210.7395 - val_loss: 320426.6250\n",
      "Epoch 351/1000\n",
      "131/131 [==============================] - 0s - loss: 535443.8278 - val_loss: 490598.4241\n",
      "Epoch 352/1000\n",
      "131/131 [==============================] - 0s - loss: 546461.0251 - val_loss: 310264.4955\n",
      "Epoch 353/1000\n",
      "131/131 [==============================] - 0s - loss: 526626.7313 - val_loss: 312448.6518\n",
      "Epoch 354/1000\n",
      "131/131 [==============================] - 0s - loss: 526343.7654 - val_loss: 557691.1339\n",
      "Epoch 355/1000\n",
      "131/131 [==============================] - 0s - loss: 505584.7617 - val_loss: 237409.3080\n",
      "Epoch 356/1000\n",
      "131/131 [==============================] - 0s - loss: 562851.0786 - val_loss: 246500.2812\n",
      "Epoch 357/1000\n",
      "131/131 [==============================] - 0s - loss: 594088.8350 - val_loss: 246729.0045\n",
      "Epoch 358/1000\n",
      "131/131 [==============================] - 0s - loss: 544830.1005 - val_loss: 587706.1250\n",
      "Epoch 359/1000\n",
      "131/131 [==============================] - 0s - loss: 581879.4425 - val_loss: 607775.8750\n",
      "Epoch 360/1000\n",
      "131/131 [==============================] - 0s - loss: 578001.1622 - val_loss: 580475.4241\n",
      "Epoch 361/1000\n",
      "131/131 [==============================] - 0s - loss: 519968.1501 - val_loss: 594404.4911\n",
      "Epoch 362/1000\n",
      "131/131 [==============================] - 0s - loss: 556725.4764 - val_loss: 364579.1920\n",
      "Epoch 363/1000\n",
      "131/131 [==============================] - 0s - loss: 499203.8641 - val_loss: 570313.1518\n",
      "Epoch 364/1000\n",
      "131/131 [==============================] - 0s - loss: 516163.8406 - val_loss: 298894.3259\n",
      "Epoch 365/1000\n",
      "131/131 [==============================] - 0s - loss: 509911.4007 - val_loss: 297103.2143\n",
      "Epoch 366/1000\n",
      "131/131 [==============================] - 0s - loss: 484223.3676 - val_loss: 325575.2589\n",
      "Epoch 367/1000\n",
      "131/131 [==============================] - 0s - loss: 494624.8598 - val_loss: 350905.8438\n",
      "Epoch 368/1000\n",
      "131/131 [==============================] - 0s - loss: 440398.7328 - val_loss: 432621.2232\n",
      "Epoch 369/1000\n",
      "131/131 [==============================] - 0s - loss: 479060.8169 - val_loss: 595037.3571\n",
      "Epoch 370/1000\n",
      "131/131 [==============================] - 0s - loss: 551737.1551 - val_loss: 639215.0714\n",
      "Epoch 371/1000\n",
      "131/131 [==============================] - 0s - loss: 474672.7532 - val_loss: 285707.7188\n",
      "Epoch 372/1000\n",
      "131/131 [==============================] - 0s - loss: 506772.0089 - val_loss: 279763.2812\n",
      "Epoch 373/1000\n",
      "131/131 [==============================] - 0s - loss: 481800.1565 - val_loss: 278218.4286\n",
      "Epoch 374/1000\n",
      "131/131 [==============================] - 0s - loss: 581734.9404 - val_loss: 429906.2232\n",
      "Epoch 375/1000\n",
      "131/131 [==============================] - 0s - loss: 612355.2003 - val_loss: 283698.1652\n",
      "Epoch 376/1000\n",
      "131/131 [==============================] - 0s - loss: 549662.8532 - val_loss: 559347.9464\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 525980.1329 - val_loss: 315206.3795\n",
      "Epoch 378/1000\n",
      "131/131 [==============================] - 0s - loss: 476474.8531 - val_loss: 302128.68304\n",
      "Epoch 379/1000\n",
      "131/131 [==============================] - 0s - loss: 500673.1438 - val_loss: 333364.6607\n",
      "Epoch 380/1000\n",
      "131/131 [==============================] - 0s - loss: 521291.2527 - val_loss: 332309.0848\n",
      "Epoch 381/1000\n",
      "131/131 [==============================] - 0s - loss: 572488.5886 - val_loss: 346403.7589\n",
      "Epoch 382/1000\n",
      "131/131 [==============================] - 0s - loss: 517080.9942 - val_loss: 428112.7857\n",
      "Epoch 383/1000\n",
      "131/131 [==============================] - 0s - loss: 535037.2068 - val_loss: 322011.2946\n",
      "Epoch 384/1000\n",
      "131/131 [==============================] - 0s - loss: 441484.6415 - val_loss: 319106.52236916.53\n",
      "Epoch 385/1000\n",
      "131/131 [==============================] - 0s - loss: 542661.3475 - val_loss: 318706.4866\n",
      "Epoch 386/1000\n",
      "131/131 [==============================] - 0s - loss: 509518.4962 - val_loss: 312632.7277\n",
      "Epoch 387/1000\n",
      "131/131 [==============================] - 0s - loss: 514822.9943 - val_loss: 352410.7411\n",
      "Epoch 388/1000\n",
      "131/131 [==============================] - 0s - loss: 485576.7592 - val_loss: 365483.2679\n",
      "Epoch 389/1000\n",
      "131/131 [==============================] - 0s - loss: 548194.9889 - val_loss: 623773.3214\n",
      "Epoch 390/1000\n",
      "131/131 [==============================] - 0s - loss: 615648.2471 - val_loss: 546384.5759\n",
      "Epoch 391/1000\n",
      "131/131 [==============================] - 0s - loss: 567750.3241 - val_loss: 291667.0580\n",
      "Epoch 392/1000\n",
      "131/131 [==============================] - 0s - loss: 491891.8320 - val_loss: 440333.9598\n",
      "Epoch 393/1000\n",
      "131/131 [==============================] - 0s - loss: 530647.4110 - val_loss: 311645.8036\n",
      "Epoch 394/1000\n",
      "131/131 [==============================] - 0s - loss: 531013.4769 - val_loss: 316552.2143\n",
      "Epoch 395/1000\n",
      "131/131 [==============================] - 0s - loss: 521473.7789 - val_loss: 314794.6339\n",
      "Epoch 396/1000\n",
      "131/131 [==============================] - 0s - loss: 508222.2159 - val_loss: 313936.4241\n",
      "Epoch 397/1000\n",
      "131/131 [==============================] - 0s - loss: 534595.1963 - val_loss: 365611.8973\n",
      "Epoch 398/1000\n",
      "131/131 [==============================] - 0s - loss: 520357.9592 - val_loss: 337186.1964\n",
      "Epoch 399/1000\n",
      "131/131 [==============================] - 0s - loss: 523999.5388 - val_loss: 655057.6339\n",
      "Epoch 400/1000\n",
      "131/131 [==============================] - 0s - loss: 501609.4721 - val_loss: 707164.5536\n",
      "Epoch 401/1000\n",
      "131/131 [==============================] - 0s - loss: 538622.2169 - val_loss: 289517.4911\n",
      "Epoch 402/1000\n",
      "131/131 [==============================] - 0s - loss: 509148.7923 - val_loss: 306770.6116\n",
      "Epoch 403/1000\n",
      "131/131 [==============================] - 0s - loss: 520792.9995 - val_loss: 601779.0982\n",
      "Epoch 404/1000\n",
      "131/131 [==============================] - 0s - loss: 647954.1039 - val_loss: 434753.5000\n",
      "Epoch 405/1000\n",
      "131/131 [==============================] - 0s - loss: 643732.7674 - val_loss: 690808.2768\n",
      "Epoch 406/1000\n",
      "131/131 [==============================] - 0s - loss: 563979.2325 - val_loss: 637903.3929\n",
      "Epoch 407/1000\n",
      "131/131 [==============================] - 0s - loss: 531758.7718 - val_loss: 353914.7500\n",
      "Epoch 408/1000\n",
      "131/131 [==============================] - 0s - loss: 486615.7152 - val_loss: 672241.7321\n",
      "Epoch 409/1000\n",
      "131/131 [==============================] - 0s - loss: 487928.5239 - val_loss: 252394.8839\n",
      "Epoch 410/1000\n",
      "131/131 [==============================] - 0s - loss: 486953.0135 - val_loss: 264982.9732\n",
      "Epoch 411/1000\n",
      "131/131 [==============================] - 0s - loss: 431203.7418 - val_loss: 224473.0402\n",
      "Epoch 412/1000\n",
      "131/131 [==============================] - 0s - loss: 487087.2883 - val_loss: 262762.3527\n",
      "Epoch 413/1000\n",
      "131/131 [==============================] - 0s - loss: 509462.2268 - val_loss: 294346.1161\n",
      "Epoch 414/1000\n",
      "131/131 [==============================] - 0s - loss: 530840.0392 - val_loss: 218895.7455\n",
      "Epoch 415/1000\n",
      "131/131 [==============================] - 0s - loss: 497769.4632 - val_loss: 301211.2277\n",
      "Epoch 416/1000\n",
      "131/131 [==============================] - 0s - loss: 552240.4169 - val_loss: 619496.4821\n",
      "Epoch 417/1000\n",
      "131/131 [==============================] - 0s - loss: 521679.9923 - val_loss: 313512.8036\n",
      "Epoch 418/1000\n",
      "131/131 [==============================] - 0s - loss: 522351.1280 - val_loss: 309158.0000\n",
      "Epoch 419/1000\n",
      "131/131 [==============================] - 0s - loss: 496761.4717 - val_loss: 254261.9955\n",
      "Epoch 420/1000\n",
      "131/131 [==============================] - 0s - loss: 451683.2554 - val_loss: 264464.8795\n",
      "Epoch 421/1000\n",
      "131/131 [==============================] - 0s - loss: 531315.5144 - val_loss: 299812.7366\n",
      "Epoch 422/1000\n",
      "131/131 [==============================] - 0s - loss: 467852.7102 - val_loss: 255576.8393\n",
      "Epoch 423/1000\n",
      "131/131 [==============================] - 0s - loss: 445647.6654 - val_loss: 338273.0580\n",
      "Epoch 424/1000\n",
      "131/131 [==============================] - 0s - loss: 495291.0581 - val_loss: 328047.3170\n",
      "Epoch 425/1000\n",
      "131/131 [==============================] - 0s - loss: 488976.5509 - val_loss: 338162.0045\n",
      "Epoch 426/1000\n",
      "131/131 [==============================] - 0s - loss: 500559.3117 - val_loss: 317430.5491\n",
      "Epoch 427/1000\n",
      "131/131 [==============================] - 0s - loss: 468419.1539 - val_loss: 258631.0848\n",
      "Epoch 428/1000\n",
      "131/131 [==============================] - 0s - loss: 482501.4122 - val_loss: 327389.7009\n",
      "Epoch 429/1000\n",
      "131/131 [==============================] - 0s - loss: 472313.9010 - val_loss: 292407.6741\n",
      "Epoch 430/1000\n",
      "131/131 [==============================] - 0s - loss: 468288.9314 - val_loss: 291405.2321\n",
      "Epoch 431/1000\n",
      "131/131 [==============================] - 0s - loss: 443633.5154 - val_loss: 298846.5402\n",
      "Epoch 432/1000\n",
      "131/131 [==============================] - 0s - loss: 509827.7340 - val_loss: 612418.51127\n",
      "Epoch 433/1000\n",
      "131/131 [==============================] - 0s - loss: 477954.5601 - val_loss: 260842.0536\n",
      "Epoch 434/1000\n",
      "131/131 [==============================] - 0s - loss: 521257.7168 - val_loss: 259544.0580\n",
      "Epoch 435/1000\n",
      "131/131 [==============================] - 0s - loss: 451187.2004 - val_loss: 305213.6071\n",
      "Epoch 436/1000\n",
      "131/131 [==============================] - 0s - loss: 471642.5443 - val_loss: 286484.1161\n",
      "Epoch 437/1000\n",
      "131/131 [==============================] - 0s - loss: 461389.1636 - val_loss: 243994.7723\n",
      "Epoch 438/1000\n",
      "131/131 [==============================] - 0s - loss: 475310.5163 - val_loss: 266590.2768\n",
      "Epoch 439/1000\n",
      "131/131 [==============================] - 0s - loss: 504040.4156 - val_loss: 272498.8438\n",
      "Epoch 440/1000\n",
      "131/131 [==============================] - 0s - loss: 481347.0117 - val_loss: 264803.2277\n",
      "Epoch 441/1000\n",
      "131/131 [==============================] - 0s - loss: 429218.6251 - val_loss: 259783.9241\n",
      "Epoch 442/1000\n",
      "131/131 [==============================] - 0s - loss: 418471.4612 - val_loss: 279370.0759\n",
      "Epoch 443/1000\n",
      "131/131 [==============================] - 0s - loss: 449978.5219 - val_loss: 294529.0625\n",
      "Epoch 444/1000\n",
      "131/131 [==============================] - 0s - loss: 483626.6845 - val_loss: 250359.2321\n",
      "Epoch 445/1000\n",
      "131/131 [==============================] - 0s - loss: 428318.7093 - val_loss: 260088.5491\n",
      "Epoch 446/1000\n",
      "131/131 [==============================] - 0s - loss: 482849.3134 - val_loss: 257666.6250\n",
      "Epoch 447/1000\n",
      "131/131 [==============================] - 0s - loss: 447953.7352 - val_loss: 221980.4464\n",
      "Epoch 448/1000\n",
      "131/131 [==============================] - 0s - loss: 500784.6856 - val_loss: 266693.7009\n",
      "Epoch 449/1000\n",
      "131/131 [==============================] - 0s - loss: 453853.0893 - val_loss: 293609.6562\n",
      "Epoch 450/1000\n",
      "131/131 [==============================] - 0s - loss: 444629.8602 - val_loss: 274301.9821\n",
      "Epoch 451/1000\n",
      "131/131 [==============================] - 0s - loss: 415530.6293 - val_loss: 304298.2277\n",
      "Epoch 452/1000\n",
      "131/131 [==============================] - 0s - loss: 475565.9236 - val_loss: 305512.0000\n",
      "Epoch 453/1000\n",
      "131/131 [==============================] - 0s - loss: 543992.5318 - val_loss: 667548.4643\n",
      "Epoch 454/1000\n",
      "131/131 [==============================] - 0s - loss: 526500.6948 - val_loss: 339949.9688\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 519764.2571 - val_loss: 310459.3393\n",
      "Epoch 456/1000\n",
      "131/131 [==============================] - 0s - loss: 454652.3492 - val_loss: 335943.6696\n",
      "Epoch 457/1000\n",
      "131/131 [==============================] - 0s - loss: 463356.8381 - val_loss: 324812.8170\n",
      "Epoch 458/1000\n",
      "131/131 [==============================] - 0s - loss: 461893.1109 - val_loss: 614641.2589\n",
      "Epoch 459/1000\n",
      "131/131 [==============================] - 0s - loss: 475239.9406 - val_loss: 267704.2143\n",
      "Epoch 460/1000\n",
      "131/131 [==============================] - 0s - loss: 412509.0837 - val_loss: 285486.7589\n",
      "Epoch 461/1000\n",
      "131/131 [==============================] - 0s - loss: 406828.8685 - val_loss: 321872.5134\n",
      "Epoch 462/1000\n",
      "131/131 [==============================] - 0s - loss: 484600.9294 - val_loss: 310287.4955\n",
      "Epoch 463/1000\n",
      "131/131 [==============================] - 0s - loss: 432032.8519 - val_loss: 290966.5491\n",
      "Epoch 464/1000\n",
      "131/131 [==============================] - 0s - loss: 431986.9398 - val_loss: 296436.2991\n",
      "Epoch 465/1000\n",
      "131/131 [==============================] - 0s - loss: 389159.3149 - val_loss: 292785.7321\n",
      "Epoch 466/1000\n",
      "131/131 [==============================] - 0s - loss: 492736.6314 - val_loss: 293071.1429\n",
      "Epoch 467/1000\n",
      "131/131 [==============================] - 0s - loss: 448641.3150 - val_loss: 321109.6786\n",
      "Epoch 468/1000\n",
      "131/131 [==============================] - 0s - loss: 449806.7572 - val_loss: 267286.4464\n",
      "Epoch 469/1000\n",
      "131/131 [==============================] - 0s - loss: 439048.4559 - val_loss: 296430.7143\n",
      "Epoch 470/1000\n",
      "131/131 [==============================] - 0s - loss: 454826.7901 - val_loss: 333841.7857\n",
      "Epoch 471/1000\n",
      "131/131 [==============================] - 0s - loss: 490055.3365 - val_loss: 301750.30800\n",
      "Epoch 472/1000\n",
      "131/131 [==============================] - 0s - loss: 437984.3047 - val_loss: 297486.4420\n",
      "Epoch 473/1000\n",
      "131/131 [==============================] - 0s - loss: 435767.0956 - val_loss: 276056.6741\n",
      "Epoch 474/1000\n",
      "131/131 [==============================] - 0s - loss: 484515.8824 - val_loss: 321871.1071\n",
      "Epoch 475/1000\n",
      "131/131 [==============================] - 0s - loss: 482058.5502 - val_loss: 643925.8750\n",
      "Epoch 476/1000\n",
      "131/131 [==============================] - 0s - loss: 464323.2371 - val_loss: 334559.1920\n",
      "Epoch 477/1000\n",
      "131/131 [==============================] - 0s - loss: 511024.2774 - val_loss: 284542.1116\n",
      "Epoch 478/1000\n",
      "131/131 [==============================] - 0s - loss: 467060.9035 - val_loss: 304243.7723\n",
      "Epoch 479/1000\n",
      "131/131 [==============================] - 0s - loss: 471031.8735 - val_loss: 284097.8795\n",
      "Epoch 480/1000\n",
      "131/131 [==============================] - 0s - loss: 462460.7290 - val_loss: 307892.5357\n",
      "Epoch 481/1000\n",
      "131/131 [==============================] - 0s - loss: 497248.9803 - val_loss: 243144.9598\n",
      "Epoch 482/1000\n",
      "131/131 [==============================] - 0s - loss: 510803.1172 - val_loss: 257958.7857\n",
      "Epoch 483/1000\n",
      "131/131 [==============================] - 0s - loss: 444547.0168 - val_loss: 226296.0491\n",
      "Epoch 484/1000\n",
      "131/131 [==============================] - 0s - loss: 487828.6654 - val_loss: 274986.7679\n",
      "Epoch 485/1000\n",
      "131/131 [==============================] - 0s - loss: 483755.6698 - val_loss: 236854.2991\n",
      "Epoch 486/1000\n",
      "131/131 [==============================] - 0s - loss: 384891.5161 - val_loss: 219148.7812\n",
      "Epoch 487/1000\n",
      "131/131 [==============================] - 0s - loss: 432172.0285 - val_loss: 260443.7188\n",
      "Epoch 488/1000\n",
      "131/131 [==============================] - 0s - loss: 418331.9994 - val_loss: 257193.0491\n",
      "Epoch 489/1000\n",
      "131/131 [==============================] - 0s - loss: 486609.9855 - val_loss: 264565.5670\n",
      "Epoch 490/1000\n",
      "131/131 [==============================] - 0s - loss: 476675.7551 - val_loss: 263866.5402\n",
      "Epoch 491/1000\n",
      "131/131 [==============================] - 0s - loss: 464175.2112 - val_loss: 272005.7991\n",
      "Epoch 492/1000\n",
      "131/131 [==============================] - 0s - loss: 432688.1737 - val_loss: 259711.0848\n",
      "Epoch 493/1000\n",
      "131/131 [==============================] - 0s - loss: 493595.3029 - val_loss: 245119.6830\n",
      "Epoch 494/1000\n",
      "131/131 [==============================] - 0s - loss: 464273.6070 - val_loss: 287039.5848\n",
      "Epoch 495/1000\n",
      "131/131 [==============================] - 0s - loss: 477370.1920 - val_loss: 563148.2321\n",
      "Epoch 496/1000\n",
      "131/131 [==============================] - 0s - loss: 463267.9743 - val_loss: 263793.4107\n",
      "Epoch 497/1000\n",
      "131/131 [==============================] - 0s - loss: 470624.3123 - val_loss: 298668.2812\n",
      "Epoch 498/1000\n",
      "131/131 [==============================] - 0s - loss: 509959.5938 - val_loss: 266687.6339\n",
      "Epoch 499/1000\n",
      "131/131 [==============================] - 0s - loss: 479865.5620 - val_loss: 304937.8527\n",
      "Epoch 500/1000\n",
      "131/131 [==============================] - 0s - loss: 416279.3915 - val_loss: 511318.2054\n",
      "Epoch 501/1000\n",
      "131/131 [==============================] - 0s - loss: 515651.1045 - val_loss: 286609.8125\n",
      "Epoch 502/1000\n",
      "131/131 [==============================] - 0s - loss: 429303.2743 - val_loss: 271116.8705\n",
      "Epoch 503/1000\n",
      "131/131 [==============================] - 0s - loss: 405273.6817 - val_loss: 263297.2545\n",
      "Epoch 504/1000\n",
      "131/131 [==============================] - 0s - loss: 537700.4914 - val_loss: 250842.2143\n",
      "Epoch 505/1000\n",
      "131/131 [==============================] - 0s - loss: 470160.2850 - val_loss: 265484.5982\n",
      "Epoch 506/1000\n",
      "131/131 [==============================] - 0s - loss: 468919.3341 - val_loss: 282647.58937\n",
      "Epoch 507/1000\n",
      "131/131 [==============================] - 0s - loss: 498772.5293 - val_loss: 275017.7455\n",
      "Epoch 508/1000\n",
      "131/131 [==============================] - 0s - loss: 467506.0701 - val_loss: 655407.4643\n",
      "Epoch 509/1000\n",
      "131/131 [==============================] - 0s - loss: 450625.1757 - val_loss: 696746.5089\n",
      "Epoch 510/1000\n",
      "131/131 [==============================] - 0s - loss: 532077.3449 - val_loss: 301728.0625\n",
      "Epoch 511/1000\n",
      "131/131 [==============================] - 0s - loss: 511005.1232 - val_loss: 281825.0580\n",
      "Epoch 512/1000\n",
      "131/131 [==============================] - 0s - loss: 438490.8266 - val_loss: 386045.6875\n",
      "Epoch 513/1000\n",
      "131/131 [==============================] - 0s - loss: 539186.1841 - val_loss: 272429.4643\n",
      "Epoch 514/1000\n",
      "131/131 [==============================] - 0s - loss: 431920.8852 - val_loss: 256343.5625\n",
      "Epoch 515/1000\n",
      "131/131 [==============================] - 0s - loss: 430615.4725 - val_loss: 314027.6027\n",
      "Epoch 516/1000\n",
      "131/131 [==============================] - 0s - loss: 445179.1738 - val_loss: 523234.1161\n",
      "Epoch 517/1000\n",
      "131/131 [==============================] - 0s - loss: 498321.7071 - val_loss: 698083.7500\n",
      "Epoch 518/1000\n",
      "131/131 [==============================] - 0s - loss: 572047.5963 - val_loss: 738992.6964\n",
      "Epoch 519/1000\n",
      "131/131 [==============================] - 0s - loss: 528561.1022 - val_loss: 351670.9911\n",
      "Epoch 520/1000\n",
      "131/131 [==============================] - 0s - loss: 489392.3358 - val_loss: 633591.1071\n",
      "Epoch 521/1000\n",
      "131/131 [==============================] - 0s - loss: 541452.3307 - val_loss: 489939.4821\n",
      "Epoch 522/1000\n",
      "131/131 [==============================] - 0s - loss: 486151.5896 - val_loss: 339082.2143\n",
      "Epoch 523/1000\n",
      "131/131 [==============================] - 0s - loss: 492272.8000 - val_loss: 642637.4107\n",
      "Epoch 524/1000\n",
      "131/131 [==============================] - 0s - loss: 502075.8959 - val_loss: 348871.5000\n",
      "Epoch 525/1000\n",
      "131/131 [==============================] - 0s - loss: 432322.3630 - val_loss: 355165.7232\n",
      "Epoch 526/1000\n",
      "131/131 [==============================] - 0s - loss: 482180.1045 - val_loss: 325432.6027\n",
      "Epoch 527/1000\n",
      "131/131 [==============================] - 0s - loss: 526940.0866 - val_loss: 293831.1562\n",
      "Epoch 528/1000\n",
      "131/131 [==============================] - 0s - loss: 510430.6316 - val_loss: 765014.8571\n",
      "Epoch 529/1000\n",
      "131/131 [==============================] - 0s - loss: 493829.5490 - val_loss: 367587.4196\n",
      "Epoch 530/1000\n",
      "131/131 [==============================] - 0s - loss: 520110.8086 - val_loss: 310276.7143\n",
      "Epoch 531/1000\n",
      "131/131 [==============================] - 0s - loss: 482475.9588 - val_loss: 321219.6741\n",
      "Epoch 532/1000\n",
      "131/131 [==============================] - 0s - loss: 509553.5496 - val_loss: 291366.8973\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 467956.6751 - val_loss: 279405.2321\n",
      "Epoch 534/1000\n",
      "131/131 [==============================] - 0s - loss: 501219.4070 - val_loss: 284108.1339\n",
      "Epoch 535/1000\n",
      "131/131 [==============================] - 0s - loss: 510692.8231 - val_loss: 251910.8348\n",
      "Epoch 536/1000\n",
      "131/131 [==============================] - 0s - loss: 540760.6695 - val_loss: 362705.1339\n",
      "Epoch 537/1000\n",
      "131/131 [==============================] - 0s - loss: 523618.8732 - val_loss: 280121.8884\n",
      "Epoch 538/1000\n",
      "131/131 [==============================] - 0s - loss: 467347.2177 - val_loss: 298924.3080\n",
      "Epoch 539/1000\n",
      "131/131 [==============================] - 0s - loss: 468874.1650 - val_loss: 331520.0446\n",
      "Epoch 540/1000\n",
      "131/131 [==============================] - 0s - loss: 490306.6590 - val_loss: 329421.0402\n",
      "Epoch 541/1000\n",
      "131/131 [==============================] - 0s - loss: 484901.9212 - val_loss: 321483.9241\n",
      "Epoch 542/1000\n",
      "131/131 [==============================] - 0s - loss: 532464.7473 - val_loss: 387266.7232\n",
      "Epoch 543/1000\n",
      "131/131 [==============================] - 0s - loss: 475652.3776 - val_loss: 291750.9866\n",
      "Epoch 544/1000\n",
      "131/131 [==============================] - 0s - loss: 520570.1449 - val_loss: 306516.5625\n",
      "Epoch 545/1000\n",
      "131/131 [==============================] - 0s - loss: 601129.9461 - val_loss: 683096.8839\n",
      "Epoch 546/1000\n",
      "131/131 [==============================] - 0s - loss: 497415.3516 - val_loss: 552443.4286\n",
      "Epoch 547/1000\n",
      "131/131 [==============================] - 0s - loss: 538295.0476 - val_loss: 610661.5179\n",
      "Epoch 548/1000\n",
      "131/131 [==============================] - 0s - loss: 504934.5454 - val_loss: 360120.0982\n",
      "Epoch 549/1000\n",
      "131/131 [==============================] - 0s - loss: 642967.1227 - val_loss: 583780.5179\n",
      "Epoch 550/1000\n",
      "131/131 [==============================] - 0s - loss: 492242.8621 - val_loss: 397511.0357\n",
      "Epoch 551/1000\n",
      "131/131 [==============================] - 0s - loss: 575807.1428 - val_loss: 492718.5714\n",
      "Epoch 552/1000\n",
      "131/131 [==============================] - 0s - loss: 559351.6549 - val_loss: 554760.1920\n",
      "Epoch 553/1000\n",
      "131/131 [==============================] - 0s - loss: 556023.8235 - val_loss: 678848.5357\n",
      "Epoch 554/1000\n",
      "131/131 [==============================] - 0s - loss: 601941.3087 - val_loss: 661571.5714\n",
      "Epoch 555/1000\n",
      "131/131 [==============================] - 0s - loss: 625398.8758 - val_loss: 414893.7768\n",
      "Epoch 556/1000\n",
      "131/131 [==============================] - 0s - loss: 453594.6546 - val_loss: 383134.1607\n",
      "Epoch 557/1000\n",
      "131/131 [==============================] - 0s - loss: 506395.8523 - val_loss: 389235.3839\n",
      "Epoch 558/1000\n",
      "131/131 [==============================] - 0s - loss: 485090.3129 - val_loss: 353254.4911\n",
      "Epoch 559/1000\n",
      "131/131 [==============================] - 0s - loss: 526407.8281 - val_loss: 362025.7768\n",
      "Epoch 560/1000\n",
      "131/131 [==============================] - 0s - loss: 484783.3157 - val_loss: 365339.2321\n",
      "Epoch 561/1000\n",
      "131/131 [==============================] - 0s - loss: 439755.9326 - val_loss: 317011.5670\n",
      "Epoch 562/1000\n",
      "131/131 [==============================] - 0s - loss: 526811.3557 - val_loss: 304261.7589\n",
      "Epoch 563/1000\n",
      "131/131 [==============================] - 0s - loss: 434297.1603 - val_loss: 321595.3125\n",
      "Epoch 564/1000\n",
      "131/131 [==============================] - 0s - loss: 540700.2340 - val_loss: 292530.8750\n",
      "Epoch 565/1000\n",
      "131/131 [==============================] - 0s - loss: 462604.2903 - val_loss: 324000.1607\n",
      "Epoch 566/1000\n",
      "131/131 [==============================] - 0s - loss: 447078.4536 - val_loss: 330105.3036\n",
      "Epoch 567/1000\n",
      "131/131 [==============================] - 0s - loss: 504834.8655 - val_loss: 371110.5402\n",
      "Epoch 568/1000\n",
      "131/131 [==============================] - 0s - loss: 455007.1987 - val_loss: 325055.2812\n",
      "Epoch 569/1000\n",
      "131/131 [==============================] - 0s - loss: 428334.6111 - val_loss: 332969.1295\n",
      "Epoch 570/1000\n",
      "131/131 [==============================] - 0s - loss: 464410.0251 - val_loss: 299587.6607\n",
      "Epoch 571/1000\n",
      "131/131 [==============================] - 0s - loss: 483996.5396 - val_loss: 322098.7366\n",
      "Epoch 572/1000\n",
      "131/131 [==============================] - 0s - loss: 499669.5936 - val_loss: 326377.2009\n",
      "Epoch 573/1000\n",
      "131/131 [==============================] - 0s - loss: 434818.4966 - val_loss: 298599.9375\n",
      "Epoch 574/1000\n",
      "131/131 [==============================] - 0s - loss: 472968.2728 - val_loss: 327599.8125\n",
      "Epoch 575/1000\n",
      "131/131 [==============================] - 0s - loss: 470775.7581 - val_loss: 348029.0848\n",
      "Epoch 576/1000\n",
      "131/131 [==============================] - 0s - loss: 470479.1279 - val_loss: 301314.0223\n",
      "Epoch 577/1000\n",
      "131/131 [==============================] - 0s - loss: 498707.4282 - val_loss: 333937.7411\n",
      "Epoch 578/1000\n",
      "131/131 [==============================] - 0s - loss: 524186.3983 - val_loss: 339880.1652\n",
      "Epoch 579/1000\n",
      "131/131 [==============================] - 0s - loss: 488260.1211 - val_loss: 315225.8795\n",
      "Epoch 580/1000\n",
      "131/131 [==============================] - 0s - loss: 530102.7855 - val_loss: 307649.7500\n",
      "Epoch 581/1000\n",
      "131/131 [==============================] - 0s - loss: 474578.9971 - val_loss: 296028.2009\n",
      "Epoch 582/1000\n",
      "131/131 [==============================] - 0s - loss: 447516.9304 - val_loss: 355502.4018\n",
      "Epoch 583/1000\n",
      "131/131 [==============================] - 0s - loss: 440262.9243 - val_loss: 330063.1116\n",
      "Epoch 584/1000\n",
      "131/131 [==============================] - 0s - loss: 500045.0051 - val_loss: 324716.9464\n",
      "Epoch 585/1000\n",
      "131/131 [==============================] - 0s - loss: 507249.0196 - val_loss: 379442.4375\n",
      "Epoch 586/1000\n",
      "131/131 [==============================] - 0s - loss: 476205.9292 - val_loss: 355215.0982\n",
      "Epoch 587/1000\n",
      "131/131 [==============================] - 0s - loss: 462378.6358 - val_loss: 321033.4598\n",
      "Epoch 588/1000\n",
      "131/131 [==============================] - 0s - loss: 451446.8824 - val_loss: 354954.6652\n",
      "Epoch 589/1000\n",
      "131/131 [==============================] - 0s - loss: 443866.9722 - val_loss: 328918.2545\n",
      "Epoch 590/1000\n",
      "131/131 [==============================] - 0s - loss: 490412.8928 - val_loss: 770288.2679\n",
      "Epoch 591/1000\n",
      "131/131 [==============================] - 0s - loss: 476368.5066 - val_loss: 781704.0000\n",
      "Epoch 592/1000\n",
      "131/131 [==============================] - 0s - loss: 555592.1026 - val_loss: 620615.9866\n",
      "Epoch 593/1000\n",
      "131/131 [==============================] - 0s - loss: 455426.5699 - val_loss: 714928.6250\n",
      "Epoch 594/1000\n",
      "131/131 [==============================] - 0s - loss: 500226.5371 - val_loss: 431444.1250\n",
      "Epoch 595/1000\n",
      "131/131 [==============================] - 0s - loss: 535842.9974 - val_loss: 422998.2946\n",
      "Epoch 596/1000\n",
      "131/131 [==============================] - 0s - loss: 496469.6846 - val_loss: 521991.11612944.04\n",
      "Epoch 597/1000\n",
      "131/131 [==============================] - 0s - loss: 497024.5825 - val_loss: 403412.1786\n",
      "Epoch 598/1000\n",
      "131/131 [==============================] - 0s - loss: 488887.8809 - val_loss: 779369.8393\n",
      "Epoch 599/1000\n",
      "131/131 [==============================] - 0s - loss: 552829.8006 - val_loss: 371939.2768\n",
      "Epoch 600/1000\n",
      "131/131 [==============================] - 0s - loss: 511035.1292 - val_loss: 427543.7679\n",
      "Epoch 601/1000\n",
      "131/131 [==============================] - 0s - loss: 474129.9754 - val_loss: 768430.3214\n",
      "Epoch 602/1000\n",
      "131/131 [==============================] - 0s - loss: 508510.4882 - val_loss: 668945.5893\n",
      "Epoch 603/1000\n",
      "131/131 [==============================] - 0s - loss: 561018.9413 - val_loss: 487589.4196\n",
      "Epoch 604/1000\n",
      "131/131 [==============================] - 0s - loss: 503020.6288 - val_loss: 385300.5268\n",
      "Epoch 605/1000\n",
      "131/131 [==============================] - 0s - loss: 573897.5246 - val_loss: 759270.0893\n",
      "Epoch 606/1000\n",
      "131/131 [==============================] - 0s - loss: 543946.1917 - val_loss: 769450.4286\n",
      "Epoch 607/1000\n",
      "131/131 [==============================] - 0s - loss: 630355.4869 - val_loss: 619613.2098\n",
      "Epoch 608/1000\n",
      "131/131 [==============================] - 0s - loss: 576812.7392 - val_loss: 408798.3661\n",
      "Epoch 609/1000\n",
      "131/131 [==============================] - 0s - loss: 651919.7230 - val_loss: 484024.2500\n",
      "Epoch 610/1000\n",
      "131/131 [==============================] - 0s - loss: 488199.7555 - val_loss: 325962.6786\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 594392.9055 - val_loss: 292962.2946\n",
      "Epoch 612/1000\n",
      "131/131 [==============================] - 0s - loss: 569160.9215 - val_loss: 706301.4375\n",
      "Epoch 613/1000\n",
      "131/131 [==============================] - 0s - loss: 521690.1769 - val_loss: 333654.2321\n",
      "Epoch 614/1000\n",
      "131/131 [==============================] - 0s - loss: 604302.9347 - val_loss: 339661.4732\n",
      "Epoch 615/1000\n",
      "131/131 [==============================] - 0s - loss: 562083.3569 - val_loss: 329036.4821\n",
      "Epoch 616/1000\n",
      "131/131 [==============================] - 0s - loss: 463992.8290 - val_loss: 343619.5000\n",
      "Epoch 617/1000\n",
      "131/131 [==============================] - 0s - loss: 422620.6642 - val_loss: 323464.5848\n",
      "Epoch 618/1000\n",
      "131/131 [==============================] - 0s - loss: 512138.5725 - val_loss: 706413.6161\n",
      "Epoch 619/1000\n",
      "131/131 [==============================] - 0s - loss: 490576.2676 - val_loss: 303209.1116\n",
      "Epoch 620/1000\n",
      "131/131 [==============================] - 0s - loss: 442159.0797 - val_loss: 688224.6339\n",
      "Epoch 621/1000\n",
      "131/131 [==============================] - 0s - loss: 494343.9027 - val_loss: 381485.1161\n",
      "Epoch 622/1000\n",
      "131/131 [==============================] - 0s - loss: 492091.8007 - val_loss: 329782.8214\n",
      "Epoch 623/1000\n",
      "131/131 [==============================] - 0s - loss: 468946.8892 - val_loss: 342969.1027\n",
      "Epoch 624/1000\n",
      "131/131 [==============================] - 0s - loss: 504014.6048 - val_loss: 313908.9018\n",
      "Epoch 625/1000\n",
      "131/131 [==============================] - 0s - loss: 566622.6897 - val_loss: 297582.8705\n",
      "Epoch 626/1000\n",
      "131/131 [==============================] - 0s - loss: 479689.8300 - val_loss: 759597.7500\n",
      "Epoch 627/1000\n",
      "131/131 [==============================] - 0s - loss: 546677.1419 - val_loss: 717100.3571\n",
      "Epoch 628/1000\n",
      "131/131 [==============================] - 0s - loss: 534228.9758 - val_loss: 520089.0536\n",
      "Epoch 629/1000\n",
      "131/131 [==============================] - 0s - loss: 497949.8820 - val_loss: 404630.8839\n",
      "Epoch 630/1000\n",
      "131/131 [==============================] - 0s - loss: 466346.5632 - val_loss: 454236.1071\n",
      "Epoch 631/1000\n",
      "131/131 [==============================] - 0s - loss: 484538.5035 - val_loss: 393698.7589\n",
      "Epoch 632/1000\n",
      "131/131 [==============================] - 0s - loss: 447668.4511 - val_loss: 407383.7589\n",
      "Epoch 633/1000\n",
      "131/131 [==============================] - 0s - loss: 471509.6273 - val_loss: 282291.6741\n",
      "Epoch 634/1000\n",
      "131/131 [==============================] - 0s - loss: 527009.6698 - val_loss: 287480.7679\n",
      "Epoch 635/1000\n",
      "131/131 [==============================] - 0s - loss: 476341.7300 - val_loss: 269114.6384\n",
      "Epoch 636/1000\n",
      "131/131 [==============================] - 0s - loss: 535555.6056 - val_loss: 308117.5179\n",
      "Epoch 637/1000\n",
      "131/131 [==============================] - 0s - loss: 518931.5915 - val_loss: 770467.9464\n",
      "Epoch 638/1000\n",
      "131/131 [==============================] - 0s - loss: 505649.9080 - val_loss: 389506.0804\n",
      "Epoch 639/1000\n",
      "131/131 [==============================] - 0s - loss: 533601.2368 - val_loss: 316183.1116\n",
      "Epoch 640/1000\n",
      "131/131 [==============================] - 0s - loss: 445662.2049 - val_loss: 323561.1518\n",
      "Epoch 641/1000\n",
      "131/131 [==============================] - 0s - loss: 452267.8290 - val_loss: 363578.3393\n",
      "Epoch 642/1000\n",
      "131/131 [==============================] - 0s - loss: 422785.1997 - val_loss: 364590.7188\n",
      "Epoch 643/1000\n",
      "131/131 [==============================] - 0s - loss: 558708.2691 - val_loss: 768306.9286\n",
      "Epoch 644/1000\n",
      "131/131 [==============================] - 0s - loss: 497237.9771 - val_loss: 329312.1071\n",
      "Epoch 645/1000\n",
      "131/131 [==============================] - 0s - loss: 433131.4155 - val_loss: 499692.4286\n",
      "Epoch 646/1000\n",
      "131/131 [==============================] - 0s - loss: 488034.0887 - val_loss: 263685.3080\n",
      "Epoch 647/1000\n",
      "131/131 [==============================] - 0s - loss: 533428.9410 - val_loss: 667502.6607\n",
      "Epoch 648/1000\n",
      "131/131 [==============================] - 0s - loss: 534871.0653 - val_loss: 711727.4018\n",
      "Epoch 649/1000\n",
      "131/131 [==============================] - 0s - loss: 527060.9230 - val_loss: 328612.5312\n",
      "Epoch 650/1000\n",
      "131/131 [==============================] - 0s - loss: 473563.5112 - val_loss: 672981.5000\n",
      "Epoch 651/1000\n",
      "131/131 [==============================] - 0s - loss: 510105.1310 - val_loss: 354732.8795\n",
      "Epoch 652/1000\n",
      "131/131 [==============================] - 0s - loss: 559135.8593 - val_loss: 225367.2902\n",
      "Epoch 653/1000\n",
      "131/131 [==============================] - 0s - loss: 537734.9700 - val_loss: 234045.2679\n",
      "Epoch 654/1000\n",
      "131/131 [==============================] - 0s - loss: 534116.8623 - val_loss: 354745.0848\n",
      "Epoch 655/1000\n",
      "131/131 [==============================] - 0s - loss: 573933.3581 - val_loss: 347502.8839\n",
      "Epoch 656/1000\n",
      "131/131 [==============================] - 0s - loss: 519657.2854 - val_loss: 318473.6116\n",
      "Epoch 657/1000\n",
      "131/131 [==============================] - 0s - loss: 489802.3080 - val_loss: 420096.9286\n",
      "Epoch 658/1000\n",
      "131/131 [==============================] - 0s - loss: 605476.0604 - val_loss: 296373.1920\n",
      "Epoch 659/1000\n",
      "131/131 [==============================] - 0s - loss: 549255.0123 - val_loss: 342308.2679\n",
      "Epoch 660/1000\n",
      "131/131 [==============================] - 0s - loss: 516226.9442 - val_loss: 339360.3125\n",
      "Epoch 661/1000\n",
      "131/131 [==============================] - 0s - loss: 595438.0951 - val_loss: 239567.1027\n",
      "Epoch 662/1000\n",
      "131/131 [==============================] - 0s - loss: 759776.5029 - val_loss: 511885.3125\n",
      "Epoch 663/1000\n",
      "131/131 [==============================] - 0s - loss: 689205.4105 - val_loss: 437532.6071\n",
      "Epoch 664/1000\n",
      "131/131 [==============================] - 0s - loss: 681899.6778 - val_loss: 640560.6830\n",
      "Epoch 665/1000\n",
      "131/131 [==============================] - 0s - loss: 584400.6526 - val_loss: 552127.5804\n",
      "Epoch 666/1000\n",
      "131/131 [==============================] - 0s - loss: 647444.3226 - val_loss: 301013.0759\n",
      "Epoch 667/1000\n",
      "131/131 [==============================] - 0s - loss: 599212.6954 - val_loss: 464708.3973\n",
      "Epoch 668/1000\n",
      "131/131 [==============================] - 0s - loss: 621560.1314 - val_loss: 285350.9777\n",
      "Epoch 669/1000\n",
      "131/131 [==============================] - 0s - loss: 543575.7383 - val_loss: 248134.0402\n",
      "Epoch 670/1000\n",
      "131/131 [==============================] - 0s - loss: 623067.5961 - val_loss: 580393.5625\n",
      "Epoch 671/1000\n",
      "131/131 [==============================] - 0s - loss: 473401.8544 - val_loss: 695831.7679\n",
      "Epoch 672/1000\n",
      "131/131 [==============================] - 0s - loss: 549164.8455 - val_loss: 683515.8839\n",
      "Epoch 673/1000\n",
      "131/131 [==============================] - 0s - loss: 558036.0560 - val_loss: 689451.8125\n",
      "Epoch 674/1000\n",
      "131/131 [==============================] - 0s - loss: 526932.0060 - val_loss: 698833.6964\n",
      "Epoch 675/1000\n",
      "131/131 [==============================] - 0s - loss: 545911.4494 - val_loss: 220182.8393\n",
      "Epoch 676/1000\n",
      "131/131 [==============================] - 0s - loss: 591399.0949 - val_loss: 218467.9955\n",
      "Epoch 677/1000\n",
      "131/131 [==============================] - 0s - loss: 636875.1894 - val_loss: 214822.7902\n",
      "Epoch 678/1000\n",
      "131/131 [==============================] - 0s - loss: 638677.8125 - val_loss: 299411.7634\n",
      "Epoch 679/1000\n",
      "131/131 [==============================] - 0s - loss: 626326.7363 - val_loss: 348146.3304\n",
      "Epoch 680/1000\n",
      "131/131 [==============================] - 0s - loss: 580985.1286 - val_loss: 626245.5357\n",
      "Epoch 681/1000\n",
      "131/131 [==============================] - 0s - loss: 597736.9759 - val_loss: 651449.2321\n",
      "Epoch 682/1000\n",
      "131/131 [==============================] - 0s - loss: 553077.7170 - val_loss: 740074.0446\n",
      "Epoch 683/1000\n",
      "131/131 [==============================] - 0s - loss: 594234.9568 - val_loss: 768886.0893\n",
      "Epoch 684/1000\n",
      "131/131 [==============================] - 0s - loss: 532008.3719 - val_loss: 709354.4018\n",
      "Epoch 685/1000\n",
      "131/131 [==============================] - 0s - loss: 537249.0156 - val_loss: 756224.9821\n",
      "Epoch 686/1000\n",
      "131/131 [==============================] - 0s - loss: 499628.1637 - val_loss: 708882.8795\n",
      "Epoch 687/1000\n",
      "131/131 [==============================] - 0s - loss: 637753.9558 - val_loss: 692093.1429\n",
      "Epoch 688/1000\n",
      "131/131 [==============================] - 0s - loss: 487027.0788 - val_loss: 700006.8214\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 603978.4346 - val_loss: 294649.2634\n",
      "Epoch 690/1000\n",
      "131/131 [==============================] - 0s - loss: 579858.6718 - val_loss: 193388.4777\n",
      "Epoch 691/1000\n",
      "131/131 [==============================] - 0s - loss: 554905.5792 - val_loss: 700252.0982\n",
      "Epoch 692/1000\n",
      "131/131 [==============================] - 0s - loss: 561039.6225 - val_loss: 741746.5714\n",
      "Epoch 693/1000\n",
      "131/131 [==============================] - 0s - loss: 533011.1597 - val_loss: 265443.8214\n",
      "Epoch 694/1000\n",
      "131/131 [==============================] - 0s - loss: 559486.6838 - val_loss: 701247.0536\n",
      "Epoch 695/1000\n",
      "131/131 [==============================] - 0s - loss: 548043.5744 - val_loss: 689964.7679\n",
      "Epoch 696/1000\n",
      "131/131 [==============================] - 0s - loss: 573781.4726 - val_loss: 241550.2545\n",
      "Epoch 697/1000\n",
      "131/131 [==============================] - 0s - loss: 527865.4099 - val_loss: 561143.3304\n",
      "Epoch 698/1000\n",
      "131/131 [==============================] - 0s - loss: 496629.5040 - val_loss: 750162.3214\n",
      "Epoch 699/1000\n",
      "131/131 [==============================] - 0s - loss: 636132.8425 - val_loss: 264905.5848\n",
      "Epoch 700/1000\n",
      "131/131 [==============================] - 0s - loss: 632271.4614 - val_loss: 230289.7545\n",
      "Epoch 701/1000\n",
      "131/131 [==============================] - 0s - loss: 635580.7005 - val_loss: 249209.2768\n",
      "Epoch 702/1000\n",
      "131/131 [==============================] - 0s - loss: 506916.0886 - val_loss: 299477.6920\n",
      "Epoch 703/1000\n",
      "131/131 [==============================] - 0s - loss: 561830.5448 - val_loss: 324966.2679\n",
      "Epoch 704/1000\n",
      "131/131 [==============================] - 0s - loss: 545007.9803 - val_loss: 319879.8661\n",
      "Epoch 705/1000\n",
      "131/131 [==============================] - 0s - loss: 566390.4660 - val_loss: 662356.9464\n",
      "Epoch 706/1000\n",
      "131/131 [==============================] - 0s - loss: 487139.4599 - val_loss: 703680.3214\n",
      "Epoch 707/1000\n",
      "131/131 [==============================] - 0s - loss: 606824.9836 - val_loss: 584022.9866\n",
      "Epoch 708/1000\n",
      "131/131 [==============================] - 0s - loss: 588460.5222 - val_loss: 370078.6384\n",
      "Epoch 709/1000\n",
      "131/131 [==============================] - 0s - loss: 595326.2392 - val_loss: 324135.8571\n",
      "Epoch 710/1000\n",
      "131/131 [==============================] - 0s - loss: 464166.9090 - val_loss: 704626.5089\n",
      "Epoch 711/1000\n",
      "131/131 [==============================] - 0s - loss: 577185.9127 - val_loss: 706713.5446\n",
      "Epoch 712/1000\n",
      "131/131 [==============================] - 0s - loss: 579298.6927 - val_loss: 704761.5536\n",
      "Epoch 713/1000\n",
      "131/131 [==============================] - 0s - loss: 497643.7428 - val_loss: 715284.3393\n",
      "Epoch 714/1000\n",
      "131/131 [==============================] - 0s - loss: 523501.8662 - val_loss: 610129.9911\n",
      "Epoch 715/1000\n",
      "131/131 [==============================] - 0s - loss: 518495.0738 - val_loss: 626146.3036\n",
      "Epoch 716/1000\n",
      "131/131 [==============================] - 0s - loss: 549904.9363 - val_loss: 466836.7589\n",
      "Epoch 717/1000\n",
      "131/131 [==============================] - 0s - loss: 509024.4810 - val_loss: 611770.6607\n",
      "Epoch 718/1000\n",
      "131/131 [==============================] - 0s - loss: 525116.6391 - val_loss: 283244.5536\n",
      "Epoch 719/1000\n",
      "131/131 [==============================] - 0s - loss: 540161.5187 - val_loss: 275666.9732\n",
      "Epoch 720/1000\n",
      "131/131 [==============================] - 0s - loss: 508819.6286 - val_loss: 343730.2411\n",
      "Epoch 721/1000\n",
      "131/131 [==============================] - 0s - loss: 463210.2820 - val_loss: 327001.8259\n",
      "Epoch 722/1000\n",
      "131/131 [==============================] - 0s - loss: 535033.7233 - val_loss: 330754.7812\n",
      "Epoch 723/1000\n",
      "131/131 [==============================] - 0s - loss: 488800.5236 - val_loss: 340533.7500\n",
      "Epoch 724/1000\n",
      "131/131 [==============================] - 0s - loss: 505477.9148 - val_loss: 327940.6652\n",
      "Epoch 725/1000\n",
      "131/131 [==============================] - 0s - loss: 528004.2102 - val_loss: 279593.5536\n",
      "Epoch 726/1000\n",
      "131/131 [==============================] - 0s - loss: 491630.8720 - val_loss: 309591.9330\n",
      "Epoch 727/1000\n",
      "131/131 [==============================] - 0s - loss: 555910.4875 - val_loss: 765310.3393\n",
      "Epoch 728/1000\n",
      "131/131 [==============================] - 0s - loss: 546800.2015 - val_loss: 715388.0714\n",
      "Epoch 729/1000\n",
      "131/131 [==============================] - 0s - loss: 469163.2176 - val_loss: 383681.1205\n",
      "Epoch 730/1000\n",
      "131/131 [==============================] - 0s - loss: 531356.1267 - val_loss: 322313.3214\n",
      "Epoch 731/1000\n",
      "131/131 [==============================] - 0s - loss: 485409.6187 - val_loss: 324088.3571\n",
      "Epoch 732/1000\n",
      "131/131 [==============================] - 0s - loss: 491948.9629 - val_loss: 743995.8750\n",
      "Epoch 733/1000\n",
      "131/131 [==============================] - 0s - loss: 448874.5572 - val_loss: 395431.0804\n",
      "Epoch 734/1000\n",
      "131/131 [==============================] - 0s - loss: 447197.7576 - val_loss: 302922.4420\n",
      "Epoch 735/1000\n",
      "131/131 [==============================] - 0s - loss: 463905.8391 - val_loss: 305377.8080\n",
      "Epoch 736/1000\n",
      "131/131 [==============================] - 0s - loss: 569798.5918 - val_loss: 296956.1027\n",
      "Epoch 737/1000\n",
      "131/131 [==============================] - 0s - loss: 521111.8795 - val_loss: 323938.1964\n",
      "Epoch 738/1000\n",
      "131/131 [==============================] - 0s - loss: 539684.4455 - val_loss: 326718.2679\n",
      "Epoch 739/1000\n",
      "131/131 [==============================] - 0s - loss: 494986.0597 - val_loss: 364584.6875\n",
      "Epoch 740/1000\n",
      "131/131 [==============================] - 0s - loss: 523396.1608 - val_loss: 353273.5357\n",
      "Epoch 741/1000\n",
      "131/131 [==============================] - 0s - loss: 475570.6048 - val_loss: 392858.3661\n",
      "Epoch 742/1000\n",
      "131/131 [==============================] - 0s - loss: 482351.6515 - val_loss: 371287.0357\n",
      "Epoch 743/1000\n",
      "131/131 [==============================] - 0s - loss: 469123.6872 - val_loss: 681801.5982\n",
      "Epoch 744/1000\n",
      "131/131 [==============================] - 0s - loss: 473076.1398 - val_loss: 343888.1071\n",
      "Epoch 745/1000\n",
      "131/131 [==============================] - 0s - loss: 484332.3774 - val_loss: 310317.1652\n",
      "Epoch 746/1000\n",
      "131/131 [==============================] - 0s - loss: 477471.7925 - val_loss: 331591.6429\n",
      "Epoch 747/1000\n",
      "131/131 [==============================] - 0s - loss: 497334.9217 - val_loss: 311431.9420\n",
      "Epoch 748/1000\n",
      "131/131 [==============================] - 0s - loss: 476409.2898 - val_loss: 328062.7188\n",
      "Epoch 749/1000\n",
      "131/131 [==============================] - 0s - loss: 512476.3292 - val_loss: 353797.0848\n",
      "Epoch 750/1000\n",
      "131/131 [==============================] - 0s - loss: 444004.3051 - val_loss: 319196.8929\n",
      "Epoch 751/1000\n",
      "131/131 [==============================] - 0s - loss: 588743.5711 - val_loss: 321742.3170\n",
      "Epoch 752/1000\n",
      "131/131 [==============================] - 0s - loss: 512695.7737 - val_loss: 797267.7143\n",
      "Epoch 753/1000\n",
      "131/131 [==============================] - 0s - loss: 509011.7056 - val_loss: 758643.3839\n",
      "Epoch 754/1000\n",
      "131/131 [==============================] - 0s - loss: 508473.7812 - val_loss: 302707.8884\n",
      "Epoch 755/1000\n",
      "131/131 [==============================] - 0s - loss: 499914.2873 - val_loss: 280612.6562\n",
      "Epoch 756/1000\n",
      "131/131 [==============================] - 0s - loss: 461691.6262 - val_loss: 312652.4509\n",
      "Epoch 757/1000\n",
      "131/131 [==============================] - 0s - loss: 455791.7133 - val_loss: 293299.3125\n",
      "Epoch 758/1000\n",
      "131/131 [==============================] - 0s - loss: 456629.0812 - val_loss: 361187.0893\n",
      "Epoch 759/1000\n",
      "131/131 [==============================] - 0s - loss: 453757.6360 - val_loss: 316203.6116\n",
      "Epoch 760/1000\n",
      "131/131 [==============================] - 0s - loss: 474530.0214 - val_loss: 457222.4911\n",
      "Epoch 761/1000\n",
      "131/131 [==============================] - 0s - loss: 553263.3581 - val_loss: 367786.6875\n",
      "Epoch 762/1000\n",
      "131/131 [==============================] - 0s - loss: 515473.7528 - val_loss: 347245.4643\n",
      "Epoch 763/1000\n",
      "131/131 [==============================] - 0s - loss: 480939.8139 - val_loss: 345482.5357\n",
      "Epoch 764/1000\n",
      "131/131 [==============================] - 0s - loss: 498099.4791 - val_loss: 341711.1116\n",
      "Epoch 765/1000\n",
      "131/131 [==============================] - 0s - loss: 468049.7001 - val_loss: 337322.2679\n",
      "Epoch 766/1000\n",
      "131/131 [==============================] - 0s - loss: 514884.6850 - val_loss: 369261.9777\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 450654.4158 - val_loss: 379034.46888761.\n",
      "Epoch 768/1000\n",
      "131/131 [==============================] - 0s - loss: 470622.3234 - val_loss: 387610.4196\n",
      "Epoch 769/1000\n",
      "131/131 [==============================] - 0s - loss: 479930.4204 - val_loss: 273769.0848\n",
      "Epoch 770/1000\n",
      "131/131 [==============================] - 0s - loss: 458756.3121 - val_loss: 335304.4598\n",
      "Epoch 771/1000\n",
      "131/131 [==============================] - 0s - loss: 503123.9782 - val_loss: 343660.4464\n",
      "Epoch 772/1000\n",
      "131/131 [==============================] - 0s - loss: 554047.3810 - val_loss: 361600.3795\n",
      "Epoch 773/1000\n",
      "131/131 [==============================] - 0s - loss: 507641.7334 - val_loss: 311965.3170\n",
      "Epoch 774/1000\n",
      "131/131 [==============================] - 0s - loss: 431967.7476 - val_loss: 339956.5670\n",
      "Epoch 775/1000\n",
      "131/131 [==============================] - 0s - loss: 467871.5552 - val_loss: 318685.9286\n",
      "Epoch 776/1000\n",
      "131/131 [==============================] - 0s - loss: 479764.7522 - val_loss: 290738.8080\n",
      "Epoch 777/1000\n",
      "131/131 [==============================] - 0s - loss: 497969.4839 - val_loss: 312459.5848\n",
      "Epoch 778/1000\n",
      "131/131 [==============================] - 0s - loss: 508406.3126 - val_loss: 248741.3214\n",
      "Epoch 779/1000\n",
      "131/131 [==============================] - 0s - loss: 431272.7149 - val_loss: 302268.0491\n",
      "Epoch 780/1000\n",
      "131/131 [==============================] - 0s - loss: 536853.3142 - val_loss: 246625.8795\n",
      "Epoch 781/1000\n",
      "131/131 [==============================] - 0s - loss: 438148.4246 - val_loss: 531907.3125\n",
      "Epoch 782/1000\n",
      "131/131 [==============================] - 0s - loss: 527504.2366 - val_loss: 221052.3884\n",
      "Epoch 783/1000\n",
      "131/131 [==============================] - 0s - loss: 477348.1838 - val_loss: 239803.2188\n",
      "Epoch 784/1000\n",
      "131/131 [==============================] - 0s - loss: 534545.7398 - val_loss: 564038.6741\n",
      "Epoch 785/1000\n",
      "131/131 [==============================] - 0s - loss: 525041.4108 - val_loss: 251908.4509\n",
      "Epoch 786/1000\n",
      "131/131 [==============================] - 0s - loss: 517967.4065 - val_loss: 213071.5089\n",
      "Epoch 787/1000\n",
      "131/131 [==============================] - 0s - loss: 563617.6540 - val_loss: 377553.4643\n",
      "Epoch 788/1000\n",
      "131/131 [==============================] - 0s - loss: 514112.6078 - val_loss: 778330.8929\n",
      "Epoch 789/1000\n",
      "131/131 [==============================] - 0s - loss: 554787.0793 - val_loss: 704641.2768\n",
      "Epoch 790/1000\n",
      "131/131 [==============================] - 0s - loss: 512250.3688 - val_loss: 166522.3817\n",
      "Epoch 791/1000\n",
      "131/131 [==============================] - 0s - loss: 603031.3746 - val_loss: 176858.6250\n",
      "Epoch 792/1000\n",
      "131/131 [==============================] - 0s - loss: 574549.2827 - val_loss: 293308.7812\n",
      "Epoch 793/1000\n",
      "131/131 [==============================] - 0s - loss: 522422.4144 - val_loss: 227707.29917648.91\n",
      "Epoch 794/1000\n",
      "131/131 [==============================] - 0s - loss: 479645.8730 - val_loss: 261022.2009\n",
      "Epoch 795/1000\n",
      "131/131 [==============================] - 0s - loss: 518403.6207 - val_loss: 208108.6786\n",
      "Epoch 796/1000\n",
      "131/131 [==============================] - 0s - loss: 485267.1662 - val_loss: 224656.6830\n",
      "Epoch 797/1000\n",
      "131/131 [==============================] - 0s - loss: 519116.5646 - val_loss: 442964.5536955\n",
      "Epoch 798/1000\n",
      "131/131 [==============================] - 0s - loss: 479546.0734 - val_loss: 216359.2054\n",
      "Epoch 799/1000\n",
      "131/131 [==============================] - 0s - loss: 474673.4215 - val_loss: 731511.3571\n",
      "Epoch 800/1000\n",
      "131/131 [==============================] - 0s - loss: 531683.4373 - val_loss: 682941.2321\n",
      "Epoch 801/1000\n",
      "131/131 [==============================] - 0s - loss: 528404.3954 - val_loss: 784190.0536\n",
      "Epoch 802/1000\n",
      "131/131 [==============================] - 0s - loss: 497652.9161 - val_loss: 629779.2143\n",
      "Epoch 803/1000\n",
      "131/131 [==============================] - 0s - loss: 460960.7155 - val_loss: 629917.1607\n",
      "Epoch 804/1000\n",
      "131/131 [==============================] - 0s - loss: 486222.2554 - val_loss: 321872.1562\n",
      "Epoch 805/1000\n",
      "131/131 [==============================] - 0s - loss: 509059.2427 - val_loss: 770232.0312\n",
      "Epoch 806/1000\n",
      "131/131 [==============================] - 0s - loss: 527187.3572 - val_loss: 393244.1429\n",
      "Epoch 807/1000\n",
      "131/131 [==============================] - 0s - loss: 524230.3918 - val_loss: 398685.9554\n",
      "Epoch 808/1000\n",
      "131/131 [==============================] - 0s - loss: 424542.4498 - val_loss: 320751.2321\n",
      "Epoch 809/1000\n",
      "131/131 [==============================] - 0s - loss: 460919.9967 - val_loss: 387561.1964\n",
      "Epoch 810/1000\n",
      "131/131 [==============================] - 0s - loss: 523939.5443 - val_loss: 348256.3973\n",
      "Epoch 811/1000\n",
      "131/131 [==============================] - 0s - loss: 497236.9204 - val_loss: 322566.1116\n",
      "Epoch 812/1000\n",
      "131/131 [==============================] - 0s - loss: 492160.8031 - val_loss: 258344.9911\n",
      "Epoch 813/1000\n",
      "131/131 [==============================] - 0s - loss: 520042.6208 - val_loss: 412307.4196\n",
      "Epoch 814/1000\n",
      "131/131 [==============================] - 0s - loss: 473600.5350 - val_loss: 202557.5201\n",
      "Epoch 815/1000\n",
      "131/131 [==============================] - 0s - loss: 484475.2101 - val_loss: 670909.2277\n",
      "Epoch 816/1000\n",
      "131/131 [==============================] - 0s - loss: 491844.9606 - val_loss: 820500.0714\n",
      "Epoch 817/1000\n",
      "131/131 [==============================] - 0s - loss: 473872.2093 - val_loss: 317882.5848\n",
      "Epoch 818/1000\n",
      "131/131 [==============================] - 0s - loss: 497264.7946 - val_loss: 341695.3482\n",
      "Epoch 819/1000\n",
      "131/131 [==============================] - 0s - loss: 442559.5142 - val_loss: 373949.2679\n",
      "Epoch 820/1000\n",
      "131/131 [==============================] - 0s - loss: 451878.5242 - val_loss: 325538.5893\n",
      "Epoch 821/1000\n",
      "131/131 [==============================] - 0s - loss: 436214.5504 - val_loss: 728679.4643\n",
      "Epoch 822/1000\n",
      "131/131 [==============================] - 0s - loss: 483830.9144 - val_loss: 766452.0804\n",
      "Epoch 823/1000\n",
      "131/131 [==============================] - 0s - loss: 497687.6580 - val_loss: 576303.3571\n",
      "Epoch 824/1000\n",
      "131/131 [==============================] - 0s - loss: 455378.5633 - val_loss: 762370.8571\n",
      "Epoch 825/1000\n",
      "131/131 [==============================] - 0s - loss: 536825.5136 - val_loss: 419332.5625\n",
      "Epoch 826/1000\n",
      "131/131 [==============================] - 0s - loss: 408869.7694 - val_loss: 387881.9018\n",
      "Epoch 827/1000\n",
      "131/131 [==============================] - 0s - loss: 434726.3129 - val_loss: 649818.5714\n",
      "Epoch 828/1000\n",
      "131/131 [==============================] - 0s - loss: 544849.6714 - val_loss: 599642.5536\n",
      "Epoch 829/1000\n",
      "131/131 [==============================] - 0s - loss: 446357.0397 - val_loss: 324542.8571\n",
      "Epoch 830/1000\n",
      "131/131 [==============================] - 0s - loss: 489394.3682 - val_loss: 380022.5000\n",
      "Epoch 831/1000\n",
      "131/131 [==============================] - 0s - loss: 509405.1192 - val_loss: 296698.2098\n",
      "Epoch 832/1000\n",
      "131/131 [==============================] - 0s - loss: 472710.3826 - val_loss: 232017.8170\n",
      "Epoch 833/1000\n",
      "131/131 [==============================] - 0s - loss: 447547.5112 - val_loss: 317125.9330\n",
      "Epoch 834/1000\n",
      "131/131 [==============================] - 0s - loss: 441749.0680 - val_loss: 286854.8973\n",
      "Epoch 835/1000\n",
      "131/131 [==============================] - 0s - loss: 447116.0698 - val_loss: 326024.2679\n",
      "Epoch 836/1000\n",
      "131/131 [==============================] - 0s - loss: 472639.7888 - val_loss: 230566.5089\n",
      "Epoch 837/1000\n",
      "131/131 [==============================] - 0s - loss: 442126.6731 - val_loss: 729253.7411\n",
      "Epoch 838/1000\n",
      "131/131 [==============================] - 0s - loss: 602971.3206 - val_loss: 713746.5134\n",
      "Epoch 839/1000\n",
      "131/131 [==============================] - 0s - loss: 508135.4080 - val_loss: 763309.2679\n",
      "Epoch 840/1000\n",
      "131/131 [==============================] - 0s - loss: 454796.9303 - val_loss: 279888.6027\n",
      "Epoch 841/1000\n",
      "131/131 [==============================] - 0s - loss: 476710.3147 - val_loss: 849345.3214\n",
      "Epoch 842/1000\n",
      "131/131 [==============================] - 0s - loss: 447625.4958 - val_loss: 266216.9420\n",
      "Epoch 843/1000\n",
      "131/131 [==============================] - 0s - loss: 478970.2965 - val_loss: 334982.2098\n",
      "Epoch 844/1000\n",
      "131/131 [==============================] - 0s - loss: 582410.9337 - val_loss: 250273.7098\n",
      "Epoch 845/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 544352.6129 - val_loss: 414133.8839\n",
      "Epoch 846/1000\n",
      "131/131 [==============================] - 0s - loss: 546422.6662 - val_loss: 340061.8929\n",
      "Epoch 847/1000\n",
      "131/131 [==============================] - 0s - loss: 565930.1832 - val_loss: 260229.0580\n",
      "Epoch 848/1000\n",
      "131/131 [==============================] - 0s - loss: 551193.6225 - val_loss: 316759.4732\n",
      "Epoch 849/1000\n",
      "131/131 [==============================] - 0s - loss: 503251.9894 - val_loss: 521559.2054\n",
      "Epoch 850/1000\n",
      "131/131 [==============================] - 0s - loss: 422790.2815 - val_loss: 634936.1607\n",
      "Epoch 851/1000\n",
      "131/131 [==============================] - 0s - loss: 504829.9507 - val_loss: 267500.6830\n",
      "Epoch 852/1000\n",
      "131/131 [==============================] - 0s - loss: 454876.6409 - val_loss: 317363.1250\n",
      "Epoch 853/1000\n",
      "131/131 [==============================] - 0s - loss: 464381.2899 - val_loss: 240976.1830\n",
      "Epoch 854/1000\n",
      "131/131 [==============================] - 0s - loss: 477481.9002 - val_loss: 296888.7679\n",
      "Epoch 855/1000\n",
      "131/131 [==============================] - 0s - loss: 456802.4054 - val_loss: 243546.2902\n",
      "Epoch 856/1000\n",
      "131/131 [==============================] - 0s - loss: 457823.4500 - val_loss: 340048.6205\n",
      "Epoch 857/1000\n",
      "131/131 [==============================] - 0s - loss: 489711.0189 - val_loss: 343623.1473\n",
      "Epoch 858/1000\n",
      "131/131 [==============================] - 0s - loss: 484677.7195 - val_loss: 268702.6027\n",
      "Epoch 859/1000\n",
      "131/131 [==============================] - 0s - loss: 441269.2323 - val_loss: 266620.7500\n",
      "Epoch 860/1000\n",
      "131/131 [==============================] - 0s - loss: 508620.4314 - val_loss: 230075.0134\n",
      "Epoch 861/1000\n",
      "131/131 [==============================] - 0s - loss: 478184.0313 - val_loss: 262721.2321\n",
      "Epoch 862/1000\n",
      "131/131 [==============================] - 0s - loss: 572135.6982 - val_loss: 220041.5938579\n",
      "Epoch 863/1000\n",
      "131/131 [==============================] - 0s - loss: 594658.0309 - val_loss: 234912.5446\n",
      "Epoch 864/1000\n",
      "131/131 [==============================] - 0s - loss: 524889.9198 - val_loss: 247510.8571\n",
      "Epoch 865/1000\n",
      "131/131 [==============================] - 0s - loss: 516583.1480 - val_loss: 233550.2009\n",
      "Epoch 866/1000\n",
      "131/131 [==============================] - 0s - loss: 553416.5354 - val_loss: 269529.4062\n",
      "Epoch 867/1000\n",
      "131/131 [==============================] - 0s - loss: 464041.1080 - val_loss: 312532.0223\n",
      "Epoch 868/1000\n",
      "131/131 [==============================] - 0s - loss: 441936.0689 - val_loss: 345876.9866\n",
      "Epoch 869/1000\n",
      "131/131 [==============================] - 0s - loss: 422642.8138 - val_loss: 288627.0714\n",
      "Epoch 870/1000\n",
      "131/131 [==============================] - 0s - loss: 518391.4220 - val_loss: 389392.3393\n",
      "Epoch 871/1000\n",
      "131/131 [==============================] - 0s - loss: 437233.8752 - val_loss: 390827.1696\n",
      "Epoch 872/1000\n",
      "131/131 [==============================] - 0s - loss: 456129.3020 - val_loss: 397333.1161\n",
      "Epoch 873/1000\n",
      "131/131 [==============================] - 0s - loss: 413046.0460 - val_loss: 342816.3705\n",
      "Epoch 874/1000\n",
      "131/131 [==============================] - 0s - loss: 482182.4747 - val_loss: 365761.6473\n",
      "Epoch 875/1000\n",
      "131/131 [==============================] - 0s - loss: 465379.7650 - val_loss: 328295.4821\n",
      "Epoch 876/1000\n",
      "131/131 [==============================] - 0s - loss: 488449.3838 - val_loss: 430845.2054\n",
      "Epoch 877/1000\n",
      "131/131 [==============================] - 0s - loss: 532313.8766 - val_loss: 378230.0268\n",
      "Epoch 878/1000\n",
      "131/131 [==============================] - 0s - loss: 455986.8689 - val_loss: 424421.8125\n",
      "Epoch 879/1000\n",
      "131/131 [==============================] - 0s - loss: 456392.3384 - val_loss: 341129.3973\n",
      "Epoch 880/1000\n",
      "131/131 [==============================] - 0s - loss: 430983.0484 - val_loss: 287969.2634\n",
      "Epoch 881/1000\n",
      "131/131 [==============================] - 0s - loss: 469468.0400 - val_loss: 341612.0179\n",
      "Epoch 882/1000\n",
      "131/131 [==============================] - 0s - loss: 449002.7389 - val_loss: 339852.3259\n",
      "Epoch 883/1000\n",
      "131/131 [==============================] - 0s - loss: 492716.2843 - val_loss: 349903.2277\n",
      "Epoch 884/1000\n",
      "131/131 [==============================] - 0s - loss: 419279.4672 - val_loss: 342907.4062\n",
      "Epoch 885/1000\n",
      "131/131 [==============================] - 0s - loss: 611403.8842 - val_loss: 355680.1830\n",
      "Epoch 886/1000\n",
      "131/131 [==============================] - 0s - loss: 538440.2013 - val_loss: 334689.1295\n",
      "Epoch 887/1000\n",
      "131/131 [==============================] - 0s - loss: 431849.6114 - val_loss: 249784.0848\n",
      "Epoch 888/1000\n",
      "131/131 [==============================] - 0s - loss: 497483.9015 - val_loss: 246554.2366\n",
      "Epoch 889/1000\n",
      "131/131 [==============================] - 0s - loss: 502972.4193 - val_loss: 276557.2188\n",
      "Epoch 890/1000\n",
      "131/131 [==============================] - 0s - loss: 761704.0980 - val_loss: 215633.1964\n",
      "Epoch 891/1000\n",
      "131/131 [==============================] - 0s - loss: 721867.1021 - val_loss: 635042.2500\n",
      "Epoch 892/1000\n",
      "131/131 [==============================] - 0s - loss: 791465.2374 - val_loss: 204584.4040\n",
      "Epoch 893/1000\n",
      "131/131 [==============================] - 0s - loss: 650692.1285 - val_loss: 248242.6071\n",
      "Epoch 894/1000\n",
      "131/131 [==============================] - 0s - loss: 711899.3638 - val_loss: 291228.3348\n",
      "Epoch 895/1000\n",
      "131/131 [==============================] - 0s - loss: 675929.4854 - val_loss: 398621.3348\n",
      "Epoch 896/1000\n",
      "131/131 [==============================] - 0s - loss: 760526.0841 - val_loss: 167790.8504\n",
      "Epoch 897/1000\n",
      "131/131 [==============================] - 0s - loss: 887051.2538 - val_loss: 236112.8192\n",
      "Epoch 898/1000\n",
      "131/131 [==============================] - 0s - loss: 710965.7830 - val_loss: 189121.0714\n",
      "Epoch 899/1000\n",
      "131/131 [==============================] - 0s - loss: 792403.0799 - val_loss: 639006.2768\n",
      "Epoch 900/1000\n",
      "131/131 [==============================] - 0s - loss: 661515.3285 - val_loss: 592350.9018\n",
      "Epoch 901/1000\n",
      "131/131 [==============================] - 0s - loss: 604446.5991 - val_loss: 693912.3571\n",
      "Epoch 902/1000\n",
      "131/131 [==============================] - 0s - loss: 702509.5341 - val_loss: 363453.7946\n",
      "Epoch 903/1000\n",
      "131/131 [==============================] - 0s - loss: 628099.0803 - val_loss: 536738.4330\n",
      "Epoch 904/1000\n",
      "131/131 [==============================] - 0s - loss: 627986.6120 - val_loss: 357971.7478\n",
      "Epoch 905/1000\n",
      "131/131 [==============================] - 0s - loss: 696624.7774 - val_loss: 779614.3750\n",
      "Epoch 906/1000\n",
      "131/131 [==============================] - 0s - loss: 545987.9639 - val_loss: 218212.9643\n",
      "Epoch 907/1000\n",
      "131/131 [==============================] - 0s - loss: 604089.1141 - val_loss: 310657.3259\n",
      "Epoch 908/1000\n",
      "131/131 [==============================] - 0s - loss: 598603.4744 - val_loss: 337515.5000\n",
      "Epoch 909/1000\n",
      "131/131 [==============================] - 0s - loss: 596439.2639 - val_loss: 487601.3393\n",
      "Epoch 910/1000\n",
      "131/131 [==============================] - 0s - loss: 520146.2622 - val_loss: 290469.9955\n",
      "Epoch 911/1000\n",
      "131/131 [==============================] - 0s - loss: 628195.1343 - val_loss: 289076.0759\n",
      "Epoch 912/1000\n",
      "131/131 [==============================] - 0s - loss: 587305.8896 - val_loss: 226692.8661\n",
      "Epoch 913/1000\n",
      "131/131 [==============================] - 0s - loss: 687727.7221 - val_loss: 231193.3125\n",
      "Epoch 914/1000\n",
      "131/131 [==============================] - 0s - loss: 595662.9250 - val_loss: 361648.2679\n",
      "Epoch 915/1000\n",
      "131/131 [==============================] - 0s - loss: 539022.9241 - val_loss: 401933.6071\n",
      "Epoch 916/1000\n",
      "131/131 [==============================] - 0s - loss: 599447.6751 - val_loss: 279970.4241\n",
      "Epoch 917/1000\n",
      "131/131 [==============================] - 0s - loss: 584514.7193 - val_loss: 331807.0000\n",
      "Epoch 918/1000\n",
      "131/131 [==============================] - 0s - loss: 564216.8273 - val_loss: 379242.7054\n",
      "Epoch 919/1000\n",
      "131/131 [==============================] - 0s - loss: 500166.1903 - val_loss: 296984.9643\n",
      "Epoch 920/1000\n",
      "131/131 [==============================] - 0s - loss: 456048.6230 - val_loss: 352751.6607\n",
      "Epoch 921/1000\n",
      "131/131 [==============================] - 0s - loss: 518219.1636 - val_loss: 328886.1027\n",
      "Epoch 922/1000\n",
      "131/131 [==============================] - 0s - loss: 510575.2388 - val_loss: 390128.1339\n",
      "Epoch 923/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s - loss: 482152.1133 - val_loss: 378953.3839\n",
      "Epoch 924/1000\n",
      "131/131 [==============================] - 0s - loss: 608969.1745 - val_loss: 613959.5179\n",
      "Epoch 925/1000\n",
      "131/131 [==============================] - 0s - loss: 448696.2561 - val_loss: 363084.6741\n",
      "Epoch 926/1000\n",
      "131/131 [==============================] - 0s - loss: 515817.7226 - val_loss: 461184.1429\n",
      "Epoch 927/1000\n",
      "131/131 [==============================] - 0s - loss: 507395.3836 - val_loss: 412026.6429\n",
      "Epoch 928/1000\n",
      "131/131 [==============================] - 0s - loss: 518151.2492 - val_loss: 263962.1875\n",
      "Epoch 929/1000\n",
      "131/131 [==============================] - 0s - loss: 713407.0283 - val_loss: 157553.4464\n",
      "Epoch 930/1000\n",
      "131/131 [==============================] - 0s - loss: 663337.6980 - val_loss: 385574.4955\n",
      "Epoch 931/1000\n",
      "131/131 [==============================] - 0s - loss: 615577.2270 - val_loss: 627620.8750\n",
      "Epoch 932/1000\n",
      "131/131 [==============================] - 0s - loss: 715031.4680 - val_loss: 634016.4107\n",
      "Epoch 933/1000\n",
      "131/131 [==============================] - 0s - loss: 566729.2775 - val_loss: 296838.7277\n",
      "Epoch 934/1000\n",
      "131/131 [==============================] - 0s - loss: 751336.1291 - val_loss: 199405.1473\n",
      "Epoch 935/1000\n",
      "131/131 [==============================] - 0s - loss: 703801.9212 - val_loss: 233056.2991\n",
      "Epoch 936/1000\n",
      "131/131 [==============================] - 0s - loss: 705263.4486 - val_loss: 225994.3170\n",
      "Epoch 937/1000\n",
      "131/131 [==============================] - 0s - loss: 693010.7887 - val_loss: 505399.3103\n",
      "Epoch 938/1000\n",
      "131/131 [==============================] - 0s - loss: 670824.8845 - val_loss: 304605.4598\n",
      "Epoch 939/1000\n",
      "131/131 [==============================] - 0s - loss: 631589.7176 - val_loss: 311619.7277\n",
      "Epoch 940/1000\n",
      "131/131 [==============================] - 0s - loss: 586355.2182 - val_loss: 621087.0179\n",
      "Epoch 941/1000\n",
      "131/131 [==============================] - 0s - loss: 571367.8093 - val_loss: 315794.0290\n",
      "Epoch 942/1000\n",
      "131/131 [==============================] - 0s - loss: 582139.5435 - val_loss: 314605.4018\n",
      "Epoch 943/1000\n",
      "131/131 [==============================] - 0s - loss: 553926.2935 - val_loss: 645376.4330\n",
      "Epoch 944/1000\n",
      "131/131 [==============================] - 0s - loss: 732672.5445 - val_loss: 447779.3125\n",
      "Epoch 945/1000\n",
      "131/131 [==============================] - 0s - loss: 659945.8027 - val_loss: 349623.9152\n",
      "Epoch 946/1000\n",
      "131/131 [==============================] - 0s - loss: 623585.5422 - val_loss: 610786.6161\n",
      "Epoch 947/1000\n",
      "131/131 [==============================] - 0s - loss: 655275.7492 - val_loss: 513038.0179\n",
      "Epoch 948/1000\n",
      "131/131 [==============================] - 0s - loss: 568514.9334 - val_loss: 431054.3125\n",
      "Epoch 949/1000\n",
      "131/131 [==============================] - 0s - loss: 687162.7619 - val_loss: 446554.8125\n",
      "Epoch 950/1000\n",
      "131/131 [==============================] - 0s - loss: 596766.6485 - val_loss: 657523.7500\n",
      "Epoch 951/1000\n",
      "131/131 [==============================] - 0s - loss: 665033.0392 - val_loss: 637382.55802352.32\n",
      "Epoch 952/1000\n",
      "131/131 [==============================] - 0s - loss: 675801.3113 - val_loss: 495776.6830\n",
      "Epoch 953/1000\n",
      "131/131 [==============================] - 0s - loss: 585963.3368 - val_loss: 670066.7589\n",
      "Epoch 954/1000\n",
      "131/131 [==============================] - 0s - loss: 604608.3108 - val_loss: 433578.9598\n",
      "Epoch 955/1000\n",
      "131/131 [==============================] - 0s - loss: 624187.1286 - val_loss: 637967.3438\n",
      "Epoch 956/1000\n",
      "131/131 [==============================] - 0s - loss: 589798.5870 - val_loss: 701933.6875\n",
      "Epoch 957/1000\n",
      "131/131 [==============================] - 0s - loss: 587746.1236 - val_loss: 742700.4643\n",
      "Epoch 958/1000\n",
      "131/131 [==============================] - 0s - loss: 538599.4888 - val_loss: 719263.6607\n",
      "Epoch 959/1000\n",
      "131/131 [==============================] - 0s - loss: 631108.0021 - val_loss: 751126.1964\n",
      "Epoch 960/1000\n",
      "131/131 [==============================] - 0s - loss: 615455.7965 - val_loss: 753230.5625\n",
      "Epoch 961/1000\n",
      "131/131 [==============================] - 0s - loss: 561881.2689 - val_loss: 730632.2366\n",
      "Epoch 962/1000\n",
      "131/131 [==============================] - 0s - loss: 591981.9277 - val_loss: 651884.6652\n",
      "Epoch 963/1000\n",
      "131/131 [==============================] - 0s - loss: 651864.3845 - val_loss: 660258.2545\n",
      "Epoch 964/1000\n",
      "131/131 [==============================] - 0s - loss: 631484.2690 - val_loss: 610547.7277\n",
      "Epoch 965/1000\n",
      "131/131 [==============================] - 0s - loss: 598826.0835 - val_loss: 714128.7188\n",
      "Epoch 966/1000\n",
      "131/131 [==============================] - 0s - loss: 615052.1869 - val_loss: 580495.9754\n",
      "Epoch 967/1000\n",
      "131/131 [==============================] - 0s - loss: 627430.8366 - val_loss: 663841.2768\n",
      "Epoch 968/1000\n",
      "131/131 [==============================] - 0s - loss: 669806.5860 - val_loss: 658085.6987\n",
      "Epoch 969/1000\n",
      "131/131 [==============================] - 0s - loss: 591839.8847 - val_loss: 647608.7991\n",
      "Epoch 970/1000\n",
      "131/131 [==============================] - 0s - loss: 647123.2634 - val_loss: 662724.8080\n",
      "Epoch 971/1000\n",
      "131/131 [==============================] - 0s - loss: 645478.2868 - val_loss: 279822.1473\n",
      "Epoch 972/1000\n",
      "131/131 [==============================] - 0s - loss: 569098.7430 - val_loss: 688319.1071\n",
      "Epoch 973/1000\n",
      "131/131 [==============================] - 0s - loss: 692310.7030 - val_loss: 500461.9576\n",
      "Epoch 974/1000\n",
      "131/131 [==============================] - 0s - loss: 692943.7871 - val_loss: 294251.1964\n",
      "Epoch 975/1000\n",
      "131/131 [==============================] - 0s - loss: 618384.9100 - val_loss: 539501.8571\n",
      "Epoch 976/1000\n",
      "131/131 [==============================] - 0s - loss: 660568.9579 - val_loss: 428411.6607\n",
      "Epoch 977/1000\n",
      "131/131 [==============================] - 0s - loss: 613070.8454 - val_loss: 665583.9018\n",
      "Epoch 978/1000\n",
      "131/131 [==============================] - 0s - loss: 582739.0673 - val_loss: 697101.3839\n",
      "Epoch 979/1000\n",
      "131/131 [==============================] - 0s - loss: 628678.0886 - val_loss: 505785.7277\n",
      "Epoch 980/1000\n",
      "131/131 [==============================] - 0s - loss: 594363.0860 - val_loss: 252371.4442\n",
      "Epoch 981/1000\n",
      "131/131 [==============================] - 0s - loss: 669211.3912 - val_loss: 255493.0915\n",
      "Epoch 982/1000\n",
      "131/131 [==============================] - 0s - loss: 675706.7228 - val_loss: 232238.8013834\n",
      "Epoch 983/1000\n",
      "131/131 [==============================] - 0s - loss: 572149.5123 - val_loss: 695646.6607\n",
      "Epoch 984/1000\n",
      "131/131 [==============================] - 0s - loss: 624006.7669 - val_loss: 646037.1920\n",
      "Epoch 985/1000\n",
      "131/131 [==============================] - 0s - loss: 652343.0697 - val_loss: 365788.5223\n",
      "Epoch 986/1000\n",
      "131/131 [==============================] - 0s - loss: 621394.1476 - val_loss: 602656.3080\n",
      "Epoch 987/1000\n",
      "131/131 [==============================] - 0s - loss: 605392.6183 - val_loss: 615509.8304\n",
      "Epoch 988/1000\n",
      "131/131 [==============================] - 0s - loss: 565780.9085 - val_loss: 403838.1741\n",
      "Epoch 989/1000\n",
      "131/131 [==============================] - 0s - loss: 612269.0797 - val_loss: 555556.7902\n",
      "Epoch 990/1000\n",
      "131/131 [==============================] - 0s - loss: 626728.8793 - val_loss: 622096.8839\n",
      "Epoch 991/1000\n",
      "131/131 [==============================] - 0s - loss: 577621.5213 - val_loss: 742392.2143\n",
      "Epoch 992/1000\n",
      "131/131 [==============================] - 0s - loss: 513732.8449 - val_loss: 276442.7634\n",
      "Epoch 993/1000\n",
      "131/131 [==============================] - 0s - loss: 660650.8084 - val_loss: 766427.9107\n",
      "Epoch 994/1000\n",
      "131/131 [==============================] - 0s - loss: 639032.6525 - val_loss: 428742.1161\n",
      "Epoch 995/1000\n",
      "131/131 [==============================] - 0s - loss: 638039.5166 - val_loss: 531217.2500\n",
      "Epoch 996/1000\n",
      "131/131 [==============================] - 0s - loss: 604494.8511 - val_loss: 470256.1830\n",
      "Epoch 997/1000\n",
      "131/131 [==============================] - 0s - loss: 523833.1393 - val_loss: 651846.8616\n",
      "Epoch 998/1000\n",
      "131/131 [==============================] - 0s - loss: 637580.0969 - val_loss: 716030.2411\n",
      "Epoch 999/1000\n",
      "131/131 [==============================] - 0s - loss: 668349.7362 - val_loss: 707317.6205\n",
      "Epoch 1000/1000\n",
      "131/131 [==============================] - 0s - loss: 615932.5544 - val_loss: 696419.0625\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 1807.50219727]\n",
      "result len(data): 160\n",
      "result data.shape: (160,)\n",
      "result len(slicing): 135\n",
      "result slicing_shape: (135, 25)\n",
      "[array([4966,  275,  216,  231,  279, 2847,  186,   87,  180,  113,  198,\n",
      "        171,   30,  198,  137, 1462,  104,  121,   38,  140,  113, 1266,\n",
      "        150,   85,  183])]\n",
      "X_train shape: (134, 24, 1)\n",
      "y_train shape: (134,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 127 samples, validate on 7 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 607834.7568 - val_loss: 61761.8532\n",
      "Epoch 2/1000\n",
      "127/127 [==============================] - 0s - loss: 263310.6372 - val_loss: 59619.6694\n",
      "Epoch 3/1000\n",
      "127/127 [==============================] - 0s - loss: 211119.6708 - val_loss: 64432.8906\n",
      "Epoch 4/1000\n",
      "127/127 [==============================] - 0s - loss: 239632.5197 - val_loss: 28296.4136\n",
      "Epoch 5/1000\n",
      "127/127 [==============================] - 0s - loss: 267931.8398 - val_loss: 41118.3860\n",
      "Epoch 6/1000\n",
      "127/127 [==============================] - 0s - loss: 216193.6850 - val_loss: 43804.6255\n",
      "Epoch 7/1000\n",
      "127/127 [==============================] - 0s - loss: 221962.3469 - val_loss: 58419.8314\n",
      "Epoch 8/1000\n",
      "127/127 [==============================] - 0s - loss: 215441.7691 - val_loss: 65058.9698\n",
      "Epoch 9/1000\n",
      "127/127 [==============================] - 0s - loss: 221430.0464 - val_loss: 77069.7304\n",
      "Epoch 10/1000\n",
      "127/127 [==============================] - 0s - loss: 223205.6171 - val_loss: 55879.5677\n",
      "Epoch 11/1000\n",
      "127/127 [==============================] - 0s - loss: 218357.1394 - val_loss: 60641.4466\n",
      "Epoch 12/1000\n",
      "127/127 [==============================] - 0s - loss: 216758.5293 - val_loss: 52907.8473\n",
      "Epoch 13/1000\n",
      "127/127 [==============================] - 0s - loss: 215907.8245 - val_loss: 48766.4714\n",
      "Epoch 14/1000\n",
      "127/127 [==============================] - 0s - loss: 195340.5887 - val_loss: 59262.4295\n",
      "Epoch 15/1000\n",
      "127/127 [==============================] - 0s - loss: 225721.5846 - val_loss: 54380.8027\n",
      "Epoch 16/1000\n",
      "127/127 [==============================] - 0s - loss: 232625.5393 - val_loss: 58460.6739\n",
      "Epoch 17/1000\n",
      "127/127 [==============================] - 0s - loss: 223277.5025 - val_loss: 50936.3354\n",
      "Epoch 18/1000\n",
      "127/127 [==============================] - 0s - loss: 182410.9579 - val_loss: 51735.3503\n",
      "Epoch 19/1000\n",
      "127/127 [==============================] - 0s - loss: 230270.4870 - val_loss: 47771.3652\n",
      "Epoch 20/1000\n",
      "127/127 [==============================] - 0s - loss: 205554.8393 - val_loss: 61945.6978\n",
      "Epoch 21/1000\n",
      "127/127 [==============================] - 0s - loss: 214653.7890 - val_loss: 42110.4495\n",
      "Epoch 22/1000\n",
      "127/127 [==============================] - 0s - loss: 228618.9536 - val_loss: 44390.9074\n",
      "Epoch 23/1000\n",
      "127/127 [==============================] - 0s - loss: 212374.6270 - val_loss: 62011.6664\n",
      "Epoch 24/1000\n",
      "127/127 [==============================] - 0s - loss: 207823.9529 - val_loss: 37365.5350\n",
      "Epoch 25/1000\n",
      "127/127 [==============================] - 0s - loss: 220597.2145 - val_loss: 73434.4665\n",
      "Epoch 26/1000\n",
      "127/127 [==============================] - 0s - loss: 205642.7624 - val_loss: 62623.0166\n",
      "Epoch 27/1000\n",
      "127/127 [==============================] - 0s - loss: 231683.8697 - val_loss: 65722.8428\n",
      "Epoch 28/1000\n",
      "127/127 [==============================] - 0s - loss: 221853.8497 - val_loss: 54639.1065\n",
      "Epoch 29/1000\n",
      "127/127 [==============================] - 0s - loss: 225801.9116 - val_loss: 54579.5731\n",
      "Epoch 30/1000\n",
      "127/127 [==============================] - 0s - loss: 228066.2746 - val_loss: 56706.8398\n",
      "Epoch 31/1000\n",
      "127/127 [==============================] - 0s - loss: 193011.8810 - val_loss: 52497.5834\n",
      "Epoch 32/1000\n",
      "127/127 [==============================] - 0s - loss: 212083.3063 - val_loss: 69814.4280\n",
      "Epoch 33/1000\n",
      "127/127 [==============================] - 0s - loss: 214358.1755 - val_loss: 67754.3817\n",
      "Epoch 34/1000\n",
      "127/127 [==============================] - 0s - loss: 225500.4288 - val_loss: 48717.6419\n",
      "Epoch 35/1000\n",
      "127/127 [==============================] - 0s - loss: 195957.6752 - val_loss: 49757.2958\n",
      "Epoch 36/1000\n",
      "127/127 [==============================] - 0s - loss: 219945.8379 - val_loss: 55886.8404\n",
      "Epoch 37/1000\n",
      "127/127 [==============================] - 0s - loss: 206697.2419 - val_loss: 73762.9905\n",
      "Epoch 38/1000\n",
      "127/127 [==============================] - 0s - loss: 209474.6608 - val_loss: 38885.4713\n",
      "Epoch 39/1000\n",
      "127/127 [==============================] - 0s - loss: 212106.4325 - val_loss: 52503.5527\n",
      "Epoch 40/1000\n",
      "127/127 [==============================] - 0s - loss: 219124.4406 - val_loss: 44401.4316\n",
      "Epoch 41/1000\n",
      "127/127 [==============================] - 0s - loss: 214308.3962 - val_loss: 44706.5421\n",
      "Epoch 42/1000\n",
      "127/127 [==============================] - 0s - loss: 211797.2042 - val_loss: 51017.8892\n",
      "Epoch 43/1000\n",
      "127/127 [==============================] - 0s - loss: 203806.1867 - val_loss: 51754.2397\n",
      "Epoch 44/1000\n",
      "127/127 [==============================] - 0s - loss: 208814.3517 - val_loss: 55485.3662\n",
      "Epoch 45/1000\n",
      "127/127 [==============================] - 0s - loss: 212024.3501 - val_loss: 52355.2160\n",
      "Epoch 46/1000\n",
      "127/127 [==============================] - 0s - loss: 226256.4516 - val_loss: 76271.5441\n",
      "Epoch 47/1000\n",
      "127/127 [==============================] - 0s - loss: 199742.6641 - val_loss: 66793.6341\n",
      "Epoch 48/1000\n",
      "127/127 [==============================] - 0s - loss: 213409.1511 - val_loss: 67574.4593\n",
      "Epoch 49/1000\n",
      "127/127 [==============================] - 0s - loss: 228464.2898 - val_loss: 69435.6367\n",
      "Epoch 50/1000\n",
      "127/127 [==============================] - 0s - loss: 215888.3363 - val_loss: 68837.9111\n",
      "Epoch 51/1000\n",
      "127/127 [==============================] - 0s - loss: 231065.5550 - val_loss: 70039.8348\n",
      "Epoch 52/1000\n",
      "127/127 [==============================] - 0s - loss: 210693.1371 - val_loss: 61842.5109\n",
      "Epoch 53/1000\n",
      "127/127 [==============================] - 0s - loss: 180597.3231 - val_loss: 64725.6680\n",
      "Epoch 54/1000\n",
      "127/127 [==============================] - 0s - loss: 199222.6286 - val_loss: 66048.6338\n",
      "Epoch 55/1000\n",
      "127/127 [==============================] - 0s - loss: 179998.6047 - val_loss: 65129.0650\n",
      "Epoch 56/1000\n",
      "127/127 [==============================] - 0s - loss: 201739.0736 - val_loss: 52279.2706\n",
      "Epoch 57/1000\n",
      "127/127 [==============================] - 0s - loss: 206811.3498 - val_loss: 47133.8564\n",
      "Epoch 58/1000\n",
      "127/127 [==============================] - 0s - loss: 216697.3645 - val_loss: 39666.6413\n",
      "Epoch 59/1000\n",
      "127/127 [==============================] - 0s - loss: 199758.5312 - val_loss: 44385.7295\n",
      "Epoch 60/1000\n",
      "127/127 [==============================] - 0s - loss: 209012.9866 - val_loss: 47997.6472\n",
      "Epoch 61/1000\n",
      "127/127 [==============================] - 0s - loss: 208139.5354 - val_loss: 62240.1331\n",
      "Epoch 62/1000\n",
      "127/127 [==============================] - 0s - loss: 208586.9493 - val_loss: 56568.9149\n",
      "Epoch 63/1000\n",
      "127/127 [==============================] - 0s - loss: 202412.8071 - val_loss: 51653.2836\n",
      "Epoch 64/1000\n",
      "127/127 [==============================] - 0s - loss: 209366.0228 - val_loss: 56043.1108\n",
      "Epoch 65/1000\n",
      "127/127 [==============================] - 0s - loss: 197597.2451 - val_loss: 60367.994198460.35\n",
      "Epoch 66/1000\n",
      "127/127 [==============================] - 0s - loss: 197031.1441 - val_loss: 41254.1000\n",
      "Epoch 67/1000\n",
      "127/127 [==============================] - 0s - loss: 180892.8319 - val_loss: 35244.6469\n",
      "Epoch 68/1000\n",
      "127/127 [==============================] - 0s - loss: 219162.5631 - val_loss: 61071.2810\n",
      "Epoch 69/1000\n",
      "127/127 [==============================] - 0s - loss: 191744.4990 - val_loss: 61891.4460\n",
      "Epoch 70/1000\n",
      "127/127 [==============================] - 0s - loss: 210395.5529 - val_loss: 55598.4004\n",
      "Epoch 71/1000\n",
      "127/127 [==============================] - 0s - loss: 200488.8642 - val_loss: 57573.3214\n",
      "Epoch 72/1000\n",
      "127/127 [==============================] - 0s - loss: 199301.0208 - val_loss: 66172.8797\n",
      "Epoch 73/1000\n",
      "127/127 [==============================] - 0s - loss: 211049.7022 - val_loss: 65912.4688\n",
      "Epoch 74/1000\n",
      "127/127 [==============================] - 0s - loss: 193955.0914 - val_loss: 72676.7282\n",
      "Epoch 75/1000\n",
      "127/127 [==============================] - 0s - loss: 211506.6430 - val_loss: 49107.8915\n",
      "Epoch 76/1000\n",
      "127/127 [==============================] - 0s - loss: 193110.1018 - val_loss: 79211.3700\n",
      "Epoch 77/1000\n",
      "127/127 [==============================] - 0s - loss: 179587.7277 - val_loss: 96559.9676\n",
      "Epoch 78/1000\n",
      "127/127 [==============================] - 0s - loss: 178717.0091 - val_loss: 69622.8901\n",
      "Epoch 79/1000\n",
      "127/127 [==============================] - 0s - loss: 192686.5639 - val_loss: 65843.5625\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 189839.7140 - val_loss: 46710.0248\n",
      "Epoch 81/1000\n",
      "127/127 [==============================] - 0s - loss: 188567.3876 - val_loss: 45127.1155\n",
      "Epoch 82/1000\n",
      "127/127 [==============================] - 0s - loss: 197464.6149 - val_loss: 32086.6385\n",
      "Epoch 83/1000\n",
      "127/127 [==============================] - 0s - loss: 209066.1732 - val_loss: 48376.2084\n",
      "Epoch 84/1000\n",
      "127/127 [==============================] - 0s - loss: 228147.7375 - val_loss: 47710.7672\n",
      "Epoch 85/1000\n",
      "127/127 [==============================] - 0s - loss: 188899.6466 - val_loss: 51947.9580\n",
      "Epoch 86/1000\n",
      "127/127 [==============================] - 0s - loss: 199525.2263 - val_loss: 46571.8775\n",
      "Epoch 87/1000\n",
      "127/127 [==============================] - 0s - loss: 183244.6998 - val_loss: 63567.2455\n",
      "Epoch 88/1000\n",
      "127/127 [==============================] - 0s - loss: 210211.5250 - val_loss: 58351.4473\n",
      "Epoch 89/1000\n",
      "127/127 [==============================] - 0s - loss: 196853.2815 - val_loss: 65720.3934\n",
      "Epoch 90/1000\n",
      "127/127 [==============================] - 0s - loss: 181625.9043 - val_loss: 64193.9704\n",
      "Epoch 91/1000\n",
      "127/127 [==============================] - 0s - loss: 179510.4723 - val_loss: 78252.0692\n",
      "Epoch 92/1000\n",
      "127/127 [==============================] - 0s - loss: 182154.2893 - val_loss: 65269.4035\n",
      "Epoch 93/1000\n",
      "127/127 [==============================] - 0s - loss: 190451.1985 - val_loss: 64953.7812\n",
      "Epoch 94/1000\n",
      "127/127 [==============================] - 0s - loss: 183124.8076 - val_loss: 68309.7215\n",
      "Epoch 95/1000\n",
      "127/127 [==============================] - 0s - loss: 200953.5153 - val_loss: 57377.3234\n",
      "Epoch 96/1000\n",
      "127/127 [==============================] - 0s - loss: 176247.8629 - val_loss: 62028.6635\n",
      "Epoch 97/1000\n",
      "127/127 [==============================] - 0s - loss: 182742.6166 - val_loss: 47253.6451\n",
      "Epoch 98/1000\n",
      "127/127 [==============================] - 0s - loss: 206988.6307 - val_loss: 40173.2980\n",
      "Epoch 99/1000\n",
      "127/127 [==============================] - 0s - loss: 203228.6556 - val_loss: 54081.0117\n",
      "Epoch 100/1000\n",
      "127/127 [==============================] - 0s - loss: 192836.1447 - val_loss: 59849.9403\n",
      "Epoch 101/1000\n",
      "127/127 [==============================] - 0s - loss: 193339.7122 - val_loss: 78616.3248\n",
      "Epoch 102/1000\n",
      "127/127 [==============================] - 0s - loss: 191919.3898 - val_loss: 55884.5092\n",
      "Epoch 103/1000\n",
      "127/127 [==============================] - 0s - loss: 181352.8225 - val_loss: 63552.2347\n",
      "Epoch 104/1000\n",
      "127/127 [==============================] - 0s - loss: 172360.9030 - val_loss: 71547.0561\n",
      "Epoch 105/1000\n",
      "127/127 [==============================] - 0s - loss: 169365.6956 - val_loss: 93934.2634\n",
      "Epoch 106/1000\n",
      "127/127 [==============================] - 0s - loss: 173673.8054 - val_loss: 82377.1336\n",
      "Epoch 107/1000\n",
      "127/127 [==============================] - 0s - loss: 196256.2699 - val_loss: 76615.7542\n",
      "Epoch 108/1000\n",
      "127/127 [==============================] - 0s - loss: 174672.4750 - val_loss: 66189.7891\n",
      "Epoch 109/1000\n",
      "127/127 [==============================] - 0s - loss: 167383.6462 - val_loss: 70010.6814\n",
      "Epoch 110/1000\n",
      "127/127 [==============================] - 0s - loss: 187706.8137 - val_loss: 35660.7119\n",
      "Epoch 111/1000\n",
      "127/127 [==============================] - 0s - loss: 161321.0474 - val_loss: 69326.3560\n",
      "Epoch 112/1000\n",
      "127/127 [==============================] - 0s - loss: 173032.4520 - val_loss: 70515.1124\n",
      "Epoch 113/1000\n",
      "127/127 [==============================] - 0s - loss: 168867.2021 - val_loss: 69050.9531\n",
      "Epoch 114/1000\n",
      "127/127 [==============================] - 0s - loss: 195902.7202 - val_loss: 87610.8996\n",
      "Epoch 115/1000\n",
      "127/127 [==============================] - 0s - loss: 183370.0811 - val_loss: 71880.0631\n",
      "Epoch 116/1000\n",
      "127/127 [==============================] - 0s - loss: 191287.3462 - val_loss: 83615.1228\n",
      "Epoch 117/1000\n",
      "127/127 [==============================] - 0s - loss: 183072.9691 - val_loss: 75188.8158\n",
      "Epoch 118/1000\n",
      "127/127 [==============================] - 0s - loss: 191790.3514 - val_loss: 79465.2941\n",
      "Epoch 119/1000\n",
      "127/127 [==============================] - 0s - loss: 183220.7842 - val_loss: 80243.6451\n",
      "Epoch 120/1000\n",
      "127/127 [==============================] - 0s - loss: 178094.0515 - val_loss: 79371.0190\n",
      "Epoch 121/1000\n",
      "127/127 [==============================] - 0s - loss: 176145.3050 - val_loss: 70305.2773\n",
      "Epoch 122/1000\n",
      "127/127 [==============================] - 0s - loss: 182337.2974 - val_loss: 68493.8326\n",
      "Epoch 123/1000\n",
      "127/127 [==============================] - 0s - loss: 172702.3371 - val_loss: 81607.3309\n",
      "Epoch 124/1000\n",
      "127/127 [==============================] - 0s - loss: 198460.0373 - val_loss: 62164.1278\n",
      "Epoch 125/1000\n",
      "127/127 [==============================] - 0s - loss: 171914.7604 - val_loss: 66639.1677\n",
      "Epoch 126/1000\n",
      "127/127 [==============================] - 0s - loss: 178497.1859 - val_loss: 73363.0714\n",
      "Epoch 127/1000\n",
      "127/127 [==============================] - 0s - loss: 189489.5089 - val_loss: 80499.9626\n",
      "Epoch 128/1000\n",
      "127/127 [==============================] - 0s - loss: 185291.0037 - val_loss: 65156.2147\n",
      "Epoch 129/1000\n",
      "127/127 [==============================] - 0s - loss: 171182.1750 - val_loss: 81811.5954\n",
      "Epoch 130/1000\n",
      "127/127 [==============================] - 0s - loss: 176144.7476 - val_loss: 59502.8505\n",
      "Epoch 131/1000\n",
      "127/127 [==============================] - 0s - loss: 179363.3924 - val_loss: 67123.0050\n",
      "Epoch 132/1000\n",
      "127/127 [==============================] - 0s - loss: 160031.7662 - val_loss: 59209.9411\n",
      "Epoch 133/1000\n",
      "127/127 [==============================] - 0s - loss: 173948.1419 - val_loss: 54433.4046\n",
      "Epoch 134/1000\n",
      "127/127 [==============================] - 0s - loss: 171344.9894 - val_loss: 62723.4424\n",
      "Epoch 135/1000\n",
      "127/127 [==============================] - 0s - loss: 182677.1970 - val_loss: 84691.3259\n",
      "Epoch 136/1000\n",
      "127/127 [==============================] - 0s - loss: 170390.7689 - val_loss: 104766.7852\n",
      "Epoch 137/1000\n",
      "127/127 [==============================] - 0s - loss: 173183.1459 - val_loss: 76593.9576\n",
      "Epoch 138/1000\n",
      "127/127 [==============================] - 0s - loss: 179962.4775 - val_loss: 69842.3052\n",
      "Epoch 139/1000\n",
      "127/127 [==============================] - 0s - loss: 166163.8777 - val_loss: 67432.1652\n",
      "Epoch 140/1000\n",
      "127/127 [==============================] - 0s - loss: 185359.8213 - val_loss: 71218.8281\n",
      "Epoch 141/1000\n",
      "127/127 [==============================] - 0s - loss: 176533.1436 - val_loss: 74920.3661\n",
      "Epoch 142/1000\n",
      "127/127 [==============================] - 0s - loss: 177209.6317 - val_loss: 73979.3387\n",
      "Epoch 143/1000\n",
      "127/127 [==============================] - 0s - loss: 169441.4242 - val_loss: 87277.2321\n",
      "Epoch 144/1000\n",
      "127/127 [==============================] - 0s - loss: 175258.3919 - val_loss: 58404.4771\n",
      "Epoch 145/1000\n",
      "127/127 [==============================] - 0s - loss: 188676.9940 - val_loss: 64179.8041\n",
      "Epoch 146/1000\n",
      "127/127 [==============================] - 0s - loss: 177293.0043 - val_loss: 60383.7679\n",
      "Epoch 147/1000\n",
      "127/127 [==============================] - 0s - loss: 176589.6904 - val_loss: 42933.6300\n",
      "Epoch 148/1000\n",
      "127/127 [==============================] - 0s - loss: 169489.8904 - val_loss: 80247.9422\n",
      "Epoch 149/1000\n",
      "127/127 [==============================] - 0s - loss: 187176.1792 - val_loss: 77562.3052\n",
      "Epoch 150/1000\n",
      "127/127 [==============================] - 0s - loss: 177831.4713 - val_loss: 56856.8298\n",
      "Epoch 151/1000\n",
      "127/127 [==============================] - 0s - loss: 192606.7278 - val_loss: 81357.0642\n",
      "Epoch 152/1000\n",
      "127/127 [==============================] - 0s - loss: 183778.8685 - val_loss: 83150.9302\n",
      "Epoch 153/1000\n",
      "127/127 [==============================] - 0s - loss: 164665.9742 - val_loss: 77746.7059\n",
      "Epoch 154/1000\n",
      "127/127 [==============================] - 0s - loss: 175632.4997 - val_loss: 67968.4749\n",
      "Epoch 155/1000\n",
      "127/127 [==============================] - 0s - loss: 170470.4269 - val_loss: 62129.4900\n",
      "Epoch 156/1000\n",
      "127/127 [==============================] - 0s - loss: 169751.3314 - val_loss: 68938.1557\n",
      "Epoch 157/1000\n",
      "127/127 [==============================] - 0s - loss: 184644.8554 - val_loss: 56296.2068\n",
      "Epoch 158/1000\n",
      "127/127 [==============================] - 0s - loss: 174472.9675 - val_loss: 82502.3482\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 177288.4009 - val_loss: 70075.6680\n",
      "Epoch 160/1000\n",
      "127/127 [==============================] - 0s - loss: 174085.0499 - val_loss: 67783.2528\n",
      "Epoch 161/1000\n",
      "127/127 [==============================] - 0s - loss: 172712.7172 - val_loss: 66549.0999\n",
      "Epoch 162/1000\n",
      "127/127 [==============================] - 0s - loss: 180927.5093 - val_loss: 71619.1027\n",
      "Epoch 163/1000\n",
      "127/127 [==============================] - 0s - loss: 169101.1362 - val_loss: 82535.4174\n",
      "Epoch 164/1000\n",
      "127/127 [==============================] - 0s - loss: 167907.9238 - val_loss: 77411.4325\n",
      "Epoch 165/1000\n",
      "127/127 [==============================] - 0s - loss: 182347.1235 - val_loss: 77590.2812\n",
      "Epoch 166/1000\n",
      "127/127 [==============================] - 0s - loss: 177682.6929 - val_loss: 62589.6646\n",
      "Epoch 167/1000\n",
      "127/127 [==============================] - 0s - loss: 177037.8129 - val_loss: 72199.0982\n",
      "Epoch 168/1000\n",
      "127/127 [==============================] - 0s - loss: 195662.5822 - val_loss: 76524.992746590.\n",
      "Epoch 169/1000\n",
      "127/127 [==============================] - 0s - loss: 142938.1021 - val_loss: 74836.6049\n",
      "Epoch 170/1000\n",
      "127/127 [==============================] - 0s - loss: 167593.6658 - val_loss: 66708.8136\n",
      "Epoch 171/1000\n",
      "127/127 [==============================] - 0s - loss: 177552.1026 - val_loss: 77760.1696\n",
      "Epoch 172/1000\n",
      "127/127 [==============================] - 0s - loss: 165610.2657 - val_loss: 81202.8477\n",
      "Epoch 173/1000\n",
      "127/127 [==============================] - 0s - loss: 147257.2569 - val_loss: 83844.2812\n",
      "Epoch 174/1000\n",
      "127/127 [==============================] - 0s - loss: 165839.1292 - val_loss: 63275.9180\n",
      "Epoch 175/1000\n",
      "127/127 [==============================] - 0s - loss: 172660.8136 - val_loss: 75688.0871\n",
      "Epoch 176/1000\n",
      "127/127 [==============================] - 0s - loss: 160875.2887 - val_loss: 77311.6724\n",
      "Epoch 177/1000\n",
      "127/127 [==============================] - 0s - loss: 179313.5652 - val_loss: 75707.0089\n",
      "Epoch 178/1000\n",
      "127/127 [==============================] - 0s - loss: 174921.7740 - val_loss: 72704.140175\n",
      "Epoch 179/1000\n",
      "127/127 [==============================] - 0s - loss: 178190.2120 - val_loss: 67528.1473\n",
      "Epoch 180/1000\n",
      "127/127 [==============================] - 0s - loss: 183677.7665 - val_loss: 62870.5218\n",
      "Epoch 181/1000\n",
      "127/127 [==============================] - 0s - loss: 164976.2143 - val_loss: 60510.6546\n",
      "Epoch 182/1000\n",
      "127/127 [==============================] - 0s - loss: 172722.8611 - val_loss: 74779.4883\n",
      "Epoch 183/1000\n",
      "127/127 [==============================] - 0s - loss: 170777.8019 - val_loss: 75126.2444\n",
      "Epoch 184/1000\n",
      "127/127 [==============================] - 0s - loss: 181009.7805 - val_loss: 88047.9191\n",
      "Epoch 185/1000\n",
      "127/127 [==============================] - 0s - loss: 172919.1826 - val_loss: 117287.5190\n",
      "Epoch 186/1000\n",
      "127/127 [==============================] - 0s - loss: 173236.0203 - val_loss: 67117.9866\n",
      "Epoch 187/1000\n",
      "127/127 [==============================] - 0s - loss: 192998.2984 - val_loss: 110183.7132\n",
      "Epoch 188/1000\n",
      "127/127 [==============================] - 0s - loss: 174447.4725 - val_loss: 66824.6931\n",
      "Epoch 189/1000\n",
      "127/127 [==============================] - 0s - loss: 176547.2724 - val_loss: 82081.2746\n",
      "Epoch 190/1000\n",
      "127/127 [==============================] - 0s - loss: 170831.8981 - val_loss: 103858.2349\n",
      "Epoch 191/1000\n",
      "127/127 [==============================] - 0s - loss: 171138.7153 - val_loss: 112102.6730\n",
      "Epoch 192/1000\n",
      "127/127 [==============================] - 0s - loss: 167550.1539 - val_loss: 108599.1004\n",
      "Epoch 193/1000\n",
      "127/127 [==============================] - 0s - loss: 152270.7532 - val_loss: 104360.7723\n",
      "Epoch 194/1000\n",
      "127/127 [==============================] - 0s - loss: 148583.3756 - val_loss: 108510.7946\n",
      "Epoch 195/1000\n",
      "127/127 [==============================] - 0s - loss: 164037.0834 - val_loss: 111077.0458\n",
      "Epoch 196/1000\n",
      "127/127 [==============================] - 0s - loss: 138253.9965 - val_loss: 117810.6261\n",
      "Epoch 197/1000\n",
      "127/127 [==============================] - 0s - loss: 154064.8476 - val_loss: 99498.289156188.68\n",
      "Epoch 198/1000\n",
      "127/127 [==============================] - 0s - loss: 151724.5323 - val_loss: 99424.4040\n",
      "Epoch 199/1000\n",
      "127/127 [==============================] - 0s - loss: 153713.9206 - val_loss: 85836.2550\n",
      "Epoch 200/1000\n",
      "127/127 [==============================] - 0s - loss: 153592.9731 - val_loss: 95089.3415\n",
      "Epoch 201/1000\n",
      "127/127 [==============================] - 0s - loss: 188570.4564 - val_loss: 82886.3231\n",
      "Epoch 202/1000\n",
      "127/127 [==============================] - 0s - loss: 160927.8436 - val_loss: 52292.3131\n",
      "Epoch 203/1000\n",
      "127/127 [==============================] - 0s - loss: 161200.0490 - val_loss: 60360.4866\n",
      "Epoch 204/1000\n",
      "127/127 [==============================] - 0s - loss: 186929.0899 - val_loss: 86830.9827\n",
      "Epoch 205/1000\n",
      "127/127 [==============================] - 0s - loss: 189178.9528 - val_loss: 39906.2746\n",
      "Epoch 206/1000\n",
      "127/127 [==============================] - 0s - loss: 162563.7292 - val_loss: 47049.9308\n",
      "Epoch 207/1000\n",
      "127/127 [==============================] - 0s - loss: 165674.9743 - val_loss: 34818.4688\n",
      "Epoch 208/1000\n",
      "127/127 [==============================] - 0s - loss: 146949.5091 - val_loss: 46623.3510\n",
      "Epoch 209/1000\n",
      "127/127 [==============================] - 0s - loss: 155715.1204 - val_loss: 57135.8571\n",
      "Epoch 210/1000\n",
      "127/127 [==============================] - 0s - loss: 155276.7015 - val_loss: 56541.2439\n",
      "Epoch 211/1000\n",
      "127/127 [==============================] - 0s - loss: 145065.8193 - val_loss: 71675.5915\n",
      "Epoch 212/1000\n",
      "127/127 [==============================] - 0s - loss: 167787.5685 - val_loss: 60392.4344\n",
      "Epoch 213/1000\n",
      "127/127 [==============================] - 0s - loss: 180296.2424 - val_loss: 63843.3744\n",
      "Epoch 214/1000\n",
      "127/127 [==============================] - 0s - loss: 159134.2128 - val_loss: 65352.6370\n",
      "Epoch 215/1000\n",
      "127/127 [==============================] - 0s - loss: 147729.9733 - val_loss: 60324.4738\n",
      "Epoch 216/1000\n",
      "127/127 [==============================] - 0s - loss: 170708.2135 - val_loss: 56975.8242\n",
      "Epoch 217/1000\n",
      "127/127 [==============================] - 0s - loss: 176644.8921 - val_loss: 56262.1080\n",
      "Epoch 218/1000\n",
      "127/127 [==============================] - 0s - loss: 165627.5134 - val_loss: 81868.4888\n",
      "Epoch 219/1000\n",
      "127/127 [==============================] - 0s - loss: 143748.1864 - val_loss: 72662.3438\n",
      "Epoch 220/1000\n",
      "127/127 [==============================] - 0s - loss: 162298.8115 - val_loss: 93817.9676\n",
      "Epoch 221/1000\n",
      "127/127 [==============================] - 0s - loss: 132827.0162 - val_loss: 117634.1205\n",
      "Epoch 222/1000\n",
      "127/127 [==============================] - 0s - loss: 146629.8686 - val_loss: 101463.4643\n",
      "Epoch 223/1000\n",
      "127/127 [==============================] - 0s - loss: 141600.2263 - val_loss: 187346.3996\n",
      "Epoch 224/1000\n",
      "127/127 [==============================] - 0s - loss: 168670.2056 - val_loss: 136111.5882\n",
      "Epoch 225/1000\n",
      "127/127 [==============================] - 0s - loss: 173959.2948 - val_loss: 76927.6415\n",
      "Epoch 226/1000\n",
      "127/127 [==============================] - 0s - loss: 136783.2674 - val_loss: 70637.1116\n",
      "Epoch 227/1000\n",
      "127/127 [==============================] - 0s - loss: 161415.1755 - val_loss: 101380.3097\n",
      "Epoch 228/1000\n",
      "127/127 [==============================] - 0s - loss: 125123.2417 - val_loss: 73872.771257\n",
      "Epoch 229/1000\n",
      "127/127 [==============================] - 0s - loss: 138535.7489 - val_loss: 219547.2712\n",
      "Epoch 230/1000\n",
      "127/127 [==============================] - 0s - loss: 178160.0169 - val_loss: 96652.6881\n",
      "Epoch 231/1000\n",
      "127/127 [==============================] - 0s - loss: 128717.2583 - val_loss: 198134.1339\n",
      "Epoch 232/1000\n",
      "127/127 [==============================] - 0s - loss: 124760.0355 - val_loss: 70612.1004\n",
      "Epoch 233/1000\n",
      "127/127 [==============================] - 0s - loss: 184187.5374 - val_loss: 28020.7656\n",
      "Epoch 234/1000\n",
      "127/127 [==============================] - 0s - loss: 165000.7193 - val_loss: 75761.8025\n",
      "Epoch 235/1000\n",
      "127/127 [==============================] - 0s - loss: 172708.7078 - val_loss: 55954.7824\n",
      "Epoch 236/1000\n",
      "127/127 [==============================] - 0s - loss: 160149.0077 - val_loss: 76453.8248\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 147328.2145 - val_loss: 68797.3761\n",
      "Epoch 238/1000\n",
      "127/127 [==============================] - 0s - loss: 106423.8168 - val_loss: 356151.2054\n",
      "Epoch 239/1000\n",
      "127/127 [==============================] - 0s - loss: 158752.5950 - val_loss: 123498.6724\n",
      "Epoch 240/1000\n",
      "127/127 [==============================] - 0s - loss: 115634.2676 - val_loss: 106012.80862747.59\n",
      "Epoch 241/1000\n",
      "127/127 [==============================] - 0s - loss: 151373.6354 - val_loss: 164159.7093\n",
      "Epoch 242/1000\n",
      "127/127 [==============================] - 0s - loss: 132036.2980 - val_loss: 37426.9980\n",
      "Epoch 243/1000\n",
      "127/127 [==============================] - 0s - loss: 102060.7499 - val_loss: 17876.4609\n",
      "Epoch 244/1000\n",
      "127/127 [==============================] - 0s - loss: 156149.7653 - val_loss: 45385.5569\n",
      "Epoch 245/1000\n",
      "127/127 [==============================] - 0s - loss: 139409.1001 - val_loss: 34668.7215\n",
      "Epoch 246/1000\n",
      "127/127 [==============================] - 0s - loss: 138215.3276 - val_loss: 41915.2634\n",
      "Epoch 247/1000\n",
      "127/127 [==============================] - 0s - loss: 129994.1192 - val_loss: 29189.6546\n",
      "Epoch 248/1000\n",
      "127/127 [==============================] - 0s - loss: 135389.1405 - val_loss: 33274.7746\n",
      "Epoch 249/1000\n",
      "127/127 [==============================] - 0s - loss: 140429.0956 - val_loss: 46134.6574\n",
      "Epoch 250/1000\n",
      "127/127 [==============================] - 0s - loss: 149363.0948 - val_loss: 40757.4767\n",
      "Epoch 251/1000\n",
      "127/127 [==============================] - 0s - loss: 116082.1425 - val_loss: 31243.3552\n",
      "Epoch 252/1000\n",
      "127/127 [==============================] - 0s - loss: 127000.6189 - val_loss: 38527.9218\n",
      "Epoch 253/1000\n",
      "127/127 [==============================] - 0s - loss: 137672.0105 - val_loss: 33483.974940785.87\n",
      "Epoch 254/1000\n",
      "127/127 [==============================] - 0s - loss: 133839.7124 - val_loss: 38228.7525\n",
      "Epoch 255/1000\n",
      "127/127 [==============================] - 0s - loss: 117365.2896 - val_loss: 47857.0045\n",
      "Epoch 256/1000\n",
      "127/127 [==============================] - 0s - loss: 112289.4544 - val_loss: 53463.0743\n",
      "Epoch 257/1000\n",
      "127/127 [==============================] - 0s - loss: 105709.7020 - val_loss: 54485.7930\n",
      "Epoch 258/1000\n",
      "127/127 [==============================] - 0s - loss: 116309.5692 - val_loss: 58665.2882\n",
      "Epoch 259/1000\n",
      "127/127 [==============================] - 0s - loss: 125237.5211 - val_loss: 34543.8465\n",
      "Epoch 260/1000\n",
      "127/127 [==============================] - 0s - loss: 139448.7767 - val_loss: 82949.7885\n",
      "Epoch 261/1000\n",
      "127/127 [==============================] - 0s - loss: 103478.3823 - val_loss: 60698.8298\n",
      "Epoch 262/1000\n",
      "127/127 [==============================] - 0s - loss: 101086.0189 - val_loss: 66316.4911\n",
      "Epoch 263/1000\n",
      "127/127 [==============================] - 0s - loss: 121492.4124 - val_loss: 46297.3943\n",
      "Epoch 264/1000\n",
      "127/127 [==============================] - 0s - loss: 123742.8289 - val_loss: 62437.7132\n",
      "Epoch 265/1000\n",
      "127/127 [==============================] - 0s - loss: 96152.9283 - val_loss: 74796.3917\n",
      "Epoch 266/1000\n",
      "127/127 [==============================] - 0s - loss: 97622.6671 - val_loss: 42452.9386\n",
      "Epoch 267/1000\n",
      "127/127 [==============================] - 0s - loss: 126506.8905 - val_loss: 55353.0954\n",
      "Epoch 268/1000\n",
      "127/127 [==============================] - 0s - loss: 113844.6670 - val_loss: 48434.7232\n",
      "Epoch 269/1000\n",
      "127/127 [==============================] - 0s - loss: 154591.5732 - val_loss: 46968.0255\n",
      "Epoch 270/1000\n",
      "127/127 [==============================] - 0s - loss: 158500.6225 - val_loss: 44095.8428\n",
      "Epoch 271/1000\n",
      "127/127 [==============================] - 0s - loss: 118086.0682 - val_loss: 58652.0711\n",
      "Epoch 272/1000\n",
      "127/127 [==============================] - 0s - loss: 120888.9003 - val_loss: 65577.3404\n",
      "Epoch 273/1000\n",
      "127/127 [==============================] - 0s - loss: 127424.6233 - val_loss: 71909.6094\n",
      "Epoch 274/1000\n",
      "127/127 [==============================] - 0s - loss: 103858.8753 - val_loss: 34298.6695\n",
      "Epoch 275/1000\n",
      "127/127 [==============================] - 0s - loss: 117542.4076 - val_loss: 58492.3610\n",
      "Epoch 276/1000\n",
      "127/127 [==============================] - 0s - loss: 109098.8381 - val_loss: 64736.7712\n",
      "Epoch 277/1000\n",
      "127/127 [==============================] - 0s - loss: 125930.6694 - val_loss: 65859.3661\n",
      "Epoch 278/1000\n",
      "127/127 [==============================] - 0s - loss: 105159.2999 - val_loss: 81518.8917\n",
      "Epoch 279/1000\n",
      "127/127 [==============================] - 0s - loss: 115004.3227 - val_loss: 58721.3348\n",
      "Epoch 280/1000\n",
      "127/127 [==============================] - 0s - loss: 176395.6030 - val_loss: 46266.0869\n",
      "Epoch 281/1000\n",
      "127/127 [==============================] - 0s - loss: 104546.0430 - val_loss: 43037.6769\n",
      "Epoch 282/1000\n",
      "127/127 [==============================] - 0s - loss: 153640.2284 - val_loss: 73649.4699\n",
      "Epoch 283/1000\n",
      "127/127 [==============================] - 0s - loss: 169361.4217 - val_loss: 73161.1789\n",
      "Epoch 284/1000\n",
      "127/127 [==============================] - 0s - loss: 127409.9204 - val_loss: 59660.5262\n",
      "Epoch 285/1000\n",
      "127/127 [==============================] - 0s - loss: 133141.0233 - val_loss: 196884.0272\n",
      "Epoch 286/1000\n",
      "127/127 [==============================] - 0s - loss: 114679.6493 - val_loss: 51914.4442\n",
      "Epoch 287/1000\n",
      "127/127 [==============================] - 0s - loss: 139305.7291 - val_loss: 36512.4269\n",
      "Epoch 288/1000\n",
      "127/127 [==============================] - 0s - loss: 116992.0763 - val_loss: 40775.9316\n",
      "Epoch 289/1000\n",
      "127/127 [==============================] - 0s - loss: 95374.2918 - val_loss: 70064.4358\n",
      "Epoch 290/1000\n",
      "127/127 [==============================] - 0s - loss: 98243.4010 - val_loss: 68282.2405\n",
      "Epoch 291/1000\n",
      "127/127 [==============================] - 0s - loss: 91130.1962 - val_loss: 70896.9738\n",
      "Epoch 292/1000\n",
      "127/127 [==============================] - 0s - loss: 134058.2456 - val_loss: 22363.8661\n",
      "Epoch 293/1000\n",
      "127/127 [==============================] - 0s - loss: 85423.4737 - val_loss: 28975.8557\n",
      "Epoch 294/1000\n",
      "127/127 [==============================] - 0s - loss: 116873.1645 - val_loss: 65673.9869\n",
      "Epoch 295/1000\n",
      "127/127 [==============================] - 0s - loss: 112679.7172 - val_loss: 56498.7997\n",
      "Epoch 296/1000\n",
      "127/127 [==============================] - 0s - loss: 153466.9846 - val_loss: 106017.83966475.52\n",
      "Epoch 297/1000\n",
      "127/127 [==============================] - 0s - loss: 80814.3546 - val_loss: 92646.3956\n",
      "Epoch 298/1000\n",
      "127/127 [==============================] - 0s - loss: 122990.2249 - val_loss: 73723.1900\n",
      "Epoch 299/1000\n",
      "127/127 [==============================] - 0s - loss: 139813.0612 - val_loss: 70630.9035\n",
      "Epoch 300/1000\n",
      "127/127 [==============================] - 0s - loss: 94129.2954 - val_loss: 43772.8488\n",
      "Epoch 301/1000\n",
      "127/127 [==============================] - 0s - loss: 109084.5161 - val_loss: 47833.2819\n",
      "Epoch 302/1000\n",
      "127/127 [==============================] - 0s - loss: 110602.5586 - val_loss: 47234.9284\n",
      "Epoch 303/1000\n",
      "127/127 [==============================] - 0s - loss: 104872.9885 - val_loss: 27332.5801\n",
      "Epoch 304/1000\n",
      "127/127 [==============================] - 0s - loss: 148082.3763 - val_loss: 50910.4710\n",
      "Epoch 305/1000\n",
      "127/127 [==============================] - 0s - loss: 116667.4722 - val_loss: 54552.7907\n",
      "Epoch 306/1000\n",
      "127/127 [==============================] - 0s - loss: 80265.7945 - val_loss: 44060.5631\n",
      "Epoch 307/1000\n",
      "127/127 [==============================] - 0s - loss: 124218.4868 - val_loss: 29308.3005\n",
      "Epoch 308/1000\n",
      "127/127 [==============================] - 0s - loss: 105265.6791 - val_loss: 51320.46885247.\n",
      "Epoch 309/1000\n",
      "127/127 [==============================] - 0s - loss: 94990.7707 - val_loss: 67927.4914\n",
      "Epoch 310/1000\n",
      "127/127 [==============================] - 0s - loss: 82434.8466 - val_loss: 56557.0552\n",
      "Epoch 311/1000\n",
      "127/127 [==============================] - 0s - loss: 99445.1490 - val_loss: 25996.4420\n",
      "Epoch 312/1000\n",
      "127/127 [==============================] - 0s - loss: 90810.5937 - val_loss: 50253.9743\n",
      "Epoch 313/1000\n",
      "127/127 [==============================] - 0s - loss: 81236.5619 - val_loss: 28926.7478\n",
      "Epoch 314/1000\n",
      "127/127 [==============================] - 0s - loss: 97834.7690 - val_loss: 43263.8027\n",
      "Epoch 315/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 92352.4418 - val_loss: 31925.9157\n",
      "Epoch 316/1000\n",
      "127/127 [==============================] - 0s - loss: 109222.4796 - val_loss: 38648.6044\n",
      "Epoch 317/1000\n",
      "127/127 [==============================] - 0s - loss: 81317.9521 - val_loss: 17943.6459\n",
      "Epoch 318/1000\n",
      "127/127 [==============================] - 0s - loss: 90263.4863 - val_loss: 33689.7490\n",
      "Epoch 319/1000\n",
      "127/127 [==============================] - 0s - loss: 103256.8489 - val_loss: 43059.6968\n",
      "Epoch 320/1000\n",
      "127/127 [==============================] - 0s - loss: 103073.9010 - val_loss: 43980.4057\n",
      "Epoch 321/1000\n",
      "127/127 [==============================] - 0s - loss: 100990.3365 - val_loss: 20408.1352\n",
      "Epoch 322/1000\n",
      "127/127 [==============================] - 0s - loss: 84249.3753 - val_loss: 12864.2733\n",
      "Epoch 323/1000\n",
      "127/127 [==============================] - 0s - loss: 105728.9175 - val_loss: 37076.7003\n",
      "Epoch 324/1000\n",
      "127/127 [==============================] - 0s - loss: 147860.5131 - val_loss: 32455.6885\n",
      "Epoch 325/1000\n",
      "127/127 [==============================] - 0s - loss: 171583.3719 - val_loss: 40061.9766\n",
      "Epoch 326/1000\n",
      "127/127 [==============================] - 0s - loss: 182004.2823 - val_loss: 14842.0631\n",
      "Epoch 327/1000\n",
      "127/127 [==============================] - 0s - loss: 146552.3278 - val_loss: 55930.5965\n",
      "Epoch 328/1000\n",
      "127/127 [==============================] - 0s - loss: 63219.7444 - val_loss: 47494.1616\n",
      "Epoch 329/1000\n",
      "127/127 [==============================] - 0s - loss: 93913.8603 - val_loss: 49617.3527\n",
      "Epoch 330/1000\n",
      "127/127 [==============================] - 0s - loss: 93415.6233 - val_loss: 85572.7801\n",
      "Epoch 331/1000\n",
      "127/127 [==============================] - 0s - loss: 158011.4008 - val_loss: 79028.7985\n",
      "Epoch 332/1000\n",
      "127/127 [==============================] - 0s - loss: 132531.4102 - val_loss: 54670.6119\n",
      "Epoch 333/1000\n",
      "127/127 [==============================] - 0s - loss: 99860.3038 - val_loss: 43565.3647\n",
      "Epoch 334/1000\n",
      "127/127 [==============================] - 0s - loss: 75401.8936 - val_loss: 42251.2076\n",
      "Epoch 335/1000\n",
      "127/127 [==============================] - 0s - loss: 95840.5228 - val_loss: 40269.1635\n",
      "Epoch 336/1000\n",
      "127/127 [==============================] - 0s - loss: 97433.4536 - val_loss: 45624.7737\n",
      "Epoch 337/1000\n",
      "127/127 [==============================] - 0s - loss: 103727.8666 - val_loss: 9494.9563\n",
      "Epoch 338/1000\n",
      "127/127 [==============================] - 0s - loss: 117081.4917 - val_loss: 30238.3627\n",
      "Epoch 339/1000\n",
      "127/127 [==============================] - 0s - loss: 104263.8201 - val_loss: 20454.8948\n",
      "Epoch 340/1000\n",
      "127/127 [==============================] - 0s - loss: 127688.8646 - val_loss: 27863.0173\n",
      "Epoch 341/1000\n",
      "127/127 [==============================] - 0s - loss: 108369.0777 - val_loss: 41631.2214\n",
      "Epoch 342/1000\n",
      "127/127 [==============================] - 0s - loss: 87825.2223 - val_loss: 64916.9434\n",
      "Epoch 343/1000\n",
      "127/127 [==============================] - 0s - loss: 140858.2839 - val_loss: 52944.5566\n",
      "Epoch 344/1000\n",
      "127/127 [==============================] - 0s - loss: 99946.1597 - val_loss: 57568.5474\n",
      "Epoch 345/1000\n",
      "127/127 [==============================] - 0s - loss: 116371.7403 - val_loss: 43680.2680\n",
      "Epoch 346/1000\n",
      "127/127 [==============================] - 0s - loss: 98936.5267 - val_loss: 46952.3109\n",
      "Epoch 347/1000\n",
      "127/127 [==============================] - 0s - loss: 106563.9286 - val_loss: 47147.7151\n",
      "Epoch 348/1000\n",
      "127/127 [==============================] - 0s - loss: 93798.4856 - val_loss: 64472.0193\n",
      "Epoch 349/1000\n",
      "127/127 [==============================] - 0s - loss: 80252.9288 - val_loss: 65554.8220\n",
      "Epoch 350/1000\n",
      "127/127 [==============================] - 0s - loss: 94628.9631 - val_loss: 50093.7923\n",
      "Epoch 351/1000\n",
      "127/127 [==============================] - 0s - loss: 98125.9525 - val_loss: 46639.0194\n",
      "Epoch 352/1000\n",
      "127/127 [==============================] - 0s - loss: 87105.5291 - val_loss: 23980.6084\n",
      "Epoch 353/1000\n",
      "127/127 [==============================] - 0s - loss: 162875.3903 - val_loss: 34917.2582\n",
      "Epoch 354/1000\n",
      "127/127 [==============================] - 0s - loss: 162145.7945 - val_loss: 37974.7828\n",
      "Epoch 355/1000\n",
      "127/127 [==============================] - 0s - loss: 160505.3434 - val_loss: 39816.6186\n",
      "Epoch 356/1000\n",
      "127/127 [==============================] - 0s - loss: 144027.0655 - val_loss: 55531.6203\n",
      "Epoch 357/1000\n",
      "127/127 [==============================] - 0s - loss: 66530.3080 - val_loss: 55030.3744\n",
      "Epoch 358/1000\n",
      "127/127 [==============================] - 0s - loss: 123843.4296 - val_loss: 37581.6655\n",
      "Epoch 359/1000\n",
      "127/127 [==============================] - 0s - loss: 96749.4569 - val_loss: 74982.8811\n",
      "Epoch 360/1000\n",
      "127/127 [==============================] - 0s - loss: 78706.0286 - val_loss: 36586.2448\n",
      "Epoch 361/1000\n",
      "127/127 [==============================] - 0s - loss: 81189.8746 - val_loss: 46972.8122\n",
      "Epoch 362/1000\n",
      "127/127 [==============================] - 0s - loss: 140246.0716 - val_loss: 63336.3898\n",
      "Epoch 363/1000\n",
      "127/127 [==============================] - 0s - loss: 78117.6756 - val_loss: 65049.6763\n",
      "Epoch 364/1000\n",
      "127/127 [==============================] - 0s - loss: 82077.8702 - val_loss: 37644.5145\n",
      "Epoch 365/1000\n",
      "127/127 [==============================] - 0s - loss: 80023.3298 - val_loss: 61158.7380\n",
      "Epoch 366/1000\n",
      "127/127 [==============================] - 0s - loss: 88907.4951 - val_loss: 39382.6157\n",
      "Epoch 367/1000\n",
      "127/127 [==============================] - 0s - loss: 109996.3707 - val_loss: 42022.6197\n",
      "Epoch 368/1000\n",
      "127/127 [==============================] - 0s - loss: 89900.0861 - val_loss: 29139.4576\n",
      "Epoch 369/1000\n",
      "127/127 [==============================] - 0s - loss: 72702.3571 - val_loss: 46475.2307\n",
      "Epoch 370/1000\n",
      "127/127 [==============================] - 0s - loss: 91134.1346 - val_loss: 43539.346399547.767\n",
      "Epoch 371/1000\n",
      "127/127 [==============================] - 0s - loss: 82326.9513 - val_loss: 54223.3470\n",
      "Epoch 372/1000\n",
      "127/127 [==============================] - 0s - loss: 78588.9464 - val_loss: 50552.0862\n",
      "Epoch 373/1000\n",
      "127/127 [==============================] - 0s - loss: 64653.2371 - val_loss: 45431.5569\n",
      "Epoch 374/1000\n",
      "127/127 [==============================] - 0s - loss: 75245.8824 - val_loss: 50357.5672\n",
      "Epoch 375/1000\n",
      "127/127 [==============================] - 0s - loss: 63870.7945 - val_loss: 61512.9562\n",
      "Epoch 376/1000\n",
      "127/127 [==============================] - 0s - loss: 79870.5555 - val_loss: 45499.6503\n",
      "Epoch 377/1000\n",
      "127/127 [==============================] - 0s - loss: 100678.9062 - val_loss: 43913.8686\n",
      "Epoch 378/1000\n",
      "127/127 [==============================] - 0s - loss: 77322.0533 - val_loss: 46409.7882\n",
      "Epoch 379/1000\n",
      "127/127 [==============================] - 0s - loss: 111864.3509 - val_loss: 70864.4113\n",
      "Epoch 380/1000\n",
      "127/127 [==============================] - 0s - loss: 71610.6000 - val_loss: 74322.1914\n",
      "Epoch 381/1000\n",
      "127/127 [==============================] - 0s - loss: 83600.3652 - val_loss: 72527.3887\n",
      "Epoch 382/1000\n",
      "127/127 [==============================] - 0s - loss: 81465.1585 - val_loss: 62946.1908\n",
      "Epoch 383/1000\n",
      "127/127 [==============================] - 0s - loss: 73706.6981 - val_loss: 56010.3962\n",
      "Epoch 384/1000\n",
      "127/127 [==============================] - 0s - loss: 65809.7460 - val_loss: 36088.5490\n",
      "Epoch 385/1000\n",
      "127/127 [==============================] - 0s - loss: 79568.5169 - val_loss: 63022.2095\n",
      "Epoch 386/1000\n",
      "127/127 [==============================] - 0s - loss: 77412.6498 - val_loss: 55112.28048995\n",
      "Epoch 387/1000\n",
      "127/127 [==============================] - 0s - loss: 94670.1897 - val_loss: 63325.7006\n",
      "Epoch 388/1000\n",
      "127/127 [==============================] - 0s - loss: 80092.4412 - val_loss: 47256.8555\n",
      "Epoch 389/1000\n",
      "127/127 [==============================] - 0s - loss: 51985.0570 - val_loss: 45507.155745471.46\n",
      "Epoch 390/1000\n",
      "127/127 [==============================] - 0s - loss: 68822.0427 - val_loss: 51361.4453\n",
      "Epoch 391/1000\n",
      "127/127 [==============================] - 0s - loss: 75136.4093 - val_loss: 53723.7317\n",
      "Epoch 392/1000\n",
      "127/127 [==============================] - 0s - loss: 108931.2250 - val_loss: 45103.5773\n",
      "Epoch 393/1000\n",
      "127/127 [==============================] - 0s - loss: 73680.8332 - val_loss: 42858.3292\n",
      "Epoch 394/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 79121.4566 - val_loss: 43453.3799\n",
      "Epoch 395/1000\n",
      "127/127 [==============================] - 0s - loss: 68276.3520 - val_loss: 51410.3627\n",
      "Epoch 396/1000\n",
      "127/127 [==============================] - 0s - loss: 93244.4964 - val_loss: 38435.3090\n",
      "Epoch 397/1000\n",
      "127/127 [==============================] - 0s - loss: 78523.0422 - val_loss: 39009.8178\n",
      "Epoch 398/1000\n",
      "127/127 [==============================] - 0s - loss: 69360.6675 - val_loss: 74821.9082\n",
      "Epoch 399/1000\n",
      "127/127 [==============================] - 0s - loss: 97852.2006 - val_loss: 38332.3895\n",
      "Epoch 400/1000\n",
      "127/127 [==============================] - 0s - loss: 74603.5172 - val_loss: 43306.0873\n",
      "Epoch 401/1000\n",
      "127/127 [==============================] - 0s - loss: 73983.1648 - val_loss: 58896.6509\n",
      "Epoch 402/1000\n",
      "127/127 [==============================] - 0s - loss: 71687.3860 - val_loss: 48932.4364\n",
      "Epoch 403/1000\n",
      "127/127 [==============================] - 0s - loss: 78586.3001 - val_loss: 51030.6066\n",
      "Epoch 404/1000\n",
      "127/127 [==============================] - 0s - loss: 54014.1361 - val_loss: 37418.3719\n",
      "Epoch 405/1000\n",
      "127/127 [==============================] - 0s - loss: 65313.9201 - val_loss: 34258.7398\n",
      "Epoch 406/1000\n",
      "127/127 [==============================] - 0s - loss: 125114.1250 - val_loss: 51434.2097\n",
      "Epoch 407/1000\n",
      "127/127 [==============================] - 0s - loss: 115395.9107 - val_loss: 45436.5261\n",
      "Epoch 408/1000\n",
      "127/127 [==============================] - 0s - loss: 102359.0717 - val_loss: 55235.4332\n",
      "Epoch 409/1000\n",
      "127/127 [==============================] - 0s - loss: 68389.3996 - val_loss: 56576.1562\n",
      "Epoch 410/1000\n",
      "127/127 [==============================] - 0s - loss: 70852.5289 - val_loss: 72081.0843\n",
      "Epoch 411/1000\n",
      "127/127 [==============================] - 0s - loss: 109351.7461 - val_loss: 61405.81478671\n",
      "Epoch 412/1000\n",
      "127/127 [==============================] - 0s - loss: 80932.9730 - val_loss: 66651.4265\n",
      "Epoch 413/1000\n",
      "127/127 [==============================] - 0s - loss: 56201.6535 - val_loss: 59393.9588\n",
      "Epoch 414/1000\n",
      "127/127 [==============================] - 0s - loss: 81910.0746 - val_loss: 55111.6547\n",
      "Epoch 415/1000\n",
      "127/127 [==============================] - 0s - loss: 51730.7276 - val_loss: 49734.4632\n",
      "Epoch 416/1000\n",
      "127/127 [==============================] - 0s - loss: 57926.0855 - val_loss: 40812.3214\n",
      "Epoch 417/1000\n",
      "127/127 [==============================] - 0s - loss: 132207.2030 - val_loss: 80843.9325\n",
      "Epoch 418/1000\n",
      "127/127 [==============================] - 0s - loss: 68888.4280 - val_loss: 43700.8125\n",
      "Epoch 419/1000\n",
      "127/127 [==============================] - 0s - loss: 72892.2103 - val_loss: 74362.7461\n",
      "Epoch 420/1000\n",
      "127/127 [==============================] - 0s - loss: 70252.2899 - val_loss: 73700.5751554\n",
      "Epoch 421/1000\n",
      "127/127 [==============================] - 0s - loss: 146127.6148 - val_loss: 57761.8895\n",
      "Epoch 422/1000\n",
      "127/127 [==============================] - 0s - loss: 56866.9363 - val_loss: 74821.7757\n",
      "Epoch 423/1000\n",
      "127/127 [==============================] - 0s - loss: 81254.1392 - val_loss: 58243.4275\n",
      "Epoch 424/1000\n",
      "127/127 [==============================] - 0s - loss: 78273.8601 - val_loss: 49142.6032\n",
      "Epoch 425/1000\n",
      "127/127 [==============================] - 0s - loss: 64372.3156 - val_loss: 55880.5455\n",
      "Epoch 426/1000\n",
      "127/127 [==============================] - 0s - loss: 105456.1147 - val_loss: 30297.5218\n",
      "Epoch 427/1000\n",
      "127/127 [==============================] - 0s - loss: 72665.1020 - val_loss: 65315.9821\n",
      "Epoch 428/1000\n",
      "127/127 [==============================] - 0s - loss: 69847.2965 - val_loss: 59612.6999\n",
      "Epoch 429/1000\n",
      "127/127 [==============================] - 0s - loss: 60760.2857 - val_loss: 54724.9590\n",
      "Epoch 430/1000\n",
      "127/127 [==============================] - 0s - loss: 48252.0020 - val_loss: 72688.2107\n",
      "Epoch 431/1000\n",
      "127/127 [==============================] - 0s - loss: 55897.5149 - val_loss: 56885.9107\n",
      "Epoch 432/1000\n",
      "127/127 [==============================] - 0s - loss: 71858.1648 - val_loss: 44112.2645\n",
      "Epoch 433/1000\n",
      "127/127 [==============================] - 0s - loss: 80500.7004 - val_loss: 59059.1998\n",
      "Epoch 434/1000\n",
      "127/127 [==============================] - 0s - loss: 52507.9660 - val_loss: 61481.7093\n",
      "Epoch 435/1000\n",
      "127/127 [==============================] - 0s - loss: 72092.6651 - val_loss: 27765.0935\n",
      "Epoch 436/1000\n",
      "127/127 [==============================] - 0s - loss: 83614.4771 - val_loss: 78538.3983\n",
      "Epoch 437/1000\n",
      "127/127 [==============================] - 0s - loss: 66528.1851 - val_loss: 72444.1738\n",
      "Epoch 438/1000\n",
      "127/127 [==============================] - 0s - loss: 58442.7417 - val_loss: 71425.9523\n",
      "Epoch 439/1000\n",
      "127/127 [==============================] - 0s - loss: 63416.0366 - val_loss: 49500.2356\n",
      "Epoch 440/1000\n",
      "127/127 [==============================] - 0s - loss: 93160.7439 - val_loss: 43976.1425\n",
      "Epoch 441/1000\n",
      "127/127 [==============================] - 0s - loss: 132068.3191 - val_loss: 73960.3135\n",
      "Epoch 442/1000\n",
      "127/127 [==============================] - 0s - loss: 68113.7156 - val_loss: 86473.2160\n",
      "Epoch 443/1000\n",
      "127/127 [==============================] - 0s - loss: 54026.3175 - val_loss: 75009.5039\n",
      "Epoch 444/1000\n",
      "127/127 [==============================] - 0s - loss: 79315.3818 - val_loss: 48175.9729\n",
      "Epoch 445/1000\n",
      "127/127 [==============================] - 0s - loss: 59171.7345 - val_loss: 48875.4018\n",
      "Epoch 446/1000\n",
      "127/127 [==============================] - 0s - loss: 76814.8284 - val_loss: 106472.5636\n",
      "Epoch 447/1000\n",
      "127/127 [==============================] - 0s - loss: 62501.2670 - val_loss: 73492.9163\n",
      "Epoch 448/1000\n",
      "127/127 [==============================] - 0s - loss: 73286.8310 - val_loss: 57183.7132\n",
      "Epoch 449/1000\n",
      "127/127 [==============================] - 0s - loss: 64864.2094 - val_loss: 53984.9953\n",
      "Epoch 450/1000\n",
      "127/127 [==============================] - 0s - loss: 49036.8670 - val_loss: 63052.2533\n",
      "Epoch 451/1000\n",
      "127/127 [==============================] - 0s - loss: 71160.6562 - val_loss: 63794.2143\n",
      "Epoch 452/1000\n",
      "127/127 [==============================] - 0s - loss: 74036.4803 - val_loss: 68191.1117\n",
      "Epoch 453/1000\n",
      "127/127 [==============================] - 0s - loss: 55294.4882 - val_loss: 67012.1059\n",
      "Epoch 454/1000\n",
      "127/127 [==============================] - 0s - loss: 55820.0175 - val_loss: 58531.6793\n",
      "Epoch 455/1000\n",
      "127/127 [==============================] - 0s - loss: 78974.7170 - val_loss: 71382.3504\n",
      "Epoch 456/1000\n",
      "127/127 [==============================] - 0s - loss: 56657.5375 - val_loss: 53965.2480503\n",
      "Epoch 457/1000\n",
      "127/127 [==============================] - 0s - loss: 64873.4101 - val_loss: 60193.0558\n",
      "Epoch 458/1000\n",
      "127/127 [==============================] - 0s - loss: 55006.8358 - val_loss: 75131.0725\n",
      "Epoch 459/1000\n",
      "127/127 [==============================] - 0s - loss: 67205.9002 - val_loss: 52055.0545\n",
      "Epoch 460/1000\n",
      "127/127 [==============================] - 0s - loss: 57299.8636 - val_loss: 41432.7995\n",
      "Epoch 461/1000\n",
      "127/127 [==============================] - 0s - loss: 75924.6103 - val_loss: 33891.1878\n",
      "Epoch 462/1000\n",
      "127/127 [==============================] - 0s - loss: 85644.9301 - val_loss: 42701.2678\n",
      "Epoch 463/1000\n",
      "127/127 [==============================] - 0s - loss: 52072.3070 - val_loss: 47930.1934\n",
      "Epoch 464/1000\n",
      "127/127 [==============================] - 0s - loss: 59868.2561 - val_loss: 64951.8744\n",
      "Epoch 465/1000\n",
      "127/127 [==============================] - 0s - loss: 50781.8311 - val_loss: 74085.22664932\n",
      "Epoch 466/1000\n",
      "127/127 [==============================] - 0s - loss: 53281.3907 - val_loss: 36460.6102\n",
      "Epoch 467/1000\n",
      "127/127 [==============================] - 0s - loss: 37761.8897 - val_loss: 57587.0424\n",
      "Epoch 468/1000\n",
      "127/127 [==============================] - 0s - loss: 73433.1595 - val_loss: 20297.8181\n",
      "Epoch 469/1000\n",
      "127/127 [==============================] - 0s - loss: 75643.2347 - val_loss: 53682.1674\n",
      "Epoch 470/1000\n",
      "127/127 [==============================] - 0s - loss: 116458.1653 - val_loss: 61266.8684\n",
      "Epoch 471/1000\n",
      "127/127 [==============================] - 0s - loss: 43063.6550 - val_loss: 52412.3649\n",
      "Epoch 472/1000\n",
      "127/127 [==============================] - 0s - loss: 55360.8612 - val_loss: 72245.5652\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 49477.7319 - val_loss: 65698.8601\n",
      "Epoch 474/1000\n",
      "127/127 [==============================] - 0s - loss: 63430.8349 - val_loss: 57629.1657\n",
      "Epoch 475/1000\n",
      "127/127 [==============================] - 0s - loss: 73213.6911 - val_loss: 62921.4480\n",
      "Epoch 476/1000\n",
      "127/127 [==============================] - 0s - loss: 56153.4741 - val_loss: 74479.8592\n",
      "Epoch 477/1000\n",
      "127/127 [==============================] - 0s - loss: 58463.9372 - val_loss: 36686.1505\n",
      "Epoch 478/1000\n",
      "127/127 [==============================] - 0s - loss: 69985.2757 - val_loss: 57277.8015\n",
      "Epoch 479/1000\n",
      "127/127 [==============================] - 0s - loss: 45291.8968 - val_loss: 49781.4241\n",
      "Epoch 480/1000\n",
      "127/127 [==============================] - 0s - loss: 69722.9078 - val_loss: 62782.8892\n",
      "Epoch 481/1000\n",
      "127/127 [==============================] - 0s - loss: 113765.7046 - val_loss: 61048.7887\n",
      "Epoch 482/1000\n",
      "127/127 [==============================] - 0s - loss: 65498.5066 - val_loss: 64065.8993\n",
      "Epoch 483/1000\n",
      "127/127 [==============================] - 0s - loss: 58641.3228 - val_loss: 59301.9429\n",
      "Epoch 484/1000\n",
      "127/127 [==============================] - 0s - loss: 68606.4177 - val_loss: 51768.6385\n",
      "Epoch 485/1000\n",
      "127/127 [==============================] - 0s - loss: 65269.9421 - val_loss: 51614.2263\n",
      "Epoch 486/1000\n",
      "127/127 [==============================] - 0s - loss: 70758.3083 - val_loss: 55539.3092\n",
      "Epoch 487/1000\n",
      "127/127 [==============================] - 0s - loss: 47568.7158 - val_loss: 64106.7041\n",
      "Epoch 488/1000\n",
      "127/127 [==============================] - 0s - loss: 136347.4716 - val_loss: 80476.1200\n",
      "Epoch 489/1000\n",
      "127/127 [==============================] - 0s - loss: 106031.1111 - val_loss: 81150.2683\n",
      "Epoch 490/1000\n",
      "127/127 [==============================] - 0s - loss: 43766.1489 - val_loss: 66934.8753\n",
      "Epoch 491/1000\n",
      "127/127 [==============================] - 0s - loss: 49064.6206 - val_loss: 65231.6039\n",
      "Epoch 492/1000\n",
      "127/127 [==============================] - 0s - loss: 36155.6164 - val_loss: 59886.5255\n",
      "Epoch 493/1000\n",
      "127/127 [==============================] - 0s - loss: 54400.2891 - val_loss: 60990.1518\n",
      "Epoch 494/1000\n",
      "127/127 [==============================] - 0s - loss: 43975.3104 - val_loss: 73080.5798\n",
      "Epoch 495/1000\n",
      "127/127 [==============================] - 0s - loss: 68953.7547 - val_loss: 48998.6719\n",
      "Epoch 496/1000\n",
      "127/127 [==============================] - 0s - loss: 68503.2144 - val_loss: 68543.3426\n",
      "Epoch 497/1000\n",
      "127/127 [==============================] - 0s - loss: 59756.1161 - val_loss: 64960.3896\n",
      "Epoch 498/1000\n",
      "127/127 [==============================] - 0s - loss: 61586.1975 - val_loss: 73563.6791\n",
      "Epoch 499/1000\n",
      "127/127 [==============================] - 0s - loss: 48457.1417 - val_loss: 37669.8758\n",
      "Epoch 500/1000\n",
      "127/127 [==============================] - 0s - loss: 39937.8263 - val_loss: 46762.6858\n",
      "Epoch 501/1000\n",
      "127/127 [==============================] - 0s - loss: 63854.7131 - val_loss: 14718.9090\n",
      "Epoch 502/1000\n",
      "127/127 [==============================] - 0s - loss: 69976.8899 - val_loss: 45089.2289\n",
      "Epoch 503/1000\n",
      "127/127 [==============================] - 0s - loss: 67901.0610 - val_loss: 13044.4488\n",
      "Epoch 504/1000\n",
      "127/127 [==============================] - 0s - loss: 56780.2394 - val_loss: 38695.5970\n",
      "Epoch 505/1000\n",
      "127/127 [==============================] - 0s - loss: 31540.4146 - val_loss: 46320.3985\n",
      "Epoch 506/1000\n",
      "127/127 [==============================] - 0s - loss: 51551.3377 - val_loss: 63485.1158\n",
      "Epoch 507/1000\n",
      "127/127 [==============================] - 0s - loss: 54205.0429 - val_loss: 52950.6956\n",
      "Epoch 508/1000\n",
      "127/127 [==============================] - 0s - loss: 70940.9188 - val_loss: 46583.4894\n",
      "Epoch 509/1000\n",
      "127/127 [==============================] - 0s - loss: 45121.9717 - val_loss: 36403.3424\n",
      "Epoch 510/1000\n",
      "127/127 [==============================] - 0s - loss: 58817.5000 - val_loss: 54591.7545\n",
      "Epoch 511/1000\n",
      "127/127 [==============================] - 0s - loss: 46265.3106 - val_loss: 50383.4826\n",
      "Epoch 512/1000\n",
      "127/127 [==============================] - 0s - loss: 60848.3088 - val_loss: 63430.4121\n",
      "Epoch 513/1000\n",
      "127/127 [==============================] - 0s - loss: 58203.6412 - val_loss: 31713.0869\n",
      "Epoch 514/1000\n",
      "127/127 [==============================] - 0s - loss: 37876.4527 - val_loss: 50096.2495\n",
      "Epoch 515/1000\n",
      "127/127 [==============================] - 0s - loss: 50182.9193 - val_loss: 42331.1986\n",
      "Epoch 516/1000\n",
      "127/127 [==============================] - 0s - loss: 49979.1991 - val_loss: 43662.5706\n",
      "Epoch 517/1000\n",
      "127/127 [==============================] - 0s - loss: 66374.0736 - val_loss: 68607.292150192.\n",
      "Epoch 518/1000\n",
      "127/127 [==============================] - 0s - loss: 64186.8191 - val_loss: 54685.3744\n",
      "Epoch 519/1000\n",
      "127/127 [==============================] - 0s - loss: 96395.7969 - val_loss: 43674.7708\n",
      "Epoch 520/1000\n",
      "127/127 [==============================] - 0s - loss: 51908.9475 - val_loss: 44857.0085\n",
      "Epoch 521/1000\n",
      "127/127 [==============================] - 0s - loss: 43936.4967 - val_loss: 44639.4977\n",
      "Epoch 522/1000\n",
      "127/127 [==============================] - 0s - loss: 54992.0813 - val_loss: 47887.0589\n",
      "Epoch 523/1000\n",
      "127/127 [==============================] - 0s - loss: 55373.2976 - val_loss: 46693.8728\n",
      "Epoch 524/1000\n",
      "127/127 [==============================] - 0s - loss: 73667.2838 - val_loss: 59767.6640\n",
      "Epoch 525/1000\n",
      "127/127 [==============================] - 0s - loss: 59475.3105 - val_loss: 64459.3845\n",
      "Epoch 526/1000\n",
      "127/127 [==============================] - 0s - loss: 43424.4886 - val_loss: 31685.2740\n",
      "Epoch 527/1000\n",
      "127/127 [==============================] - 0s - loss: 66774.6561 - val_loss: 45893.0081\n",
      "Epoch 528/1000\n",
      "127/127 [==============================] - 0s - loss: 45214.3451 - val_loss: 42340.3361\n",
      "Epoch 529/1000\n",
      "127/127 [==============================] - 0s - loss: 56684.2168 - val_loss: 64080.7243\n",
      "Epoch 530/1000\n",
      "127/127 [==============================] - 0s - loss: 41762.0749 - val_loss: 60709.8800\n",
      "Epoch 531/1000\n",
      "127/127 [==============================] - 0s - loss: 44154.9715 - val_loss: 51294.3300\n",
      "Epoch 532/1000\n",
      "127/127 [==============================] - 0s - loss: 95321.4470 - val_loss: 37350.9396\n",
      "Epoch 533/1000\n",
      "127/127 [==============================] - 0s - loss: 65927.1850 - val_loss: 38536.2638\n",
      "Epoch 534/1000\n",
      "127/127 [==============================] - 0s - loss: 31261.5968 - val_loss: 46389.0997\n",
      "Epoch 535/1000\n",
      "127/127 [==============================] - 0s - loss: 69163.6873 - val_loss: 62828.485555936\n",
      "Epoch 536/1000\n",
      "127/127 [==============================] - 0s - loss: 84464.4628 - val_loss: 81974.9074\n",
      "Epoch 537/1000\n",
      "127/127 [==============================] - 0s - loss: 47465.3435 - val_loss: 74527.1456\n",
      "Epoch 538/1000\n",
      "127/127 [==============================] - 0s - loss: 77368.9838 - val_loss: 44643.0802\n",
      "Epoch 539/1000\n",
      "127/127 [==============================] - 0s - loss: 63863.2842 - val_loss: 48748.7492\n",
      "Epoch 540/1000\n",
      "127/127 [==============================] - 0s - loss: 46754.3537 - val_loss: 11214.8376\n",
      "Epoch 541/1000\n",
      "127/127 [==============================] - 0s - loss: 47169.9051 - val_loss: 43312.1657\n",
      "Epoch 542/1000\n",
      "127/127 [==============================] - 0s - loss: 32356.4348 - val_loss: 33242.6506\n",
      "Epoch 543/1000\n",
      "127/127 [==============================] - 0s - loss: 77458.6771 - val_loss: 48872.789864738.08\n",
      "Epoch 544/1000\n",
      "127/127 [==============================] - 0s - loss: 65219.1358 - val_loss: 31615.7291\n",
      "Epoch 545/1000\n",
      "127/127 [==============================] - 0s - loss: 33669.3971 - val_loss: 60577.4559\n",
      "Epoch 546/1000\n",
      "127/127 [==============================] - 0s - loss: 65272.5953 - val_loss: 54248.1306\n",
      "Epoch 547/1000\n",
      "127/127 [==============================] - 0s - loss: 35028.0465 - val_loss: 43991.5194\n",
      "Epoch 548/1000\n",
      "127/127 [==============================] - 0s - loss: 43720.7234 - val_loss: 51829.1131\n",
      "Epoch 549/1000\n",
      "127/127 [==============================] - 0s - loss: 36735.2047 - val_loss: 45887.5148\n",
      "Epoch 550/1000\n",
      "127/127 [==============================] - 0s - loss: 37710.6860 - val_loss: 51287.1415\n",
      "Epoch 551/1000\n",
      "127/127 [==============================] - 0s - loss: 38896.2047 - val_loss: 40926.5290\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 58784.4935 - val_loss: 26570.4521\n",
      "Epoch 553/1000\n",
      "127/127 [==============================] - 0s - loss: 48537.9638 - val_loss: 41470.5551\n",
      "Epoch 554/1000\n",
      "127/127 [==============================] - 0s - loss: 36871.6977 - val_loss: 55368.2069\n",
      "Epoch 555/1000\n",
      "127/127 [==============================] - 0s - loss: 34200.2487 - val_loss: 36619.8912\n",
      "Epoch 556/1000\n",
      "127/127 [==============================] - 0s - loss: 23265.7781 - val_loss: 56214.6657\n",
      "Epoch 557/1000\n",
      "127/127 [==============================] - 0s - loss: 43680.4272 - val_loss: 33029.3358\n",
      "Epoch 558/1000\n",
      "127/127 [==============================] - 0s - loss: 60991.8207 - val_loss: 25069.4544\n",
      "Epoch 559/1000\n",
      "127/127 [==============================] - 0s - loss: 56203.2521 - val_loss: 41941.0566\n",
      "Epoch 560/1000\n",
      "127/127 [==============================] - 0s - loss: 77298.8925 - val_loss: 55710.0999\n",
      "Epoch 561/1000\n",
      "127/127 [==============================] - 0s - loss: 120128.5809 - val_loss: 45723.9408\n",
      "Epoch 562/1000\n",
      "127/127 [==============================] - 0s - loss: 42438.6981 - val_loss: 38140.7960\n",
      "Epoch 563/1000\n",
      "127/127 [==============================] - 0s - loss: 63516.8468 - val_loss: 37829.2644\n",
      "Epoch 564/1000\n",
      "127/127 [==============================] - 0s - loss: 43501.0179 - val_loss: 54923.3556\n",
      "Epoch 565/1000\n",
      "127/127 [==============================] - 0s - loss: 40842.8872 - val_loss: 40144.8473\n",
      "Epoch 566/1000\n",
      "127/127 [==============================] - 0s - loss: 30022.0486 - val_loss: 53090.7512\n",
      "Epoch 567/1000\n",
      "127/127 [==============================] - 0s - loss: 69070.7733 - val_loss: 40636.3192\n",
      "Epoch 568/1000\n",
      "127/127 [==============================] - 0s - loss: 57113.8065 - val_loss: 53438.6696\n",
      "Epoch 569/1000\n",
      "127/127 [==============================] - 0s - loss: 84117.1747 - val_loss: 43193.3755\n",
      "Epoch 570/1000\n",
      "127/127 [==============================] - 0s - loss: 46806.6189 - val_loss: 40853.8196\n",
      "Epoch 571/1000\n",
      "127/127 [==============================] - 0s - loss: 62296.7006 - val_loss: 15800.2748\n",
      "Epoch 572/1000\n",
      "127/127 [==============================] - 0s - loss: 37666.3803 - val_loss: 42236.6329\n",
      "Epoch 573/1000\n",
      "127/127 [==============================] - 0s - loss: 37467.9256 - val_loss: 56354.5098\n",
      "Epoch 574/1000\n",
      "127/127 [==============================] - 0s - loss: 56118.6213 - val_loss: 60718.1182\n",
      "Epoch 575/1000\n",
      "127/127 [==============================] - 0s - loss: 51030.7974 - val_loss: 53583.2849\n",
      "Epoch 576/1000\n",
      "127/127 [==============================] - 0s - loss: 28208.0384 - val_loss: 36685.6998\n",
      "Epoch 577/1000\n",
      "127/127 [==============================] - 0s - loss: 43086.4259 - val_loss: 39278.9623\n",
      "Epoch 578/1000\n",
      "127/127 [==============================] - 0s - loss: 39883.0921 - val_loss: 56360.4620\n",
      "Epoch 579/1000\n",
      "127/127 [==============================] - 0s - loss: 47502.8848 - val_loss: 42972.6877\n",
      "Epoch 580/1000\n",
      "127/127 [==============================] - 0s - loss: 60327.8370 - val_loss: 46558.9312\n",
      "Epoch 581/1000\n",
      "127/127 [==============================] - 0s - loss: 50403.2871 - val_loss: 39391.5170\n",
      "Epoch 582/1000\n",
      "127/127 [==============================] - 0s - loss: 40068.0339 - val_loss: 56719.3172\n",
      "Epoch 583/1000\n",
      "127/127 [==============================] - 0s - loss: 21918.9463 - val_loss: 66106.8025\n",
      "Epoch 584/1000\n",
      "127/127 [==============================] - 0s - loss: 39381.5751 - val_loss: 61329.6290\n",
      "Epoch 585/1000\n",
      "127/127 [==============================] - 0s - loss: 29902.8020 - val_loss: 59686.4261\n",
      "Epoch 586/1000\n",
      "127/127 [==============================] - 0s - loss: 101666.3017 - val_loss: 43033.6562\n",
      "Epoch 587/1000\n",
      "127/127 [==============================] - 0s - loss: 47555.5864 - val_loss: 54458.0801\n",
      "Epoch 588/1000\n",
      "127/127 [==============================] - 0s - loss: 38467.3512 - val_loss: 58601.3136\n",
      "Epoch 589/1000\n",
      "127/127 [==============================] - 0s - loss: 49543.6839 - val_loss: 12940.5365\n",
      "Epoch 590/1000\n",
      "127/127 [==============================] - 0s - loss: 35061.1357 - val_loss: 58601.9138\n",
      "Epoch 591/1000\n",
      "127/127 [==============================] - 0s - loss: 41928.9947 - val_loss: 49542.5013\n",
      "Epoch 592/1000\n",
      "127/127 [==============================] - 0s - loss: 57257.3868 - val_loss: 16056.0512\n",
      "Epoch 593/1000\n",
      "127/127 [==============================] - 0s - loss: 46073.2862 - val_loss: 13306.2297\n",
      "Epoch 594/1000\n",
      "127/127 [==============================] - 0s - loss: 94041.1843 - val_loss: 8469.3707\n",
      "Epoch 595/1000\n",
      "127/127 [==============================] - 0s - loss: 51091.5191 - val_loss: 49693.1032\n",
      "Epoch 596/1000\n",
      "127/127 [==============================] - 0s - loss: 47500.9309 - val_loss: 44006.1347\n",
      "Epoch 597/1000\n",
      "127/127 [==============================] - 0s - loss: 31426.1382 - val_loss: 32681.0594\n",
      "Epoch 598/1000\n",
      "127/127 [==============================] - 0s - loss: 46169.3438 - val_loss: 45373.4991\n",
      "Epoch 599/1000\n",
      "127/127 [==============================] - 0s - loss: 80962.4475 - val_loss: 52616.0997\n",
      "Epoch 600/1000\n",
      "127/127 [==============================] - 0s - loss: 30083.4054 - val_loss: 32193.4905\n",
      "Epoch 601/1000\n",
      "127/127 [==============================] - 0s - loss: 49169.8844 - val_loss: 51161.9239\n",
      "Epoch 602/1000\n",
      "127/127 [==============================] - 0s - loss: 29339.8747 - val_loss: 44752.0614\n",
      "Epoch 603/1000\n",
      "127/127 [==============================] - 0s - loss: 34709.1859 - val_loss: 52469.7404\n",
      "Epoch 604/1000\n",
      "127/127 [==============================] - 0s - loss: 74313.4140 - val_loss: 54544.1239\n",
      "Epoch 605/1000\n",
      "127/127 [==============================] - 0s - loss: 42935.8000 - val_loss: 59635.9584\n",
      "Epoch 606/1000\n",
      "127/127 [==============================] - 0s - loss: 81197.8996 - val_loss: 30673.9985\n",
      "Epoch 607/1000\n",
      "127/127 [==============================] - 0s - loss: 42249.1458 - val_loss: 64413.8019\n",
      "Epoch 608/1000\n",
      "127/127 [==============================] - 0s - loss: 56237.7188 - val_loss: 65516.5621\n",
      "Epoch 609/1000\n",
      "127/127 [==============================] - 0s - loss: 36683.2489 - val_loss: 53768.3888\n",
      "Epoch 610/1000\n",
      "127/127 [==============================] - 0s - loss: 36316.8572 - val_loss: 67652.4300\n",
      "Epoch 611/1000\n",
      "127/127 [==============================] - 0s - loss: 61007.7493 - val_loss: 54790.0848\n",
      "Epoch 612/1000\n",
      "127/127 [==============================] - 0s - loss: 36085.7600 - val_loss: 57286.6535\n",
      "Epoch 613/1000\n",
      "127/127 [==============================] - 0s - loss: 76007.0880 - val_loss: 64679.5014\n",
      "Epoch 614/1000\n",
      "127/127 [==============================] - 0s - loss: 29174.8790 - val_loss: 53858.1138\n",
      "Epoch 615/1000\n",
      "127/127 [==============================] - 0s - loss: 68054.7631 - val_loss: 69292.6779\n",
      "Epoch 616/1000\n",
      "127/127 [==============================] - 0s - loss: 105555.7832 - val_loss: 74079.2578\n",
      "Epoch 617/1000\n",
      "127/127 [==============================] - 0s - loss: 24801.8969 - val_loss: 63449.8676\n",
      "Epoch 618/1000\n",
      "127/127 [==============================] - 0s - loss: 47057.0656 - val_loss: 56412.117633738.01\n",
      "Epoch 619/1000\n",
      "127/127 [==============================] - 0s - loss: 61768.5323 - val_loss: 55744.7680\n",
      "Epoch 620/1000\n",
      "127/127 [==============================] - 0s - loss: 34306.6856 - val_loss: 61456.8803\n",
      "Epoch 621/1000\n",
      "127/127 [==============================] - 0s - loss: 131487.4626 - val_loss: 71135.5287\n",
      "Epoch 622/1000\n",
      "127/127 [==============================] - 0s - loss: 47207.8994 - val_loss: 76677.3403\n",
      "Epoch 623/1000\n",
      "127/127 [==============================] - 0s - loss: 44339.3945 - val_loss: 66184.9086\n",
      "Epoch 624/1000\n",
      "127/127 [==============================] - 0s - loss: 52944.4610 - val_loss: 62353.8515\n",
      "Epoch 625/1000\n",
      "127/127 [==============================] - 0s - loss: 31036.8792 - val_loss: 63529.4121\n",
      "Epoch 626/1000\n",
      "127/127 [==============================] - 0s - loss: 55196.3623 - val_loss: 56375.7877\n",
      "Epoch 627/1000\n",
      "127/127 [==============================] - 0s - loss: 48080.7676 - val_loss: 56408.5751\n",
      "Epoch 628/1000\n",
      "127/127 [==============================] - 0s - loss: 62680.5100 - val_loss: 52731.0918\n",
      "Epoch 629/1000\n",
      "127/127 [==============================] - 0s - loss: 29830.7518 - val_loss: 58924.6725\n",
      "Epoch 630/1000\n",
      "127/127 [==============================] - 0s - loss: 30804.2337 - val_loss: 55316.4321\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 71675.1034 - val_loss: 64104.1373\n",
      "Epoch 632/1000\n",
      "127/127 [==============================] - 0s - loss: 48420.0800 - val_loss: 50578.1493\n",
      "Epoch 633/1000\n",
      "127/127 [==============================] - 0s - loss: 40170.9070 - val_loss: 50005.8571\n",
      "Epoch 634/1000\n",
      "127/127 [==============================] - 0s - loss: 57495.4136 - val_loss: 51119.7910\n",
      "Epoch 635/1000\n",
      "127/127 [==============================] - 0s - loss: 55077.1611 - val_loss: 52328.4431\n",
      "Epoch 636/1000\n",
      "127/127 [==============================] - 0s - loss: 52900.5550 - val_loss: 53309.2520\n",
      "Epoch 637/1000\n",
      "127/127 [==============================] - 0s - loss: 29591.8587 - val_loss: 67440.6459\n",
      "Epoch 638/1000\n",
      "127/127 [==============================] - 0s - loss: 115748.3060 - val_loss: 64559.4199\n",
      "Epoch 639/1000\n",
      "127/127 [==============================] - 0s - loss: 51131.8034 - val_loss: 59093.3770\n",
      "Epoch 640/1000\n",
      "127/127 [==============================] - 0s - loss: 60070.9246 - val_loss: 74153.9648\n",
      "Epoch 641/1000\n",
      "127/127 [==============================] - 0s - loss: 45970.5665 - val_loss: 63139.074561137\n",
      "Epoch 642/1000\n",
      "127/127 [==============================] - 0s - loss: 47854.4981 - val_loss: 64346.2316\n",
      "Epoch 643/1000\n",
      "127/127 [==============================] - 0s - loss: 67286.7520 - val_loss: 54725.8860\n",
      "Epoch 644/1000\n",
      "127/127 [==============================] - 0s - loss: 91543.6964 - val_loss: 50210.2494\n",
      "Epoch 645/1000\n",
      "127/127 [==============================] - 0s - loss: 27331.3008 - val_loss: 57066.5568\n",
      "Epoch 646/1000\n",
      "127/127 [==============================] - 0s - loss: 33442.5844 - val_loss: 52352.0022\n",
      "Epoch 647/1000\n",
      "127/127 [==============================] - 0s - loss: 44150.2051 - val_loss: 59019.0578\n",
      "Epoch 648/1000\n",
      "127/127 [==============================] - 0s - loss: 44297.5923 - val_loss: 56737.1624\n",
      "Epoch 649/1000\n",
      "127/127 [==============================] - 0s - loss: 59383.0616 - val_loss: 64148.409676875.\n",
      "Epoch 650/1000\n",
      "127/127 [==============================] - 0s - loss: 23554.7828 - val_loss: 62721.0480\n",
      "Epoch 651/1000\n",
      "127/127 [==============================] - 0s - loss: 47195.8167 - val_loss: 57819.7983\n",
      "Epoch 652/1000\n",
      "127/127 [==============================] - 0s - loss: 41624.9519 - val_loss: 54578.3725\n",
      "Epoch 653/1000\n",
      "127/127 [==============================] - 0s - loss: 46956.9287 - val_loss: 79541.9665\n",
      "Epoch 654/1000\n",
      "127/127 [==============================] - 0s - loss: 55380.3753 - val_loss: 76735.7751\n",
      "Epoch 655/1000\n",
      "127/127 [==============================] - 0s - loss: 22658.0364 - val_loss: 56032.3818\n",
      "Epoch 656/1000\n",
      "127/127 [==============================] - 0s - loss: 32183.3823 - val_loss: 66437.5857\n",
      "Epoch 657/1000\n",
      "127/127 [==============================] - 0s - loss: 44032.4106 - val_loss: 80700.6920\n",
      "Epoch 658/1000\n",
      "127/127 [==============================] - 0s - loss: 51821.8240 - val_loss: 63340.6189\n",
      "Epoch 659/1000\n",
      "127/127 [==============================] - 0s - loss: 22962.9826 - val_loss: 57688.1498\n",
      "Epoch 660/1000\n",
      "127/127 [==============================] - 0s - loss: 70622.6159 - val_loss: 71738.6588\n",
      "Epoch 661/1000\n",
      "127/127 [==============================] - 0s - loss: 27361.2300 - val_loss: 54240.0986\n",
      "Epoch 662/1000\n",
      "127/127 [==============================] - 0s - loss: 117630.8979 - val_loss: 61256.0424\n",
      "Epoch 663/1000\n",
      "127/127 [==============================] - 0s - loss: 55263.5480 - val_loss: 53638.1217\n",
      "Epoch 664/1000\n",
      "127/127 [==============================] - 0s - loss: 35868.4378 - val_loss: 66233.4759\n",
      "Epoch 665/1000\n",
      "127/127 [==============================] - 0s - loss: 38951.1576 - val_loss: 45937.7974\n",
      "Epoch 666/1000\n",
      "127/127 [==============================] - 0s - loss: 45160.2440 - val_loss: 66255.7609\n",
      "Epoch 667/1000\n",
      "127/127 [==============================] - 0s - loss: 27689.6230 - val_loss: 41572.7044\n",
      "Epoch 668/1000\n",
      "127/127 [==============================] - 0s - loss: 54410.0349 - val_loss: 72657.6822\n",
      "Epoch 669/1000\n",
      "127/127 [==============================] - 0s - loss: 43021.1702 - val_loss: 59707.8247\n",
      "Epoch 670/1000\n",
      "127/127 [==============================] - 0s - loss: 34854.9439 - val_loss: 63725.6236\n",
      "Epoch 671/1000\n",
      "127/127 [==============================] - 0s - loss: 30414.7003 - val_loss: 61521.0170\n",
      "Epoch 672/1000\n",
      "127/127 [==============================] - 0s - loss: 49035.9427 - val_loss: 77706.4149\n",
      "Epoch 673/1000\n",
      "127/127 [==============================] - 0s - loss: 52555.6487 - val_loss: 87629.4319\n",
      "Epoch 674/1000\n",
      "127/127 [==============================] - 0s - loss: 62580.0159 - val_loss: 59678.4801289\n",
      "Epoch 675/1000\n",
      "127/127 [==============================] - 0s - loss: 29232.4792 - val_loss: 64642.6124\n",
      "Epoch 676/1000\n",
      "127/127 [==============================] - 0s - loss: 31213.5090 - val_loss: 61888.6492\n",
      "Epoch 677/1000\n",
      "127/127 [==============================] - 0s - loss: 33849.2793 - val_loss: 71567.6275\n",
      "Epoch 678/1000\n",
      "127/127 [==============================] - 0s - loss: 25584.5192 - val_loss: 65646.0100\n",
      "Epoch 679/1000\n",
      "127/127 [==============================] - 0s - loss: 46149.4738 - val_loss: 68051.5304\n",
      "Epoch 680/1000\n",
      "127/127 [==============================] - 0s - loss: 39291.9360 - val_loss: 71716.0198\n",
      "Epoch 681/1000\n",
      "127/127 [==============================] - 0s - loss: 44211.8103 - val_loss: 56088.3426\n",
      "Epoch 682/1000\n",
      "127/127 [==============================] - 0s - loss: 36220.8852 - val_loss: 70818.5015\n",
      "Epoch 683/1000\n",
      "127/127 [==============================] - 0s - loss: 21540.2182 - val_loss: 63929.987923960.3\n",
      "Epoch 684/1000\n",
      "127/127 [==============================] - 0s - loss: 38037.9794 - val_loss: 84499.2151\n",
      "Epoch 685/1000\n",
      "127/127 [==============================] - 0s - loss: 44704.5160 - val_loss: 76357.1473\n",
      "Epoch 686/1000\n",
      "127/127 [==============================] - 0s - loss: 25518.4841 - val_loss: 71491.7121\n",
      "Epoch 687/1000\n",
      "127/127 [==============================] - 0s - loss: 24885.2873 - val_loss: 71593.743225553.\n",
      "Epoch 688/1000\n",
      "127/127 [==============================] - 0s - loss: 41640.3158 - val_loss: 56109.9955\n",
      "Epoch 689/1000\n",
      "127/127 [==============================] - 0s - loss: 50237.2420 - val_loss: 73618.7674\n",
      "Epoch 690/1000\n",
      "127/127 [==============================] - 0s - loss: 22078.8091 - val_loss: 69730.2999\n",
      "Epoch 691/1000\n",
      "127/127 [==============================] - 0s - loss: 146711.8415 - val_loss: 52898.8443\n",
      "Epoch 692/1000\n",
      "127/127 [==============================] - 0s - loss: 192537.0354 - val_loss: 47732.8366\n",
      "Epoch 693/1000\n",
      "127/127 [==============================] - 0s - loss: 163262.5187 - val_loss: 55592.2760\n",
      "Epoch 694/1000\n",
      "127/127 [==============================] - 0s - loss: 147033.3414 - val_loss: 80996.8795\n",
      "Epoch 695/1000\n",
      "127/127 [==============================] - 0s - loss: 63522.4752 - val_loss: 83777.9927\n",
      "Epoch 696/1000\n",
      "127/127 [==============================] - 0s - loss: 42185.6482 - val_loss: 65177.0266\n",
      "Epoch 697/1000\n",
      "127/127 [==============================] - 0s - loss: 72195.1422 - val_loss: 69937.3050\n",
      "Epoch 698/1000\n",
      "127/127 [==============================] - 0s - loss: 46106.5211 - val_loss: 65226.4732\n",
      "Epoch 699/1000\n",
      "127/127 [==============================] - 0s - loss: 27272.8032 - val_loss: 77308.7480\n",
      "Epoch 700/1000\n",
      "127/127 [==============================] - 0s - loss: 42572.8452 - val_loss: 80948.3475\n",
      "Epoch 701/1000\n",
      "127/127 [==============================] - 0s - loss: 30025.9214 - val_loss: 70557.0545\n",
      "Epoch 702/1000\n",
      "127/127 [==============================] - 0s - loss: 28913.1080 - val_loss: 57322.0000\n",
      "Epoch 703/1000\n",
      "127/127 [==============================] - 0s - loss: 42718.2542 - val_loss: 72979.7832\n",
      "Epoch 704/1000\n",
      "127/127 [==============================] - 0s - loss: 30872.5256 - val_loss: 69576.9450\n",
      "Epoch 705/1000\n",
      "127/127 [==============================] - 0s - loss: 39513.7034 - val_loss: 62351.2076\n",
      "Epoch 706/1000\n",
      "127/127 [==============================] - 0s - loss: 28133.2777 - val_loss: 70536.6719\n",
      "Epoch 707/1000\n",
      "127/127 [==============================] - 0s - loss: 35185.4622 - val_loss: 63358.1211\n",
      "Epoch 708/1000\n",
      "127/127 [==============================] - 0s - loss: 34180.7908 - val_loss: 80387.4905\n",
      "Epoch 709/1000\n",
      "127/127 [==============================] - 0s - loss: 60797.8541 - val_loss: 74772.8320\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 48006.4073 - val_loss: 100448.5859\n",
      "Epoch 711/1000\n",
      "127/127 [==============================] - 0s - loss: 78287.2199 - val_loss: 78347.2232\n",
      "Epoch 712/1000\n",
      "127/127 [==============================] - 0s - loss: 32883.5567 - val_loss: 79572.1197\n",
      "Epoch 713/1000\n",
      "127/127 [==============================] - 0s - loss: 45098.5149 - val_loss: 64874.1646\n",
      "Epoch 714/1000\n",
      "127/127 [==============================] - 0s - loss: 36086.7062 - val_loss: 70729.1523\n",
      "Epoch 715/1000\n",
      "127/127 [==============================] - 0s - loss: 70498.1951 - val_loss: 69777.6659\n",
      "Epoch 716/1000\n",
      "127/127 [==============================] - 0s - loss: 33254.8186 - val_loss: 55017.2455\n",
      "Epoch 717/1000\n",
      "127/127 [==============================] - 0s - loss: 37802.5238 - val_loss: 59697.3943\n",
      "Epoch 718/1000\n",
      "127/127 [==============================] - 0s - loss: 51742.3101 - val_loss: 71812.0073\n",
      "Epoch 719/1000\n",
      "127/127 [==============================] - 0s - loss: 36721.0830 - val_loss: 79350.5929\n",
      "Epoch 720/1000\n",
      "127/127 [==============================] - 0s - loss: 69465.5093 - val_loss: 71811.4648 72924.069 - ETA: 0s - loss: 66982.\n",
      "Epoch 721/1000\n",
      "127/127 [==============================] - 0s - loss: 68070.8194 - val_loss: 72357.7603\n",
      "Epoch 722/1000\n",
      "127/127 [==============================] - 0s - loss: 29555.3562 - val_loss: 76101.97413415\n",
      "Epoch 723/1000\n",
      "127/127 [==============================] - 0s - loss: 26619.8206 - val_loss: 54096.7594\n",
      "Epoch 724/1000\n",
      "127/127 [==============================] - 0s - loss: 43524.2885 - val_loss: 26520.5817\n",
      "Epoch 725/1000\n",
      "127/127 [==============================] - 0s - loss: 30885.6899 - val_loss: 27153.1149\n",
      "Epoch 726/1000\n",
      "127/127 [==============================] - 0s - loss: 34579.6215 - val_loss: 64503.1373\n",
      "Epoch 727/1000\n",
      "127/127 [==============================] - 0s - loss: 26470.8217 - val_loss: 64938.9612\n",
      "Epoch 728/1000\n",
      "127/127 [==============================] - 0s - loss: 24688.0685 - val_loss: 66820.5223\n",
      "Epoch 729/1000\n",
      "127/127 [==============================] - 0s - loss: 23250.5020 - val_loss: 70474.6094\n",
      "Epoch 730/1000\n",
      "127/127 [==============================] - 0s - loss: 38508.2650 - val_loss: 54963.0306\n",
      "Epoch 731/1000\n",
      "127/127 [==============================] - 0s - loss: 53950.2520 - val_loss: 59879.5831\n",
      "Epoch 732/1000\n",
      "127/127 [==============================] - 0s - loss: 36976.5873 - val_loss: 77939.2924\n",
      "Epoch 733/1000\n",
      "127/127 [==============================] - 0s - loss: 26662.3039 - val_loss: 92794.8616\n",
      "Epoch 734/1000\n",
      "127/127 [==============================] - 0s - loss: 43499.2970 - val_loss: 70388.4266\n",
      "Epoch 735/1000\n",
      "127/127 [==============================] - 0s - loss: 40234.4615 - val_loss: 55570.2560\n",
      "Epoch 736/1000\n",
      "127/127 [==============================] - 0s - loss: 48518.9779 - val_loss: 68863.5928\n",
      "Epoch 737/1000\n",
      "127/127 [==============================] - 0s - loss: 30644.4786 - val_loss: 64182.1823\n",
      "Epoch 738/1000\n",
      "127/127 [==============================] - 0s - loss: 31795.8706 - val_loss: 87501.1562\n",
      "Epoch 739/1000\n",
      "127/127 [==============================] - 0s - loss: 21369.4762 - val_loss: 71546.1677\n",
      "Epoch 740/1000\n",
      "127/127 [==============================] - 0s - loss: 60193.3018 - val_loss: 61658.8795\n",
      "Epoch 741/1000\n",
      "127/127 [==============================] - 0s - loss: 30465.5582 - val_loss: 66155.5954\n",
      "Epoch 742/1000\n",
      "127/127 [==============================] - 0s - loss: 32385.2012 - val_loss: 49225.9499\n",
      "Epoch 743/1000\n",
      "127/127 [==============================] - 0s - loss: 28633.0752 - val_loss: 65638.0850\n",
      "Epoch 744/1000\n",
      "127/127 [==============================] - 0s - loss: 24936.1147 - val_loss: 61258.0804\n",
      "Epoch 745/1000\n",
      "127/127 [==============================] - 0s - loss: 25348.7510 - val_loss: 59258.4788\n",
      "Epoch 746/1000\n",
      "127/127 [==============================] - 0s - loss: 39077.2180 - val_loss: 62508.1918\n",
      "Epoch 747/1000\n",
      "127/127 [==============================] - 0s - loss: 51191.1769 - val_loss: 62474.7259\n",
      "Epoch 748/1000\n",
      "127/127 [==============================] - 0s - loss: 21321.5009 - val_loss: 75413.0010\n",
      "Epoch 749/1000\n",
      "127/127 [==============================] - 0s - loss: 29262.5647 - val_loss: 100775.8839\n",
      "Epoch 750/1000\n",
      "127/127 [==============================] - 0s - loss: 29000.7185 - val_loss: 81225.5497\n",
      "Epoch 751/1000\n",
      "127/127 [==============================] - 0s - loss: 54019.1764 - val_loss: 55321.3828\n",
      "Epoch 752/1000\n",
      "127/127 [==============================] - 0s - loss: 63012.6973 - val_loss: 60758.9060\n",
      "Epoch 753/1000\n",
      "127/127 [==============================] - 0s - loss: 50561.3411 - val_loss: 58082.6663\n",
      "Epoch 754/1000\n",
      "127/127 [==============================] - 0s - loss: 48739.4266 - val_loss: 96004.9498\n",
      "Epoch 755/1000\n",
      "127/127 [==============================] - 0s - loss: 32373.3951 - val_loss: 82268.0739\n",
      "Epoch 756/1000\n",
      "127/127 [==============================] - 0s - loss: 31325.5671 - val_loss: 87388.9205\n",
      "Epoch 757/1000\n",
      "127/127 [==============================] - 0s - loss: 35453.3817 - val_loss: 70747.2667\n",
      "Epoch 758/1000\n",
      "127/127 [==============================] - 0s - loss: 33026.3462 - val_loss: 60486.7008\n",
      "Epoch 759/1000\n",
      "127/127 [==============================] - 0s - loss: 42771.1330 - val_loss: 62944.6484\n",
      "Epoch 760/1000\n",
      "127/127 [==============================] - 0s - loss: 34671.5343 - val_loss: 67003.5151\n",
      "Epoch 761/1000\n",
      "127/127 [==============================] - 0s - loss: 28398.7270 - val_loss: 62431.775730372.41\n",
      "Epoch 762/1000\n",
      "127/127 [==============================] - 0s - loss: 27768.2217 - val_loss: 65242.3892\n",
      "Epoch 763/1000\n",
      "127/127 [==============================] - 0s - loss: 39487.8445 - val_loss: 63207.9262\n",
      "Epoch 764/1000\n",
      "127/127 [==============================] - 0s - loss: 36595.7772 - val_loss: 74334.9939\n",
      "Epoch 765/1000\n",
      "127/127 [==============================] - 0s - loss: 18243.5802 - val_loss: 70928.7076\n",
      "Epoch 766/1000\n",
      "127/127 [==============================] - 0s - loss: 41147.2034 - val_loss: 93349.7313\n",
      "Epoch 767/1000\n",
      "127/127 [==============================] - 0s - loss: 51690.8133 - val_loss: 71994.6451\n",
      "Epoch 768/1000\n",
      "127/127 [==============================] - 0s - loss: 25750.9390 - val_loss: 90988.6098\n",
      "Epoch 769/1000\n",
      "127/127 [==============================] - 0s - loss: 42526.7428 - val_loss: 76097.3234\n",
      "Epoch 770/1000\n",
      "127/127 [==============================] - 0s - loss: 50674.8737 - val_loss: 99004.8873\n",
      "Epoch 771/1000\n",
      "127/127 [==============================] - 0s - loss: 18863.6763 - val_loss: 88835.5142\n",
      "Epoch 772/1000\n",
      "127/127 [==============================] - 0s - loss: 31729.6969 - val_loss: 82562.1049\n",
      "Epoch 773/1000\n",
      "127/127 [==============================] - 0s - loss: 33264.9734 - val_loss: 68868.7006\n",
      "Epoch 774/1000\n",
      "127/127 [==============================] - 0s - loss: 85048.7035 - val_loss: 72196.0363\n",
      "Epoch 775/1000\n",
      "127/127 [==============================] - 0s - loss: 38419.8169 - val_loss: 78188.2433\n",
      "Epoch 776/1000\n",
      "127/127 [==============================] - 0s - loss: 34487.6233 - val_loss: 69811.9431\n",
      "Epoch 777/1000\n",
      "127/127 [==============================] - 0s - loss: 20122.2442 - val_loss: 72158.1878\n",
      "Epoch 778/1000\n",
      "127/127 [==============================] - 0s - loss: 35688.1952 - val_loss: 79583.4849\n",
      "Epoch 779/1000\n",
      "127/127 [==============================] - 0s - loss: 20305.4588 - val_loss: 73636.0466\n",
      "Epoch 780/1000\n",
      "127/127 [==============================] - 0s - loss: 55692.2742 - val_loss: 80065.4085\n",
      "Epoch 781/1000\n",
      "127/127 [==============================] - 0s - loss: 54307.6359 - val_loss: 70940.9305\n",
      "Epoch 782/1000\n",
      "127/127 [==============================] - 0s - loss: 109586.8535 - val_loss: 59096.9886\n",
      "Epoch 783/1000\n",
      "127/127 [==============================] - 0s - loss: 92639.3562 - val_loss: 54007.2218\n",
      "Epoch 784/1000\n",
      "127/127 [==============================] - 0s - loss: 65904.3161 - val_loss: 101871.7423\n",
      "Epoch 785/1000\n",
      "127/127 [==============================] - 0s - loss: 70206.1328 - val_loss: 67296.6758\n",
      "Epoch 786/1000\n",
      "127/127 [==============================] - 0s - loss: 44463.0771 - val_loss: 65367.1585\n",
      "Epoch 787/1000\n",
      "127/127 [==============================] - 0s - loss: 97943.4464 - val_loss: 53746.9099\n",
      "Epoch 788/1000\n",
      "127/127 [==============================] - 0s - loss: 43546.7727 - val_loss: 62705.7266\n",
      "Epoch 789/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 41127.0093 - val_loss: 79120.3011\n",
      "Epoch 790/1000\n",
      "127/127 [==============================] - 0s - loss: 30073.0932 - val_loss: 54513.1215\n",
      "Epoch 791/1000\n",
      "127/127 [==============================] - 0s - loss: 26193.2073 - val_loss: 64279.6136\n",
      "Epoch 792/1000\n",
      "127/127 [==============================] - 0s - loss: 34552.0625 - val_loss: 27565.7331\n",
      "Epoch 793/1000\n",
      "127/127 [==============================] - 0s - loss: 27812.6029 - val_loss: 71723.5635\n",
      "Epoch 794/1000\n",
      "127/127 [==============================] - 0s - loss: 25307.8817 - val_loss: 74853.7667\n",
      "Epoch 795/1000\n",
      "127/127 [==============================] - 0s - loss: 35628.1315 - val_loss: 60528.6588\n",
      "Epoch 796/1000\n",
      "127/127 [==============================] - 0s - loss: 52824.3081 - val_loss: 70345.6116\n",
      "Epoch 797/1000\n",
      "127/127 [==============================] - 0s - loss: 19879.9442 - val_loss: 71670.5614\n",
      "Epoch 798/1000\n",
      "127/127 [==============================] - 0s - loss: 25097.2447 - val_loss: 60981.2475\n",
      "Epoch 799/1000\n",
      "127/127 [==============================] - 0s - loss: 26083.3150 - val_loss: 59039.2646\n",
      "Epoch 800/1000\n",
      "127/127 [==============================] - 0s - loss: 46472.5560 - val_loss: 85962.4040\n",
      "Epoch 801/1000\n",
      "127/127 [==============================] - 0s - loss: 24102.0653 - val_loss: 60422.5707\n",
      "Epoch 802/1000\n",
      "127/127 [==============================] - 0s - loss: 54947.6131 - val_loss: 107440.7341\n",
      "Epoch 803/1000\n",
      "127/127 [==============================] - 0s - loss: 28851.5227 - val_loss: 68571.2282\n",
      "Epoch 804/1000\n",
      "127/127 [==============================] - 0s - loss: 34053.2161 - val_loss: 69295.5363\n",
      "Epoch 805/1000\n",
      "127/127 [==============================] - 0s - loss: 32991.8862 - val_loss: 60341.9713\n",
      "Epoch 806/1000\n",
      "127/127 [==============================] - 0s - loss: 32013.4628 - val_loss: 64046.6212\n",
      "Epoch 807/1000\n",
      "127/127 [==============================] - 0s - loss: 28459.1317 - val_loss: 62982.534722966.8\n",
      "Epoch 808/1000\n",
      "127/127 [==============================] - 0s - loss: 32195.5072 - val_loss: 57409.6508\n",
      "Epoch 809/1000\n",
      "127/127 [==============================] - 0s - loss: 37066.0474 - val_loss: 63343.5629\n",
      "Epoch 810/1000\n",
      "127/127 [==============================] - 0s - loss: 26880.2997 - val_loss: 59996.4910\n",
      "Epoch 811/1000\n",
      "127/127 [==============================] - 0s - loss: 20016.0691 - val_loss: 65573.6282\n",
      "Epoch 812/1000\n",
      "127/127 [==============================] - 0s - loss: 36197.2531 - val_loss: 69542.6211\n",
      "Epoch 813/1000\n",
      "127/127 [==============================] - 0s - loss: 29186.2264 - val_loss: 64956.0086\n",
      "Epoch 814/1000\n",
      "127/127 [==============================] - 0s - loss: 23258.6687 - val_loss: 65297.1809\n",
      "Epoch 815/1000\n",
      "127/127 [==============================] - 0s - loss: 22550.8020 - val_loss: 75586.9551\n",
      "Epoch 816/1000\n",
      "127/127 [==============================] - 0s - loss: 19303.2541 - val_loss: 78987.39971881\n",
      "Epoch 817/1000\n",
      "127/127 [==============================] - 0s - loss: 27201.1618 - val_loss: 68499.404931988.\n",
      "Epoch 818/1000\n",
      "127/127 [==============================] - 0s - loss: 20481.3442 - val_loss: 71423.750318633\n",
      "Epoch 819/1000\n",
      "127/127 [==============================] - 0s - loss: 51049.9088 - val_loss: 64045.2210\n",
      "Epoch 820/1000\n",
      "127/127 [==============================] - 0s - loss: 20106.7241 - val_loss: 75677.6356\n",
      "Epoch 821/1000\n",
      "127/127 [==============================] - 0s - loss: 38767.2804 - val_loss: 75848.8972\n",
      "Epoch 822/1000\n",
      "127/127 [==============================] - 0s - loss: 37930.3575 - val_loss: 75678.5516\n",
      "Epoch 823/1000\n",
      "127/127 [==============================] - 0s - loss: 22065.2107 - val_loss: 72926.0142\n",
      "Epoch 824/1000\n",
      "127/127 [==============================] - 0s - loss: 16790.0141 - val_loss: 76614.2171\n",
      "Epoch 825/1000\n",
      "127/127 [==============================] - 0s - loss: 14928.2162 - val_loss: 83261.7372\n",
      "Epoch 826/1000\n",
      "127/127 [==============================] - 0s - loss: 30593.9010 - val_loss: 94213.6306\n",
      "Epoch 827/1000\n",
      "127/127 [==============================] - 0s - loss: 32438.2464 - val_loss: 76551.4219\n",
      "Epoch 828/1000\n",
      "127/127 [==============================] - 0s - loss: 24570.5467 - val_loss: 132251.1643\n",
      "Epoch 829/1000\n",
      "127/127 [==============================] - 0s - loss: 21125.9211 - val_loss: 65117.3640\n",
      "Epoch 830/1000\n",
      "127/127 [==============================] - 0s - loss: 21897.6568 - val_loss: 103819.1222\n",
      "Epoch 831/1000\n",
      "127/127 [==============================] - 0s - loss: 15749.9466 - val_loss: 94211.9286\n",
      "Epoch 832/1000\n",
      "127/127 [==============================] - 0s - loss: 42585.8674 - val_loss: 93047.6713\n",
      "Epoch 833/1000\n",
      "127/127 [==============================] - 0s - loss: 26573.1655 - val_loss: 88595.0469\n",
      "Epoch 834/1000\n",
      "127/127 [==============================] - 0s - loss: 40094.2894 - val_loss: 127464.5815\n",
      "Epoch 835/1000\n",
      "127/127 [==============================] - 0s - loss: 62899.6813 - val_loss: 80525.1144\n",
      "Epoch 836/1000\n",
      "127/127 [==============================] - 0s - loss: 42362.0708 - val_loss: 70423.3848\n",
      "Epoch 837/1000\n",
      "127/127 [==============================] - 0s - loss: 52081.9295 - val_loss: 79444.2684\n",
      "Epoch 838/1000\n",
      "127/127 [==============================] - 0s - loss: 24899.1389 - val_loss: 75990.3597\n",
      "Epoch 839/1000\n",
      "127/127 [==============================] - 0s - loss: 44249.1674 - val_loss: 80347.6462\n",
      "Epoch 840/1000\n",
      "127/127 [==============================] - 0s - loss: 15190.4341 - val_loss: 68121.4888\n",
      "Epoch 841/1000\n",
      "127/127 [==============================] - 0s - loss: 53028.7833 - val_loss: 55169.3156\n",
      "Epoch 842/1000\n",
      "127/127 [==============================] - 0s - loss: 76828.4005 - val_loss: 63057.790744537.97\n",
      "Epoch 843/1000\n",
      "127/127 [==============================] - 0s - loss: 43894.6649 - val_loss: 57077.724544903.4\n",
      "Epoch 844/1000\n",
      "127/127 [==============================] - 0s - loss: 39666.6209 - val_loss: 57414.6390\n",
      "Epoch 845/1000\n",
      "127/127 [==============================] - 0s - loss: 25556.6558 - val_loss: 65231.3136\n",
      "Epoch 846/1000\n",
      "127/127 [==============================] - 0s - loss: 25260.3978 - val_loss: 61443.2535\n",
      "Epoch 847/1000\n",
      "127/127 [==============================] - 0s - loss: 35882.0712 - val_loss: 60509.7288\n",
      "Epoch 848/1000\n",
      "127/127 [==============================] - 0s - loss: 16578.2725 - val_loss: 50109.3103\n",
      "Epoch 849/1000\n",
      "127/127 [==============================] - 0s - loss: 42455.9900 - val_loss: 49872.2672\n",
      "Epoch 850/1000\n",
      "127/127 [==============================] - 0s - loss: 30650.4070 - val_loss: 70257.6272\n",
      "Epoch 851/1000\n",
      "127/127 [==============================] - 0s - loss: 24352.0685 - val_loss: 66073.3597\n",
      "Epoch 852/1000\n",
      "127/127 [==============================] - 0s - loss: 31627.8067 - val_loss: 64562.7651\n",
      "Epoch 853/1000\n",
      "127/127 [==============================] - 0s - loss: 29727.3963 - val_loss: 68041.7718\n",
      "Epoch 854/1000\n",
      "127/127 [==============================] - 0s - loss: 48727.5711 - val_loss: 48795.6137\n",
      "Epoch 855/1000\n",
      "127/127 [==============================] - 0s - loss: 34941.7402 - val_loss: 74139.2550\n",
      "Epoch 856/1000\n",
      "127/127 [==============================] - 0s - loss: 26896.9727 - val_loss: 65092.8513\n",
      "Epoch 857/1000\n",
      "127/127 [==============================] - 0s - loss: 81171.1335 - val_loss: 72502.9643\n",
      "Epoch 858/1000\n",
      "127/127 [==============================] - 0s - loss: 44492.3528 - val_loss: 60202.2143\n",
      "Epoch 859/1000\n",
      "127/127 [==============================] - 0s - loss: 54171.5398 - val_loss: 61266.6682\n",
      "Epoch 860/1000\n",
      "127/127 [==============================] - 0s - loss: 33035.7126 - val_loss: 69468.1136\n",
      "Epoch 861/1000\n",
      "127/127 [==============================] - 0s - loss: 55283.7013 - val_loss: 71642.8425\n",
      "Epoch 862/1000\n",
      "127/127 [==============================] - 0s - loss: 38066.0742 - val_loss: 71962.8411\n",
      "Epoch 863/1000\n",
      "127/127 [==============================] - 0s - loss: 36827.4904 - val_loss: 71726.4587\n",
      "Epoch 864/1000\n",
      "127/127 [==============================] - 0s - loss: 67982.7344 - val_loss: 69764.4737\n",
      "Epoch 865/1000\n",
      "127/127 [==============================] - 0s - loss: 34050.9120 - val_loss: 75901.5848\n",
      "Epoch 866/1000\n",
      "127/127 [==============================] - 0s - loss: 40551.5801 - val_loss: 68361.0080\n",
      "Epoch 867/1000\n",
      "127/127 [==============================] - 0s - loss: 20668.5028 - val_loss: 65932.8318\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 27030.7729 - val_loss: 63708.4766\n",
      "Epoch 869/1000\n",
      "127/127 [==============================] - 0s - loss: 20951.7990 - val_loss: 59488.9088\n",
      "Epoch 870/1000\n",
      "127/127 [==============================] - 0s - loss: 27435.2444 - val_loss: 49493.0672\n",
      "Epoch 871/1000\n",
      "127/127 [==============================] - 0s - loss: 24838.4963 - val_loss: 45804.2589\n",
      "Epoch 872/1000\n",
      "127/127 [==============================] - 0s - loss: 16178.6195 - val_loss: 68220.9280\n",
      "Epoch 873/1000\n",
      "127/127 [==============================] - 0s - loss: 31262.7409 - val_loss: 38014.8926\n",
      "Epoch 874/1000\n",
      "127/127 [==============================] - 0s - loss: 36842.1444 - val_loss: 64229.8544\n",
      "Epoch 875/1000\n",
      "127/127 [==============================] - 0s - loss: 62929.0884 - val_loss: 61535.611763902.363\n",
      "Epoch 876/1000\n",
      "127/127 [==============================] - 0s - loss: 58929.6191 - val_loss: 65593.7525\n",
      "Epoch 877/1000\n",
      "127/127 [==============================] - 0s - loss: 48395.7582 - val_loss: 70511.7104\n",
      "Epoch 878/1000\n",
      "127/127 [==============================] - 0s - loss: 28872.0860 - val_loss: 50461.8973\n",
      "Epoch 879/1000\n",
      "127/127 [==============================] - 0s - loss: 38381.0130 - val_loss: 70465.4860\n",
      "Epoch 880/1000\n",
      "127/127 [==============================] - 0s - loss: 24579.3189 - val_loss: 66524.1246\n",
      "Epoch 881/1000\n",
      "127/127 [==============================] - 0s - loss: 31231.8841 - val_loss: 66406.092914023\n",
      "Epoch 882/1000\n",
      "127/127 [==============================] - 0s - loss: 44702.5745 - val_loss: 59610.9911\n",
      "Epoch 883/1000\n",
      "127/127 [==============================] - 0s - loss: 32006.0782 - val_loss: 67892.2256\n",
      "Epoch 884/1000\n",
      "127/127 [==============================] - 0s - loss: 17587.1472 - val_loss: 64533.8119\n",
      "Epoch 885/1000\n",
      "127/127 [==============================] - 0s - loss: 25409.8687 - val_loss: 60348.8576\n",
      "Epoch 886/1000\n",
      "127/127 [==============================] - 0s - loss: 27984.1677 - val_loss: 51740.8329\n",
      "Epoch 887/1000\n",
      "127/127 [==============================] - 0s - loss: 25623.4365 - val_loss: 57710.9053\n",
      "Epoch 888/1000\n",
      "127/127 [==============================] - 0s - loss: 25960.4334 - val_loss: 69672.6665\n",
      "Epoch 889/1000\n",
      "127/127 [==============================] - 0s - loss: 19961.4202 - val_loss: 77004.1508\n",
      "Epoch 890/1000\n",
      "127/127 [==============================] - 0s - loss: 23005.6887 - val_loss: 57220.56811168\n",
      "Epoch 891/1000\n",
      "127/127 [==============================] - 0s - loss: 22280.2081 - val_loss: 75218.9203\n",
      "Epoch 892/1000\n",
      "127/127 [==============================] - 0s - loss: 61599.8546 - val_loss: 59886.9176\n",
      "Epoch 893/1000\n",
      "127/127 [==============================] - 0s - loss: 19089.7517 - val_loss: 81844.0905\n",
      "Epoch 894/1000\n",
      "127/127 [==============================] - 0s - loss: 21758.7026 - val_loss: 83883.126422240.202\n",
      "Epoch 895/1000\n",
      "127/127 [==============================] - 0s - loss: 16134.2218 - val_loss: 65742.6169\n",
      "Epoch 896/1000\n",
      "127/127 [==============================] - 0s - loss: 55644.8991 - val_loss: 70095.5836\n",
      "Epoch 897/1000\n",
      "127/127 [==============================] - 0s - loss: 33163.4626 - val_loss: 66691.8493\n",
      "Epoch 898/1000\n",
      "127/127 [==============================] - 0s - loss: 22772.5555 - val_loss: 69222.5512\n",
      "Epoch 899/1000\n",
      "127/127 [==============================] - 0s - loss: 49638.3465 - val_loss: 58879.2245\n",
      "Epoch 900/1000\n",
      "127/127 [==============================] - 0s - loss: 21755.3272 - val_loss: 96753.6197\n",
      "Epoch 901/1000\n",
      "127/127 [==============================] - 0s - loss: 17786.7764 - val_loss: 71835.3075\n",
      "Epoch 902/1000\n",
      "127/127 [==============================] - 0s - loss: 33529.5816 - val_loss: 71670.3191\n",
      "Epoch 903/1000\n",
      "127/127 [==============================] - 0s - loss: 47045.4686 - val_loss: 65497.1967\n",
      "Epoch 904/1000\n",
      "127/127 [==============================] - 0s - loss: 31349.9495 - val_loss: 56711.1752\n",
      "Epoch 905/1000\n",
      "127/127 [==============================] - 0s - loss: 26333.0625 - val_loss: 71861.4036\n",
      "Epoch 906/1000\n",
      "127/127 [==============================] - 0s - loss: 22143.7517 - val_loss: 64532.8610\n",
      "Epoch 907/1000\n",
      "127/127 [==============================] - 0s - loss: 29706.0320 - val_loss: 60373.1482\n",
      "Epoch 908/1000\n",
      "127/127 [==============================] - 0s - loss: 20022.8300 - val_loss: 80463.5631\n",
      "Epoch 909/1000\n",
      "127/127 [==============================] - 0s - loss: 21269.7849 - val_loss: 74769.1864\n",
      "Epoch 910/1000\n",
      "127/127 [==============================] - 0s - loss: 49249.8220 - val_loss: 63968.9120\n",
      "Epoch 911/1000\n",
      "127/127 [==============================] - 0s - loss: 43168.1449 - val_loss: 56578.2598\n",
      "Epoch 912/1000\n",
      "127/127 [==============================] - 0s - loss: 41522.8312 - val_loss: 64163.8809\n",
      "Epoch 913/1000\n",
      "127/127 [==============================] - 0s - loss: 25562.6158 - val_loss: 68192.9227\n",
      "Epoch 914/1000\n",
      "127/127 [==============================] - 0s - loss: 19453.5195 - val_loss: 62310.1622\n",
      "Epoch 915/1000\n",
      "127/127 [==============================] - 0s - loss: 19450.3368 - val_loss: 65467.9588\n",
      "Epoch 916/1000\n",
      "127/127 [==============================] - 0s - loss: 20905.4663 - val_loss: 61217.1071\n",
      "Epoch 917/1000\n",
      "127/127 [==============================] - 0s - loss: 23331.2678 - val_loss: 65151.5879\n",
      "Epoch 918/1000\n",
      "127/127 [==============================] - 0s - loss: 13901.9291 - val_loss: 51653.3970\n",
      "Epoch 919/1000\n",
      "127/127 [==============================] - 0s - loss: 18721.5645 - val_loss: 70987.4838\n",
      "Epoch 920/1000\n",
      "127/127 [==============================] - 0s - loss: 30732.6936 - val_loss: 56639.8696\n",
      "Epoch 921/1000\n",
      "127/127 [==============================] - 0s - loss: 17740.1439 - val_loss: 60309.4333\n",
      "Epoch 922/1000\n",
      "127/127 [==============================] - 0s - loss: 28170.1464 - val_loss: 81329.3689\n",
      "Epoch 923/1000\n",
      "127/127 [==============================] - 0s - loss: 19396.3612 - val_loss: 66057.6476\n",
      "Epoch 924/1000\n",
      "127/127 [==============================] - 0s - loss: 18495.4595 - val_loss: 62718.7461\n",
      "Epoch 925/1000\n",
      "127/127 [==============================] - 0s - loss: 22202.9953 - val_loss: 66789.5681\n",
      "Epoch 926/1000\n",
      "127/127 [==============================] - 0s - loss: 28146.1896 - val_loss: 79301.4701\n",
      "Epoch 927/1000\n",
      "127/127 [==============================] - 0s - loss: 45948.1797 - val_loss: 71708.3503\n",
      "Epoch 928/1000\n",
      "127/127 [==============================] - 0s - loss: 28941.1116 - val_loss: 73034.0918\n",
      "Epoch 929/1000\n",
      "127/127 [==============================] - 0s - loss: 14608.5839 - val_loss: 66040.3390\n",
      "Epoch 930/1000\n",
      "127/127 [==============================] - 0s - loss: 23981.0456 - val_loss: 73538.8108\n",
      "Epoch 931/1000\n",
      "127/127 [==============================] - 0s - loss: 16807.2545 - val_loss: 75869.5653\n",
      "Epoch 932/1000\n",
      "127/127 [==============================] - 0s - loss: 17263.3154 - val_loss: 68900.1797\n",
      "Epoch 933/1000\n",
      "127/127 [==============================] - 0s - loss: 20907.4181 - val_loss: 84671.0675\n",
      "Epoch 934/1000\n",
      "127/127 [==============================] - 0s - loss: 16020.9697 - val_loss: 65963.5385\n",
      "Epoch 935/1000\n",
      "127/127 [==============================] - 0s - loss: 28415.6609 - val_loss: 76219.4263\n",
      "Epoch 936/1000\n",
      "127/127 [==============================] - 0s - loss: 15164.1420 - val_loss: 71618.7751\n",
      "Epoch 937/1000\n",
      "127/127 [==============================] - 0s - loss: 15510.8938 - val_loss: 76690.5363\n",
      "Epoch 938/1000\n",
      "127/127 [==============================] - 0s - loss: 19094.6072 - val_loss: 70522.7146\n",
      "Epoch 939/1000\n",
      "127/127 [==============================] - 0s - loss: 13609.7790 - val_loss: 61431.067816031.\n",
      "Epoch 940/1000\n",
      "127/127 [==============================] - 0s - loss: 26933.4227 - val_loss: 73568.8839\n",
      "Epoch 941/1000\n",
      "127/127 [==============================] - 0s - loss: 27225.1880 - val_loss: 66791.0465\n",
      "Epoch 942/1000\n",
      "127/127 [==============================] - 0s - loss: 39190.3727 - val_loss: 78907.5106\n",
      "Epoch 943/1000\n",
      "127/127 [==============================] - 0s - loss: 23664.7848 - val_loss: 70348.5957\n",
      "Epoch 944/1000\n",
      "127/127 [==============================] - 0s - loss: 43385.2597 - val_loss: 80849.9874\n",
      "Epoch 945/1000\n",
      "127/127 [==============================] - 0s - loss: 16824.8406 - val_loss: 66654.7030\n",
      "Epoch 946/1000\n",
      "127/127 [==============================] - 0s - loss: 15310.5105 - val_loss: 70286.0181\n",
      "Epoch 947/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s - loss: 22192.8353 - val_loss: 59875.0190\n",
      "Epoch 948/1000\n",
      "127/127 [==============================] - 0s - loss: 46237.3850 - val_loss: 70868.6607\n",
      "Epoch 949/1000\n",
      "127/127 [==============================] - 0s - loss: 24854.7846 - val_loss: 60342.9542\n",
      "Epoch 950/1000\n",
      "127/127 [==============================] - 0s - loss: 20033.6130 - val_loss: 64042.0773\n",
      "Epoch 951/1000\n",
      "127/127 [==============================] - 0s - loss: 44466.2994 - val_loss: 70860.0017\n",
      "Epoch 952/1000\n",
      "127/127 [==============================] - 0s - loss: 37222.9018 - val_loss: 63430.947840080.45\n",
      "Epoch 953/1000\n",
      "127/127 [==============================] - 0s - loss: 15775.4105 - val_loss: 57995.9690\n",
      "Epoch 954/1000\n",
      "127/127 [==============================] - 0s - loss: 34236.1328 - val_loss: 61824.7598\n",
      "Epoch 955/1000\n",
      "127/127 [==============================] - 0s - loss: 33113.5137 - val_loss: 68324.5073\n",
      "Epoch 956/1000\n",
      "127/127 [==============================] - 0s - loss: 24847.6857 - val_loss: 65495.5731\n",
      "Epoch 957/1000\n",
      "127/127 [==============================] - 0s - loss: 16823.4357 - val_loss: 70251.7433\n",
      "Epoch 958/1000\n",
      "127/127 [==============================] - 0s - loss: 39941.4940 - val_loss: 56852.4205\n",
      "Epoch 959/1000\n",
      "127/127 [==============================] - 0s - loss: 18145.9693 - val_loss: 66288.6099\n",
      "Epoch 960/1000\n",
      "127/127 [==============================] - 0s - loss: 32328.9674 - val_loss: 78603.2907\n",
      "Epoch 961/1000\n",
      "127/127 [==============================] - 0s - loss: 30666.8513 - val_loss: 58668.1621\n",
      "Epoch 962/1000\n",
      "127/127 [==============================] - 0s - loss: 55044.5776 - val_loss: 65708.2969\n",
      "Epoch 963/1000\n",
      "127/127 [==============================] - 0s - loss: 46740.9978 - val_loss: 64567.7927\n",
      "Epoch 964/1000\n",
      "127/127 [==============================] - 0s - loss: 52206.4589 - val_loss: 67047.0195\n",
      "Epoch 965/1000\n",
      "127/127 [==============================] - 0s - loss: 31617.1949 - val_loss: 53367.6035\n",
      "Epoch 966/1000\n",
      "127/127 [==============================] - 0s - loss: 14411.3795 - val_loss: 69916.9626\n",
      "Epoch 967/1000\n",
      "127/127 [==============================] - 0s - loss: 34684.3082 - val_loss: 71469.5385\n",
      "Epoch 968/1000\n",
      "127/127 [==============================] - 0s - loss: 16878.3478 - val_loss: 68549.9565\n",
      "Epoch 969/1000\n",
      "127/127 [==============================] - 0s - loss: 29479.4732 - val_loss: 68455.5424\n",
      "Epoch 970/1000\n",
      "127/127 [==============================] - 0s - loss: 25038.7497 - val_loss: 60371.3736\n",
      "Epoch 971/1000\n",
      "127/127 [==============================] - 0s - loss: 17706.4090 - val_loss: 50951.5017\n",
      "Epoch 972/1000\n",
      "127/127 [==============================] - 0s - loss: 19790.3636 - val_loss: 73535.4135\n",
      "Epoch 973/1000\n",
      "127/127 [==============================] - 0s - loss: 22063.3857 - val_loss: 53601.0499\n",
      "Epoch 974/1000\n",
      "127/127 [==============================] - 0s - loss: 25754.5926 - val_loss: 111877.1897\n",
      "Epoch 975/1000\n",
      "127/127 [==============================] - 0s - loss: 22003.1189 - val_loss: 64839.3926\n",
      "Epoch 976/1000\n",
      "127/127 [==============================] - 0s - loss: 21346.0675 - val_loss: 61003.5671\n",
      "Epoch 977/1000\n",
      "127/127 [==============================] - 0s - loss: 29633.5148 - val_loss: 65944.4113\n",
      "Epoch 978/1000\n",
      "127/127 [==============================] - 0s - loss: 13641.6858 - val_loss: 70025.2773\n",
      "Epoch 979/1000\n",
      "127/127 [==============================] - 0s - loss: 12720.5661 - val_loss: 64444.1657\n",
      "Epoch 980/1000\n",
      "127/127 [==============================] - 0s - loss: 15440.9485 - val_loss: 58772.4023\n",
      "Epoch 981/1000\n",
      "127/127 [==============================] - 0s - loss: 15712.6620 - val_loss: 65468.8521\n",
      "Epoch 982/1000\n",
      "127/127 [==============================] - 0s - loss: 17144.9961 - val_loss: 62376.2896\n",
      "Epoch 983/1000\n",
      "127/127 [==============================] - 0s - loss: 11319.7086 - val_loss: 63315.0402\n",
      "Epoch 984/1000\n",
      "127/127 [==============================] - 0s - loss: 30562.9762 - val_loss: 81843.8983\n",
      "Epoch 985/1000\n",
      "127/127 [==============================] - 0s - loss: 26699.5430 - val_loss: 62098.9983\n",
      "Epoch 986/1000\n",
      "127/127 [==============================] - 0s - loss: 30322.3759 - val_loss: 76474.9503\n",
      "Epoch 987/1000\n",
      "127/127 [==============================] - 0s - loss: 14797.9847 - val_loss: 60724.9563\n",
      "Epoch 988/1000\n",
      "127/127 [==============================] - 0s - loss: 44916.1569 - val_loss: 146985.2042\n",
      "Epoch 989/1000\n",
      "127/127 [==============================] - 0s - loss: 54306.2030 - val_loss: 71341.8368461\n",
      "Epoch 990/1000\n",
      "127/127 [==============================] - 0s - loss: 32347.7077 - val_loss: 53728.24123514\n",
      "Epoch 991/1000\n",
      "127/127 [==============================] - 0s - loss: 46794.1347 - val_loss: 52912.4888\n",
      "Epoch 992/1000\n",
      "127/127 [==============================] - 0s - loss: 37491.3749 - val_loss: 53606.6738\n",
      "Epoch 993/1000\n",
      "127/127 [==============================] - 0s - loss: 21968.4317 - val_loss: 65453.5067178\n",
      "Epoch 994/1000\n",
      "127/127 [==============================] - 0s - loss: 47031.3327 - val_loss: 117389.3320\n",
      "Epoch 995/1000\n",
      "127/127 [==============================] - 0s - loss: 17745.6212 - val_loss: 83042.7913\n",
      "Epoch 996/1000\n",
      "127/127 [==============================] - 0s - loss: 25223.9676 - val_loss: 90478.0837\n",
      "Epoch 997/1000\n",
      "127/127 [==============================] - 0s - loss: 30671.1411 - val_loss: 70335.2620\n",
      "Epoch 998/1000\n",
      "127/127 [==============================] - 0s - loss: 20463.0081 - val_loss: 87452.9453\n",
      "Epoch 999/1000\n",
      "127/127 [==============================] - 0s - loss: 21042.4866 - val_loss: 70799.8940\n",
      "Epoch 1000/1000\n",
      "127/127 [==============================] - 0s - loss: 22215.7212 - val_loss: 67332.1741\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 460.72879028]\n",
      "result len(data): 54\n",
      "result data.shape: (54,)\n",
      "result len(slicing): 29\n",
      "result slicing_shape: (29, 25)\n",
      "[array([3346,   22,   23, 2936,   41,   22, 1929,   36, 1626,   23,   14,\n",
      "       1309,   26,   36,   14,   23,   14,   14,   26, 2933, 2876,   19,\n",
      "         19,   22, 1659])]\n",
      "X_train shape: (28, 24, 1)\n",
      "y_train shape: (28,)\n",
      "X_test shape: (1, 24, 1)\n",
      "y_test shape: (1,)\n",
      "Train on 26 samples, validate on 2 samples\n",
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s - loss: 2903934.5931 - val_loss: 58309.0781\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s - loss: 2688499.4645 - val_loss: 79500.2812\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s - loss: 2748080.6148 - val_loss: 55083.3047\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s - loss: 2790666.4381 - val_loss: 114213.6797\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s - loss: 2607919.4219 - val_loss: 128442.4297\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s - loss: 2664566.4832 - val_loss: 530563.7500\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s - loss: 2404305.3981 - val_loss: 577750.8750\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s - loss: 2618202.0577 - val_loss: 227900.7344\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s - loss: 2444044.0096 - val_loss: 485672.3125\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s - loss: 2570147.1635 - val_loss: 480394.2812\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s - loss: 2225313.2356 - val_loss: 871957.2500\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s - loss: 2199381.5601 - val_loss: 945811.0000\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s - loss: 2134377.4345 - val_loss: 914888.8125\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s - loss: 2402805.7067 - val_loss: 290698.2812\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s - loss: 2389448.0625 - val_loss: 973849.6250\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s - loss: 2503281.9663 - val_loss: 828589.5000\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s - loss: 2156346.5505 - val_loss: 320498.2188\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s - loss: 2453387.8966 - val_loss: 356886.4062\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s - loss: 1921666.4279 - val_loss: 254314.5000\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s - loss: 1977141.3125 - val_loss: 619799.7500\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 2384136.0012 - val_loss: 361969.0312\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s - loss: 1666905.3438 - val_loss: 106768.9531\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s - loss: 1935249.0607 - val_loss: 515927.2500\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s - loss: 1650309.4363 - val_loss: 740263.3750\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s - loss: 1642639.8798 - val_loss: 437660.5938\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s - loss: 1925152.7740 - val_loss: 603255.1875\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s - loss: 2081614.9183 - val_loss: 613028.8750\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s - loss: 2006584.8269 - val_loss: 320437.9375\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s - loss: 1966372.5962 - val_loss: 153289.2656\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s - loss: 1815454.5865 - val_loss: 161097.0938\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s - loss: 2018714.9363 - val_loss: 206965.1250\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s - loss: 1436722.6442 - val_loss: 246829.7188\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s - loss: 1699390.6082 - val_loss: 502851.6250\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s - loss: 1676363.7548 - val_loss: 426496.8125\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s - loss: 1520041.1055 - val_loss: 409755.9375\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s - loss: 1868405.5709 - val_loss: 1058467.7500\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s - loss: 1537853.3966 - val_loss: 1408400.8750\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s - loss: 1736375.2019 - val_loss: 513987.5625\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s - loss: 1356252.9513 - val_loss: 1065401.3750\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s - loss: 1826247.1950 - val_loss: 1256841.7500\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s - loss: 2094784.6923 - val_loss: 622278.8750\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s - loss: 2421386.3543 - val_loss: 187420.4688\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s - loss: 2294913.0697 - val_loss: 686681.6250\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s - loss: 1728099.5787 - val_loss: 1819845.3750\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s - loss: 1904561.7290 - val_loss: 169038.7344\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s - loss: 1583700.6797 - val_loss: 70140.6406\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s - loss: 1963386.8726 - val_loss: 92800.2500\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s - loss: 1547275.3721 - val_loss: 970086.6250\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s - loss: 1660227.4267 - val_loss: 311113.8438\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s - loss: 1830481.5721 - val_loss: 250203.4688\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s - loss: 1586054.3885 - val_loss: 128514.6797\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s - loss: 1324922.0637 - val_loss: 1607193.1250\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s - loss: 1364636.0739 - val_loss: 2329310.0000\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s - loss: 1430449.8678 - val_loss: 1716292.1250\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s - loss: 1550260.3894 - val_loss: 1515674.2500\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s - loss: 1609058.0553 - val_loss: 1701186.8750\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s - loss: 1405613.5709 - val_loss: 1816961.0000\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s - loss: 1192191.3702 - val_loss: 1801362.5000\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s - loss: 1349315.7428 - val_loss: 1476487.2500\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s - loss: 1116274.8678 - val_loss: 1094374.0000\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s - loss: 1431871.6982 - val_loss: 871805.1250\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s - loss: 1976474.7181 - val_loss: 2304792.0000\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s - loss: 1530620.8887 - val_loss: 2315324.2500\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s - loss: 1596352.5739 - val_loss: 2032793.3750\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s - loss: 1085004.1953 - val_loss: 2437879.2500\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s - loss: 982082.0223 - val_loss: 2252819.7500\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s - loss: 1089656.1195 - val_loss: 2313432.5000\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s - loss: 1314538.8044 - val_loss: 2562545.0000\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s - loss: 931002.7697 - val_loss: 1297910.8750\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s - loss: 2314409.8642 - val_loss: 1391603.3750\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s - loss: 993228.3531 - val_loss: 1268643.8750\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s - loss: 1046736.5760 - val_loss: 1920407.2500\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s - loss: 980483.3567 - val_loss: 2122086.2500\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s - loss: 1142523.2692 - val_loss: 442852.9375\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s - loss: 1125265.8999 - val_loss: 1969185.3750\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s - loss: 1288716.1620 - val_loss: 379760.8438\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s - loss: 979327.0616 - val_loss: 2708745.5000\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s - loss: 1154924.5817 - val_loss: 1945679.1250\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s - loss: 1551556.9519 - val_loss: 2995856.5000\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s - loss: 948639.1887 - val_loss: 2604163.7500\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s - loss: 2102354.7266 - val_loss: 2237471.2500\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s - loss: 890273.1189 - val_loss: 1585271.6250\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s - loss: 1200747.1016 - val_loss: 2175863.2500\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s - loss: 1094909.7380 - val_loss: 833721.3125\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s - loss: 957717.5749 - val_loss: 1478184.7500\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s - loss: 939814.4050 - val_loss: 2236270.7500\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s - loss: 1056228.2332 - val_loss: 2534306.0000\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s - loss: 1316892.3840 - val_loss: 2427662.7500\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s - loss: 1069832.4778 - val_loss: 2672156.7500\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s - loss: 1168262.1265 - val_loss: 54030.5156\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s - loss: 901320.2937 - val_loss: 1243474.7500\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s - loss: 976175.8193 - val_loss: 2047293.1250\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s - loss: 1069018.5821 - val_loss: 1826400.2500\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s - loss: 1369770.1605 - val_loss: 3147061.0000\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s - loss: 1230424.6815 - val_loss: 2986450.0000\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s - loss: 936961.1343 - val_loss: 2857545.2500\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s - loss: 1134910.9186 - val_loss: 3228558.7500\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s - loss: 980375.1970 - val_loss: 3136215.5000\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s - loss: 973988.0853 - val_loss: 3274436.0000\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 791402.2668 - val_loss: 3250596.2500\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s - loss: 1055548.0442 - val_loss: 2972237.7500\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s - loss: 1025381.7897 - val_loss: 3016377.0000\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s - loss: 1216611.6289 - val_loss: 2934380.7500\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s - loss: 957527.3123 - val_loss: 2473532.5000\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s - loss: 1051045.1957 - val_loss: 1232462.5000\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s - loss: 1799788.5777 - val_loss: 3147134.2500\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s - loss: 733997.3191 - val_loss: 3206361.2500\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s - loss: 1083979.9922 - val_loss: 2698824.0000\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s - loss: 820779.4857 - val_loss: 2877142.2500\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s - loss: 1086847.4375 - val_loss: 3269564.2500\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s - loss: 1067553.7566 - val_loss: 2997320.2500\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s - loss: 834799.6991 - val_loss: 2322555.7500\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s - loss: 798767.0159 - val_loss: 2732270.5000\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s - loss: 722730.0074 - val_loss: 2901984.7500\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s - loss: 871767.8051 - val_loss: 2874171.7500\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s - loss: 1916993.7021 - val_loss: 2582198.7500\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s - loss: 1608337.5027 - val_loss: 2539710.7500\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s - loss: 1051138.3273 - val_loss: 2641944.0000\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s - loss: 938503.9506 - val_loss: 318723.6562\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s - loss: 915453.4118 - val_loss: 343000.9688\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s - loss: 881651.5504 - val_loss: 1083999.7500\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s - loss: 757272.2949 - val_loss: 1389912.6250\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s - loss: 2147172.9684 - val_loss: 478947.1875\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s - loss: 2237411.8669 - val_loss: 1897375.1250\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s - loss: 959818.5252 - val_loss: 389459.0312\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s - loss: 1252046.5873 - val_loss: 2809013.0000\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s - loss: 894914.9712 - val_loss: 2795632.7500\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s - loss: 991011.3526 - val_loss: 1900102.3750\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s - loss: 935439.5243 - val_loss: 221643.1250\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s - loss: 1481076.7494 - val_loss: 445643.0938\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s - loss: 1526416.6830 - val_loss: 2606171.0000\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s - loss: 831817.3074 - val_loss: 2508402.5000\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s - loss: 942709.1988 - val_loss: 2997209.7500\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s - loss: 776110.5847 - val_loss: 3189218.5000\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s - loss: 582812.0669 - val_loss: 3097697.0000\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s - loss: 1032291.6842 - val_loss: 2652731.7500\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s - loss: 2010266.1218 - val_loss: 2665441.7500\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s - loss: 1144511.1869 - val_loss: 3204468.2500\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s - loss: 797595.9714 - val_loss: 3232759.0000\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s - loss: 1842024.5276 - val_loss: 3386007.5000\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s - loss: 1151286.7596 - val_loss: 3237430.7500\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s - loss: 1093135.5167 - val_loss: 3149408.2500\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s - loss: 1059961.9661 - val_loss: 3013193.7500\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s - loss: 1089664.4336 - val_loss: 2974268.2500\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s - loss: 1246881.1265 - val_loss: 2976320.7500\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s - loss: 1051902.1227 - val_loss: 2883780.2500\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s - loss: 997573.6098 - val_loss: 2974356.7500\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s - loss: 832807.6941 - val_loss: 2957224.0000\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s - loss: 812376.3732 - val_loss: 2874856.7500\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s - loss: 934405.8138 - val_loss: 2931353.0000\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s - loss: 1233794.3407 - val_loss: 2919863.5000\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s - loss: 842006.4251 - val_loss: 2786353.7500\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s - loss: 869204.2579 - val_loss: 3332950.5000\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s - loss: 1020268.2794 - val_loss: 3284280.7500\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s - loss: 666459.8505 - val_loss: 3027423.5000\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s - loss: 864736.5662 - val_loss: 2671956.5000\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s - loss: 638093.5283 - val_loss: 2686748.7500\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s - loss: 740224.1242 - val_loss: 2568712.5000\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s - loss: 790043.1218 - val_loss: 2628383.0000\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s - loss: 766382.0386 - val_loss: 2550290.2500\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s - loss: 903448.9784 - val_loss: 2348374.7500\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s - loss: 863320.3078 - val_loss: 2535152.5000\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s - loss: 961942.7401 - val_loss: 2861954.2500\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s - loss: 646146.2314 - val_loss: 2902038.0000\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s - loss: 1043564.2643 - val_loss: 3194316.5000\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s - loss: 904292.6850 - val_loss: 2680015.2500\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s - loss: 1028429.6272 - val_loss: 3086255.7500\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s - loss: 703884.7385 - val_loss: 3125291.0000\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s - loss: 828357.1948 - val_loss: 3214288.0000\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s - loss: 788116.2861 - val_loss: 3064995.0000\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s - loss: 742282.5775 - val_loss: 3117618.7500\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s - loss: 1171886.5986 - val_loss: 3789079.5000\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s - loss: 692550.7691 - val_loss: 3466739.2500\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s - loss: 696873.9833 - val_loss: 3085778.2500\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s - loss: 706155.3409 - val_loss: 3012732.5000\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s - loss: 1066897.7257 - val_loss: 3197065.5000\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s - loss: 752172.8056 - val_loss: 3672696.5000\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 759546.6098 - val_loss: 3147636.2500\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s - loss: 838360.0732 - val_loss: 3366483.0000\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s - loss: 744781.2429 - val_loss: 3773377.5000\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s - loss: 794174.6400 - val_loss: 3189991.7500\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s - loss: 674799.5648 - val_loss: 3134987.2500\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s - loss: 710185.3017 - val_loss: 3090962.7500\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s - loss: 647955.7843 - val_loss: 2619227.2500\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s - loss: 649206.6561 - val_loss: 2603650.0000\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s - loss: 692233.0613 - val_loss: 2488765.2500\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s - loss: 619089.9070 - val_loss: 1905957.2500\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s - loss: 633306.9884 - val_loss: 3918896.0000\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s - loss: 610243.1526 - val_loss: 4043141.7500\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s - loss: 595888.4818 - val_loss: 3956678.5000\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s - loss: 1041765.2853 - val_loss: 3247741.5000\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s - loss: 783490.9759 - val_loss: 3672510.0000\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s - loss: 674553.1366 - val_loss: 3838077.5000\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s - loss: 904690.7760 - val_loss: 2472291.5000\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s - loss: 976364.8938 - val_loss: 2413975.7500\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s - loss: 845971.1653 - val_loss: 2438105.5000\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s - loss: 661730.5428 - val_loss: 3175800.0000\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s - loss: 646383.3385 - val_loss: 2545814.0000\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s - loss: 756704.5829 - val_loss: 3400147.0000\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s - loss: 702231.2463 - val_loss: 2476184.7500\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s - loss: 581955.7252 - val_loss: 2546413.7500\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s - loss: 700213.4167 - val_loss: 2613845.7500\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s - loss: 704678.4010 - val_loss: 3498070.7500\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s - loss: 713880.9847 - val_loss: 2255154.5000\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s - loss: 572874.7706 - val_loss: 1963572.6250\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s - loss: 738628.2892 - val_loss: 3428457.5000\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s - loss: 733242.4061 - val_loss: 2345223.5000\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s - loss: 722025.1051 - val_loss: 2277471.7500\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s - loss: 695425.3262 - val_loss: 2321244.5000\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s - loss: 817445.7926 - val_loss: 4009119.5000\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s - loss: 711889.9018 - val_loss: 4083210.2500\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s - loss: 848157.5347 - val_loss: 4112488.7500\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s - loss: 856203.2156 - val_loss: 4003833.0000\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s - loss: 555325.1077 - val_loss: 4009577.0000\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s - loss: 805315.5117 - val_loss: 3894410.7500\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s - loss: 642228.6400 - val_loss: 3915315.0000\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s - loss: 610609.4376 - val_loss: 3872174.7500\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s - loss: 701740.9431 - val_loss: 3995427.2500\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s - loss: 602626.7096 - val_loss: 3965064.7500\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s - loss: 563410.7038 - val_loss: 3854427.7500\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s - loss: 713687.1016 - val_loss: 3805494.2500\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s - loss: 723046.0268 - val_loss: 2955791.2500\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s - loss: 695687.1191 - val_loss: 3790273.5000\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s - loss: 956831.1484 - val_loss: 3958911.0000\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s - loss: 819144.6924 - val_loss: 3827430.0000\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s - loss: 922033.3426 - val_loss: 3865459.2500\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s - loss: 1039839.3894 - val_loss: 2302834.2500\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s - loss: 659592.2882 - val_loss: 2233140.7500\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s - loss: 683801.0593 - val_loss: 2251508.7500\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s - loss: 717661.7087 - val_loss: 2165141.5000\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s - loss: 712654.5444 - val_loss: 1991850.5000\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s - loss: 628222.8904 - val_loss: 1911729.1250\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s - loss: 744821.5408 - val_loss: 2498708.0000\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s - loss: 756675.3801 - val_loss: 2333424.5000\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s - loss: 720722.8031 - val_loss: 2750842.5000\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s - loss: 679727.8570 - val_loss: 3934678.0000\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s - loss: 688311.4513 - val_loss: 720416.9375\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s - loss: 687709.8886 - val_loss: 935234.5000\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s - loss: 606585.9933 - val_loss: 1383060.6250\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s - loss: 580253.1108 - val_loss: 3477552.7500\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s - loss: 722098.4232 - val_loss: 3411221.2500\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s - loss: 642474.5742 - val_loss: 3423815.0000\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s - loss: 797169.0223 - val_loss: 1018514.6250\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s - loss: 539818.3388 - val_loss: 585348.7500\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s - loss: 704392.7540 - val_loss: 723002.7500\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s - loss: 689430.7095 - val_loss: 688257.8125\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s - loss: 687978.5811 - val_loss: 521165.9375\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s - loss: 733521.1688 - val_loss: 1046516.0000\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s - loss: 771749.7847 - val_loss: 1518276.7500\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s - loss: 670505.3018 - val_loss: 1151899.0000\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s - loss: 612057.7100 - val_loss: 1682120.7500\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s - loss: 681039.1898 - val_loss: 1537995.2500\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s - loss: 594830.3736 - val_loss: 1919792.5000\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s - loss: 559290.9035 - val_loss: 3967755.5000\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s - loss: 696600.2895 - val_loss: 1133169.7500\n",
      "Epoch 256/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 604827.3989 - val_loss: 1673656.0000\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s - loss: 634972.4094 - val_loss: 1493373.3750\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s - loss: 691644.9241 - val_loss: 1561391.6250\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s - loss: 652584.2383 - val_loss: 1492803.6250\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s - loss: 592359.6095 - val_loss: 1953240.1250\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s - loss: 588050.2249 - val_loss: 1864723.5000\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s - loss: 637644.6224 - val_loss: 2781881.0000\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s - loss: 674616.4732 - val_loss: 2527508.7500\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s - loss: 550424.2797 - val_loss: 2389008.7500\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s - loss: 869984.0139 - val_loss: 2472312.5000\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s - loss: 523055.3654 - val_loss: 2620111.0000\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s - loss: 636004.4519 - val_loss: 2595157.2500\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s - loss: 669103.2489 - val_loss: 1539047.1250\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s - loss: 610602.2322 - val_loss: 2460818.5000\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s - loss: 540695.6983 - val_loss: 2471488.5000\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s - loss: 1884362.0701 - val_loss: 2442106.7500\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s - loss: 1265330.3759 - val_loss: 3210375.7500\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s - loss: 588326.4596 - val_loss: 3217270.5000\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s - loss: 569590.8511 - val_loss: 3201581.5000\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s - loss: 635001.4584 - val_loss: 3250765.0000\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s - loss: 639418.5079 - val_loss: 3230187.7500\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s - loss: 629161.7865 - val_loss: 2810374.7500\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s - loss: 596393.6328 - val_loss: 2904244.2500\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s - loss: 1941122.0522 - val_loss: 2497216.0000\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s - loss: 678663.1167 - val_loss: 2521859.2500\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s - loss: 615268.0282 - val_loss: 2520341.2500\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s - loss: 595946.7692 - val_loss: 2554306.2500\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s - loss: 580817.6082 - val_loss: 2562846.7500\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s - loss: 855396.9519 - val_loss: 2593213.0000\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s - loss: 530947.1004 - val_loss: 2556855.0000\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s - loss: 686248.4123 - val_loss: 2681972.7500\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s - loss: 664710.7225 - val_loss: 2548428.7500\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s - loss: 644932.5652 - val_loss: 2544396.2500\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s - loss: 488020.7144 - val_loss: 2611613.7500\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s - loss: 604748.1618 - val_loss: 2446644.5000\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s - loss: 730699.0282 - val_loss: 2565848.5000\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s - loss: 707319.7848 - val_loss: 2662753.0000\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s - loss: 578575.7450 - val_loss: 2390199.2500\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s - loss: 636146.5601 - val_loss: 3130849.5000\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s - loss: 625126.0492 - val_loss: 3333324.2500\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s - loss: 633313.2345 - val_loss: 3289874.5000\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s - loss: 589179.2623 - val_loss: 3637049.2500\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s - loss: 1094837.1950 - val_loss: 4208756.5000\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s - loss: 655735.5300 - val_loss: 3426970.2500\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s - loss: 679204.8597 - val_loss: 3421754.5000\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s - loss: 683275.1823 - val_loss: 3996758.7500\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s - loss: 597394.6674 - val_loss: 3981885.2500\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s - loss: 656854.7575 - val_loss: 2973635.2500\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s - loss: 571809.0727 - val_loss: 2933859.2500\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s - loss: 697234.4683 - val_loss: 2375010.2500\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s - loss: 655892.7386 - val_loss: 2404967.2500\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s - loss: 577965.7373 - val_loss: 2441304.2500\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s - loss: 597140.2575 - val_loss: 2325895.5000\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s - loss: 622548.6136 - val_loss: 3196222.0000\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s - loss: 688147.2459 - val_loss: 3409360.7500\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s - loss: 571596.6213 - val_loss: 2544206.2500\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s - loss: 681498.7656 - val_loss: 805204.6875\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s - loss: 681616.9021 - val_loss: 826921.1250\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s - loss: 637851.5859 - val_loss: 3999634.2500\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s - loss: 1020496.3186 - val_loss: 2635829.7500\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s - loss: 694845.6173 - val_loss: 1434633.3750\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s - loss: 804946.3957 - val_loss: 1135637.8750\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s - loss: 603299.0793 - val_loss: 961972.0625\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s - loss: 889868.6012 - val_loss: 1276478.1250\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s - loss: 622927.2289 - val_loss: 993259.6250\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s - loss: 664802.2798 - val_loss: 1155734.8750\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s - loss: 561970.2730 - val_loss: 2481318.5000\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s - loss: 759507.6443 - val_loss: 2479676.5000\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s - loss: 721561.3493 - val_loss: 966777.4375\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s - loss: 610097.1269 - val_loss: 945194.9375\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s - loss: 563986.0908 - val_loss: 2290897.2500\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s - loss: 547154.3220 - val_loss: 3669622.5000\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s - loss: 578200.6375 - val_loss: 2710884.2500\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s - loss: 617225.0498 - val_loss: 3541380.7500\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s - loss: 602552.1282 - val_loss: 3232527.5000\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s - loss: 721280.6170 - val_loss: 2333465.2500\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s - loss: 750190.4016 - val_loss: 3238869.5000\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s - loss: 663788.3007 - val_loss: 3299936.0000\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 605566.5303 - val_loss: 2940955.0000\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s - loss: 575157.2932 - val_loss: 3177287.0000\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s - loss: 577591.6444 - val_loss: 1445314.3750\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s - loss: 792062.7402 - val_loss: 1316126.3750\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s - loss: 746597.3957 - val_loss: 887067.0625\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s - loss: 560100.6486 - val_loss: 773858.3125\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s - loss: 587839.3374 - val_loss: 529347.5000\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s - loss: 614536.9554 - val_loss: 733110.3125\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s - loss: 601977.0851 - val_loss: 601602.1250\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s - loss: 571493.5651 - val_loss: 887351.9375\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s - loss: 591099.0642 - val_loss: 2208431.7500\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s - loss: 619208.1893 - val_loss: 150525.9219\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s - loss: 633509.6964 - val_loss: 142177.0000\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s - loss: 617122.1212 - val_loss: 2889127.0000\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s - loss: 504603.3304 - val_loss: 2833088.0000\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s - loss: 619017.6332 - val_loss: 2370340.7500\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s - loss: 612507.1357 - val_loss: 3830651.5000\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s - loss: 814465.4534 - val_loss: 2481141.5000\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s - loss: 566875.8239 - val_loss: 2927559.0000\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s - loss: 555179.2711 - val_loss: 3197977.2500\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s - loss: 621876.3383 - val_loss: 3628488.0000\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s - loss: 584435.0946 - val_loss: 3396770.0000\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s - loss: 637241.2701 - val_loss: 1027128.3125\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s - loss: 590351.6857 - val_loss: 2128770.0000\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s - loss: 667149.4097 - val_loss: 1317472.8750\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s - loss: 570344.7642 - val_loss: 4335349.5000\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s - loss: 645611.8744 - val_loss: 3866623.0000\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s - loss: 617386.4289 - val_loss: 3894263.2500\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s - loss: 653625.5092 - val_loss: 3090722.5000\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s - loss: 567131.7197 - val_loss: 3291067.7500\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s - loss: 529952.0106 - val_loss: 2663547.5000\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s - loss: 564368.6358 - val_loss: 3179700.5000\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s - loss: 558782.1363 - val_loss: 2904516.5000\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s - loss: 603437.6103 - val_loss: 2584549.2500\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s - loss: 570306.1555 - val_loss: 3375950.5000\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s - loss: 521967.4889 - val_loss: 3603054.5000\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s - loss: 596973.1823 - val_loss: 1987348.6250\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s - loss: 791472.5491 - val_loss: 3192546.0000\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s - loss: 585855.5868 - val_loss: 3371823.5000\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s - loss: 497889.0800 - val_loss: 2923929.0000\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s - loss: 688278.8704 - val_loss: 4321858.5000\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s - loss: 470696.9413 - val_loss: 4331332.5000\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s - loss: 556050.4866 - val_loss: 4298721.0000\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s - loss: 601777.3226 - val_loss: 4220262.5000\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s - loss: 588350.8888 - val_loss: 4196825.5000\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s - loss: 739583.3599 - val_loss: 4357332.5000\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s - loss: 526935.9339 - val_loss: 4268322.5000\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s - loss: 546606.1861 - val_loss: 4322653.0000\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s - loss: 490692.2649 - val_loss: 4233191.5000\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s - loss: 529796.5502 - val_loss: 3753255.7500\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s - loss: 666340.3172 - val_loss: 3952791.2500\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s - loss: 517155.0463 - val_loss: 4028535.0000\n",
      "Epoch 386/1000\n",
      "26/26 [==============================] - 0s - loss: 569203.7990 - val_loss: 3790309.0000\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s - loss: 642926.1045 - val_loss: 1900849.1250\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s - loss: 558961.3685 - val_loss: 2921659.0000\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s - loss: 572212.3420 - val_loss: 2978351.5000\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s - loss: 556451.9412 - val_loss: 3283088.2500\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s - loss: 500507.2635 - val_loss: 2848704.7500\n",
      "Epoch 392/1000\n",
      "26/26 [==============================] - 0s - loss: 606317.4859 - val_loss: 2810425.0000\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s - loss: 632935.4033 - val_loss: 2408572.0000\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s - loss: 572200.9231 - val_loss: 2957868.2500\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s - loss: 557768.4279 - val_loss: 2981800.5000\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s - loss: 570546.6924 - val_loss: 2552110.5000\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s - loss: 601278.1429 - val_loss: 3007557.0000\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s - loss: 557454.9813 - val_loss: 3679810.0000\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s - loss: 699715.9348 - val_loss: 3807787.2500\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s - loss: 560561.2164 - val_loss: 2476825.2500\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s - loss: 600382.0044 - val_loss: 2639755.7500\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s - loss: 537649.9506 - val_loss: 3282247.2500\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s - loss: 554690.6581 - val_loss: 3255195.0000\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s - loss: 566672.0543 - val_loss: 3097178.0000\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s - loss: 749771.7193 - val_loss: 3563495.2500\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s - loss: 585107.4974 - val_loss: 3047499.5000\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s - loss: 525214.9761 - val_loss: 3385545.0000\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s - loss: 562135.7352 - val_loss: 3262610.2500\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s - loss: 556473.4115 - val_loss: 2203909.2500\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s - loss: 554034.9602 - val_loss: 2166278.0000\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s - loss: 540008.0657 - val_loss: 2125191.7500\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s - loss: 517239.9405 - val_loss: 1173454.7500\n",
      "Epoch 413/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 564381.0043 - val_loss: 1364492.8750\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s - loss: 568946.2352 - val_loss: 2434975.7500\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s - loss: 522100.2852 - val_loss: 975847.8125\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s - loss: 560560.4055 - val_loss: 3529160.7500\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s - loss: 608810.5059 - val_loss: 4060862.5000\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s - loss: 643863.2746 - val_loss: 4289834.5000\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s - loss: 606182.4236 - val_loss: 4336395.0000\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s - loss: 451835.0080 - val_loss: 4200987.0000\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s - loss: 569815.5509 - val_loss: 4391938.0000\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s - loss: 576086.4975 - val_loss: 4391120.0000\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s - loss: 563934.7217 - val_loss: 2702088.2500\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s - loss: 511807.3173 - val_loss: 4226435.5000\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s - loss: 626063.7709 - val_loss: 4352114.5000\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s - loss: 586654.0401 - val_loss: 1915450.8750\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s - loss: 590290.4125 - val_loss: 920727.1875\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s - loss: 585242.1157 - val_loss: 2656986.7500\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s - loss: 545858.4062 - val_loss: 2670419.7500\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s - loss: 553107.7364 - val_loss: 2944798.5000\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s - loss: 576400.5827 - val_loss: 4337174.5000\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s - loss: 733660.5363 - val_loss: 4369847.0000\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s - loss: 582713.5347 - val_loss: 4182390.2500\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s - loss: 560131.1045 - val_loss: 3675275.5000\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s - loss: 530320.5571 - val_loss: 3362749.2500\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s - loss: 533252.2892 - val_loss: 3154154.5000\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s - loss: 544109.9543 - val_loss: 1904599.6250\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s - loss: 616755.6145 - val_loss: 4006835.0000\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s - loss: 767570.5915 - val_loss: 2404903.2500\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s - loss: 491605.0430 - val_loss: 2711861.7500\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s - loss: 598916.3661 - val_loss: 3022599.7500\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s - loss: 569752.2195 - val_loss: 2922133.2500\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s - loss: 614084.4781 - val_loss: 2822352.7500\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s - loss: 493426.9955 - val_loss: 3035315.5000\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s - loss: 577586.3706 - val_loss: 3421049.2500\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s - loss: 494922.2416 - val_loss: 3024822.7500\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s - loss: 458958.7562 - val_loss: 3113291.2500\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s - loss: 540236.2961 - val_loss: 2958638.5000\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s - loss: 620275.2668 - val_loss: 4101063.7500\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s - loss: 678015.4567 - val_loss: 1920427.8750\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s - loss: 495010.1823 - val_loss: 2167450.7500\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s - loss: 675558.1436 - val_loss: 2094612.7500\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s - loss: 595436.0188 - val_loss: 1734802.6250\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s - loss: 548564.5392 - val_loss: 1823047.0000\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s - loss: 570972.7374 - val_loss: 3925303.0000\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s - loss: 867646.7375 - val_loss: 4289926.5000\n",
      "Epoch 457/1000\n",
      "26/26 [==============================] - 0s - loss: 559271.9951 - val_loss: 886447.8750\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s - loss: 570501.8133 - val_loss: 2044.1816\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s - loss: 626337.3082 - val_loss: 2549.6792\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s - loss: 629962.3549 - val_loss: 512990.0000\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s - loss: 591271.3323 - val_loss: 2526456.0000\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s - loss: 532860.3180 - val_loss: 755437.0000\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s - loss: 565609.4669 - val_loss: 1565359.2500\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s - loss: 644642.8210 - val_loss: 1394168.0000\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s - loss: 710677.3973 - val_loss: 3125014.2500\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s - loss: 539796.8602 - val_loss: 1711392.3750\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s - loss: 556777.1562 - val_loss: 846946.3125\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s - loss: 586072.0290 - val_loss: 890693.8125\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s - loss: 605416.0744 - val_loss: 1072160.6250\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s - loss: 529759.4600 - val_loss: 1397372.2500\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s - loss: 522893.8361 - val_loss: 842471.0000\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s - loss: 631470.9874 - val_loss: 1945990.8750\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s - loss: 685525.0291 - val_loss: 1360847.6250\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s - loss: 556933.4373 - val_loss: 1391921.6250\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s - loss: 599165.9665 - val_loss: 1287391.7500\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s - loss: 545133.4370 - val_loss: 1477757.2500\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s - loss: 569270.2750 - val_loss: 3970458.7500\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s - loss: 610301.6346 - val_loss: 3783374.2500\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s - loss: 557073.7381 - val_loss: 2445453.5000\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s - loss: 525784.5161 - val_loss: 2255903.5000\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s - loss: 486455.7883 - val_loss: 786698.6250\n",
      "Epoch 482/1000\n",
      "26/26 [==============================] - 0s - loss: 440309.7206 - val_loss: 797526.6875\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s - loss: 616584.1067 - val_loss: 226220.5469\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s - loss: 589142.4909 - val_loss: 707561.6250\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s - loss: 571823.3042 - val_loss: 1173652.7500\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s - loss: 620747.6965 - val_loss: 2846757.0000\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s - loss: 572545.9926 - val_loss: 2561300.7500\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s - loss: 772025.7699 - val_loss: 175103.7656\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s - loss: 622487.9953 - val_loss: 239714.3438\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s - loss: 563194.6084 - val_loss: 388123.8125\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s - loss: 603595.2203 - val_loss: 873161.6875\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 546143.2338 - val_loss: 2614818.5000\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s - loss: 567704.4035 - val_loss: 2682247.2500\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s - loss: 587393.3144 - val_loss: 323988.1562\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s - loss: 674505.2012 - val_loss: 529250.0000\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s - loss: 510016.8527 - val_loss: 1072145.7500\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s - loss: 613338.7199 - val_loss: 1073904.2500\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s - loss: 534085.5892 - val_loss: 1054989.0000\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s - loss: 472311.0995 - val_loss: 1020820.3125\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s - loss: 608391.5664 - val_loss: 1134573.8750\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s - loss: 589384.5252 - val_loss: 1123046.2500\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s - loss: 575768.0081 - val_loss: 1000709.4375\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s - loss: 568786.5658 - val_loss: 1088847.1250\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s - loss: 591234.5179 - val_loss: 2263471.7500\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s - loss: 753200.5880 - val_loss: 21837.4805\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s - loss: 928841.6184 - val_loss: 1390748.7500\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s - loss: 461016.7925 - val_loss: 1267767.1250\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s - loss: 540080.8294 - val_loss: 1222428.3750\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s - loss: 515072.0309 - val_loss: 1187026.7500\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s - loss: 747650.8605 - val_loss: 651970.5000\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s - loss: 592404.2992 - val_loss: 2391269.5000\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s - loss: 567738.1208 - val_loss: 1487671.8750\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s - loss: 607294.7031 - val_loss: 2658984.7500\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s - loss: 585033.2991 - val_loss: 2199456.7500\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s - loss: 651955.5871 - val_loss: 2442978.7500\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s - loss: 574180.8676 - val_loss: 1771053.6250\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s - loss: 550533.7561 - val_loss: 1211222.6250\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s - loss: 489896.7711 - val_loss: 586981.2500\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s - loss: 537223.9790 - val_loss: 1822639.1250\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s - loss: 526855.8681 - val_loss: 1139132.7500\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s - loss: 590380.5521 - val_loss: 1697314.3750\n",
      "Epoch 522/1000\n",
      "26/26 [==============================] - 0s - loss: 498805.5622 - val_loss: 1053138.6250\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s - loss: 807471.7151 - val_loss: 366568.6250\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s - loss: 632111.3779 - val_loss: 338372.7812\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s - loss: 570033.7610 - val_loss: 425576.9062\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s - loss: 581984.1910 - val_loss: 600227.9375\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s - loss: 594050.8899 - val_loss: 473299.8125\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s - loss: 539862.6291 - val_loss: 180189.4531\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s - loss: 603503.2258 - val_loss: 260.8870\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s - loss: 692831.5199 - val_loss: 1141.4270\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s - loss: 886735.4417 - val_loss: 426.8759\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s - loss: 905449.4011 - val_loss: 1381.7523\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s - loss: 613547.8427 - val_loss: 318.5943\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s - loss: 581128.6500 - val_loss: 275.0366\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s - loss: 578929.7588 - val_loss: 1194.3572\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s - loss: 863210.0302 - val_loss: 4238.1719\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s - loss: 556111.8725 - val_loss: 2598.8560\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s - loss: 566291.8360 - val_loss: 1988053.0000\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s - loss: 589961.8342 - val_loss: 714280.6250\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s - loss: 574722.5836 - val_loss: 577327.8125\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s - loss: 507584.5706 - val_loss: 674766.3750\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s - loss: 647527.0871 - val_loss: 808567.0625\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s - loss: 585711.2097 - val_loss: 407238.5625\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s - loss: 542757.7698 - val_loss: 816738.1250\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s - loss: 605495.4389 - val_loss: 855649.6875\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s - loss: 1031059.4678 - val_loss: 1029188.6875\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s - loss: 528113.8603 - val_loss: 1011017.6250\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s - loss: 585102.3897 - val_loss: 666766.7500\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s - loss: 615232.6042 - val_loss: 935576.1250\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s - loss: 686358.4437 - val_loss: 873742.1250\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s - loss: 557094.7115 - val_loss: 825949.0000\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s - loss: 542619.8433 - val_loss: 934583.9375\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s - loss: 580029.8186 - val_loss: 1183277.1250\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s - loss: 533574.9865 - val_loss: 1101190.1250\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s - loss: 592442.8117 - val_loss: 876711.1250\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s - loss: 619181.7305 - val_loss: 932265.1875\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s - loss: 571660.9846 - val_loss: 805336.2500\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s - loss: 561985.8900 - val_loss: 774939.0625\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s - loss: 510013.3749 - val_loss: 741550.6250\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s - loss: 569321.0744 - val_loss: 453795.0938\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s - loss: 456705.1520 - val_loss: 441236.8438\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s - loss: 553706.0582 - val_loss: 467534.5312\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s - loss: 648273.7249 - val_loss: 528986.6250\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s - loss: 527275.6521 - val_loss: 713158.1875\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s - loss: 538883.2318 - val_loss: 897065.1250\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s - loss: 542723.4145 - val_loss: 814096.7500\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s - loss: 1520451.0808 - val_loss: 770843.6875\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s - loss: 626751.5559 - val_loss: 805519.3125\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s - loss: 509122.7856 - val_loss: 805315.6250\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s - loss: 919834.8579 - val_loss: 787831.7500\n",
      "Epoch 571/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 451196.8836 - val_loss: 801903.9375\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s - loss: 599894.6879 - val_loss: 796269.1250\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s - loss: 594552.5422 - val_loss: 785990.7500\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s - loss: 621112.6330 - val_loss: 742017.8750\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s - loss: 648494.4737 - val_loss: 694538.6250\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s - loss: 527493.6323 - val_loss: 684288.1250\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s - loss: 506089.0683 - val_loss: 661060.4375\n",
      "Epoch 578/1000\n",
      "26/26 [==============================] - 0s - loss: 504525.6284 - val_loss: 661332.0625\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s - loss: 549469.1796 - val_loss: 693974.5000\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s - loss: 572636.4979 - val_loss: 737598.3125\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s - loss: 1856462.8756 - val_loss: 835128.6875\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s - loss: 617756.8302 - val_loss: 815874.4375\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s - loss: 525550.1442 - val_loss: 784074.8125\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s - loss: 646304.5918 - val_loss: 43634.9531\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s - loss: 874593.1685 - val_loss: 931761.3750\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s - loss: 1254356.6118 - val_loss: 1151128.3750\n",
      "Epoch 587/1000\n",
      "26/26 [==============================] - 0s - loss: 479047.7145 - val_loss: 880365.0000\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s - loss: 569272.4988 - val_loss: 847895.2500\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s - loss: 523566.7240 - val_loss: 940380.1250\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s - loss: 505059.8083 - val_loss: 949197.3125\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s - loss: 485772.6655 - val_loss: 913639.0625\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s - loss: 614011.0712 - val_loss: 1960032.5000\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s - loss: 605002.2819 - val_loss: 3216249.0000\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s - loss: 600410.3009 - val_loss: 3053086.2500\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s - loss: 588706.0458 - val_loss: 2390802.0000\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s - loss: 599475.9335 - val_loss: 1086498.0000\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s - loss: 622093.5646 - val_loss: 3878395.7500\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s - loss: 595482.2701 - val_loss: 867487.1250\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s - loss: 493333.6363 - val_loss: 2930053.7500\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s - loss: 503922.3314 - val_loss: 752528.3750\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s - loss: 572331.8805 - val_loss: 21.2091\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s - loss: 554974.9416 - val_loss: 1250.5181\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s - loss: 1959706.7412 - val_loss: 220.8918\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s - loss: 1545952.1238 - val_loss: 1398.3344\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s - loss: 1629702.5024 - val_loss: 2673.7075\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s - loss: 3012161.2717 - val_loss: 10345.3242\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s - loss: 1728311.0343 - val_loss: 9642.7041\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s - loss: 1634495.4748 - val_loss: 8333.6465\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s - loss: 1337227.7776 - val_loss: 8272.0410\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s - loss: 1277343.3918 - val_loss: 10036.2617\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s - loss: 1808961.4751 - val_loss: 10330.2461\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s - loss: 1512829.5332 - val_loss: 12354.7949\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s - loss: 927718.5434 - val_loss: 10402.6611\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s - loss: 1563192.3304 - val_loss: 8982.4209\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s - loss: 1391150.6014 - val_loss: 5584.6475\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s - loss: 2343382.7235 - val_loss: 20888.7773\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s - loss: 1484839.9411 - val_loss: 25726.0352\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s - loss: 1455512.9423 - val_loss: 28971.9922\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s - loss: 1464735.6938 - val_loss: 37893.3828\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s - loss: 1579024.1559 - val_loss: 42144.4023\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s - loss: 1348551.4736 - val_loss: 53252.0898\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s - loss: 1332360.0481 - val_loss: 25837.0664\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s - loss: 1212650.8555 - val_loss: 2776870.5000\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s - loss: 630541.4032 - val_loss: 2553117.7500\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s - loss: 671755.3131 - val_loss: 3056594.5000\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s - loss: 795225.1641 - val_loss: 2436754.0000\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s - loss: 1062851.5793 - val_loss: 4451226.5000\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s - loss: 814475.9928 - val_loss: 4370473.0000\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s - loss: 688082.0628 - val_loss: 3776555.0000\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s - loss: 673098.0580 - val_loss: 3813970.2500\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s - loss: 744771.3865 - val_loss: 2355932.2500\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s - loss: 531541.5581 - val_loss: 2173361.2500\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s - loss: 640945.5791 - val_loss: 1963618.0000\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s - loss: 677545.3469 - val_loss: 1631673.8750\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s - loss: 652021.2013 - val_loss: 1468857.2500\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s - loss: 571425.9811 - val_loss: 1907755.3750\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s - loss: 663098.7343 - val_loss: 1833183.7500\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s - loss: 583202.8293 - val_loss: 2053857.7500\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s - loss: 583264.6828 - val_loss: 1404287.6250\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s - loss: 581893.7127 - val_loss: 996086.9375\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s - loss: 583999.2920 - val_loss: 219852.7344\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s - loss: 528991.3253 - val_loss: 774150.6250\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s - loss: 518762.2873 - val_loss: 994375.1875\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s - loss: 580108.2616 - val_loss: 26239.7168\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s - loss: 513069.7584 - val_loss: 1301195.0000\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s - loss: 609774.3535 - val_loss: 8439.6914\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s - loss: 547086.0849 - val_loss: 261937.4531\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s - loss: 633533.1442 - val_loss: 762262.2500\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s - loss: 624574.3066 - val_loss: 1074357.8750\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 526092.6715 - val_loss: 4368837.5000\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s - loss: 551192.9356 - val_loss: 4280727.0000\n",
      "Epoch 652/1000\n",
      "26/26 [==============================] - 0s - loss: 714383.8303 - val_loss: 4106687.2500\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s - loss: 595237.1333 - val_loss: 4016185.5000\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s - loss: 560814.1416 - val_loss: 4441895.5000\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s - loss: 606056.9770 - val_loss: 4300028.0000\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s - loss: 576356.8177 - val_loss: 1613539.6250\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s - loss: 722050.5819 - val_loss: 3442042.7500\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s - loss: 526494.0660 - val_loss: 3780786.7500\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s - loss: 621755.1553 - val_loss: 3663740.2500\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s - loss: 558860.7770 - val_loss: 4200297.5000\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s - loss: 534191.1122 - val_loss: 4265910.5000\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s - loss: 653744.9652 - val_loss: 2932063.7500\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s - loss: 626222.3948 - val_loss: 1021211.7500\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s - loss: 583023.1072 - val_loss: 2516961.5000\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s - loss: 580157.5488 - val_loss: 2546295.5000\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s - loss: 504562.4682 - val_loss: 3624255.5000\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s - loss: 792364.0229 - val_loss: 4296881.5000\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s - loss: 566265.5036 - val_loss: 4310022.5000\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s - loss: 603107.1632 - val_loss: 4233810.5000\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s - loss: 520927.5906 - val_loss: 4342244.5000\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s - loss: 513739.6057 - val_loss: 4398500.0000\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s - loss: 663459.8364 - val_loss: 4373838.0000\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s - loss: 495312.8245 - val_loss: 3545837.0000\n",
      "Epoch 674/1000\n",
      "26/26 [==============================] - 0s - loss: 526757.4897 - val_loss: 4356072.0000\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s - loss: 532510.3935 - val_loss: 1936636.7500\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s - loss: 554863.9144 - val_loss: 1730019.6250\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s - loss: 649582.1184 - val_loss: 4437785.0000\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s - loss: 651545.9722 - val_loss: 4386748.5000\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s - loss: 554844.4352 - val_loss: 4403532.5000\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s - loss: 545183.6156 - val_loss: 1043736.3750\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s - loss: 666318.2722 - val_loss: 2336661.5000\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s - loss: 639687.6093 - val_loss: 1870.1321\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s - loss: 574542.5000 - val_loss: 3824471.0000\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s - loss: 546011.7325 - val_loss: 4030026.0000\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s - loss: 508853.2723 - val_loss: 4396455.0000\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s - loss: 509055.6517 - val_loss: 3855230.0000\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s - loss: 538184.5680 - val_loss: 3857161.7500\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s - loss: 597309.5571 - val_loss: 4133589.5000\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s - loss: 546144.7802 - val_loss: 4178467.5000\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s - loss: 474275.6570 - val_loss: 4318965.0000\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s - loss: 554184.0855 - val_loss: 4224376.5000\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s - loss: 576489.3374 - val_loss: 4399813.0000\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s - loss: 491633.0406 - val_loss: 4388274.5000\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s - loss: 465691.8431 - val_loss: 4375489.0000\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s - loss: 528173.2640 - val_loss: 3825867.5000\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s - loss: 457986.6705 - val_loss: 3345185.5000\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s - loss: 601252.5043 - val_loss: 4041595.2500\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s - loss: 592242.4661 - val_loss: 4134274.2500\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s - loss: 600120.9318 - val_loss: 553945.9375\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s - loss: 489108.6253 - val_loss: 3911486.5000\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s - loss: 571835.8101 - val_loss: 4401771.5000\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s - loss: 589377.9856 - val_loss: 2328677.5000\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s - loss: 697193.0698 - val_loss: 3538858.7500\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s - loss: 604354.1188 - val_loss: 2806504.7500\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s - loss: 502984.5995 - val_loss: 3499381.7500\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s - loss: 483827.4555 - val_loss: 4230679.5000\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s - loss: 568540.8604 - val_loss: 4251154.5000\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s - loss: 503091.4362 - val_loss: 4249786.0000\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s - loss: 631707.6131 - val_loss: 3503188.0000\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s - loss: 494518.2260 - val_loss: 4338727.5000\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s - loss: 601026.6639 - val_loss: 1137961.3750\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s - loss: 509241.1354 - val_loss: 1012085.7500\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s - loss: 587686.7320 - val_loss: 442415.1875\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s - loss: 766139.4598 - val_loss: 4284916.5000\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s - loss: 471140.4451 - val_loss: 4433280.0000\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s - loss: 511557.8896 - val_loss: 4443819.5000\n",
      "Epoch 717/1000\n",
      "26/26 [==============================] - 0s - loss: 1390651.3149 - val_loss: 4465208.5000\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s - loss: 507805.5227 - val_loss: 4463752.5000\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s - loss: 540311.8058 - val_loss: 4263125.5000\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s - loss: 491375.9563 - val_loss: 4236731.0000\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s - loss: 502419.5734 - val_loss: 4291244.5000\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s - loss: 578297.9132 - val_loss: 1032856.0000\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s - loss: 462259.0111 - val_loss: 1240947.0000\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s - loss: 615956.0036 - val_loss: 651340.1875\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s - loss: 540488.2235 - val_loss: 1305621.6250\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s - loss: 571137.6718 - val_loss: 714323.5625\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s - loss: 528705.4210 - val_loss: 447077.5938\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 556124.9562 - val_loss: 2012536.8750\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s - loss: 520665.9527 - val_loss: 112145.0859\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s - loss: 495595.2377 - val_loss: 34201.7812\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s - loss: 547711.2956 - val_loss: 2900810.5000\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s - loss: 600943.8817 - val_loss: 4385162.0000\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s - loss: 492401.7260 - val_loss: 4391813.0000\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s - loss: 552904.3707 - val_loss: 4197642.0000\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s - loss: 472826.3050 - val_loss: 4192894.5000\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s - loss: 587307.9275 - val_loss: 3700775.5000\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s - loss: 529923.9474 - val_loss: 3801067.0000\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s - loss: 550416.3969 - val_loss: 3698125.5000\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s - loss: 553253.1641 - val_loss: 2552918.2500\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s - loss: 555036.2534 - val_loss: 741304.4375\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s - loss: 609325.9177 - val_loss: 643395.8125\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s - loss: 601906.0950 - val_loss: 601569.0000\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s - loss: 685568.1977 - val_loss: 1025525.6875\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s - loss: 525862.3400 - val_loss: 964270.4375\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s - loss: 570674.8864 - val_loss: 890434.2500\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s - loss: 536648.7518 - val_loss: 1046857.2500\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s - loss: 615574.6977 - val_loss: 1254767.3750\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s - loss: 851348.2127 - val_loss: 4053617.0000\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s - loss: 580110.3134 - val_loss: 4056514.5000\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s - loss: 565202.2098 - val_loss: 3582522.5000\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s - loss: 528740.6238 - val_loss: 4109603.5000\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s - loss: 530918.7112 - val_loss: 4319684.0000\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s - loss: 546374.7228 - val_loss: 4293312.0000\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s - loss: 547524.3196 - val_loss: 4024116.2500\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s - loss: 513165.4683 - val_loss: 3959953.0000\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s - loss: 512034.1026 - val_loss: 3851174.2500\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s - loss: 533380.4767 - val_loss: 4165878.0000\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s - loss: 517872.8473 - val_loss: 4192180.2500\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s - loss: 574790.9908 - val_loss: 2827708.2500\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s - loss: 558512.6903 - val_loss: 3096869.0000\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s - loss: 471779.7714 - val_loss: 3016974.5000\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s - loss: 631102.5319 - val_loss: 3234420.5000\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s - loss: 700825.7376 - val_loss: 3749541.7500\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s - loss: 511765.4507 - val_loss: 3717823.7500\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s - loss: 594969.1283 - val_loss: 3465971.7500\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s - loss: 553738.0814 - val_loss: 3164533.2500\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s - loss: 667707.9149 - val_loss: 169628.8750\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s - loss: 594090.0241 - val_loss: 766810.6875\n",
      "Epoch 769/1000\n",
      "26/26 [==============================] - 0s - loss: 564583.1613 - val_loss: 849670.5625\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s - loss: 456524.2026 - val_loss: 876981.6250\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s - loss: 559515.5472 - val_loss: 966108.0625\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s - loss: 564138.7982 - val_loss: 1388197.3750\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s - loss: 502248.8197 - val_loss: 1680332.1250\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s - loss: 526641.0305 - val_loss: 1876346.6250\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s - loss: 654636.5570 - val_loss: 2653426.5000\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s - loss: 476613.3250 - val_loss: 3912280.5000\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s - loss: 570294.2929 - val_loss: 2878582.5000\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s - loss: 657555.2261 - val_loss: 2947166.7500\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s - loss: 540309.6233 - val_loss: 2463849.5000\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s - loss: 568790.1318 - val_loss: 2310712.5000\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s - loss: 526431.5529 - val_loss: 1908612.7500\n",
      "Epoch 782/1000\n",
      "26/26 [==============================] - 0s - loss: 598772.9211 - val_loss: 3761374.2500\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s - loss: 515290.0202 - val_loss: 4491316.5000\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s - loss: 525526.9271 - val_loss: 4496681.5000\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s - loss: 545886.1088 - val_loss: 4496294.0000\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s - loss: 647677.6325 - val_loss: 4277501.5000\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s - loss: 462416.3997 - val_loss: 4538557.0000\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s - loss: 543571.7720 - val_loss: 4501926.5000\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s - loss: 499659.4053 - val_loss: 4374341.0000\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s - loss: 506875.0791 - val_loss: 4281748.5000\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s - loss: 625193.0820 - val_loss: 1041033.5625\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s - loss: 596454.1820 - val_loss: 1117378.2500\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s - loss: 615051.5511 - val_loss: 804117.1875\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s - loss: 510543.5175 - val_loss: 1306561.7500\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s - loss: 587643.7450 - val_loss: 1211961.7500\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s - loss: 560945.7442 - val_loss: 746993.7500\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s - loss: 477968.9673 - val_loss: 449475.5938\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s - loss: 382442.9564 - val_loss: 16995.5078\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s - loss: 567749.6778 - val_loss: 798720.8125\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s - loss: 599091.4650 - val_loss: 3469141.5000\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s - loss: 603704.8113 - val_loss: 3464596.2500\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s - loss: 747206.1909 - val_loss: 2873702.0000\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s - loss: 522080.0167 - val_loss: 2828530.0000\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s - loss: 653204.1754 - val_loss: 3173372.0000\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s - loss: 539211.5140 - val_loss: 3092811.7500\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s - loss: 549788.1948 - val_loss: 3886804.0000\n",
      "Epoch 807/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 593137.1430 - val_loss: 3956750.2500\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s - loss: 532003.6517 - val_loss: 3900445.7500\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s - loss: 651158.7349 - val_loss: 2142321.2500\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s - loss: 541313.6045 - val_loss: 2372594.5000\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s - loss: 484887.9774 - val_loss: 1864934.7500\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s - loss: 1163806.3055 - val_loss: 3787708.7500\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s - loss: 548551.8729 - val_loss: 3846247.0000\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s - loss: 586493.5454 - val_loss: 3824199.0000\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s - loss: 523615.3333 - val_loss: 3895357.5000\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s - loss: 466375.0732 - val_loss: 3455646.5000\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s - loss: 529360.6947 - val_loss: 3846774.2500\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s - loss: 498757.8270 - val_loss: 3632161.5000\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s - loss: 497792.0678 - val_loss: 3492524.0000\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - 0s - loss: 711240.3303 - val_loss: 3106351.5000\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s - loss: 596335.3155 - val_loss: 2280099.7500\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s - loss: 487882.2901 - val_loss: 2177121.2500\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s - loss: 582952.2940 - val_loss: 2058573.2500\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s - loss: 686802.3127 - val_loss: 1400767.5000\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s - loss: 563427.2260 - val_loss: 1806115.2500\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s - loss: 588094.4467 - val_loss: 3323686.5000\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s - loss: 503500.3060 - val_loss: 911906.2500\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s - loss: 558429.2899 - val_loss: 1835854.1250\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s - loss: 476986.0433 - val_loss: 3760783.7500\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s - loss: 671499.8841 - val_loss: 3059165.2500\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s - loss: 478441.0204 - val_loss: 2273135.5000\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s - loss: 534401.9985 - val_loss: 2266944.2500\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s - loss: 1978895.9367 - val_loss: 753006.0625\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s - loss: 478641.0991 - val_loss: 2870478.0000\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s - loss: 492359.8724 - val_loss: 3138829.2500\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s - loss: 527234.0476 - val_loss: 3154470.0000\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s - loss: 589945.2932 - val_loss: 2021999.6250\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s - loss: 1294143.8970 - val_loss: 3828199.5000\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s - loss: 479682.2124 - val_loss: 3243594.0000\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s - loss: 507942.3027 - val_loss: 1754810.5000\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s - loss: 654780.1792 - val_loss: 10182.6016\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s - loss: 479880.0926 - val_loss: 11092.7510\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - 0s - loss: 490171.0896 - val_loss: 9468.4707\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s - loss: 539857.0094 - val_loss: 10177.4580\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s - loss: 566065.5540 - val_loss: 542084.1875\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s - loss: 503043.2785 - val_loss: 12447.9688\n",
      "Epoch 847/1000\n",
      "26/26 [==============================] - 0s - loss: 499556.6049 - val_loss: 12026.7510\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s - loss: 580834.1277 - val_loss: 1070.3208\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s - loss: 597964.7939 - val_loss: 35787.3320\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s - loss: 458136.9504 - val_loss: 5470.1401\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s - loss: 541950.6174 - val_loss: 2756.9124\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s - loss: 662971.8955 - val_loss: 5554.9697\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s - loss: 495313.1513 - val_loss: 8258.0420\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s - loss: 517923.1058 - val_loss: 37187.3828\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s - loss: 531918.7680 - val_loss: 148.5128\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s - loss: 597048.7538 - val_loss: 160.8929\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s - loss: 566894.1559 - val_loss: 283.0187\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s - loss: 617617.8231 - val_loss: 252.3290\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s - loss: 516502.4587 - val_loss: 22986.3203\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s - loss: 628076.7248 - val_loss: 18022.6953\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s - loss: 530511.7160 - val_loss: 449.4333\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s - loss: 547048.2979 - val_loss: 1014636.1875\n",
      "Epoch 863/1000\n",
      "26/26 [==============================] - 0s - loss: 499625.1771 - val_loss: 1163064.6250\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s - loss: 586057.0700 - val_loss: 1116105.7500\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - 0s - loss: 703589.8145 - val_loss: 2943006.7500\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s - loss: 585013.1346 - val_loss: 2768257.5000\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s - loss: 619214.9064 - val_loss: 2665499.7500\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s - loss: 474902.2947 - val_loss: 2857265.7500\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s - loss: 470598.5319 - val_loss: 1583085.6250\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s - loss: 479917.0587 - val_loss: 2372724.2500\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s - loss: 461568.6656 - val_loss: 2430226.7500\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s - loss: 457539.6641 - val_loss: 2562989.5000\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s - loss: 938399.8487 - val_loss: 2850875.0000\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s - loss: 637494.3679 - val_loss: 2455813.7500\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s - loss: 605658.3834 - val_loss: 2337140.0000\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s - loss: 554269.9872 - val_loss: 2329036.5000\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s - loss: 492851.0979 - val_loss: 2146270.7500\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s - loss: 522926.7411 - val_loss: 1438737.1250\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s - loss: 503357.2993 - val_loss: 3082413.0000\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s - loss: 542426.4763 - val_loss: 3088614.2500\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s - loss: 420877.9278 - val_loss: 3153811.5000\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s - loss: 532437.2469 - val_loss: 1510831.3750\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s - loss: 545693.9620 - val_loss: 1622711.5000\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s - loss: 561136.0434 - val_loss: 2417952.0000\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s - loss: 542304.3362 - val_loss: 1176961.1250\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 575861.8786 - val_loss: 1266155.7500\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s - loss: 487633.2814 - val_loss: 2166990.5000\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s - loss: 608551.2218 - val_loss: 93223.5703\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s - loss: 507695.7385 - val_loss: 19787.0293\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s - loss: 540336.5669 - val_loss: 499.9672\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s - loss: 775327.6898 - val_loss: 16194.9023\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s - loss: 546224.3660 - val_loss: 25421.7773\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s - loss: 494884.4294 - val_loss: 411913.0000\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s - loss: 562019.5714 - val_loss: 22150.0078\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s - loss: 506099.5967 - val_loss: 21824.3008\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s - loss: 621204.9785 - val_loss: 21159.4355\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s - loss: 564510.8426 - val_loss: 10937.4043\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s - loss: 662320.3489 - val_loss: 37925.7188\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s - loss: 521308.3430 - val_loss: 32624.1348\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s - loss: 519465.0541 - val_loss: 133520.7969\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s - loss: 617724.5970 - val_loss: 23775.2578\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s - loss: 487425.4361 - val_loss: 18508.9922\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s - loss: 553599.8871 - val_loss: 16751.1855\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s - loss: 472432.1352 - val_loss: 857890.5000\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s - loss: 549501.3110 - val_loss: 1061867.3750\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s - loss: 634122.4079 - val_loss: 34872.6484\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s - loss: 505188.0015 - val_loss: 30175.4668\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s - loss: 464083.9077 - val_loss: 194364.2969\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s - loss: 538070.9465 - val_loss: 138880.2812\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s - loss: 504130.2399 - val_loss: 420649.7188\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s - loss: 573736.3011 - val_loss: 2622635.5000\n",
      "Epoch 912/1000\n",
      "26/26 [==============================] - 0s - loss: 477197.1355 - val_loss: 2444029.7500\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s - loss: 470725.1001 - val_loss: 2219748.7500\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s - loss: 576855.6695 - val_loss: 1947203.2500\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s - loss: 551852.6391 - val_loss: 2653729.7500\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s - loss: 539334.8300 - val_loss: 3188187.0000\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s - loss: 461504.5628 - val_loss: 3098240.5000\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s - loss: 597940.4589 - val_loss: 2574503.2500\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s - loss: 555319.6033 - val_loss: 2875673.7500\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s - loss: 657127.3128 - val_loss: 1214315.5000\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s - loss: 481990.2188 - val_loss: 1405058.2500\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s - loss: 504242.6998 - val_loss: 1599474.8750\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s - loss: 596235.7098 - val_loss: 1198068.3750\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s - loss: 580361.6852 - val_loss: 1216729.8750\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s - loss: 525157.2026 - val_loss: 984365.5000\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s - loss: 543963.0202 - val_loss: 502093.1875\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s - loss: 566744.6298 - val_loss: 367605.5000\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s - loss: 511528.7240 - val_loss: 1066539.2500\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s - loss: 492705.5826 - val_loss: 555449.4375\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s - loss: 480467.9106 - val_loss: 809641.5000\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s - loss: 1194034.3227 - val_loss: 2091622.8750\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s - loss: 462463.2242 - val_loss: 2065310.6250\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s - loss: 557256.0605 - val_loss: 1821338.7500\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s - loss: 493054.8354 - val_loss: 1756040.8750\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s - loss: 525798.3364 - val_loss: 1490528.0000\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s - loss: 506789.9807 - val_loss: 1433357.7500\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s - loss: 599793.1892 - val_loss: 1299935.3750\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s - loss: 535583.3095 - val_loss: 1004622.0625\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s - loss: 590167.1819 - val_loss: 1186864.8750\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s - loss: 506293.5941 - val_loss: 1190915.6250\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s - loss: 478328.0514 - val_loss: 1398088.2500\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s - loss: 566609.6370 - val_loss: 868028.8125\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s - loss: 551063.0081 - val_loss: 1323809.1250\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s - loss: 511778.0753 - val_loss: 2537576.5000\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s - loss: 643698.6443 - val_loss: 2941.9121\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s - loss: 554793.2469 - val_loss: 2001.9728\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s - loss: 494601.5698 - val_loss: 474.3314\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s - loss: 634921.1889 - val_loss: 2547216.5000\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s - loss: 487648.4722 - val_loss: 2519468.5000\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s - loss: 602294.1879 - val_loss: 2289680.2500\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s - loss: 468026.7989 - val_loss: 2574370.2500\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s - loss: 601499.8385 - val_loss: 2502663.7500\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s - loss: 517500.3558 - val_loss: 1651947.8750\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s - loss: 442788.3918 - val_loss: 1485521.2500\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s - loss: 474703.2793 - val_loss: 2171619.2500\n",
      "Epoch 956/1000\n",
      "26/26 [==============================] - 0s - loss: 558823.6160 - val_loss: 2702033.5000\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s - loss: 506577.1406 - val_loss: 2211148.7500\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s - loss: 528274.9632 - val_loss: 2764885.2500\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s - loss: 599874.0515 - val_loss: 2826292.0000\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s - loss: 549351.0368 - val_loss: 1740903.2500\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s - loss: 461311.5666 - val_loss: 2277976.2500\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s - loss: 882403.0164 - val_loss: 622016.4375\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s - loss: 502876.5023 - val_loss: 336254.6250\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s - loss: 526594.3241 - val_loss: 467778.0625\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s - loss: 556011.2525 - val_loss: 502779.7500\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s - loss: 830248.1514 - val_loss: 955940.9375\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s - loss: 564840.8522 - val_loss: 1051544.7500\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s - loss: 517626.1976 - val_loss: 907877.2500\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s - loss: 484972.2834 - val_loss: 830891.6875\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s - loss: 467967.4477 - val_loss: 870704.0625\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s - loss: 515016.0668 - val_loss: 844076.4375\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s - loss: 470777.0509 - val_loss: 601155.4375\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s - loss: 464219.9449 - val_loss: 807810.7500\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s - loss: 447262.6123 - val_loss: 146626.0000\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s - loss: 560223.8829 - val_loss: 157362.2344\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s - loss: 574869.2124 - val_loss: 638652.2500\n",
      "Epoch 977/1000\n",
      "26/26 [==============================] - 0s - loss: 524405.0853 - val_loss: 1105606.3750\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s - loss: 447269.6012 - val_loss: 371686.2812\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s - loss: 443212.2001 - val_loss: 422984.8750\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s - loss: 488628.1543 - val_loss: 761161.3125\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s - loss: 457919.9164 - val_loss: 755614.6875\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s - loss: 535043.1482 - val_loss: 697661.0625\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s - loss: 605381.2128 - val_loss: 788906.7500\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s - loss: 488942.4491 - val_loss: 536021.0000\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s - loss: 515281.2556 - val_loss: 532745.7500\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s - loss: 465157.1242 - val_loss: 644745.8750\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s - loss: 534860.4597 - val_loss: 734190.8125\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s - loss: 700695.8916 - val_loss: 42680.7852\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s - loss: 743230.2173 - val_loss: 884384.2500\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s - loss: 517356.0306 - val_loss: 884878.5000\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s - loss: 504267.8577 - val_loss: 855747.9375\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s - loss: 552892.0538 - val_loss: 857195.6250\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s - loss: 515622.9926 - val_loss: 940125.7500\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s - loss: 563358.1639 - val_loss: 830658.5000\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s - loss: 558943.6934 - val_loss: 818810.1250\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s - loss: 501461.8352 - val_loss: 847004.2500\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s - loss: 676266.1719 - val_loss: 1108309.3750\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s - loss: 523042.4944 - val_loss: 1090524.1250\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s - loss: 558051.9746 - val_loss: 976614.5625\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s - loss: 436957.4415 - val_loss: 997129.1875\n",
      "predicted shape: (1, 1)\n",
      "point_by_point_predictions shape: (1,)\n",
      "result:  [ 0.86576462]\n"
     ]
    }
   ],
   "source": [
    "'''跑七个模型'''\n",
    "data = [Mon, Tues, Wed, Thur, Fri, Sat, Sun]\n",
    "result = []\n",
    "for index in data:\n",
    "    result.append( run_model(index) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2292.04907227], dtype=float32),\n",
       " array([ 2289.90600586], dtype=float32),\n",
       " array([ 1890.81542969], dtype=float32),\n",
       " array([ 1444.41516113], dtype=float32),\n",
       " array([ 1807.50219727], dtype=float32),\n",
       " array([ 460.72879028], dtype=float32),\n",
       " array([ 0.86576462], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.29200000e+03],\n",
       "       [  2.29000000e+03],\n",
       "       [  1.89100000e+03],\n",
       "       [  1.44400000e+03],\n",
       "       [  1.80800000e+03],\n",
       "       [  4.61000000e+02],\n",
       "       [  1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = result\n",
    "answer = np.around(answer)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2292.04907227], dtype=float32),\n",
       " array([ 2289.90600586], dtype=float32),\n",
       " array([ 1890.81542969], dtype=float32),\n",
       " array([ 1444.41516113], dtype=float32),\n",
       " array([ 1807.50219727], dtype=float32),\n",
       " array([ 460.72879028], dtype=float32),\n",
       " array([ 0.86576462], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('test_A_20171225.txt',dtype='int')\n",
    "test = data[:,1]\n",
    "ID = data[:,0]\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    if(test[i] == 1):\n",
    "        test[i] = answer[0]\n",
    "    if(test[i] == 2):\n",
    "        test[i] = answer[1]\n",
    "    if(test[i] == 3):\n",
    "        test[i] = answer[2]\n",
    "    if(test[i] == 4):\n",
    "        test[i] = answer[3]\n",
    "    if(test[i] == 5):\n",
    "        test[i] = answer[4]\n",
    "    if(test[i] == 6):\n",
    "        test[i] = answer[5]\n",
    "    if(test[i] == 7):\n",
    "        test[i] = round(np.average(Sun))\n",
    "\n",
    "ans = np.vstack( (ID,test) )\n",
    "ans = ans.T\n",
    "# 写入文件\n",
    "np.savetxt('submit/'+'week-average-LSTM_model.txt',ans, fmt='%d', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
